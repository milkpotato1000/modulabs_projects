{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78cafaf-a654-4cab-9628-24b8b46059b4",
   "metadata": {},
   "source": [
    "### **LLM API 활용해보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c74bf5-c0af-423a-ae55-79bf5306e435",
   "metadata": {},
   "source": [
    "**[앤트로픽의 Claude 2.1 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecab962-27cd-4c1f-8879-a5086c0590ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "\n",
    "anthropic.Anthropic(\n",
    "    api_key=\"YOUR_API_KEY\").messages.create(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, world\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb304f-6908-4d04-b464-d09089c4b2bd",
   "metadata": {},
   "source": [
    "**[오픈AI의 GPT-3.5 Turbo 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391b0ea-9636-4d30-b8ff-d76a52b249f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"YOUR_API_KEY\")\n",
    "client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Who won the world series in 2020?\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe2de7-faab-4c54-ad3c-b3a71a94a3cb",
   "metadata": {},
   "source": [
    "**[랭체인을 활용한 앤트로픽 Claude 2.1 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9577c-fc84-4b12-ae0a-ae92b8cea8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic \n",
    "chat = ChatAnthropic(\n",
    "    model_name=\"claude-3-haiku-20240307\",\n",
    "    anthropic_api_key=\"YOUR_API_KEY\"\n",
    ")\n",
    "chat.invoke(\"안녕~ 너를 소개해줄래?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e54ca7-bf12-466a-a953-48be864995ec",
   "metadata": {},
   "source": [
    "**[랭체인을 활용한 오픈AI GPT-3.5 Turbo 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996168c5-989e-4b41-81d5-711b7e49c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-4o-mini',\n",
    "    openai_api_key=\"YOUR_API_KEY\"\n",
    ")\n",
    "chat.invoke(\"안녕~ 너를 소개해줄래?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686342b-2d87-41f7-984d-0ffb2de72aa2",
   "metadata": {},
   "source": [
    "### **프롬프트 템플릿에 대해 알아보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf60921-0b5e-45c8-96e9-3186b0128738",
   "metadata": {},
   "source": [
    "**[ChatPromptTemplate]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f20b43-e6f2-4030-9be5-d02b5166862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "\t#SystemMessage: 유용한 챗봇이라는 역할과 이름을 부여\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"), \n",
    "    #HumanMessage와 AIMessage: 서로 안부를 묻고 답하는 대화 히스토리 주입\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    #HumanMessage로 사용자가 입력한 프롬프트를 전달\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ed911-2667-4c9a-90e4-c8be4e07c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "       \"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(text=\"I don't like eating tasty things\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e227bd0b-17fb-457f-86a5-97d8a83676b3",
   "metadata": {},
   "source": [
    "### **LLM API의 다양한 기능 활용해보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd8ae6-4c55-4700-a466-d0dfbb5371f8",
   "metadata": {},
   "source": [
    "**[LLM API의 Temperature 이애하기]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08240f98-37f0-48ef-ac6d-78e68561c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API KEY 저장을 위한 os 라이브러리 호출\n",
    "import os\n",
    "\n",
    "#OPENAI API키 저장\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "#Temperature=0\n",
    "chatgpt_temp0_1 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)\n",
    "chatgpt_temp0_2 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)\n",
    "\n",
    "#Temperature=1\n",
    "chatgpt_temp1_1 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 1)\n",
    "chatgpt_temp1_2 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 1)\n",
    "\n",
    "model_list = [chatgpt_temp0_1, chatgpt_temp0_2, chatgpt_temp1_1, chatgpt_temp1_2]\n",
    "\n",
    "for i in model_list:\n",
    "    answer = i.invoke(\"왜 파이썬이 가장 인기있는 프로그래밍 언어인지 한 문장으로 설명해줘\", max_tokens = 128)\n",
    "    print(\"-\"*100)\n",
    "    print(\">>>\",answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8bf0d-b183-4407-819d-73555754104e",
   "metadata": {},
   "source": [
    "**[ChatGPT처럼 답변 스트리밍하기]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a6d34-1c73-4b6e-b6f9-0141dec03eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)\n",
    "for chunk in chat.stream(\"달에 관한 시를 써줘\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47973815-82d8-4226-bb03-1f18b4d535f6",
   "metadata": {},
   "source": [
    "**[답변 캐싱하기]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a83d7d-e566-4bb0-8b6f-dc172f29afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache #캐시메모리 라이브러리 호출\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ab26d-d085-4188-b740-bb295dda6a92",
   "metadata": {},
   "source": [
    "**첫 질문-응답 시간 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9b3ab-70cf-47d5-817f-b13dcdbd1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#셀 실행 시간 측정\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache()) #캐시메모리 설정\n",
    "\n",
    "chat.invoke(\"일반상대성 이론을 한마디로 설명해줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1442a-7cb7-44be-87e3-a0d92c86df33",
   "metadata": {},
   "source": [
    "**두번째 질문-응답 시간 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c2ac9-ce6c-4c4b-9147-6c75291c2ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#같은 질문 전달\n",
    "chat.invoke(\"일반상대성 이론을 한마디로 설명해줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d108f-899d-46aa-9a35-1ff6f38c8d8e",
   "metadata": {},
   "source": [
    "### **실습**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c333eb-b5ac-441b-a968-4eb2e2930061",
   "metadata": {},
   "source": [
    "**[이번 장에서 배운 것 실습해보기] - 스트리밍되는 AI스터디 플래너 챗봇 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a26848-d9b2-4520-b0db-61e77d5e9c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#GPT-3.5 모델 호출\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)\n",
    "\n",
    "#ChatPromptTemplate 통해 스터디 플래너 역할 부여 및 사용자 프롬프트 매개변수화\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"당신은 공부 계획을 세워주는 스터디 플래너 머신입니다.\"\n",
    "                \"사용자의 공부 주제를 입력 받으면, 이를 학습하기 위한 공부 계획을 작성합니다.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#앞서 설정한 프롬프트 템플릿에 HumanMessage로 문장 전달\n",
    "messages = chat_template.format_messages(text=\"Large Language Model에 대해서 공부하고 싶어요.\")\n",
    "\n",
    "#stream 함수를 통해 답변 스트리밍\n",
    "for chunk in chat.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f79fe7-c008-41ca-8b82-25bd8a3164e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
