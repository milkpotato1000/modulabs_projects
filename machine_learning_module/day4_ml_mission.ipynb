{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1a2551f-75f8-428f-8407-c0cee043f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b76146-d6c1-4fa5-a787-6210309ef720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/santander_train.csv')\n",
    "test_df = pd.read_csv('./data/santander_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c271fdf-140f-4927-a13d-681b40d2d9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 371)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "2                     0.0                     0.0  67333.77       0  \n",
       "\n",
       "[3 rows x 371 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2deb02f-3ce2-44dd-b78e-43d49ee985c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0b68c3f-a506-4041-8944-7beab0e20741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "0    73012\n",
      "1     3008\n",
      "Name: count, dtype: int64\n",
      "TARGET\n",
      "0    0.960431\n",
      "1    0.039569\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['TARGET'].value_counts())\n",
    "print(train_df['TARGET'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2ad79ad-7d23-461e-a4bd-4e31a3b87a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_counts = train_df['TARGET'].value_counts().sort_index()\n",
    "sns.barplot(x=target_counts.index, y=target_counts.values)\n",
    "\n",
    "legend_labels = ['0 = satisfied', '1 = dissatisfied']\n",
    "\n",
    "plt.legend(labels=legend_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf870560-bf0b-4071-96c2-c97e203a3837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee0bb017-f2a5-4640-91fa-d3228b07a591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var3\n",
       " 2         74165\n",
       " 8           138\n",
       "-999999      116\n",
       " 9           110\n",
       " 3           108\n",
       "           ...  \n",
       " 231           1\n",
       " 188           1\n",
       " 168           1\n",
       " 135           1\n",
       " 87            1\n",
       "Name: count, Length: 208, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df['var3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "39cb999c-411c-4d1b-b7d2-9efa320de89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df['var3'].replace(-999999, 2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "72730d30-828a-4969-9f4d-f9bbe30fec9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var3\n",
       "2      74281\n",
       "8        138\n",
       "9        110\n",
       "3        108\n",
       "1        105\n",
       "       ...  \n",
       "231        1\n",
       "188        1\n",
       "168        1\n",
       "135        1\n",
       "87         1\n",
       "Name: count, Length: 207, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df['var3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "01e8847c-cda3-46e1-9fcc-70400d41a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "de995efb-6c3c-4dc9-af4f-29e5da14b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cust_df.iloc[:, :-1]\n",
    "y = cust_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bcae9495-9edb-4e58-b308-3f40fa1e5440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 (60816, 370), 테스트 세트 (15204, 370)\n",
      "TARGET\n",
      "0    0.96052\n",
      "1    0.03948\n",
      "Name: count, dtype: float64\n",
      "TARGET\n",
      "0    0.960076\n",
      "1    0.039924\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "\n",
    "print(f'학습 세트 {X_train.shape}, 테스트 세트 {X_test.shape}')\n",
    "\n",
    "print(y_train.value_counts()/len(y_train))\n",
    "\n",
    "print(y_test.value_counts()/len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "54005538-fcd9-4db4-9a52-f2faec70d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b6ddb4a-05dc-4b1a-82f8-b2e82db0c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0ab7a90-a345-4e44-a52f-65b336631c98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.84505\tvalidation_1-auc:0.81653\n",
      "[1]\tvalidation_0-auc:0.84754\tvalidation_1-auc:0.81963\n",
      "[2]\tvalidation_0-auc:0.85211\tvalidation_1-auc:0.82161\n",
      "[3]\tvalidation_0-auc:0.85425\tvalidation_1-auc:0.82364\n",
      "[4]\tvalidation_0-auc:0.85555\tvalidation_1-auc:0.82423\n",
      "[5]\tvalidation_0-auc:0.85818\tvalidation_1-auc:0.82601\n",
      "[6]\tvalidation_0-auc:0.85886\tvalidation_1-auc:0.82559\n",
      "[7]\tvalidation_0-auc:0.85973\tvalidation_1-auc:0.82567\n",
      "[8]\tvalidation_0-auc:0.86124\tvalidation_1-auc:0.82643\n",
      "[9]\tvalidation_0-auc:0.86330\tvalidation_1-auc:0.82809\n",
      "[10]\tvalidation_0-auc:0.86479\tvalidation_1-auc:0.82925\n",
      "[11]\tvalidation_0-auc:0.86582\tvalidation_1-auc:0.82905\n",
      "[12]\tvalidation_0-auc:0.86674\tvalidation_1-auc:0.82945\n",
      "[13]\tvalidation_0-auc:0.86774\tvalidation_1-auc:0.82990\n",
      "[14]\tvalidation_0-auc:0.86852\tvalidation_1-auc:0.82988\n",
      "[15]\tvalidation_0-auc:0.86897\tvalidation_1-auc:0.83041\n",
      "[16]\tvalidation_0-auc:0.86978\tvalidation_1-auc:0.83090\n",
      "[17]\tvalidation_0-auc:0.87075\tvalidation_1-auc:0.83167\n",
      "[18]\tvalidation_0-auc:0.87142\tvalidation_1-auc:0.83184\n",
      "[19]\tvalidation_0-auc:0.87230\tvalidation_1-auc:0.83248\n",
      "[20]\tvalidation_0-auc:0.87343\tvalidation_1-auc:0.83272\n",
      "[21]\tvalidation_0-auc:0.87395\tvalidation_1-auc:0.83279\n",
      "[22]\tvalidation_0-auc:0.87483\tvalidation_1-auc:0.83239\n",
      "[23]\tvalidation_0-auc:0.87541\tvalidation_1-auc:0.83234\n",
      "[24]\tvalidation_0-auc:0.87571\tvalidation_1-auc:0.83221\n",
      "[25]\tvalidation_0-auc:0.87612\tvalidation_1-auc:0.83211\n",
      "[26]\tvalidation_0-auc:0.87674\tvalidation_1-auc:0.83214\n",
      "[27]\tvalidation_0-auc:0.87729\tvalidation_1-auc:0.83201\n",
      "[28]\tvalidation_0-auc:0.87805\tvalidation_1-auc:0.83276\n",
      "[29]\tvalidation_0-auc:0.87861\tvalidation_1-auc:0.83326\n",
      "[30]\tvalidation_0-auc:0.87975\tvalidation_1-auc:0.83321\n",
      "[31]\tvalidation_0-auc:0.88046\tvalidation_1-auc:0.83302\n",
      "[32]\tvalidation_0-auc:0.88128\tvalidation_1-auc:0.83264\n",
      "[33]\tvalidation_0-auc:0.88195\tvalidation_1-auc:0.83270\n",
      "[34]\tvalidation_0-auc:0.88269\tvalidation_1-auc:0.83283\n",
      "[35]\tvalidation_0-auc:0.88327\tvalidation_1-auc:0.83279\n",
      "[36]\tvalidation_0-auc:0.88383\tvalidation_1-auc:0.83269\n",
      "[37]\tvalidation_0-auc:0.88447\tvalidation_1-auc:0.83229\n",
      "[38]\tvalidation_0-auc:0.88492\tvalidation_1-auc:0.83241\n",
      "[39]\tvalidation_0-auc:0.88540\tvalidation_1-auc:0.83238\n",
      "[40]\tvalidation_0-auc:0.88598\tvalidation_1-auc:0.83225\n",
      "[41]\tvalidation_0-auc:0.88645\tvalidation_1-auc:0.83220\n",
      "[42]\tvalidation_0-auc:0.88679\tvalidation_1-auc:0.83230\n",
      "[43]\tvalidation_0-auc:0.88718\tvalidation_1-auc:0.83245\n",
      "[44]\tvalidation_0-auc:0.88744\tvalidation_1-auc:0.83261\n",
      "[45]\tvalidation_0-auc:0.88765\tvalidation_1-auc:0.83279\n",
      "[46]\tvalidation_0-auc:0.88798\tvalidation_1-auc:0.83309\n",
      "[47]\tvalidation_0-auc:0.88823\tvalidation_1-auc:0.83312\n",
      "[48]\tvalidation_0-auc:0.88847\tvalidation_1-auc:0.83315\n",
      "[49]\tvalidation_0-auc:0.88881\tvalidation_1-auc:0.83316\n",
      "[50]\tvalidation_0-auc:0.88907\tvalidation_1-auc:0.83348\n",
      "[51]\tvalidation_0-auc:0.88945\tvalidation_1-auc:0.83344\n",
      "[52]\tvalidation_0-auc:0.88974\tvalidation_1-auc:0.83347\n",
      "[53]\tvalidation_0-auc:0.89003\tvalidation_1-auc:0.83368\n",
      "[54]\tvalidation_0-auc:0.89024\tvalidation_1-auc:0.83365\n",
      "[55]\tvalidation_0-auc:0.89056\tvalidation_1-auc:0.83367\n",
      "[56]\tvalidation_0-auc:0.89080\tvalidation_1-auc:0.83358\n",
      "[57]\tvalidation_0-auc:0.89122\tvalidation_1-auc:0.83352\n",
      "[58]\tvalidation_0-auc:0.89182\tvalidation_1-auc:0.83352\n",
      "[59]\tvalidation_0-auc:0.89223\tvalidation_1-auc:0.83352\n",
      "[60]\tvalidation_0-auc:0.89271\tvalidation_1-auc:0.83345\n",
      "[61]\tvalidation_0-auc:0.89292\tvalidation_1-auc:0.83357\n",
      "[62]\tvalidation_0-auc:0.89313\tvalidation_1-auc:0.83345\n",
      "[63]\tvalidation_0-auc:0.89359\tvalidation_1-auc:0.83362\n",
      "[64]\tvalidation_0-auc:0.89403\tvalidation_1-auc:0.83379\n",
      "[65]\tvalidation_0-auc:0.89454\tvalidation_1-auc:0.83382\n",
      "[66]\tvalidation_0-auc:0.89517\tvalidation_1-auc:0.83385\n",
      "[67]\tvalidation_0-auc:0.89576\tvalidation_1-auc:0.83406\n",
      "[68]\tvalidation_0-auc:0.89595\tvalidation_1-auc:0.83413\n",
      "[69]\tvalidation_0-auc:0.89614\tvalidation_1-auc:0.83407\n",
      "[70]\tvalidation_0-auc:0.89630\tvalidation_1-auc:0.83416\n",
      "[71]\tvalidation_0-auc:0.89647\tvalidation_1-auc:0.83428\n",
      "[72]\tvalidation_0-auc:0.89715\tvalidation_1-auc:0.83405\n",
      "[73]\tvalidation_0-auc:0.89736\tvalidation_1-auc:0.83384\n",
      "[74]\tvalidation_0-auc:0.89752\tvalidation_1-auc:0.83380\n",
      "[75]\tvalidation_0-auc:0.89757\tvalidation_1-auc:0.83377\n",
      "[76]\tvalidation_0-auc:0.89785\tvalidation_1-auc:0.83385\n",
      "[77]\tvalidation_0-auc:0.89808\tvalidation_1-auc:0.83389\n",
      "[78]\tvalidation_0-auc:0.89828\tvalidation_1-auc:0.83402\n",
      "[79]\tvalidation_0-auc:0.89845\tvalidation_1-auc:0.83398\n",
      "[80]\tvalidation_0-auc:0.89877\tvalidation_1-auc:0.83382\n",
      "[81]\tvalidation_0-auc:0.89885\tvalidation_1-auc:0.83386\n",
      "[82]\tvalidation_0-auc:0.89915\tvalidation_1-auc:0.83382\n",
      "[83]\tvalidation_0-auc:0.89926\tvalidation_1-auc:0.83380\n",
      "[84]\tvalidation_0-auc:0.89935\tvalidation_1-auc:0.83380\n",
      "[85]\tvalidation_0-auc:0.89946\tvalidation_1-auc:0.83380\n",
      "[86]\tvalidation_0-auc:0.89957\tvalidation_1-auc:0.83378\n",
      "[87]\tvalidation_0-auc:0.90009\tvalidation_1-auc:0.83388\n",
      "[88]\tvalidation_0-auc:0.90015\tvalidation_1-auc:0.83392\n",
      "[89]\tvalidation_0-auc:0.90024\tvalidation_1-auc:0.83389\n",
      "[90]\tvalidation_0-auc:0.90036\tvalidation_1-auc:0.83391\n",
      "[91]\tvalidation_0-auc:0.90045\tvalidation_1-auc:0.83390\n",
      "[92]\tvalidation_0-auc:0.90074\tvalidation_1-auc:0.83412\n",
      "[93]\tvalidation_0-auc:0.90094\tvalidation_1-auc:0.83422\n",
      "[94]\tvalidation_0-auc:0.90103\tvalidation_1-auc:0.83416\n",
      "[95]\tvalidation_0-auc:0.90156\tvalidation_1-auc:0.83430\n",
      "[96]\tvalidation_0-auc:0.90174\tvalidation_1-auc:0.83420\n",
      "[97]\tvalidation_0-auc:0.90200\tvalidation_1-auc:0.83419\n",
      "[98]\tvalidation_0-auc:0.90234\tvalidation_1-auc:0.83415\n",
      "[99]\tvalidation_0-auc:0.90243\tvalidation_1-auc:0.83408\n",
      "[100]\tvalidation_0-auc:0.90249\tvalidation_1-auc:0.83408\n",
      "[101]\tvalidation_0-auc:0.90273\tvalidation_1-auc:0.83400\n",
      "[102]\tvalidation_0-auc:0.90287\tvalidation_1-auc:0.83402\n",
      "[103]\tvalidation_0-auc:0.90331\tvalidation_1-auc:0.83398\n",
      "[104]\tvalidation_0-auc:0.90335\tvalidation_1-auc:0.83401\n",
      "[105]\tvalidation_0-auc:0.90389\tvalidation_1-auc:0.83388\n",
      "[106]\tvalidation_0-auc:0.90399\tvalidation_1-auc:0.83382\n",
      "[107]\tvalidation_0-auc:0.90424\tvalidation_1-auc:0.83391\n",
      "[108]\tvalidation_0-auc:0.90432\tvalidation_1-auc:0.83395\n",
      "[109]\tvalidation_0-auc:0.90459\tvalidation_1-auc:0.83401\n",
      "[110]\tvalidation_0-auc:0.90473\tvalidation_1-auc:0.83399\n",
      "[111]\tvalidation_0-auc:0.90486\tvalidation_1-auc:0.83404\n",
      "[112]\tvalidation_0-auc:0.90502\tvalidation_1-auc:0.83419\n",
      "[113]\tvalidation_0-auc:0.90508\tvalidation_1-auc:0.83427\n",
      "[114]\tvalidation_0-auc:0.90512\tvalidation_1-auc:0.83434\n",
      "[115]\tvalidation_0-auc:0.90533\tvalidation_1-auc:0.83431\n",
      "[116]\tvalidation_0-auc:0.90560\tvalidation_1-auc:0.83429\n",
      "[117]\tvalidation_0-auc:0.90569\tvalidation_1-auc:0.83427\n",
      "[118]\tvalidation_0-auc:0.90581\tvalidation_1-auc:0.83433\n",
      "[119]\tvalidation_0-auc:0.90592\tvalidation_1-auc:0.83432\n",
      "[120]\tvalidation_0-auc:0.90601\tvalidation_1-auc:0.83423\n",
      "[121]\tvalidation_0-auc:0.90622\tvalidation_1-auc:0.83411\n",
      "[122]\tvalidation_0-auc:0.90648\tvalidation_1-auc:0.83396\n",
      "[123]\tvalidation_0-auc:0.90673\tvalidation_1-auc:0.83392\n",
      "[124]\tvalidation_0-auc:0.90680\tvalidation_1-auc:0.83389\n",
      "[125]\tvalidation_0-auc:0.90687\tvalidation_1-auc:0.83380\n",
      "[126]\tvalidation_0-auc:0.90703\tvalidation_1-auc:0.83380\n",
      "[127]\tvalidation_0-auc:0.90706\tvalidation_1-auc:0.83381\n",
      "[128]\tvalidation_0-auc:0.90712\tvalidation_1-auc:0.83384\n",
      "[129]\tvalidation_0-auc:0.90715\tvalidation_1-auc:0.83388\n",
      "[130]\tvalidation_0-auc:0.90732\tvalidation_1-auc:0.83389\n",
      "[131]\tvalidation_0-auc:0.90758\tvalidation_1-auc:0.83387\n",
      "[132]\tvalidation_0-auc:0.90776\tvalidation_1-auc:0.83382\n",
      "[133]\tvalidation_0-auc:0.90779\tvalidation_1-auc:0.83381\n",
      "[134]\tvalidation_0-auc:0.90785\tvalidation_1-auc:0.83385\n",
      "[135]\tvalidation_0-auc:0.90807\tvalidation_1-auc:0.83385\n",
      "[136]\tvalidation_0-auc:0.90812\tvalidation_1-auc:0.83385\n",
      "[137]\tvalidation_0-auc:0.90818\tvalidation_1-auc:0.83379\n",
      "[138]\tvalidation_0-auc:0.90830\tvalidation_1-auc:0.83380\n",
      "[139]\tvalidation_0-auc:0.90848\tvalidation_1-auc:0.83378\n",
      "[140]\tvalidation_0-auc:0.90853\tvalidation_1-auc:0.83375\n",
      "[141]\tvalidation_0-auc:0.90867\tvalidation_1-auc:0.83369\n",
      "[142]\tvalidation_0-auc:0.90874\tvalidation_1-auc:0.83364\n",
      "[143]\tvalidation_0-auc:0.90888\tvalidation_1-auc:0.83364\n",
      "[144]\tvalidation_0-auc:0.90916\tvalidation_1-auc:0.83354\n",
      "[145]\tvalidation_0-auc:0.90930\tvalidation_1-auc:0.83356\n",
      "[146]\tvalidation_0-auc:0.90946\tvalidation_1-auc:0.83357\n",
      "[147]\tvalidation_0-auc:0.90977\tvalidation_1-auc:0.83361\n",
      "[148]\tvalidation_0-auc:0.91001\tvalidation_1-auc:0.83346\n",
      "[149]\tvalidation_0-auc:0.91009\tvalidation_1-auc:0.83348\n",
      "[150]\tvalidation_0-auc:0.91011\tvalidation_1-auc:0.83351\n",
      "[151]\tvalidation_0-auc:0.91033\tvalidation_1-auc:0.83358\n",
      "[152]\tvalidation_0-auc:0.91046\tvalidation_1-auc:0.83357\n",
      "[153]\tvalidation_0-auc:0.91057\tvalidation_1-auc:0.83351\n",
      "[154]\tvalidation_0-auc:0.91066\tvalidation_1-auc:0.83354\n",
      "[155]\tvalidation_0-auc:0.91079\tvalidation_1-auc:0.83359\n",
      "[156]\tvalidation_0-auc:0.91094\tvalidation_1-auc:0.83354\n",
      "[157]\tvalidation_0-auc:0.91119\tvalidation_1-auc:0.83340\n",
      "[158]\tvalidation_0-auc:0.91128\tvalidation_1-auc:0.83338\n",
      "[159]\tvalidation_0-auc:0.91134\tvalidation_1-auc:0.83343\n",
      "[160]\tvalidation_0-auc:0.91144\tvalidation_1-auc:0.83343\n",
      "[161]\tvalidation_0-auc:0.91159\tvalidation_1-auc:0.83350\n",
      "[162]\tvalidation_0-auc:0.91163\tvalidation_1-auc:0.83349\n",
      "[163]\tvalidation_0-auc:0.91171\tvalidation_1-auc:0.83357\n",
      "[164]\tvalidation_0-auc:0.91177\tvalidation_1-auc:0.83360\n",
      "[165]\tvalidation_0-auc:0.91181\tvalidation_1-auc:0.83366\n",
      "[166]\tvalidation_0-auc:0.91186\tvalidation_1-auc:0.83359\n",
      "[167]\tvalidation_0-auc:0.91202\tvalidation_1-auc:0.83358\n",
      "[168]\tvalidation_0-auc:0.91226\tvalidation_1-auc:0.83358\n",
      "[169]\tvalidation_0-auc:0.91230\tvalidation_1-auc:0.83358\n",
      "[170]\tvalidation_0-auc:0.91251\tvalidation_1-auc:0.83356\n",
      "[171]\tvalidation_0-auc:0.91255\tvalidation_1-auc:0.83350\n",
      "[172]\tvalidation_0-auc:0.91260\tvalidation_1-auc:0.83348\n",
      "[173]\tvalidation_0-auc:0.91277\tvalidation_1-auc:0.83337\n",
      "[174]\tvalidation_0-auc:0.91292\tvalidation_1-auc:0.83328\n",
      "[175]\tvalidation_0-auc:0.91298\tvalidation_1-auc:0.83328\n",
      "[176]\tvalidation_0-auc:0.91303\tvalidation_1-auc:0.83325\n",
      "[177]\tvalidation_0-auc:0.91305\tvalidation_1-auc:0.83324\n",
      "[178]\tvalidation_0-auc:0.91320\tvalidation_1-auc:0.83310\n",
      "[179]\tvalidation_0-auc:0.91339\tvalidation_1-auc:0.83308\n",
      "[180]\tvalidation_0-auc:0.91342\tvalidation_1-auc:0.83309\n",
      "[181]\tvalidation_0-auc:0.91364\tvalidation_1-auc:0.83307\n",
      "[182]\tvalidation_0-auc:0.91369\tvalidation_1-auc:0.83304\n",
      "[183]\tvalidation_0-auc:0.91389\tvalidation_1-auc:0.83313\n",
      "[184]\tvalidation_0-auc:0.91395\tvalidation_1-auc:0.83307\n",
      "[185]\tvalidation_0-auc:0.91420\tvalidation_1-auc:0.83327\n",
      "[186]\tvalidation_0-auc:0.91447\tvalidation_1-auc:0.83318\n",
      "[187]\tvalidation_0-auc:0.91454\tvalidation_1-auc:0.83315\n",
      "[188]\tvalidation_0-auc:0.91475\tvalidation_1-auc:0.83297\n",
      "[189]\tvalidation_0-auc:0.91479\tvalidation_1-auc:0.83291\n",
      "[190]\tvalidation_0-auc:0.91503\tvalidation_1-auc:0.83279\n",
      "[191]\tvalidation_0-auc:0.91515\tvalidation_1-auc:0.83277\n",
      "[192]\tvalidation_0-auc:0.91517\tvalidation_1-auc:0.83276\n",
      "[193]\tvalidation_0-auc:0.91521\tvalidation_1-auc:0.83278\n",
      "[194]\tvalidation_0-auc:0.91557\tvalidation_1-auc:0.83272\n",
      "[195]\tvalidation_0-auc:0.91567\tvalidation_1-auc:0.83266\n",
      "[196]\tvalidation_0-auc:0.91575\tvalidation_1-auc:0.83270\n",
      "[197]\tvalidation_0-auc:0.91602\tvalidation_1-auc:0.83268\n",
      "[198]\tvalidation_0-auc:0.91628\tvalidation_1-auc:0.83260\n",
      "[199]\tvalidation_0-auc:0.91647\tvalidation_1-auc:0.83251\n",
      "[200]\tvalidation_0-auc:0.91648\tvalidation_1-auc:0.83250\n",
      "[201]\tvalidation_0-auc:0.91652\tvalidation_1-auc:0.83253\n",
      "[202]\tvalidation_0-auc:0.91654\tvalidation_1-auc:0.83257\n",
      "[203]\tvalidation_0-auc:0.91662\tvalidation_1-auc:0.83267\n",
      "[204]\tvalidation_0-auc:0.91671\tvalidation_1-auc:0.83267\n",
      "[205]\tvalidation_0-auc:0.91673\tvalidation_1-auc:0.83267\n",
      "[206]\tvalidation_0-auc:0.91676\tvalidation_1-auc:0.83266\n",
      "[207]\tvalidation_0-auc:0.91699\tvalidation_1-auc:0.83264\n",
      "[208]\tvalidation_0-auc:0.91719\tvalidation_1-auc:0.83261\n",
      "[209]\tvalidation_0-auc:0.91726\tvalidation_1-auc:0.83258\n",
      "[210]\tvalidation_0-auc:0.91729\tvalidation_1-auc:0.83253\n",
      "[211]\tvalidation_0-auc:0.91750\tvalidation_1-auc:0.83254\n",
      "[212]\tvalidation_0-auc:0.91758\tvalidation_1-auc:0.83245\n",
      "[213]\tvalidation_0-auc:0.91760\tvalidation_1-auc:0.83249\n",
      "ROC AUC: 0.8386\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate = 0.05, random_state=42, early_stopping_rounds=100, eval_metric='auc')\n",
    "\n",
    "xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "model = 'xgboost'\n",
    "\n",
    "print(f'ROC AUC: {xgb_roc_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91348679-3df2-4f33-ae34-88ce70c97e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(columns=['model', 'auc_score'])\n",
    "new_row = {'model': model, 'auc_score': f'{xgb_roc_score:.4f}'}\n",
    "scores_df.loc[0] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b24dda9-3f20-42bb-9505-31a5c5b19a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9851f0a-2522-4bbd-bbb1-86f80542191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 15, 1), \n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1), # 리프노드의 분할을 위한 가중치 합 기준 (0이상 실수, default: 1), 클수록 일반화 성능 up (과적합 방지)\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95), # 분할시 사용할 데이터 비율 (0~1 실수, default: 1), 작을수록 일반화 성능 up (과적합 방지)\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7117a8f-f699-479d-81dd-0a8f67251d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d719e0b5-dde4-4085-bdf2-6301ef999020",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b0f1a0e-b5fa-4cba-aad6-182695fcac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(search_space):\n",
    "    xgb_clf=XGBClassifier(n_estimators=100,\n",
    "                          early_stopping_rounds=30,\n",
    "                          eval_metric='auc',\n",
    "                          max_depth=int(search_space['max_depth']), \n",
    "                          min_child_weight=int(search_space['min_child_weight']), \n",
    "                          colsample_bytree=search_space['colsample_bytree'], \n",
    "                          learning_rate=search_space['learning_rate'])\n",
    "    \n",
    "    # 3-fold\n",
    "    kf=KFold(n_splits=3)\n",
    "\n",
    "    # 3-fold cv 스코어를 담을 리스트 생성\n",
    "    roc_auc_list = []\n",
    "    \n",
    "    # X_train을 학습용, 검증용 으로 분리하기\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        eval_set = eval_set=[(X_tr, y_tr), (X_val, y_val)]\n",
    "\n",
    "        xgb_clf.fit(X_tr, y_tr, eval_set=eval_set)\n",
    "\n",
    "        # 1로 예측한 확률값 추출 -> roc_auc 계산, 평균 계산을 위해 리스트에 담음.\n",
    "        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])\n",
    "        roc_auc_list.append(score)\n",
    "\n",
    "    return -1*np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d211492-c395-4aa1-a7a0-bf92db0b92c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.84861\tvalidation_1-auc:0.80661                                                                  \n",
      "[1]\tvalidation_0-auc:0.85067\tvalidation_1-auc:0.80341                                                                  \n",
      "[2]\tvalidation_0-auc:0.85711\tvalidation_1-auc:0.81184                                                                  \n",
      "[3]\tvalidation_0-auc:0.85661\tvalidation_1-auc:0.80687                                                                  \n",
      "[4]\tvalidation_0-auc:0.85421\tvalidation_1-auc:0.80217                                                                  \n",
      "[5]\tvalidation_0-auc:0.85920\tvalidation_1-auc:0.80836                                                                  \n",
      "[6]\tvalidation_0-auc:0.86365\tvalidation_1-auc:0.81303                                                                  \n",
      "[7]\tvalidation_0-auc:0.86566\tvalidation_1-auc:0.81496                                                                  \n",
      "[8]\tvalidation_0-auc:0.86828\tvalidation_1-auc:0.81644                                                                  \n",
      "[9]\tvalidation_0-auc:0.86737\tvalidation_1-auc:0.81371                                                                  \n",
      "[10]\tvalidation_0-auc:0.87016\tvalidation_1-auc:0.81570                                                                 \n",
      "[11]\tvalidation_0-auc:0.87253\tvalidation_1-auc:0.81716                                                                 \n",
      "[12]\tvalidation_0-auc:0.87422\tvalidation_1-auc:0.81828                                                                 \n",
      "[13]\tvalidation_0-auc:0.87597\tvalidation_1-auc:0.81967                                                                 \n",
      "[14]\tvalidation_0-auc:0.87669\tvalidation_1-auc:0.81765                                                                 \n",
      "[15]\tvalidation_0-auc:0.87874\tvalidation_1-auc:0.81870                                                                 \n",
      "[16]\tvalidation_0-auc:0.87944\tvalidation_1-auc:0.81969                                                                 \n",
      "[17]\tvalidation_0-auc:0.88016\tvalidation_1-auc:0.81906                                                                 \n",
      "[18]\tvalidation_0-auc:0.88055\tvalidation_1-auc:0.81840                                                                 \n",
      "[19]\tvalidation_0-auc:0.88154\tvalidation_1-auc:0.81922                                                                 \n",
      "[20]\tvalidation_0-auc:0.88217\tvalidation_1-auc:0.81950                                                                 \n",
      "[21]\tvalidation_0-auc:0.88299\tvalidation_1-auc:0.82036                                                                 \n",
      "[22]\tvalidation_0-auc:0.88366\tvalidation_1-auc:0.82092                                                                 \n",
      "[23]\tvalidation_0-auc:0.88430\tvalidation_1-auc:0.82134                                                                 \n",
      "[24]\tvalidation_0-auc:0.88520\tvalidation_1-auc:0.82101                                                                 \n",
      "[25]\tvalidation_0-auc:0.88602\tvalidation_1-auc:0.82107                                                                 \n",
      "[26]\tvalidation_0-auc:0.88673\tvalidation_1-auc:0.82063                                                                 \n",
      "[27]\tvalidation_0-auc:0.88753\tvalidation_1-auc:0.82042                                                                 \n",
      "[28]\tvalidation_0-auc:0.88798\tvalidation_1-auc:0.82098                                                                 \n",
      "[29]\tvalidation_0-auc:0.88849\tvalidation_1-auc:0.82065                                                                 \n",
      "[30]\tvalidation_0-auc:0.88910\tvalidation_1-auc:0.82025                                                                 \n",
      "[31]\tvalidation_0-auc:0.88953\tvalidation_1-auc:0.82043                                                                 \n",
      "[32]\tvalidation_0-auc:0.89020\tvalidation_1-auc:0.82051                                                                 \n",
      "[33]\tvalidation_0-auc:0.89041\tvalidation_1-auc:0.82076                                                                 \n",
      "[34]\tvalidation_0-auc:0.89067\tvalidation_1-auc:0.82088                                                                 \n",
      "[35]\tvalidation_0-auc:0.89127\tvalidation_1-auc:0.82154                                                                 \n",
      "[36]\tvalidation_0-auc:0.89173\tvalidation_1-auc:0.82141                                                                 \n",
      "[37]\tvalidation_0-auc:0.89207\tvalidation_1-auc:0.82145                                                                 \n",
      "[38]\tvalidation_0-auc:0.89242\tvalidation_1-auc:0.82184                                                                 \n",
      "[39]\tvalidation_0-auc:0.89277\tvalidation_1-auc:0.82205                                                                 \n",
      "[40]\tvalidation_0-auc:0.89364\tvalidation_1-auc:0.82228                                                                 \n",
      "[41]\tvalidation_0-auc:0.89429\tvalidation_1-auc:0.82285                                                                 \n",
      "[42]\tvalidation_0-auc:0.89441\tvalidation_1-auc:0.82305                                                                 \n",
      "[43]\tvalidation_0-auc:0.89483\tvalidation_1-auc:0.82317                                                                 \n",
      "[44]\tvalidation_0-auc:0.89549\tvalidation_1-auc:0.82289                                                                 \n",
      "[45]\tvalidation_0-auc:0.89592\tvalidation_1-auc:0.82303                                                                 \n",
      "[46]\tvalidation_0-auc:0.89601\tvalidation_1-auc:0.82291                                                                 \n",
      "[47]\tvalidation_0-auc:0.89648\tvalidation_1-auc:0.82292                                                                 \n",
      "[48]\tvalidation_0-auc:0.89655\tvalidation_1-auc:0.82284                                                                 \n",
      "[49]\tvalidation_0-auc:0.89666\tvalidation_1-auc:0.82278                                                                 \n",
      "[50]\tvalidation_0-auc:0.89705\tvalidation_1-auc:0.82292                                                                 \n",
      "[51]\tvalidation_0-auc:0.89725\tvalidation_1-auc:0.82302                                                                 \n",
      "[52]\tvalidation_0-auc:0.89745\tvalidation_1-auc:0.82279                                                                 \n",
      "[53]\tvalidation_0-auc:0.89772\tvalidation_1-auc:0.82282                                                                 \n",
      "[54]\tvalidation_0-auc:0.89777\tvalidation_1-auc:0.82279                                                                 \n",
      "[55]\tvalidation_0-auc:0.89811\tvalidation_1-auc:0.82325                                                                 \n",
      "[56]\tvalidation_0-auc:0.89829\tvalidation_1-auc:0.82325                                                                 \n",
      "[57]\tvalidation_0-auc:0.89861\tvalidation_1-auc:0.82334                                                                 \n",
      "[58]\tvalidation_0-auc:0.89879\tvalidation_1-auc:0.82337                                                                 \n",
      "[59]\tvalidation_0-auc:0.89920\tvalidation_1-auc:0.82337                                                                 \n",
      "[60]\tvalidation_0-auc:0.89954\tvalidation_1-auc:0.82349                                                                 \n",
      "[61]\tvalidation_0-auc:0.89975\tvalidation_1-auc:0.82353                                                                 \n",
      "[62]\tvalidation_0-auc:0.89982\tvalidation_1-auc:0.82353                                                                 \n",
      "[63]\tvalidation_0-auc:0.90049\tvalidation_1-auc:0.82353                                                                 \n",
      "[64]\tvalidation_0-auc:0.90064\tvalidation_1-auc:0.82360                                                                 \n",
      "[65]\tvalidation_0-auc:0.90096\tvalidation_1-auc:0.82345                                                                 \n",
      "[66]\tvalidation_0-auc:0.90114\tvalidation_1-auc:0.82341                                                                 \n",
      "[67]\tvalidation_0-auc:0.90163\tvalidation_1-auc:0.82347                                                                 \n",
      "[68]\tvalidation_0-auc:0.90170\tvalidation_1-auc:0.82341                                                                 \n",
      "[69]\tvalidation_0-auc:0.90177\tvalidation_1-auc:0.82335                                                                 \n",
      "[70]\tvalidation_0-auc:0.90218\tvalidation_1-auc:0.82344                                                                 \n",
      "[71]\tvalidation_0-auc:0.90228\tvalidation_1-auc:0.82343                                                                 \n",
      "[72]\tvalidation_0-auc:0.90233\tvalidation_1-auc:0.82335                                                                 \n",
      "[73]\tvalidation_0-auc:0.90276\tvalidation_1-auc:0.82338                                                                 \n",
      "[74]\tvalidation_0-auc:0.90298\tvalidation_1-auc:0.82335                                                                 \n",
      "[75]\tvalidation_0-auc:0.90305\tvalidation_1-auc:0.82323                                                                 \n",
      "[76]\tvalidation_0-auc:0.90312\tvalidation_1-auc:0.82319                                                                 \n",
      "[77]\tvalidation_0-auc:0.90317\tvalidation_1-auc:0.82320                                                                 \n",
      "[78]\tvalidation_0-auc:0.90363\tvalidation_1-auc:0.82328                                                                 \n",
      "[79]\tvalidation_0-auc:0.90385\tvalidation_1-auc:0.82310                                                                 \n",
      "[80]\tvalidation_0-auc:0.90394\tvalidation_1-auc:0.82309                                                                 \n",
      "[81]\tvalidation_0-auc:0.90430\tvalidation_1-auc:0.82314                                                                 \n",
      "[82]\tvalidation_0-auc:0.90439\tvalidation_1-auc:0.82313                                                                 \n",
      "[83]\tvalidation_0-auc:0.90494\tvalidation_1-auc:0.82317                                                                 \n",
      "[84]\tvalidation_0-auc:0.90520\tvalidation_1-auc:0.82302                                                                 \n",
      "[85]\tvalidation_0-auc:0.90559\tvalidation_1-auc:0.82285                                                                 \n",
      "[86]\tvalidation_0-auc:0.90565\tvalidation_1-auc:0.82278                                                                 \n",
      "[87]\tvalidation_0-auc:0.90639\tvalidation_1-auc:0.82314                                                                 \n",
      "[88]\tvalidation_0-auc:0.90664\tvalidation_1-auc:0.82314                                                                 \n",
      "[89]\tvalidation_0-auc:0.90710\tvalidation_1-auc:0.82293                                                                 \n",
      "[90]\tvalidation_0-auc:0.90714\tvalidation_1-auc:0.82285                                                                 \n",
      "[91]\tvalidation_0-auc:0.90735\tvalidation_1-auc:0.82282                                                                 \n",
      "[92]\tvalidation_0-auc:0.90752\tvalidation_1-auc:0.82301                                                                 \n",
      "[93]\tvalidation_0-auc:0.90800\tvalidation_1-auc:0.82285                                                                 \n",
      "[94]\tvalidation_0-auc:0.90812\tvalidation_1-auc:0.82283                                                                 \n",
      "[0]\tvalidation_0-auc:0.83974\tvalidation_1-auc:0.80878                                                                  \n",
      "[1]\tvalidation_0-auc:0.84324\tvalidation_1-auc:0.82032                                                                  \n",
      "[2]\tvalidation_0-auc:0.85304\tvalidation_1-auc:0.83328                                                                  \n",
      "[3]\tvalidation_0-auc:0.85062\tvalidation_1-auc:0.83181                                                                  \n",
      "[4]\tvalidation_0-auc:0.84667\tvalidation_1-auc:0.83027                                                                  \n",
      "[5]\tvalidation_0-auc:0.85365\tvalidation_1-auc:0.83416                                                                  \n",
      "[6]\tvalidation_0-auc:0.85832\tvalidation_1-auc:0.83635                                                                  \n",
      "[7]\tvalidation_0-auc:0.86156\tvalidation_1-auc:0.83785                                                                  \n",
      "[8]\tvalidation_0-auc:0.86430\tvalidation_1-auc:0.83874                                                                  \n",
      "[9]\tvalidation_0-auc:0.86376\tvalidation_1-auc:0.83968                                                                  \n",
      "[10]\tvalidation_0-auc:0.86573\tvalidation_1-auc:0.84133                                                                 \n",
      "[11]\tvalidation_0-auc:0.86830\tvalidation_1-auc:0.84095                                                                 \n",
      "[12]\tvalidation_0-auc:0.86989\tvalidation_1-auc:0.84033                                                                 \n",
      "[13]\tvalidation_0-auc:0.87159\tvalidation_1-auc:0.83995                                                                 \n",
      "[14]\tvalidation_0-auc:0.87211\tvalidation_1-auc:0.84050                                                                 \n",
      "[15]\tvalidation_0-auc:0.87356\tvalidation_1-auc:0.84043                                                                 \n",
      "[16]\tvalidation_0-auc:0.87562\tvalidation_1-auc:0.84067                                                                 \n",
      "[17]\tvalidation_0-auc:0.87658\tvalidation_1-auc:0.84149                                                                 \n",
      "[18]\tvalidation_0-auc:0.87784\tvalidation_1-auc:0.84189                                                                 \n",
      "[19]\tvalidation_0-auc:0.87895\tvalidation_1-auc:0.84220                                                                 \n",
      "[20]\tvalidation_0-auc:0.87991\tvalidation_1-auc:0.84225                                                                 \n",
      "[21]\tvalidation_0-auc:0.88075\tvalidation_1-auc:0.84214                                                                 \n",
      "[22]\tvalidation_0-auc:0.88129\tvalidation_1-auc:0.84236                                                                 \n",
      "[23]\tvalidation_0-auc:0.88221\tvalidation_1-auc:0.84225                                                                 \n",
      "[24]\tvalidation_0-auc:0.88343\tvalidation_1-auc:0.84213                                                                 \n",
      "[25]\tvalidation_0-auc:0.88469\tvalidation_1-auc:0.84227                                                                 \n",
      "[26]\tvalidation_0-auc:0.88531\tvalidation_1-auc:0.84254                                                                 \n",
      "[27]\tvalidation_0-auc:0.88601\tvalidation_1-auc:0.84313                                                                 \n",
      "[28]\tvalidation_0-auc:0.88664\tvalidation_1-auc:0.84316                                                                 \n",
      "[29]\tvalidation_0-auc:0.88678\tvalidation_1-auc:0.84338                                                                 \n",
      "[30]\tvalidation_0-auc:0.88761\tvalidation_1-auc:0.84362                                                                 \n",
      "[31]\tvalidation_0-auc:0.88812\tvalidation_1-auc:0.84361                                                                 \n",
      "[32]\tvalidation_0-auc:0.88858\tvalidation_1-auc:0.84362                                                                 \n",
      "[33]\tvalidation_0-auc:0.88891\tvalidation_1-auc:0.84346                                                                 \n",
      "[34]\tvalidation_0-auc:0.88941\tvalidation_1-auc:0.84355                                                                 \n",
      "[35]\tvalidation_0-auc:0.88973\tvalidation_1-auc:0.84339                                                                 \n",
      "[36]\tvalidation_0-auc:0.88993\tvalidation_1-auc:0.84334                                                                 \n",
      "[37]\tvalidation_0-auc:0.89065\tvalidation_1-auc:0.84360                                                                 \n",
      "[38]\tvalidation_0-auc:0.89095\tvalidation_1-auc:0.84355                                                                 \n",
      "[39]\tvalidation_0-auc:0.89131\tvalidation_1-auc:0.84363                                                                 \n",
      "[40]\tvalidation_0-auc:0.89215\tvalidation_1-auc:0.84350                                                                 \n",
      "[41]\tvalidation_0-auc:0.89258\tvalidation_1-auc:0.84368                                                                 \n",
      "[42]\tvalidation_0-auc:0.89276\tvalidation_1-auc:0.84366                                                                 \n",
      "[43]\tvalidation_0-auc:0.89322\tvalidation_1-auc:0.84372                                                                 \n",
      "[44]\tvalidation_0-auc:0.89358\tvalidation_1-auc:0.84361                                                                 \n",
      "[45]\tvalidation_0-auc:0.89423\tvalidation_1-auc:0.84342                                                                 \n",
      "[46]\tvalidation_0-auc:0.89438\tvalidation_1-auc:0.84331                                                                 \n",
      "[47]\tvalidation_0-auc:0.89459\tvalidation_1-auc:0.84331                                                                 \n",
      "[48]\tvalidation_0-auc:0.89464\tvalidation_1-auc:0.84339                                                                 \n",
      "[49]\tvalidation_0-auc:0.89535\tvalidation_1-auc:0.84330                                                                 \n",
      "[50]\tvalidation_0-auc:0.89554\tvalidation_1-auc:0.84323                                                                 \n",
      "[51]\tvalidation_0-auc:0.89584\tvalidation_1-auc:0.84324                                                                 \n",
      "[52]\tvalidation_0-auc:0.89589\tvalidation_1-auc:0.84315                                                                 \n",
      "[53]\tvalidation_0-auc:0.89605\tvalidation_1-auc:0.84304                                                                 \n",
      "[54]\tvalidation_0-auc:0.89654\tvalidation_1-auc:0.84299                                                                 \n",
      "[55]\tvalidation_0-auc:0.89692\tvalidation_1-auc:0.84303                                                                 \n",
      "[56]\tvalidation_0-auc:0.89725\tvalidation_1-auc:0.84294                                                                 \n",
      "[57]\tvalidation_0-auc:0.89748\tvalidation_1-auc:0.84289                                                                 \n",
      "[58]\tvalidation_0-auc:0.89785\tvalidation_1-auc:0.84289                                                                 \n",
      "[59]\tvalidation_0-auc:0.89814\tvalidation_1-auc:0.84281                                                                 \n",
      "[60]\tvalidation_0-auc:0.89869\tvalidation_1-auc:0.84245                                                                 \n",
      "[61]\tvalidation_0-auc:0.89902\tvalidation_1-auc:0.84263                                                                 \n",
      "[62]\tvalidation_0-auc:0.89914\tvalidation_1-auc:0.84257                                                                 \n",
      "[63]\tvalidation_0-auc:0.89932\tvalidation_1-auc:0.84255                                                                 \n",
      "[64]\tvalidation_0-auc:0.89964\tvalidation_1-auc:0.84248                                                                 \n",
      "[65]\tvalidation_0-auc:0.89990\tvalidation_1-auc:0.84235                                                                 \n",
      "[66]\tvalidation_0-auc:0.90006\tvalidation_1-auc:0.84232                                                                 \n",
      "[67]\tvalidation_0-auc:0.90067\tvalidation_1-auc:0.84237                                                                 \n",
      "[68]\tvalidation_0-auc:0.90080\tvalidation_1-auc:0.84217                                                                 \n",
      "[69]\tvalidation_0-auc:0.90084\tvalidation_1-auc:0.84215                                                                 \n",
      "[70]\tvalidation_0-auc:0.90144\tvalidation_1-auc:0.84198                                                                 \n",
      "[71]\tvalidation_0-auc:0.90155\tvalidation_1-auc:0.84195                                                                 \n",
      "[72]\tvalidation_0-auc:0.90178\tvalidation_1-auc:0.84181                                                                 \n",
      "[0]\tvalidation_0-auc:0.83858\tvalidation_1-auc:0.82107                                                                  \n",
      "[1]\tvalidation_0-auc:0.83950\tvalidation_1-auc:0.81107                                                                  \n",
      "[2]\tvalidation_0-auc:0.84859\tvalidation_1-auc:0.82129                                                                  \n",
      "[3]\tvalidation_0-auc:0.84810\tvalidation_1-auc:0.81898                                                                  \n",
      "[4]\tvalidation_0-auc:0.84662\tvalidation_1-auc:0.81314                                                                  \n",
      "[5]\tvalidation_0-auc:0.85264\tvalidation_1-auc:0.81939                                                                  \n",
      "[6]\tvalidation_0-auc:0.85756\tvalidation_1-auc:0.82435                                                                  \n",
      "[7]\tvalidation_0-auc:0.85988\tvalidation_1-auc:0.82624                                                                  \n",
      "[8]\tvalidation_0-auc:0.86170\tvalidation_1-auc:0.82795                                                                  \n",
      "[9]\tvalidation_0-auc:0.86226\tvalidation_1-auc:0.82728                                                                  \n",
      "[10]\tvalidation_0-auc:0.86454\tvalidation_1-auc:0.82897                                                                 \n",
      "[11]\tvalidation_0-auc:0.86686\tvalidation_1-auc:0.83161                                                                 \n",
      "[12]\tvalidation_0-auc:0.86871\tvalidation_1-auc:0.83309                                                                 \n",
      "[13]\tvalidation_0-auc:0.87073\tvalidation_1-auc:0.83406                                                                 \n",
      "[14]\tvalidation_0-auc:0.87228\tvalidation_1-auc:0.83363                                                                 \n",
      "[15]\tvalidation_0-auc:0.87371\tvalidation_1-auc:0.83419                                                                 \n",
      "[16]\tvalidation_0-auc:0.87540\tvalidation_1-auc:0.83447                                                                 \n",
      "[17]\tvalidation_0-auc:0.87642\tvalidation_1-auc:0.83423                                                                 \n",
      "[18]\tvalidation_0-auc:0.87745\tvalidation_1-auc:0.83361                                                                 \n",
      "[19]\tvalidation_0-auc:0.87886\tvalidation_1-auc:0.83414                                                                 \n",
      "[20]\tvalidation_0-auc:0.87955\tvalidation_1-auc:0.83443                                                                 \n",
      "[21]\tvalidation_0-auc:0.88038\tvalidation_1-auc:0.83465                                                                 \n",
      "[22]\tvalidation_0-auc:0.88133\tvalidation_1-auc:0.83531                                                                 \n",
      "[23]\tvalidation_0-auc:0.88218\tvalidation_1-auc:0.83623                                                                 \n",
      "[24]\tvalidation_0-auc:0.88311\tvalidation_1-auc:0.83683                                                                 \n",
      "[25]\tvalidation_0-auc:0.88392\tvalidation_1-auc:0.83746                                                                 \n",
      "[26]\tvalidation_0-auc:0.88458\tvalidation_1-auc:0.83760                                                                 \n",
      "[27]\tvalidation_0-auc:0.88519\tvalidation_1-auc:0.83746                                                                 \n",
      "[28]\tvalidation_0-auc:0.88593\tvalidation_1-auc:0.83813                                                                 \n",
      "[29]\tvalidation_0-auc:0.88620\tvalidation_1-auc:0.83806                                                                 \n",
      "[30]\tvalidation_0-auc:0.88717\tvalidation_1-auc:0.83789                                                                 \n",
      "[31]\tvalidation_0-auc:0.88814\tvalidation_1-auc:0.83845                                                                 \n",
      "[32]\tvalidation_0-auc:0.88914\tvalidation_1-auc:0.83928                                                                 \n",
      "[33]\tvalidation_0-auc:0.88941\tvalidation_1-auc:0.83948                                                                 \n",
      "[34]\tvalidation_0-auc:0.89001\tvalidation_1-auc:0.83969                                                                 \n",
      "[35]\tvalidation_0-auc:0.89024\tvalidation_1-auc:0.83984                                                                 \n",
      "[36]\tvalidation_0-auc:0.89068\tvalidation_1-auc:0.83975                                                                 \n",
      "[37]\tvalidation_0-auc:0.89105\tvalidation_1-auc:0.83995                                                                 \n",
      "[38]\tvalidation_0-auc:0.89156\tvalidation_1-auc:0.84016                                                                 \n",
      "[39]\tvalidation_0-auc:0.89236\tvalidation_1-auc:0.84040                                                                 \n",
      "[40]\tvalidation_0-auc:0.89328\tvalidation_1-auc:0.84034                                                                 \n",
      "[41]\tvalidation_0-auc:0.89371\tvalidation_1-auc:0.84042                                                                 \n",
      "[42]\tvalidation_0-auc:0.89402\tvalidation_1-auc:0.84062                                                                 \n",
      "[43]\tvalidation_0-auc:0.89423\tvalidation_1-auc:0.84044                                                                 \n",
      "[44]\tvalidation_0-auc:0.89499\tvalidation_1-auc:0.84053                                                                 \n",
      "[45]\tvalidation_0-auc:0.89545\tvalidation_1-auc:0.84036                                                                 \n",
      "[46]\tvalidation_0-auc:0.89564\tvalidation_1-auc:0.84043                                                                 \n",
      "[47]\tvalidation_0-auc:0.89616\tvalidation_1-auc:0.84043                                                                 \n",
      "[48]\tvalidation_0-auc:0.89639\tvalidation_1-auc:0.84031                                                                 \n",
      "[49]\tvalidation_0-auc:0.89674\tvalidation_1-auc:0.84032                                                                 \n",
      "[50]\tvalidation_0-auc:0.89700\tvalidation_1-auc:0.84032                                                                 \n",
      "[51]\tvalidation_0-auc:0.89765\tvalidation_1-auc:0.84013                                                                 \n",
      "[52]\tvalidation_0-auc:0.89778\tvalidation_1-auc:0.84018                                                                 \n",
      "[53]\tvalidation_0-auc:0.89803\tvalidation_1-auc:0.84039                                                                 \n",
      "[54]\tvalidation_0-auc:0.89815\tvalidation_1-auc:0.84040                                                                 \n",
      "[55]\tvalidation_0-auc:0.89864\tvalidation_1-auc:0.84033                                                                 \n",
      "[56]\tvalidation_0-auc:0.89929\tvalidation_1-auc:0.84025                                                                 \n",
      "[57]\tvalidation_0-auc:0.89944\tvalidation_1-auc:0.84025                                                                 \n",
      "[58]\tvalidation_0-auc:0.89975\tvalidation_1-auc:0.84026                                                                 \n",
      "[59]\tvalidation_0-auc:0.90004\tvalidation_1-auc:0.84009                                                                 \n",
      "[60]\tvalidation_0-auc:0.90061\tvalidation_1-auc:0.84019                                                                 \n",
      "[61]\tvalidation_0-auc:0.90109\tvalidation_1-auc:0.84005                                                                 \n",
      "[62]\tvalidation_0-auc:0.90119\tvalidation_1-auc:0.84003                                                                 \n",
      "[63]\tvalidation_0-auc:0.90186\tvalidation_1-auc:0.84012                                                                 \n",
      "[64]\tvalidation_0-auc:0.90205\tvalidation_1-auc:0.84005                                                                 \n",
      "[65]\tvalidation_0-auc:0.90223\tvalidation_1-auc:0.84003                                                                 \n",
      "[66]\tvalidation_0-auc:0.90238\tvalidation_1-auc:0.84001                                                                 \n",
      "[67]\tvalidation_0-auc:0.90247\tvalidation_1-auc:0.83995                                                                 \n",
      "[68]\tvalidation_0-auc:0.90257\tvalidation_1-auc:0.83994                                                                 \n",
      "[69]\tvalidation_0-auc:0.90294\tvalidation_1-auc:0.83993                                                                 \n",
      "[70]\tvalidation_0-auc:0.90353\tvalidation_1-auc:0.83984                                                                 \n",
      "[71]\tvalidation_0-auc:0.90386\tvalidation_1-auc:0.84000                                                                 \n",
      "[72]\tvalidation_0-auc:0.90393\tvalidation_1-auc:0.84000                                                                 \n",
      "[0]\tvalidation_0-auc:0.79818\tvalidation_1-auc:0.72356                                                                  \n",
      "[1]\tvalidation_0-auc:0.82574\tvalidation_1-auc:0.74458                                                                  \n",
      "[2]\tvalidation_0-auc:0.86237\tvalidation_1-auc:0.79052                                                                  \n",
      "[3]\tvalidation_0-auc:0.86188\tvalidation_1-auc:0.78811                                                                  \n",
      "[4]\tvalidation_0-auc:0.86267\tvalidation_1-auc:0.78429                                                                  \n",
      "[5]\tvalidation_0-auc:0.86305\tvalidation_1-auc:0.78514                                                                  \n",
      "[6]\tvalidation_0-auc:0.87353\tvalidation_1-auc:0.79326                                                                  \n",
      "[7]\tvalidation_0-auc:0.87342\tvalidation_1-auc:0.79224                                                                  \n",
      "[8]\tvalidation_0-auc:0.88035\tvalidation_1-auc:0.79823                                                                  \n",
      "[9]\tvalidation_0-auc:0.87981\tvalidation_1-auc:0.79711                                                                  \n",
      "[10]\tvalidation_0-auc:0.88375\tvalidation_1-auc:0.80104                                                                 \n",
      "[11]\tvalidation_0-auc:0.88469\tvalidation_1-auc:0.80123                                                                 \n",
      "[12]\tvalidation_0-auc:0.88427\tvalidation_1-auc:0.80078                                                                 \n",
      "[13]\tvalidation_0-auc:0.88883\tvalidation_1-auc:0.80383                                                                 \n",
      "[14]\tvalidation_0-auc:0.89027\tvalidation_1-auc:0.80226                                                                 \n",
      "[15]\tvalidation_0-auc:0.89125\tvalidation_1-auc:0.80102                                                                 \n",
      "[16]\tvalidation_0-auc:0.89184\tvalidation_1-auc:0.80048                                                                 \n",
      "[17]\tvalidation_0-auc:0.89208\tvalidation_1-auc:0.80051                                                                 \n",
      "[18]\tvalidation_0-auc:0.89270\tvalidation_1-auc:0.80038                                                                 \n",
      "[19]\tvalidation_0-auc:0.89514\tvalidation_1-auc:0.80374                                                                 \n",
      "[20]\tvalidation_0-auc:0.89776\tvalidation_1-auc:0.80619                                                                 \n",
      "[21]\tvalidation_0-auc:0.89979\tvalidation_1-auc:0.80864                                                                 \n",
      "[22]\tvalidation_0-auc:0.90116\tvalidation_1-auc:0.81041                                                                 \n",
      "[23]\tvalidation_0-auc:0.90212\tvalidation_1-auc:0.81201                                                                 \n",
      "[24]\tvalidation_0-auc:0.90256\tvalidation_1-auc:0.81128                                                                 \n",
      "[25]\tvalidation_0-auc:0.90411\tvalidation_1-auc:0.81290                                                                 \n",
      "[26]\tvalidation_0-auc:0.90412\tvalidation_1-auc:0.81220                                                                 \n",
      "[27]\tvalidation_0-auc:0.90463\tvalidation_1-auc:0.81147                                                                 \n",
      "[28]\tvalidation_0-auc:0.90646\tvalidation_1-auc:0.81287                                                                 \n",
      "[29]\tvalidation_0-auc:0.90665\tvalidation_1-auc:0.81258                                                                 \n",
      "[30]\tvalidation_0-auc:0.90706\tvalidation_1-auc:0.81221                                                                 \n",
      "[31]\tvalidation_0-auc:0.90770\tvalidation_1-auc:0.81197                                                                 \n",
      "[32]\tvalidation_0-auc:0.90909\tvalidation_1-auc:0.81298                                                                 \n",
      "[33]\tvalidation_0-auc:0.91049\tvalidation_1-auc:0.81385                                                                 \n",
      "[34]\tvalidation_0-auc:0.91171\tvalidation_1-auc:0.81501                                                                 \n",
      "[35]\tvalidation_0-auc:0.91286\tvalidation_1-auc:0.81592                                                                 \n",
      "[36]\tvalidation_0-auc:0.91391\tvalidation_1-auc:0.81615                                                                 \n",
      "[37]\tvalidation_0-auc:0.91454\tvalidation_1-auc:0.81599                                                                 \n",
      "[38]\tvalidation_0-auc:0.91544\tvalidation_1-auc:0.81636                                                                 \n",
      "[39]\tvalidation_0-auc:0.91624\tvalidation_1-auc:0.81707                                                                 \n",
      "[40]\tvalidation_0-auc:0.91672\tvalidation_1-auc:0.81674                                                                 \n",
      "[41]\tvalidation_0-auc:0.91739\tvalidation_1-auc:0.81714                                                                 \n",
      "[42]\tvalidation_0-auc:0.91772\tvalidation_1-auc:0.81727                                                                 \n",
      "[43]\tvalidation_0-auc:0.91853\tvalidation_1-auc:0.81716                                                                 \n",
      "[44]\tvalidation_0-auc:0.91883\tvalidation_1-auc:0.81674                                                                 \n",
      "[45]\tvalidation_0-auc:0.91956\tvalidation_1-auc:0.81710                                                                 \n",
      "[46]\tvalidation_0-auc:0.91980\tvalidation_1-auc:0.81679                                                                 \n",
      "[47]\tvalidation_0-auc:0.92035\tvalidation_1-auc:0.81691                                                                 \n",
      "[48]\tvalidation_0-auc:0.92071\tvalidation_1-auc:0.81666                                                                 \n",
      "[49]\tvalidation_0-auc:0.92098\tvalidation_1-auc:0.81633                                                                 \n",
      "[50]\tvalidation_0-auc:0.92143\tvalidation_1-auc:0.81623                                                                 \n",
      "[51]\tvalidation_0-auc:0.92215\tvalidation_1-auc:0.81668                                                                 \n",
      "[52]\tvalidation_0-auc:0.92269\tvalidation_1-auc:0.81662                                                                 \n",
      "[53]\tvalidation_0-auc:0.92303\tvalidation_1-auc:0.81728                                                                 \n",
      "[54]\tvalidation_0-auc:0.92349\tvalidation_1-auc:0.81703                                                                 \n",
      "[55]\tvalidation_0-auc:0.92380\tvalidation_1-auc:0.81743                                                                 \n",
      "[56]\tvalidation_0-auc:0.92406\tvalidation_1-auc:0.81746                                                                 \n",
      "[57]\tvalidation_0-auc:0.92434\tvalidation_1-auc:0.81729                                                                 \n",
      "[58]\tvalidation_0-auc:0.92506\tvalidation_1-auc:0.81794                                                                 \n",
      "[59]\tvalidation_0-auc:0.92539\tvalidation_1-auc:0.81857                                                                 \n",
      "[60]\tvalidation_0-auc:0.92568\tvalidation_1-auc:0.81853                                                                 \n",
      "[61]\tvalidation_0-auc:0.92626\tvalidation_1-auc:0.81875                                                                 \n",
      "[62]\tvalidation_0-auc:0.92634\tvalidation_1-auc:0.81866                                                                 \n",
      "[63]\tvalidation_0-auc:0.92651\tvalidation_1-auc:0.81850                                                                 \n",
      "[64]\tvalidation_0-auc:0.92670\tvalidation_1-auc:0.81840                                                                 \n",
      "[65]\tvalidation_0-auc:0.92724\tvalidation_1-auc:0.81871                                                                 \n",
      "[66]\tvalidation_0-auc:0.92741\tvalidation_1-auc:0.81855                                                                 \n",
      "[67]\tvalidation_0-auc:0.92753\tvalidation_1-auc:0.81844                                                                 \n",
      "[68]\tvalidation_0-auc:0.92769\tvalidation_1-auc:0.81848                                                                 \n",
      "[69]\tvalidation_0-auc:0.92792\tvalidation_1-auc:0.81881                                                                 \n",
      "[70]\tvalidation_0-auc:0.92849\tvalidation_1-auc:0.81898                                                                 \n",
      "[71]\tvalidation_0-auc:0.92861\tvalidation_1-auc:0.81888                                                                 \n",
      "[72]\tvalidation_0-auc:0.92932\tvalidation_1-auc:0.81875                                                                 \n",
      "[73]\tvalidation_0-auc:0.92935\tvalidation_1-auc:0.81876                                                                 \n",
      "[74]\tvalidation_0-auc:0.92959\tvalidation_1-auc:0.81861                                                                 \n",
      "[75]\tvalidation_0-auc:0.93015\tvalidation_1-auc:0.81887                                                                 \n",
      "[76]\tvalidation_0-auc:0.93026\tvalidation_1-auc:0.81875                                                                 \n",
      "[77]\tvalidation_0-auc:0.93058\tvalidation_1-auc:0.81897                                                                 \n",
      "[78]\tvalidation_0-auc:0.93101\tvalidation_1-auc:0.81902                                                                 \n",
      "[79]\tvalidation_0-auc:0.93115\tvalidation_1-auc:0.81885                                                                 \n",
      "[80]\tvalidation_0-auc:0.93122\tvalidation_1-auc:0.81872                                                                 \n",
      "[81]\tvalidation_0-auc:0.93138\tvalidation_1-auc:0.81904                                                                 \n",
      "[82]\tvalidation_0-auc:0.93161\tvalidation_1-auc:0.81911                                                                 \n",
      "[83]\tvalidation_0-auc:0.93195\tvalidation_1-auc:0.81945                                                                 \n",
      "[84]\tvalidation_0-auc:0.93237\tvalidation_1-auc:0.81950                                                                 \n",
      "[85]\tvalidation_0-auc:0.93261\tvalidation_1-auc:0.81976                                                                 \n",
      "[86]\tvalidation_0-auc:0.93305\tvalidation_1-auc:0.82013                                                                 \n",
      "[87]\tvalidation_0-auc:0.93308\tvalidation_1-auc:0.82013                                                                 \n",
      "[88]\tvalidation_0-auc:0.93338\tvalidation_1-auc:0.82013                                                                 \n",
      "[89]\tvalidation_0-auc:0.93393\tvalidation_1-auc:0.82035                                                                 \n",
      "[90]\tvalidation_0-auc:0.93408\tvalidation_1-auc:0.82050                                                                 \n",
      "[91]\tvalidation_0-auc:0.93413\tvalidation_1-auc:0.82043                                                                 \n",
      "[92]\tvalidation_0-auc:0.93429\tvalidation_1-auc:0.82040                                                                 \n",
      "[93]\tvalidation_0-auc:0.93433\tvalidation_1-auc:0.82033                                                                 \n",
      "[94]\tvalidation_0-auc:0.93439\tvalidation_1-auc:0.82029                                                                 \n",
      "[95]\tvalidation_0-auc:0.93444\tvalidation_1-auc:0.82038                                                                 \n",
      "[96]\tvalidation_0-auc:0.93490\tvalidation_1-auc:0.82052                                                                 \n",
      "[97]\tvalidation_0-auc:0.93536\tvalidation_1-auc:0.82058                                                                 \n",
      "[98]\tvalidation_0-auc:0.93550\tvalidation_1-auc:0.82070                                                                 \n",
      "[99]\tvalidation_0-auc:0.93557\tvalidation_1-auc:0.82063                                                                 \n",
      "[0]\tvalidation_0-auc:0.78398\tvalidation_1-auc:0.73930                                                                  \n",
      "[1]\tvalidation_0-auc:0.81873\tvalidation_1-auc:0.76505                                                                  \n",
      "[2]\tvalidation_0-auc:0.85660\tvalidation_1-auc:0.81392                                                                  \n",
      "[3]\tvalidation_0-auc:0.85670\tvalidation_1-auc:0.80977                                                                  \n",
      "[4]\tvalidation_0-auc:0.85696\tvalidation_1-auc:0.80706                                                                  \n",
      "[5]\tvalidation_0-auc:0.85943\tvalidation_1-auc:0.80632                                                                  \n",
      "[6]\tvalidation_0-auc:0.87049\tvalidation_1-auc:0.81919                                                                  \n",
      "[7]\tvalidation_0-auc:0.86998\tvalidation_1-auc:0.81803                                                                  \n",
      "[8]\tvalidation_0-auc:0.87777\tvalidation_1-auc:0.82526                                                                  \n",
      "[9]\tvalidation_0-auc:0.87636\tvalidation_1-auc:0.82519                                                                  \n",
      "[10]\tvalidation_0-auc:0.88074\tvalidation_1-auc:0.82986                                                                 \n",
      "[11]\tvalidation_0-auc:0.88205\tvalidation_1-auc:0.82881                                                                 \n",
      "[12]\tvalidation_0-auc:0.88145\tvalidation_1-auc:0.82876                                                                 \n",
      "[13]\tvalidation_0-auc:0.88587\tvalidation_1-auc:0.83206                                                                 \n",
      "[14]\tvalidation_0-auc:0.88662\tvalidation_1-auc:0.83100                                                                 \n",
      "[15]\tvalidation_0-auc:0.88779\tvalidation_1-auc:0.83047                                                                 \n",
      "[16]\tvalidation_0-auc:0.88900\tvalidation_1-auc:0.82903                                                                 \n",
      "[17]\tvalidation_0-auc:0.88968\tvalidation_1-auc:0.82791                                                                 \n",
      "[18]\tvalidation_0-auc:0.89046\tvalidation_1-auc:0.82774                                                                 \n",
      "[19]\tvalidation_0-auc:0.89346\tvalidation_1-auc:0.83070                                                                 \n",
      "[20]\tvalidation_0-auc:0.89638\tvalidation_1-auc:0.83180                                                                 \n",
      "[21]\tvalidation_0-auc:0.89855\tvalidation_1-auc:0.83316                                                                 \n",
      "[22]\tvalidation_0-auc:0.89966\tvalidation_1-auc:0.83471                                                                 \n",
      "[23]\tvalidation_0-auc:0.90096\tvalidation_1-auc:0.83600                                                                 \n",
      "[24]\tvalidation_0-auc:0.90137\tvalidation_1-auc:0.83576                                                                 \n",
      "[25]\tvalidation_0-auc:0.90287\tvalidation_1-auc:0.83663                                                                 \n",
      "[26]\tvalidation_0-auc:0.90309\tvalidation_1-auc:0.83663                                                                 \n",
      "[27]\tvalidation_0-auc:0.90374\tvalidation_1-auc:0.83671                                                                 \n",
      "[28]\tvalidation_0-auc:0.90538\tvalidation_1-auc:0.83741                                                                 \n",
      "[29]\tvalidation_0-auc:0.90524\tvalidation_1-auc:0.83719                                                                 \n",
      "[30]\tvalidation_0-auc:0.90606\tvalidation_1-auc:0.83728                                                                 \n",
      "[31]\tvalidation_0-auc:0.90679\tvalidation_1-auc:0.83681                                                                 \n",
      "[32]\tvalidation_0-auc:0.90816\tvalidation_1-auc:0.83773                                                                 \n",
      "[33]\tvalidation_0-auc:0.90942\tvalidation_1-auc:0.83866                                                                 \n",
      "[34]\tvalidation_0-auc:0.91075\tvalidation_1-auc:0.83925                                                                 \n",
      "[35]\tvalidation_0-auc:0.91178\tvalidation_1-auc:0.83968                                                                 \n",
      "[36]\tvalidation_0-auc:0.91289\tvalidation_1-auc:0.83992                                                                 \n",
      "[37]\tvalidation_0-auc:0.91330\tvalidation_1-auc:0.83952                                                                 \n",
      "[38]\tvalidation_0-auc:0.91436\tvalidation_1-auc:0.84020                                                                 \n",
      "[39]\tvalidation_0-auc:0.91526\tvalidation_1-auc:0.84049                                                                 \n",
      "[40]\tvalidation_0-auc:0.91620\tvalidation_1-auc:0.84017                                                                 \n",
      "[41]\tvalidation_0-auc:0.91699\tvalidation_1-auc:0.84044                                                                 \n",
      "[42]\tvalidation_0-auc:0.91731\tvalidation_1-auc:0.84036                                                                 \n",
      "[43]\tvalidation_0-auc:0.91814\tvalidation_1-auc:0.84025                                                                 \n",
      "[44]\tvalidation_0-auc:0.91821\tvalidation_1-auc:0.84037                                                                 \n",
      "[45]\tvalidation_0-auc:0.91894\tvalidation_1-auc:0.84027                                                                 \n",
      "[46]\tvalidation_0-auc:0.91925\tvalidation_1-auc:0.84025                                                                 \n",
      "[47]\tvalidation_0-auc:0.91996\tvalidation_1-auc:0.84020                                                                 \n",
      "[48]\tvalidation_0-auc:0.92026\tvalidation_1-auc:0.84017                                                                 \n",
      "[49]\tvalidation_0-auc:0.92034\tvalidation_1-auc:0.84009                                                                 \n",
      "[50]\tvalidation_0-auc:0.92094\tvalidation_1-auc:0.83997                                                                 \n",
      "[51]\tvalidation_0-auc:0.92171\tvalidation_1-auc:0.84013                                                                 \n",
      "[52]\tvalidation_0-auc:0.92175\tvalidation_1-auc:0.84009                                                                 \n",
      "[53]\tvalidation_0-auc:0.92248\tvalidation_1-auc:0.84032                                                                 \n",
      "[54]\tvalidation_0-auc:0.92294\tvalidation_1-auc:0.84022                                                                 \n",
      "[55]\tvalidation_0-auc:0.92316\tvalidation_1-auc:0.84047                                                                 \n",
      "[56]\tvalidation_0-auc:0.92369\tvalidation_1-auc:0.84045                                                                 \n",
      "[57]\tvalidation_0-auc:0.92388\tvalidation_1-auc:0.84042                                                                 \n",
      "[58]\tvalidation_0-auc:0.92461\tvalidation_1-auc:0.84053                                                                 \n",
      "[59]\tvalidation_0-auc:0.92481\tvalidation_1-auc:0.84056                                                                 \n",
      "[60]\tvalidation_0-auc:0.92515\tvalidation_1-auc:0.84055                                                                 \n",
      "[61]\tvalidation_0-auc:0.92549\tvalidation_1-auc:0.84067                                                                 \n",
      "[62]\tvalidation_0-auc:0.92561\tvalidation_1-auc:0.84057                                                                 \n",
      "[63]\tvalidation_0-auc:0.92604\tvalidation_1-auc:0.84030                                                                 \n",
      "[64]\tvalidation_0-auc:0.92618\tvalidation_1-auc:0.84030                                                                 \n",
      "[65]\tvalidation_0-auc:0.92638\tvalidation_1-auc:0.84025                                                                 \n",
      "[66]\tvalidation_0-auc:0.92678\tvalidation_1-auc:0.84017                                                                 \n",
      "[67]\tvalidation_0-auc:0.92688\tvalidation_1-auc:0.84017                                                                 \n",
      "[68]\tvalidation_0-auc:0.92715\tvalidation_1-auc:0.84012                                                                 \n",
      "[69]\tvalidation_0-auc:0.92720\tvalidation_1-auc:0.84008                                                                 \n",
      "[70]\tvalidation_0-auc:0.92744\tvalidation_1-auc:0.84004                                                                 \n",
      "[71]\tvalidation_0-auc:0.92756\tvalidation_1-auc:0.84009                                                                 \n",
      "[72]\tvalidation_0-auc:0.92830\tvalidation_1-auc:0.84022                                                                 \n",
      "[73]\tvalidation_0-auc:0.92877\tvalidation_1-auc:0.84029                                                                 \n",
      "[74]\tvalidation_0-auc:0.92902\tvalidation_1-auc:0.84020                                                                 \n",
      "[75]\tvalidation_0-auc:0.92922\tvalidation_1-auc:0.84006                                                                 \n",
      "[76]\tvalidation_0-auc:0.92929\tvalidation_1-auc:0.84000                                                                 \n",
      "[77]\tvalidation_0-auc:0.92944\tvalidation_1-auc:0.83992                                                                 \n",
      "[78]\tvalidation_0-auc:0.92953\tvalidation_1-auc:0.83996                                                                 \n",
      "[79]\tvalidation_0-auc:0.92982\tvalidation_1-auc:0.83998                                                                 \n",
      "[80]\tvalidation_0-auc:0.92988\tvalidation_1-auc:0.83985                                                                 \n",
      "[81]\tvalidation_0-auc:0.93001\tvalidation_1-auc:0.83982                                                                 \n",
      "[82]\tvalidation_0-auc:0.93012\tvalidation_1-auc:0.83972                                                                 \n",
      "[83]\tvalidation_0-auc:0.93043\tvalidation_1-auc:0.83963                                                                 \n",
      "[84]\tvalidation_0-auc:0.93096\tvalidation_1-auc:0.83972                                                                 \n",
      "[85]\tvalidation_0-auc:0.93115\tvalidation_1-auc:0.83984                                                                 \n",
      "[86]\tvalidation_0-auc:0.93142\tvalidation_1-auc:0.83976                                                                 \n",
      "[87]\tvalidation_0-auc:0.93148\tvalidation_1-auc:0.83968                                                                 \n",
      "[88]\tvalidation_0-auc:0.93166\tvalidation_1-auc:0.83973                                                                 \n",
      "[89]\tvalidation_0-auc:0.93186\tvalidation_1-auc:0.83970                                                                 \n",
      "[90]\tvalidation_0-auc:0.93211\tvalidation_1-auc:0.83975                                                                 \n",
      "[0]\tvalidation_0-auc:0.79762\tvalidation_1-auc:0.72851                                                                  \n",
      "[1]\tvalidation_0-auc:0.82938\tvalidation_1-auc:0.75042                                                                  \n",
      "[2]\tvalidation_0-auc:0.86023\tvalidation_1-auc:0.80175                                                                  \n",
      "[3]\tvalidation_0-auc:0.86001\tvalidation_1-auc:0.79781                                                                  \n",
      "[4]\tvalidation_0-auc:0.85917\tvalidation_1-auc:0.79482                                                                  \n",
      "[5]\tvalidation_0-auc:0.86061\tvalidation_1-auc:0.79424                                                                  \n",
      "[6]\tvalidation_0-auc:0.86981\tvalidation_1-auc:0.80614                                                                  \n",
      "[7]\tvalidation_0-auc:0.87008\tvalidation_1-auc:0.80469                                                                  \n",
      "[8]\tvalidation_0-auc:0.87711\tvalidation_1-auc:0.81062                                                                  \n",
      "[9]\tvalidation_0-auc:0.87632\tvalidation_1-auc:0.81044                                                                  \n",
      "[10]\tvalidation_0-auc:0.88098\tvalidation_1-auc:0.81497                                                                 \n",
      "[11]\tvalidation_0-auc:0.88218\tvalidation_1-auc:0.81424                                                                 \n",
      "[12]\tvalidation_0-auc:0.88171\tvalidation_1-auc:0.81385                                                                 \n",
      "[13]\tvalidation_0-auc:0.88624\tvalidation_1-auc:0.81681                                                                 \n",
      "[14]\tvalidation_0-auc:0.88752\tvalidation_1-auc:0.81549                                                                 \n",
      "[15]\tvalidation_0-auc:0.88853\tvalidation_1-auc:0.81407                                                                 \n",
      "[16]\tvalidation_0-auc:0.88955\tvalidation_1-auc:0.81298                                                                 \n",
      "[17]\tvalidation_0-auc:0.89001\tvalidation_1-auc:0.81225                                                                 \n",
      "[18]\tvalidation_0-auc:0.89036\tvalidation_1-auc:0.81204                                                                 \n",
      "[19]\tvalidation_0-auc:0.89292\tvalidation_1-auc:0.81496                                                                 \n",
      "[20]\tvalidation_0-auc:0.89553\tvalidation_1-auc:0.81761                                                                 \n",
      "[21]\tvalidation_0-auc:0.89762\tvalidation_1-auc:0.82031                                                                 \n",
      "[22]\tvalidation_0-auc:0.89869\tvalidation_1-auc:0.82241                                                                 \n",
      "[23]\tvalidation_0-auc:0.90002\tvalidation_1-auc:0.82393                                                                 \n",
      "[24]\tvalidation_0-auc:0.90054\tvalidation_1-auc:0.82353                                                                 \n",
      "[25]\tvalidation_0-auc:0.90233\tvalidation_1-auc:0.82463                                                                 \n",
      "[26]\tvalidation_0-auc:0.90229\tvalidation_1-auc:0.82415                                                                 \n",
      "[27]\tvalidation_0-auc:0.90281\tvalidation_1-auc:0.82385                                                                 \n",
      "[28]\tvalidation_0-auc:0.90484\tvalidation_1-auc:0.82527                                                                 \n",
      "[29]\tvalidation_0-auc:0.90476\tvalidation_1-auc:0.82528                                                                 \n",
      "[30]\tvalidation_0-auc:0.90534\tvalidation_1-auc:0.82462                                                                 \n",
      "[31]\tvalidation_0-auc:0.90650\tvalidation_1-auc:0.82462                                                                 \n",
      "[32]\tvalidation_0-auc:0.90848\tvalidation_1-auc:0.82522                                                                 \n",
      "[33]\tvalidation_0-auc:0.90986\tvalidation_1-auc:0.82613                                                                 \n",
      "[34]\tvalidation_0-auc:0.91118\tvalidation_1-auc:0.82745                                                                 \n",
      "[35]\tvalidation_0-auc:0.91264\tvalidation_1-auc:0.82813                                                                 \n",
      "[36]\tvalidation_0-auc:0.91430\tvalidation_1-auc:0.82872                                                                 \n",
      "[37]\tvalidation_0-auc:0.91502\tvalidation_1-auc:0.82857                                                                 \n",
      "[38]\tvalidation_0-auc:0.91572\tvalidation_1-auc:0.82929                                                                 \n",
      "[39]\tvalidation_0-auc:0.91642\tvalidation_1-auc:0.83013                                                                 \n",
      "[40]\tvalidation_0-auc:0.91668\tvalidation_1-auc:0.83001                                                                 \n",
      "[41]\tvalidation_0-auc:0.91775\tvalidation_1-auc:0.83068                                                                 \n",
      "[42]\tvalidation_0-auc:0.91823\tvalidation_1-auc:0.83082                                                                 \n",
      "[43]\tvalidation_0-auc:0.91874\tvalidation_1-auc:0.83053                                                                 \n",
      "[44]\tvalidation_0-auc:0.91910\tvalidation_1-auc:0.83044                                                                 \n",
      "[45]\tvalidation_0-auc:0.92004\tvalidation_1-auc:0.83068                                                                 \n",
      "[46]\tvalidation_0-auc:0.92025\tvalidation_1-auc:0.83044                                                                 \n",
      "[47]\tvalidation_0-auc:0.92079\tvalidation_1-auc:0.83029                                                                 \n",
      "[48]\tvalidation_0-auc:0.92109\tvalidation_1-auc:0.83011                                                                 \n",
      "[49]\tvalidation_0-auc:0.92122\tvalidation_1-auc:0.83035                                                                 \n",
      "[50]\tvalidation_0-auc:0.92159\tvalidation_1-auc:0.83043                                                                 \n",
      "[51]\tvalidation_0-auc:0.92237\tvalidation_1-auc:0.83100                                                                 \n",
      "[52]\tvalidation_0-auc:0.92258\tvalidation_1-auc:0.83105                                                                 \n",
      "[53]\tvalidation_0-auc:0.92315\tvalidation_1-auc:0.83161                                                                 \n",
      "[54]\tvalidation_0-auc:0.92341\tvalidation_1-auc:0.83154                                                                 \n",
      "[55]\tvalidation_0-auc:0.92387\tvalidation_1-auc:0.83216                                                                 \n",
      "[56]\tvalidation_0-auc:0.92417\tvalidation_1-auc:0.83203                                                                 \n",
      "[57]\tvalidation_0-auc:0.92427\tvalidation_1-auc:0.83194                                                                 \n",
      "[58]\tvalidation_0-auc:0.92491\tvalidation_1-auc:0.83265                                                                 \n",
      "[59]\tvalidation_0-auc:0.92535\tvalidation_1-auc:0.83287                                                                 \n",
      "[60]\tvalidation_0-auc:0.92563\tvalidation_1-auc:0.83289                                                                 \n",
      "[61]\tvalidation_0-auc:0.92616\tvalidation_1-auc:0.83344                                                                 \n",
      "[62]\tvalidation_0-auc:0.92635\tvalidation_1-auc:0.83344                                                                 \n",
      "[63]\tvalidation_0-auc:0.92654\tvalidation_1-auc:0.83346                                                                 \n",
      "[64]\tvalidation_0-auc:0.92678\tvalidation_1-auc:0.83340                                                                 \n",
      "[65]\tvalidation_0-auc:0.92710\tvalidation_1-auc:0.83365                                                                 \n",
      "[66]\tvalidation_0-auc:0.92717\tvalidation_1-auc:0.83366                                                                 \n",
      "[67]\tvalidation_0-auc:0.92727\tvalidation_1-auc:0.83370                                                                 \n",
      "[68]\tvalidation_0-auc:0.92748\tvalidation_1-auc:0.83358                                                                 \n",
      "[69]\tvalidation_0-auc:0.92764\tvalidation_1-auc:0.83400                                                                 \n",
      "[70]\tvalidation_0-auc:0.92797\tvalidation_1-auc:0.83432                                                                 \n",
      "[71]\tvalidation_0-auc:0.92805\tvalidation_1-auc:0.83427                                                                 \n",
      "[72]\tvalidation_0-auc:0.92847\tvalidation_1-auc:0.83434                                                                 \n",
      "[73]\tvalidation_0-auc:0.92872\tvalidation_1-auc:0.83416                                                                 \n",
      "[74]\tvalidation_0-auc:0.92877\tvalidation_1-auc:0.83420                                                                 \n",
      "[75]\tvalidation_0-auc:0.92903\tvalidation_1-auc:0.83440                                                                 \n",
      "[76]\tvalidation_0-auc:0.92921\tvalidation_1-auc:0.83435                                                                 \n",
      "[77]\tvalidation_0-auc:0.92960\tvalidation_1-auc:0.83461                                                                 \n",
      "[78]\tvalidation_0-auc:0.92968\tvalidation_1-auc:0.83484                                                                 \n",
      "[79]\tvalidation_0-auc:0.92977\tvalidation_1-auc:0.83484                                                                 \n",
      "[80]\tvalidation_0-auc:0.92989\tvalidation_1-auc:0.83481                                                                 \n",
      "[81]\tvalidation_0-auc:0.93006\tvalidation_1-auc:0.83517                                                                 \n",
      "[82]\tvalidation_0-auc:0.93013\tvalidation_1-auc:0.83518                                                                 \n",
      "[83]\tvalidation_0-auc:0.93045\tvalidation_1-auc:0.83546                                                                 \n",
      "[84]\tvalidation_0-auc:0.93074\tvalidation_1-auc:0.83557                                                                 \n",
      "[85]\tvalidation_0-auc:0.93111\tvalidation_1-auc:0.83575                                                                 \n",
      "[86]\tvalidation_0-auc:0.93153\tvalidation_1-auc:0.83593                                                                 \n",
      "[87]\tvalidation_0-auc:0.93164\tvalidation_1-auc:0.83590                                                                 \n",
      "[88]\tvalidation_0-auc:0.93199\tvalidation_1-auc:0.83604                                                                 \n",
      "[89]\tvalidation_0-auc:0.93259\tvalidation_1-auc:0.83619                                                                 \n",
      "[90]\tvalidation_0-auc:0.93308\tvalidation_1-auc:0.83652                                                                 \n",
      "[91]\tvalidation_0-auc:0.93322\tvalidation_1-auc:0.83654                                                                 \n",
      "[92]\tvalidation_0-auc:0.93343\tvalidation_1-auc:0.83645                                                                 \n",
      "[93]\tvalidation_0-auc:0.93375\tvalidation_1-auc:0.83642                                                                 \n",
      "[94]\tvalidation_0-auc:0.93384\tvalidation_1-auc:0.83645                                                                 \n",
      "[95]\tvalidation_0-auc:0.93399\tvalidation_1-auc:0.83646                                                                 \n",
      "[96]\tvalidation_0-auc:0.93457\tvalidation_1-auc:0.83650                                                                 \n",
      "[97]\tvalidation_0-auc:0.93485\tvalidation_1-auc:0.83638                                                                 \n",
      "[98]\tvalidation_0-auc:0.93509\tvalidation_1-auc:0.83644                                                                 \n",
      "[99]\tvalidation_0-auc:0.93514\tvalidation_1-auc:0.83645                                                                 \n",
      "[0]\tvalidation_0-auc:0.87035\tvalidation_1-auc:0.79950                                                                  \n",
      "[1]\tvalidation_0-auc:0.88138\tvalidation_1-auc:0.79767                                                                  \n",
      "[2]\tvalidation_0-auc:0.88807\tvalidation_1-auc:0.80846                                                                  \n",
      "[3]\tvalidation_0-auc:0.88895\tvalidation_1-auc:0.80285                                                                  \n",
      "[4]\tvalidation_0-auc:0.89020\tvalidation_1-auc:0.79949                                                                  \n",
      "[5]\tvalidation_0-auc:0.89788\tvalidation_1-auc:0.80479                                                                  \n",
      "[6]\tvalidation_0-auc:0.90327\tvalidation_1-auc:0.80787                                                                  \n",
      "[7]\tvalidation_0-auc:0.90495\tvalidation_1-auc:0.80768                                                                  \n",
      "[8]\tvalidation_0-auc:0.90929\tvalidation_1-auc:0.80929                                                                  \n",
      "[9]\tvalidation_0-auc:0.91015\tvalidation_1-auc:0.80675                                                                  \n",
      "[10]\tvalidation_0-auc:0.91412\tvalidation_1-auc:0.80953                                                                 \n",
      "[11]\tvalidation_0-auc:0.91572\tvalidation_1-auc:0.80903                                                                 \n",
      "[12]\tvalidation_0-auc:0.91968\tvalidation_1-auc:0.81163                                                                 \n",
      "[13]\tvalidation_0-auc:0.92271\tvalidation_1-auc:0.81209                                                                 \n",
      "[14]\tvalidation_0-auc:0.92390\tvalidation_1-auc:0.81157                                                                 \n",
      "[15]\tvalidation_0-auc:0.92590\tvalidation_1-auc:0.81265                                                                 \n",
      "[16]\tvalidation_0-auc:0.92756\tvalidation_1-auc:0.81319                                                                 \n",
      "[17]\tvalidation_0-auc:0.92932\tvalidation_1-auc:0.81253                                                                 \n",
      "[18]\tvalidation_0-auc:0.93049\tvalidation_1-auc:0.81170                                                                 \n",
      "[19]\tvalidation_0-auc:0.93235\tvalidation_1-auc:0.81281                                                                 \n",
      "[20]\tvalidation_0-auc:0.93460\tvalidation_1-auc:0.81297                                                                 \n",
      "[21]\tvalidation_0-auc:0.93593\tvalidation_1-auc:0.81369                                                                 \n",
      "[22]\tvalidation_0-auc:0.93641\tvalidation_1-auc:0.81431                                                                 \n",
      "[23]\tvalidation_0-auc:0.93718\tvalidation_1-auc:0.81484                                                                 \n",
      "[24]\tvalidation_0-auc:0.93799\tvalidation_1-auc:0.81476                                                                 \n",
      "[25]\tvalidation_0-auc:0.93897\tvalidation_1-auc:0.81498                                                                 \n",
      "[26]\tvalidation_0-auc:0.93986\tvalidation_1-auc:0.81506                                                                 \n",
      "[27]\tvalidation_0-auc:0.94001\tvalidation_1-auc:0.81466                                                                 \n",
      "[28]\tvalidation_0-auc:0.94076\tvalidation_1-auc:0.81508                                                                 \n",
      "[29]\tvalidation_0-auc:0.94085\tvalidation_1-auc:0.81491                                                                 \n",
      "[30]\tvalidation_0-auc:0.94211\tvalidation_1-auc:0.81492                                                                 \n",
      "[31]\tvalidation_0-auc:0.94258\tvalidation_1-auc:0.81485                                                                 \n",
      "[32]\tvalidation_0-auc:0.94329\tvalidation_1-auc:0.81545                                                                 \n",
      "[33]\tvalidation_0-auc:0.94385\tvalidation_1-auc:0.81557                                                                 \n",
      "[34]\tvalidation_0-auc:0.94451\tvalidation_1-auc:0.81565                                                                 \n",
      "[35]\tvalidation_0-auc:0.94556\tvalidation_1-auc:0.81582                                                                 \n",
      "[36]\tvalidation_0-auc:0.94589\tvalidation_1-auc:0.81549                                                                 \n",
      "[37]\tvalidation_0-auc:0.94664\tvalidation_1-auc:0.81542                                                                 \n",
      "[38]\tvalidation_0-auc:0.94736\tvalidation_1-auc:0.81493                                                                 \n",
      "[39]\tvalidation_0-auc:0.94772\tvalidation_1-auc:0.81479                                                                 \n",
      "[40]\tvalidation_0-auc:0.94780\tvalidation_1-auc:0.81458                                                                 \n",
      "[41]\tvalidation_0-auc:0.94793\tvalidation_1-auc:0.81447                                                                 \n",
      "[42]\tvalidation_0-auc:0.94812\tvalidation_1-auc:0.81413                                                                 \n",
      "[43]\tvalidation_0-auc:0.94822\tvalidation_1-auc:0.81421                                                                 \n",
      "[44]\tvalidation_0-auc:0.94833\tvalidation_1-auc:0.81395                                                                 \n",
      "[45]\tvalidation_0-auc:0.94887\tvalidation_1-auc:0.81378                                                                 \n",
      "[46]\tvalidation_0-auc:0.94893\tvalidation_1-auc:0.81345                                                                 \n",
      "[47]\tvalidation_0-auc:0.94899\tvalidation_1-auc:0.81356                                                                 \n",
      "[48]\tvalidation_0-auc:0.94907\tvalidation_1-auc:0.81341                                                                 \n",
      "[49]\tvalidation_0-auc:0.94985\tvalidation_1-auc:0.81284                                                                 \n",
      "[50]\tvalidation_0-auc:0.95081\tvalidation_1-auc:0.81233                                                                 \n",
      "[51]\tvalidation_0-auc:0.95141\tvalidation_1-auc:0.81259                                                                 \n",
      "[52]\tvalidation_0-auc:0.95172\tvalidation_1-auc:0.81265                                                                 \n",
      "[53]\tvalidation_0-auc:0.95197\tvalidation_1-auc:0.81238                                                                 \n",
      "[54]\tvalidation_0-auc:0.95220\tvalidation_1-auc:0.81247                                                                 \n",
      "[55]\tvalidation_0-auc:0.95244\tvalidation_1-auc:0.81262                                                                 \n",
      "[56]\tvalidation_0-auc:0.95265\tvalidation_1-auc:0.81280                                                                 \n",
      "[57]\tvalidation_0-auc:0.95342\tvalidation_1-auc:0.81264                                                                 \n",
      "[58]\tvalidation_0-auc:0.95434\tvalidation_1-auc:0.81254                                                                 \n",
      "[59]\tvalidation_0-auc:0.95441\tvalidation_1-auc:0.81228                                                                 \n",
      "[60]\tvalidation_0-auc:0.95447\tvalidation_1-auc:0.81205                                                                 \n",
      "[61]\tvalidation_0-auc:0.95481\tvalidation_1-auc:0.81180                                                                 \n",
      "[62]\tvalidation_0-auc:0.95512\tvalidation_1-auc:0.81146                                                                 \n",
      "[63]\tvalidation_0-auc:0.95532\tvalidation_1-auc:0.81123                                                                 \n",
      "[64]\tvalidation_0-auc:0.95542\tvalidation_1-auc:0.81129                                                                 \n",
      "[65]\tvalidation_0-auc:0.95656\tvalidation_1-auc:0.81072                                                                 \n",
      "[0]\tvalidation_0-auc:0.85962\tvalidation_1-auc:0.80899                                                                  \n",
      "[1]\tvalidation_0-auc:0.87453\tvalidation_1-auc:0.81781                                                                  \n",
      "[2]\tvalidation_0-auc:0.88412\tvalidation_1-auc:0.83004                                                                  \n",
      "[3]\tvalidation_0-auc:0.88438\tvalidation_1-auc:0.82944                                                                  \n",
      "[4]\tvalidation_0-auc:0.88580\tvalidation_1-auc:0.82726                                                                  \n",
      "[5]\tvalidation_0-auc:0.89632\tvalidation_1-auc:0.83258                                                                  \n",
      "[6]\tvalidation_0-auc:0.90426\tvalidation_1-auc:0.83576                                                                  \n",
      "[7]\tvalidation_0-auc:0.90658\tvalidation_1-auc:0.83571                                                                  \n",
      "[8]\tvalidation_0-auc:0.91134\tvalidation_1-auc:0.83687                                                                  \n",
      "[9]\tvalidation_0-auc:0.91350\tvalidation_1-auc:0.83630                                                                  \n",
      "[10]\tvalidation_0-auc:0.91657\tvalidation_1-auc:0.83822                                                                 \n",
      "[11]\tvalidation_0-auc:0.91826\tvalidation_1-auc:0.83708                                                                 \n",
      "[12]\tvalidation_0-auc:0.92197\tvalidation_1-auc:0.83748                                                                 \n",
      "[13]\tvalidation_0-auc:0.92565\tvalidation_1-auc:0.83747                                                                 \n",
      "[14]\tvalidation_0-auc:0.92713\tvalidation_1-auc:0.83760                                                                 \n",
      "[15]\tvalidation_0-auc:0.92889\tvalidation_1-auc:0.83738                                                                 \n",
      "[16]\tvalidation_0-auc:0.93036\tvalidation_1-auc:0.83707                                                                 \n",
      "[17]\tvalidation_0-auc:0.93185\tvalidation_1-auc:0.83703                                                                 \n",
      "[18]\tvalidation_0-auc:0.93332\tvalidation_1-auc:0.83697                                                                 \n",
      "[19]\tvalidation_0-auc:0.93434\tvalidation_1-auc:0.83676                                                                 \n",
      "[20]\tvalidation_0-auc:0.93597\tvalidation_1-auc:0.83629                                                                 \n",
      "[21]\tvalidation_0-auc:0.93658\tvalidation_1-auc:0.83579                                                                 \n",
      "[22]\tvalidation_0-auc:0.93686\tvalidation_1-auc:0.83585                                                                 \n",
      "[23]\tvalidation_0-auc:0.93760\tvalidation_1-auc:0.83633                                                                 \n",
      "[24]\tvalidation_0-auc:0.93801\tvalidation_1-auc:0.83649                                                                 \n",
      "[25]\tvalidation_0-auc:0.93896\tvalidation_1-auc:0.83607                                                                 \n",
      "[26]\tvalidation_0-auc:0.93943\tvalidation_1-auc:0.83594                                                                 \n",
      "[27]\tvalidation_0-auc:0.93980\tvalidation_1-auc:0.83590                                                                 \n",
      "[28]\tvalidation_0-auc:0.94081\tvalidation_1-auc:0.83599                                                                 \n",
      "[29]\tvalidation_0-auc:0.94125\tvalidation_1-auc:0.83580                                                                 \n",
      "[30]\tvalidation_0-auc:0.94190\tvalidation_1-auc:0.83543                                                                 \n",
      "[31]\tvalidation_0-auc:0.94286\tvalidation_1-auc:0.83550                                                                 \n",
      "[32]\tvalidation_0-auc:0.94354\tvalidation_1-auc:0.83513                                                                 \n",
      "[33]\tvalidation_0-auc:0.94379\tvalidation_1-auc:0.83495                                                                 \n",
      "[34]\tvalidation_0-auc:0.94423\tvalidation_1-auc:0.83490                                                                 \n",
      "[35]\tvalidation_0-auc:0.94491\tvalidation_1-auc:0.83481                                                                 \n",
      "[36]\tvalidation_0-auc:0.94558\tvalidation_1-auc:0.83473                                                                 \n",
      "[37]\tvalidation_0-auc:0.94606\tvalidation_1-auc:0.83426                                                                 \n",
      "[38]\tvalidation_0-auc:0.94658\tvalidation_1-auc:0.83409                                                                 \n",
      "[39]\tvalidation_0-auc:0.94694\tvalidation_1-auc:0.83383                                                                 \n",
      "[40]\tvalidation_0-auc:0.94709\tvalidation_1-auc:0.83372                                                                 \n",
      "[0]\tvalidation_0-auc:0.86205\tvalidation_1-auc:0.80565                                                                  \n",
      "[1]\tvalidation_0-auc:0.87674\tvalidation_1-auc:0.80613                                                                  \n",
      "[2]\tvalidation_0-auc:0.88375\tvalidation_1-auc:0.81906                                                                  \n",
      "[3]\tvalidation_0-auc:0.88644\tvalidation_1-auc:0.81416                                                                  \n",
      "[4]\tvalidation_0-auc:0.88672\tvalidation_1-auc:0.80988                                                                  \n",
      "[5]\tvalidation_0-auc:0.89414\tvalidation_1-auc:0.81621                                                                  \n",
      "[6]\tvalidation_0-auc:0.90005\tvalidation_1-auc:0.81986                                                                  \n",
      "[7]\tvalidation_0-auc:0.90400\tvalidation_1-auc:0.81895                                                                  \n",
      "[8]\tvalidation_0-auc:0.90880\tvalidation_1-auc:0.82225                                                                  \n",
      "[9]\tvalidation_0-auc:0.91005\tvalidation_1-auc:0.82081                                                                  \n",
      "[10]\tvalidation_0-auc:0.91320\tvalidation_1-auc:0.82348                                                                 \n",
      "[11]\tvalidation_0-auc:0.91594\tvalidation_1-auc:0.82289                                                                 \n",
      "[12]\tvalidation_0-auc:0.91978\tvalidation_1-auc:0.82510                                                                 \n",
      "[13]\tvalidation_0-auc:0.92273\tvalidation_1-auc:0.82628                                                                 \n",
      "[14]\tvalidation_0-auc:0.92555\tvalidation_1-auc:0.82553                                                                 \n",
      "[15]\tvalidation_0-auc:0.92743\tvalidation_1-auc:0.82767                                                                 \n",
      "[16]\tvalidation_0-auc:0.92846\tvalidation_1-auc:0.82812                                                                 \n",
      "[17]\tvalidation_0-auc:0.93108\tvalidation_1-auc:0.82749                                                                 \n",
      "[18]\tvalidation_0-auc:0.93212\tvalidation_1-auc:0.82764                                                                 \n",
      "[19]\tvalidation_0-auc:0.93378\tvalidation_1-auc:0.82863                                                                 \n",
      "[20]\tvalidation_0-auc:0.93509\tvalidation_1-auc:0.82893                                                                 \n",
      "[21]\tvalidation_0-auc:0.93572\tvalidation_1-auc:0.82994                                                                 \n",
      "[22]\tvalidation_0-auc:0.93727\tvalidation_1-auc:0.83058                                                                 \n",
      "[23]\tvalidation_0-auc:0.93786\tvalidation_1-auc:0.83140                                                                 \n",
      "[24]\tvalidation_0-auc:0.93823\tvalidation_1-auc:0.83212                                                                 \n",
      "[25]\tvalidation_0-auc:0.93926\tvalidation_1-auc:0.83253                                                                 \n",
      "[26]\tvalidation_0-auc:0.94004\tvalidation_1-auc:0.83244                                                                 \n",
      "[27]\tvalidation_0-auc:0.94060\tvalidation_1-auc:0.83206                                                                 \n",
      "[28]\tvalidation_0-auc:0.94217\tvalidation_1-auc:0.83239                                                                 \n",
      "[29]\tvalidation_0-auc:0.94225\tvalidation_1-auc:0.83238                                                                 \n",
      "[30]\tvalidation_0-auc:0.94274\tvalidation_1-auc:0.83228                                                                 \n",
      "[31]\tvalidation_0-auc:0.94325\tvalidation_1-auc:0.83218                                                                 \n",
      "[32]\tvalidation_0-auc:0.94437\tvalidation_1-auc:0.83227                                                                 \n",
      "[33]\tvalidation_0-auc:0.94567\tvalidation_1-auc:0.83207                                                                 \n",
      "[34]\tvalidation_0-auc:0.94619\tvalidation_1-auc:0.83233                                                                 \n",
      "[35]\tvalidation_0-auc:0.94697\tvalidation_1-auc:0.83219                                                                 \n",
      "[36]\tvalidation_0-auc:0.94755\tvalidation_1-auc:0.83222                                                                 \n",
      "[37]\tvalidation_0-auc:0.94808\tvalidation_1-auc:0.83215                                                                 \n",
      "[38]\tvalidation_0-auc:0.94845\tvalidation_1-auc:0.83221                                                                 \n",
      "[39]\tvalidation_0-auc:0.94911\tvalidation_1-auc:0.83258                                                                 \n",
      "[40]\tvalidation_0-auc:0.94934\tvalidation_1-auc:0.83255                                                                 \n",
      "[41]\tvalidation_0-auc:0.94981\tvalidation_1-auc:0.83232                                                                 \n",
      "[42]\tvalidation_0-auc:0.94995\tvalidation_1-auc:0.83220                                                                 \n",
      "[43]\tvalidation_0-auc:0.95056\tvalidation_1-auc:0.83192                                                                 \n",
      "[44]\tvalidation_0-auc:0.95062\tvalidation_1-auc:0.83183                                                                 \n",
      "[45]\tvalidation_0-auc:0.95239\tvalidation_1-auc:0.83101                                                                 \n",
      "[46]\tvalidation_0-auc:0.95276\tvalidation_1-auc:0.83077                                                                 \n",
      "[47]\tvalidation_0-auc:0.95335\tvalidation_1-auc:0.83036                                                                 \n",
      "[48]\tvalidation_0-auc:0.95378\tvalidation_1-auc:0.82996                                                                 \n",
      "[49]\tvalidation_0-auc:0.95381\tvalidation_1-auc:0.83003                                                                 \n",
      "[50]\tvalidation_0-auc:0.95425\tvalidation_1-auc:0.82997                                                                 \n",
      "[51]\tvalidation_0-auc:0.95499\tvalidation_1-auc:0.82958                                                                 \n",
      "[52]\tvalidation_0-auc:0.95524\tvalidation_1-auc:0.82940                                                                 \n",
      "[53]\tvalidation_0-auc:0.95539\tvalidation_1-auc:0.82942                                                                 \n",
      "[54]\tvalidation_0-auc:0.95544\tvalidation_1-auc:0.82937                                                                 \n",
      "[55]\tvalidation_0-auc:0.95565\tvalidation_1-auc:0.82926                                                                 \n",
      "[56]\tvalidation_0-auc:0.95613\tvalidation_1-auc:0.82897                                                                 \n",
      "[57]\tvalidation_0-auc:0.95685\tvalidation_1-auc:0.82877                                                                 \n",
      "[58]\tvalidation_0-auc:0.95699\tvalidation_1-auc:0.82868                                                                 \n",
      "[59]\tvalidation_0-auc:0.95704\tvalidation_1-auc:0.82879                                                                 \n",
      "[60]\tvalidation_0-auc:0.95729\tvalidation_1-auc:0.82806                                                                 \n",
      "[61]\tvalidation_0-auc:0.95738\tvalidation_1-auc:0.82803                                                                 \n",
      "[62]\tvalidation_0-auc:0.95769\tvalidation_1-auc:0.82808                                                                 \n",
      "[63]\tvalidation_0-auc:0.95809\tvalidation_1-auc:0.82801                                                                 \n",
      "[64]\tvalidation_0-auc:0.95816\tvalidation_1-auc:0.82800                                                                 \n",
      "[65]\tvalidation_0-auc:0.95832\tvalidation_1-auc:0.82809                                                                 \n",
      "[66]\tvalidation_0-auc:0.95911\tvalidation_1-auc:0.82809                                                                 \n",
      "[67]\tvalidation_0-auc:0.95915\tvalidation_1-auc:0.82805                                                                 \n",
      "[68]\tvalidation_0-auc:0.95925\tvalidation_1-auc:0.82807                                                                 \n",
      "[69]\tvalidation_0-auc:0.95934\tvalidation_1-auc:0.82800                                                                 \n",
      "[0]\tvalidation_0-auc:0.86258\tvalidation_1-auc:0.80289                                                                  \n",
      "[1]\tvalidation_0-auc:0.87230\tvalidation_1-auc:0.79869                                                                  \n",
      "[2]\tvalidation_0-auc:0.87721\tvalidation_1-auc:0.80937                                                                  \n",
      "[3]\tvalidation_0-auc:0.87737\tvalidation_1-auc:0.80404                                                                  \n",
      "[4]\tvalidation_0-auc:0.87652\tvalidation_1-auc:0.79888                                                                  \n",
      "[5]\tvalidation_0-auc:0.87677\tvalidation_1-auc:0.79975                                                                  \n",
      "[6]\tvalidation_0-auc:0.88220\tvalidation_1-auc:0.80652                                                                  \n",
      "[7]\tvalidation_0-auc:0.88287\tvalidation_1-auc:0.80388                                                                  \n",
      "[8]\tvalidation_0-auc:0.88680\tvalidation_1-auc:0.80708                                                                  \n",
      "[9]\tvalidation_0-auc:0.88624\tvalidation_1-auc:0.80541                                                                  \n",
      "[10]\tvalidation_0-auc:0.88891\tvalidation_1-auc:0.80791                                                                 \n",
      "[11]\tvalidation_0-auc:0.89007\tvalidation_1-auc:0.80674                                                                 \n",
      "[12]\tvalidation_0-auc:0.89101\tvalidation_1-auc:0.80443                                                                 \n",
      "[13]\tvalidation_0-auc:0.89414\tvalidation_1-auc:0.80744                                                                 \n",
      "[14]\tvalidation_0-auc:0.89494\tvalidation_1-auc:0.80648                                                                 \n",
      "[15]\tvalidation_0-auc:0.89745\tvalidation_1-auc:0.80809                                                                 \n",
      "[16]\tvalidation_0-auc:0.89783\tvalidation_1-auc:0.80705                                                                 \n",
      "[17]\tvalidation_0-auc:0.89783\tvalidation_1-auc:0.80625                                                                 \n",
      "[18]\tvalidation_0-auc:0.89832\tvalidation_1-auc:0.80520                                                                 \n",
      "[19]\tvalidation_0-auc:0.90037\tvalidation_1-auc:0.80776                                                                 \n",
      "[20]\tvalidation_0-auc:0.90242\tvalidation_1-auc:0.80914                                                                 \n",
      "[21]\tvalidation_0-auc:0.90374\tvalidation_1-auc:0.81042                                                                 \n",
      "[22]\tvalidation_0-auc:0.90491\tvalidation_1-auc:0.81178                                                                 \n",
      "[23]\tvalidation_0-auc:0.90584\tvalidation_1-auc:0.81298                                                                 \n",
      "[24]\tvalidation_0-auc:0.90697\tvalidation_1-auc:0.81411                                                                 \n",
      "[25]\tvalidation_0-auc:0.90823\tvalidation_1-auc:0.81510                                                                 \n",
      "[26]\tvalidation_0-auc:0.90838\tvalidation_1-auc:0.81458                                                                 \n",
      "[27]\tvalidation_0-auc:0.90887\tvalidation_1-auc:0.81399                                                                 \n",
      "[28]\tvalidation_0-auc:0.90991\tvalidation_1-auc:0.81504                                                                 \n",
      "[29]\tvalidation_0-auc:0.90986\tvalidation_1-auc:0.81451                                                                 \n",
      "[30]\tvalidation_0-auc:0.91066\tvalidation_1-auc:0.81396                                                                 \n",
      "[31]\tvalidation_0-auc:0.91154\tvalidation_1-auc:0.81369                                                                 \n",
      "[32]\tvalidation_0-auc:0.91261\tvalidation_1-auc:0.81434                                                                 \n",
      "[33]\tvalidation_0-auc:0.91370\tvalidation_1-auc:0.81519                                                                 \n",
      "[34]\tvalidation_0-auc:0.91459\tvalidation_1-auc:0.81600                                                                 \n",
      "[35]\tvalidation_0-auc:0.91548\tvalidation_1-auc:0.81601                                                                 \n",
      "[36]\tvalidation_0-auc:0.91648\tvalidation_1-auc:0.81626                                                                 \n",
      "[37]\tvalidation_0-auc:0.91743\tvalidation_1-auc:0.81667                                                                 \n",
      "[38]\tvalidation_0-auc:0.91825\tvalidation_1-auc:0.81686                                                                 \n",
      "[39]\tvalidation_0-auc:0.91899\tvalidation_1-auc:0.81729                                                                 \n",
      "[40]\tvalidation_0-auc:0.91941\tvalidation_1-auc:0.81705                                                                 \n",
      "[41]\tvalidation_0-auc:0.92028\tvalidation_1-auc:0.81738                                                                 \n",
      "[42]\tvalidation_0-auc:0.92047\tvalidation_1-auc:0.81730                                                                 \n",
      "[43]\tvalidation_0-auc:0.92098\tvalidation_1-auc:0.81689                                                                 \n",
      "[44]\tvalidation_0-auc:0.92116\tvalidation_1-auc:0.81659                                                                 \n",
      "[45]\tvalidation_0-auc:0.92166\tvalidation_1-auc:0.81698                                                                 \n",
      "[46]\tvalidation_0-auc:0.92194\tvalidation_1-auc:0.81668                                                                 \n",
      "[47]\tvalidation_0-auc:0.92236\tvalidation_1-auc:0.81650                                                                 \n",
      "[48]\tvalidation_0-auc:0.92264\tvalidation_1-auc:0.81617                                                                 \n",
      "[49]\tvalidation_0-auc:0.92301\tvalidation_1-auc:0.81583                                                                 \n",
      "[50]\tvalidation_0-auc:0.92369\tvalidation_1-auc:0.81601                                                                 \n",
      "[51]\tvalidation_0-auc:0.92412\tvalidation_1-auc:0.81660                                                                 \n",
      "[52]\tvalidation_0-auc:0.92455\tvalidation_1-auc:0.81625                                                                 \n",
      "[53]\tvalidation_0-auc:0.92480\tvalidation_1-auc:0.81654                                                                 \n",
      "[54]\tvalidation_0-auc:0.92517\tvalidation_1-auc:0.81610                                                                 \n",
      "[55]\tvalidation_0-auc:0.92556\tvalidation_1-auc:0.81621                                                                 \n",
      "[56]\tvalidation_0-auc:0.92585\tvalidation_1-auc:0.81644                                                                 \n",
      "[57]\tvalidation_0-auc:0.92612\tvalidation_1-auc:0.81623                                                                 \n",
      "[58]\tvalidation_0-auc:0.92660\tvalidation_1-auc:0.81642                                                                 \n",
      "[59]\tvalidation_0-auc:0.92685\tvalidation_1-auc:0.81655                                                                 \n",
      "[60]\tvalidation_0-auc:0.92722\tvalidation_1-auc:0.81648                                                                 \n",
      "[61]\tvalidation_0-auc:0.92822\tvalidation_1-auc:0.81670                                                                 \n",
      "[62]\tvalidation_0-auc:0.92840\tvalidation_1-auc:0.81657                                                                 \n",
      "[63]\tvalidation_0-auc:0.92883\tvalidation_1-auc:0.81618                                                                 \n",
      "[64]\tvalidation_0-auc:0.92938\tvalidation_1-auc:0.81652                                                                 \n",
      "[65]\tvalidation_0-auc:0.92971\tvalidation_1-auc:0.81676                                                                 \n",
      "[66]\tvalidation_0-auc:0.93012\tvalidation_1-auc:0.81627                                                                 \n",
      "[67]\tvalidation_0-auc:0.93030\tvalidation_1-auc:0.81686                                                                 \n",
      "[68]\tvalidation_0-auc:0.93070\tvalidation_1-auc:0.81676                                                                 \n",
      "[69]\tvalidation_0-auc:0.93076\tvalidation_1-auc:0.81715                                                                 \n",
      "[70]\tvalidation_0-auc:0.93130\tvalidation_1-auc:0.81731                                                                 \n",
      "[71]\tvalidation_0-auc:0.93161\tvalidation_1-auc:0.81730                                                                 \n",
      "[0]\tvalidation_0-auc:0.85634\tvalidation_1-auc:0.81303                                                                  \n",
      "[1]\tvalidation_0-auc:0.86759\tvalidation_1-auc:0.81816                                                                  \n",
      "[2]\tvalidation_0-auc:0.87377\tvalidation_1-auc:0.82823                                                                  \n",
      "[3]\tvalidation_0-auc:0.87157\tvalidation_1-auc:0.82901                                                                  \n",
      "[4]\tvalidation_0-auc:0.86906\tvalidation_1-auc:0.82711                                                                  \n",
      "[5]\tvalidation_0-auc:0.87106\tvalidation_1-auc:0.82563                                                                  \n",
      "[6]\tvalidation_0-auc:0.87769\tvalidation_1-auc:0.83202                                                                  \n",
      "[7]\tvalidation_0-auc:0.87912\tvalidation_1-auc:0.83006                                                                  \n",
      "[8]\tvalidation_0-auc:0.88362\tvalidation_1-auc:0.83304                                                                  \n",
      "[9]\tvalidation_0-auc:0.88286\tvalidation_1-auc:0.83183                                                                  \n",
      "[10]\tvalidation_0-auc:0.88608\tvalidation_1-auc:0.83481                                                                 \n",
      "[11]\tvalidation_0-auc:0.88674\tvalidation_1-auc:0.83340                                                                 \n",
      "[12]\tvalidation_0-auc:0.88773\tvalidation_1-auc:0.83146                                                                 \n",
      "[13]\tvalidation_0-auc:0.89101\tvalidation_1-auc:0.83337                                                                 \n",
      "[14]\tvalidation_0-auc:0.89174\tvalidation_1-auc:0.83294                                                                 \n",
      "[15]\tvalidation_0-auc:0.89450\tvalidation_1-auc:0.83433                                                                 \n",
      "[16]\tvalidation_0-auc:0.89482\tvalidation_1-auc:0.83290                                                                 \n",
      "[17]\tvalidation_0-auc:0.89465\tvalidation_1-auc:0.83207                                                                 \n",
      "[18]\tvalidation_0-auc:0.89537\tvalidation_1-auc:0.83103                                                                 \n",
      "[19]\tvalidation_0-auc:0.89729\tvalidation_1-auc:0.83299                                                                 \n",
      "[20]\tvalidation_0-auc:0.89932\tvalidation_1-auc:0.83407                                                                 \n",
      "[21]\tvalidation_0-auc:0.90087\tvalidation_1-auc:0.83528                                                                 \n",
      "[22]\tvalidation_0-auc:0.90221\tvalidation_1-auc:0.83639                                                                 \n",
      "[23]\tvalidation_0-auc:0.90327\tvalidation_1-auc:0.83830                                                                 \n",
      "[24]\tvalidation_0-auc:0.90477\tvalidation_1-auc:0.83899                                                                 \n",
      "[25]\tvalidation_0-auc:0.90616\tvalidation_1-auc:0.83890                                                                 \n",
      "[26]\tvalidation_0-auc:0.90615\tvalidation_1-auc:0.83926                                                                 \n",
      "[27]\tvalidation_0-auc:0.90614\tvalidation_1-auc:0.83920                                                                 \n",
      "[28]\tvalidation_0-auc:0.90723\tvalidation_1-auc:0.83946                                                                 \n",
      "[29]\tvalidation_0-auc:0.90743\tvalidation_1-auc:0.83948                                                                 \n",
      "[30]\tvalidation_0-auc:0.90834\tvalidation_1-auc:0.83912                                                                 \n",
      "[31]\tvalidation_0-auc:0.90915\tvalidation_1-auc:0.83862                                                                 \n",
      "[32]\tvalidation_0-auc:0.91049\tvalidation_1-auc:0.83905                                                                 \n",
      "[33]\tvalidation_0-auc:0.91138\tvalidation_1-auc:0.83938                                                                 \n",
      "[34]\tvalidation_0-auc:0.91242\tvalidation_1-auc:0.83992                                                                 \n",
      "[35]\tvalidation_0-auc:0.91314\tvalidation_1-auc:0.84019                                                                 \n",
      "[36]\tvalidation_0-auc:0.91382\tvalidation_1-auc:0.84016                                                                 \n",
      "[37]\tvalidation_0-auc:0.91461\tvalidation_1-auc:0.84041                                                                 \n",
      "[38]\tvalidation_0-auc:0.91534\tvalidation_1-auc:0.84046                                                                 \n",
      "[39]\tvalidation_0-auc:0.91585\tvalidation_1-auc:0.84080                                                                 \n",
      "[40]\tvalidation_0-auc:0.91644\tvalidation_1-auc:0.84090                                                                 \n",
      "[41]\tvalidation_0-auc:0.91715\tvalidation_1-auc:0.84106                                                                 \n",
      "[42]\tvalidation_0-auc:0.91733\tvalidation_1-auc:0.84118                                                                 \n",
      "[43]\tvalidation_0-auc:0.91790\tvalidation_1-auc:0.84104                                                                 \n",
      "[44]\tvalidation_0-auc:0.91816\tvalidation_1-auc:0.84106                                                                 \n",
      "[45]\tvalidation_0-auc:0.91880\tvalidation_1-auc:0.84108                                                                 \n",
      "[46]\tvalidation_0-auc:0.91947\tvalidation_1-auc:0.84092                                                                 \n",
      "[47]\tvalidation_0-auc:0.92020\tvalidation_1-auc:0.84124                                                                 \n",
      "[48]\tvalidation_0-auc:0.92052\tvalidation_1-auc:0.84133                                                                 \n",
      "[49]\tvalidation_0-auc:0.92083\tvalidation_1-auc:0.84107                                                                 \n",
      "[50]\tvalidation_0-auc:0.92164\tvalidation_1-auc:0.84112                                                                 \n",
      "[51]\tvalidation_0-auc:0.92222\tvalidation_1-auc:0.84128                                                                 \n",
      "[52]\tvalidation_0-auc:0.92242\tvalidation_1-auc:0.84128                                                                 \n",
      "[53]\tvalidation_0-auc:0.92273\tvalidation_1-auc:0.84163                                                                 \n",
      "[54]\tvalidation_0-auc:0.92365\tvalidation_1-auc:0.84156                                                                 \n",
      "[55]\tvalidation_0-auc:0.92384\tvalidation_1-auc:0.84161                                                                 \n",
      "[56]\tvalidation_0-auc:0.92444\tvalidation_1-auc:0.84154                                                                 \n",
      "[57]\tvalidation_0-auc:0.92455\tvalidation_1-auc:0.84147                                                                 \n",
      "[58]\tvalidation_0-auc:0.92524\tvalidation_1-auc:0.84148                                                                 \n",
      "[59]\tvalidation_0-auc:0.92553\tvalidation_1-auc:0.84153                                                                 \n",
      "[60]\tvalidation_0-auc:0.92619\tvalidation_1-auc:0.84118                                                                 \n",
      "[61]\tvalidation_0-auc:0.92675\tvalidation_1-auc:0.84111                                                                 \n",
      "[62]\tvalidation_0-auc:0.92694\tvalidation_1-auc:0.84107                                                                 \n",
      "[63]\tvalidation_0-auc:0.92763\tvalidation_1-auc:0.84098                                                                 \n",
      "[64]\tvalidation_0-auc:0.92791\tvalidation_1-auc:0.84141                                                                 \n",
      "[65]\tvalidation_0-auc:0.92849\tvalidation_1-auc:0.84139                                                                 \n",
      "[66]\tvalidation_0-auc:0.92893\tvalidation_1-auc:0.84139                                                                 \n",
      "[67]\tvalidation_0-auc:0.92906\tvalidation_1-auc:0.84138                                                                 \n",
      "[68]\tvalidation_0-auc:0.92962\tvalidation_1-auc:0.84116                                                                 \n",
      "[69]\tvalidation_0-auc:0.92966\tvalidation_1-auc:0.84120                                                                 \n",
      "[70]\tvalidation_0-auc:0.93003\tvalidation_1-auc:0.84129                                                                 \n",
      "[71]\tvalidation_0-auc:0.93019\tvalidation_1-auc:0.84126                                                                 \n",
      "[72]\tvalidation_0-auc:0.93049\tvalidation_1-auc:0.84121                                                                 \n",
      "[73]\tvalidation_0-auc:0.93082\tvalidation_1-auc:0.84102                                                                 \n",
      "[74]\tvalidation_0-auc:0.93110\tvalidation_1-auc:0.84101                                                                 \n",
      "[75]\tvalidation_0-auc:0.93122\tvalidation_1-auc:0.84104                                                                 \n",
      "[76]\tvalidation_0-auc:0.93131\tvalidation_1-auc:0.84103                                                                 \n",
      "[77]\tvalidation_0-auc:0.93135\tvalidation_1-auc:0.84095                                                                 \n",
      "[78]\tvalidation_0-auc:0.93133\tvalidation_1-auc:0.84099                                                                 \n",
      "[79]\tvalidation_0-auc:0.93156\tvalidation_1-auc:0.84089                                                                 \n",
      "[80]\tvalidation_0-auc:0.93164\tvalidation_1-auc:0.84078                                                                 \n",
      "[81]\tvalidation_0-auc:0.93174\tvalidation_1-auc:0.84083                                                                 \n",
      "[82]\tvalidation_0-auc:0.93186\tvalidation_1-auc:0.84075                                                                 \n",
      "[83]\tvalidation_0-auc:0.93216\tvalidation_1-auc:0.84078                                                                 \n",
      "[0]\tvalidation_0-auc:0.85728\tvalidation_1-auc:0.80660                                                                  \n",
      "[1]\tvalidation_0-auc:0.86832\tvalidation_1-auc:0.80160                                                                  \n",
      "[2]\tvalidation_0-auc:0.87303\tvalidation_1-auc:0.81610                                                                  \n",
      "[3]\tvalidation_0-auc:0.87205\tvalidation_1-auc:0.81108                                                                  \n",
      "[4]\tvalidation_0-auc:0.87086\tvalidation_1-auc:0.80674                                                                  \n",
      "[5]\tvalidation_0-auc:0.87157\tvalidation_1-auc:0.80615                                                                  \n",
      "[6]\tvalidation_0-auc:0.87749\tvalidation_1-auc:0.81171                                                                  \n",
      "[7]\tvalidation_0-auc:0.87910\tvalidation_1-auc:0.80909                                                                  \n",
      "[8]\tvalidation_0-auc:0.88410\tvalidation_1-auc:0.81406                                                                  \n",
      "[9]\tvalidation_0-auc:0.88430\tvalidation_1-auc:0.81328                                                                  \n",
      "[10]\tvalidation_0-auc:0.88755\tvalidation_1-auc:0.81620                                                                 \n",
      "[11]\tvalidation_0-auc:0.88857\tvalidation_1-auc:0.81512                                                                 \n",
      "[12]\tvalidation_0-auc:0.88936\tvalidation_1-auc:0.81423                                                                 \n",
      "[13]\tvalidation_0-auc:0.89244\tvalidation_1-auc:0.81625                                                                 \n",
      "[14]\tvalidation_0-auc:0.89357\tvalidation_1-auc:0.81588                                                                 \n",
      "[15]\tvalidation_0-auc:0.89661\tvalidation_1-auc:0.81832                                                                 \n",
      "[16]\tvalidation_0-auc:0.89682\tvalidation_1-auc:0.81731                                                                 \n",
      "[17]\tvalidation_0-auc:0.89685\tvalidation_1-auc:0.81647                                                                 \n",
      "[18]\tvalidation_0-auc:0.89722\tvalidation_1-auc:0.81562                                                                 \n",
      "[19]\tvalidation_0-auc:0.89875\tvalidation_1-auc:0.81812                                                                 \n",
      "[20]\tvalidation_0-auc:0.90065\tvalidation_1-auc:0.82002                                                                 \n",
      "[21]\tvalidation_0-auc:0.90180\tvalidation_1-auc:0.82165                                                                 \n",
      "[22]\tvalidation_0-auc:0.90292\tvalidation_1-auc:0.82286                                                                 \n",
      "[23]\tvalidation_0-auc:0.90375\tvalidation_1-auc:0.82409                                                                 \n",
      "[24]\tvalidation_0-auc:0.90505\tvalidation_1-auc:0.82540                                                                 \n",
      "[25]\tvalidation_0-auc:0.90655\tvalidation_1-auc:0.82613                                                                 \n",
      "[26]\tvalidation_0-auc:0.90688\tvalidation_1-auc:0.82557                                                                 \n",
      "[27]\tvalidation_0-auc:0.90714\tvalidation_1-auc:0.82549                                                                 \n",
      "[28]\tvalidation_0-auc:0.90842\tvalidation_1-auc:0.82632                                                                 \n",
      "[29]\tvalidation_0-auc:0.90861\tvalidation_1-auc:0.82584                                                                 \n",
      "[30]\tvalidation_0-auc:0.90955\tvalidation_1-auc:0.82507                                                                 \n",
      "[31]\tvalidation_0-auc:0.91006\tvalidation_1-auc:0.82451                                                                 \n",
      "[32]\tvalidation_0-auc:0.91140\tvalidation_1-auc:0.82501                                                                 \n",
      "[33]\tvalidation_0-auc:0.91241\tvalidation_1-auc:0.82579                                                                 \n",
      "[34]\tvalidation_0-auc:0.91361\tvalidation_1-auc:0.82642                                                                 \n",
      "[35]\tvalidation_0-auc:0.91445\tvalidation_1-auc:0.82745                                                                 \n",
      "[36]\tvalidation_0-auc:0.91521\tvalidation_1-auc:0.82772                                                                 \n",
      "[37]\tvalidation_0-auc:0.91601\tvalidation_1-auc:0.82813                                                                 \n",
      "[38]\tvalidation_0-auc:0.91653\tvalidation_1-auc:0.82871                                                                 \n",
      "[39]\tvalidation_0-auc:0.91730\tvalidation_1-auc:0.82909                                                                 \n",
      "[40]\tvalidation_0-auc:0.91804\tvalidation_1-auc:0.82873                                                                 \n",
      "[41]\tvalidation_0-auc:0.91885\tvalidation_1-auc:0.82917                                                                 \n",
      "[42]\tvalidation_0-auc:0.91923\tvalidation_1-auc:0.82930                                                                 \n",
      "[43]\tvalidation_0-auc:0.91973\tvalidation_1-auc:0.82897                                                                 \n",
      "[44]\tvalidation_0-auc:0.92001\tvalidation_1-auc:0.82908                                                                 \n",
      "[45]\tvalidation_0-auc:0.92078\tvalidation_1-auc:0.82920                                                                 \n",
      "[46]\tvalidation_0-auc:0.92115\tvalidation_1-auc:0.82909                                                                 \n",
      "[47]\tvalidation_0-auc:0.92188\tvalidation_1-auc:0.82918                                                                 \n",
      "[48]\tvalidation_0-auc:0.92228\tvalidation_1-auc:0.82935                                                                 \n",
      "[49]\tvalidation_0-auc:0.92285\tvalidation_1-auc:0.82917                                                                 \n",
      "[50]\tvalidation_0-auc:0.92353\tvalidation_1-auc:0.82982                                                                 \n",
      "[51]\tvalidation_0-auc:0.92407\tvalidation_1-auc:0.83006                                                                 \n",
      "[52]\tvalidation_0-auc:0.92437\tvalidation_1-auc:0.83010                                                                 \n",
      "[53]\tvalidation_0-auc:0.92491\tvalidation_1-auc:0.83075                                                                 \n",
      "[54]\tvalidation_0-auc:0.92552\tvalidation_1-auc:0.83047                                                                 \n",
      "[55]\tvalidation_0-auc:0.92592\tvalidation_1-auc:0.83113                                                                 \n",
      "[56]\tvalidation_0-auc:0.92631\tvalidation_1-auc:0.83073                                                                 \n",
      "[57]\tvalidation_0-auc:0.92660\tvalidation_1-auc:0.83061                                                                 \n",
      "[58]\tvalidation_0-auc:0.92726\tvalidation_1-auc:0.83075                                                                 \n",
      "[59]\tvalidation_0-auc:0.92765\tvalidation_1-auc:0.83109                                                                 \n",
      "[60]\tvalidation_0-auc:0.92799\tvalidation_1-auc:0.83129                                                                 \n",
      "[61]\tvalidation_0-auc:0.92833\tvalidation_1-auc:0.83158                                                                 \n",
      "[62]\tvalidation_0-auc:0.92872\tvalidation_1-auc:0.83148                                                                 \n",
      "[63]\tvalidation_0-auc:0.92918\tvalidation_1-auc:0.83129                                                                 \n",
      "[64]\tvalidation_0-auc:0.92949\tvalidation_1-auc:0.83180                                                                 \n",
      "[65]\tvalidation_0-auc:0.92989\tvalidation_1-auc:0.83230                                                                 \n",
      "[66]\tvalidation_0-auc:0.93019\tvalidation_1-auc:0.83219                                                                 \n",
      "[67]\tvalidation_0-auc:0.93045\tvalidation_1-auc:0.83240                                                                 \n",
      "[68]\tvalidation_0-auc:0.93089\tvalidation_1-auc:0.83215                                                                 \n",
      "[69]\tvalidation_0-auc:0.93101\tvalidation_1-auc:0.83254                                                                 \n",
      "[70]\tvalidation_0-auc:0.93141\tvalidation_1-auc:0.83275                                                                 \n",
      "[71]\tvalidation_0-auc:0.93147\tvalidation_1-auc:0.83280                                                                 \n",
      "[72]\tvalidation_0-auc:0.93175\tvalidation_1-auc:0.83308                                                                 \n",
      "[73]\tvalidation_0-auc:0.93212\tvalidation_1-auc:0.83301                                                                 \n",
      "[74]\tvalidation_0-auc:0.93241\tvalidation_1-auc:0.83308                                                                 \n",
      "[75]\tvalidation_0-auc:0.93269\tvalidation_1-auc:0.83322                                                                 \n",
      "[76]\tvalidation_0-auc:0.93296\tvalidation_1-auc:0.83370                                                                 \n",
      "[77]\tvalidation_0-auc:0.93315\tvalidation_1-auc:0.83377                                                                 \n",
      "[78]\tvalidation_0-auc:0.93328\tvalidation_1-auc:0.83407                                                                 \n",
      "[79]\tvalidation_0-auc:0.93357\tvalidation_1-auc:0.83411                                                                 \n",
      "[80]\tvalidation_0-auc:0.93375\tvalidation_1-auc:0.83403                                                                 \n",
      "[81]\tvalidation_0-auc:0.93401\tvalidation_1-auc:0.83402                                                                 \n",
      "[82]\tvalidation_0-auc:0.93410\tvalidation_1-auc:0.83400                                                                 \n",
      "[83]\tvalidation_0-auc:0.93424\tvalidation_1-auc:0.83414                                                                 \n",
      "[84]\tvalidation_0-auc:0.93439\tvalidation_1-auc:0.83433                                                                 \n",
      "[85]\tvalidation_0-auc:0.93460\tvalidation_1-auc:0.83450                                                                 \n",
      "[86]\tvalidation_0-auc:0.93480\tvalidation_1-auc:0.83470                                                                 \n",
      "[87]\tvalidation_0-auc:0.93501\tvalidation_1-auc:0.83464                                                                 \n",
      "[88]\tvalidation_0-auc:0.93519\tvalidation_1-auc:0.83466                                                                 \n",
      "[89]\tvalidation_0-auc:0.93534\tvalidation_1-auc:0.83475                                                                 \n",
      "[90]\tvalidation_0-auc:0.93555\tvalidation_1-auc:0.83470                                                                 \n",
      "[91]\tvalidation_0-auc:0.93577\tvalidation_1-auc:0.83471                                                                 \n",
      "[92]\tvalidation_0-auc:0.93601\tvalidation_1-auc:0.83467                                                                 \n",
      "[93]\tvalidation_0-auc:0.93608\tvalidation_1-auc:0.83460                                                                 \n",
      "[94]\tvalidation_0-auc:0.93612\tvalidation_1-auc:0.83461                                                                 \n",
      "[95]\tvalidation_0-auc:0.93640\tvalidation_1-auc:0.83473                                                                 \n",
      "[96]\tvalidation_0-auc:0.93718\tvalidation_1-auc:0.83485                                                                 \n",
      "[97]\tvalidation_0-auc:0.93742\tvalidation_1-auc:0.83498                                                                 \n",
      "[98]\tvalidation_0-auc:0.93767\tvalidation_1-auc:0.83493                                                                 \n",
      "[99]\tvalidation_0-auc:0.93775\tvalidation_1-auc:0.83499                                                                 \n",
      "[0]\tvalidation_0-auc:0.88322\tvalidation_1-auc:0.79099                                                                  \n",
      "[1]\tvalidation_0-auc:0.88889\tvalidation_1-auc:0.79249                                                                  \n",
      "[2]\tvalidation_0-auc:0.89699\tvalidation_1-auc:0.80665                                                                  \n",
      "[3]\tvalidation_0-auc:0.90159\tvalidation_1-auc:0.80616                                                                  \n",
      "[4]\tvalidation_0-auc:0.90343\tvalidation_1-auc:0.80196                                                                  \n",
      "[5]\tvalidation_0-auc:0.90992\tvalidation_1-auc:0.80905                                                                  \n",
      "[6]\tvalidation_0-auc:0.91524\tvalidation_1-auc:0.81309                                                                  \n",
      "[7]\tvalidation_0-auc:0.91960\tvalidation_1-auc:0.81636                                                                  \n",
      "[8]\tvalidation_0-auc:0.92444\tvalidation_1-auc:0.81558                                                                  \n",
      "[9]\tvalidation_0-auc:0.92607\tvalidation_1-auc:0.81370                                                                  \n",
      "[10]\tvalidation_0-auc:0.92906\tvalidation_1-auc:0.81417                                                                 \n",
      "[11]\tvalidation_0-auc:0.93126\tvalidation_1-auc:0.81390                                                                 \n",
      "[12]\tvalidation_0-auc:0.93316\tvalidation_1-auc:0.81390                                                                 \n",
      "[13]\tvalidation_0-auc:0.93493\tvalidation_1-auc:0.81415                                                                 \n",
      "[14]\tvalidation_0-auc:0.93654\tvalidation_1-auc:0.81335                                                                 \n",
      "[15]\tvalidation_0-auc:0.93769\tvalidation_1-auc:0.81405                                                                 \n",
      "[16]\tvalidation_0-auc:0.93861\tvalidation_1-auc:0.81420                                                                 \n",
      "[17]\tvalidation_0-auc:0.93978\tvalidation_1-auc:0.81376                                                                 \n",
      "[18]\tvalidation_0-auc:0.94108\tvalidation_1-auc:0.81386                                                                 \n",
      "[19]\tvalidation_0-auc:0.94191\tvalidation_1-auc:0.81388                                                                 \n",
      "[20]\tvalidation_0-auc:0.94206\tvalidation_1-auc:0.81397                                                                 \n",
      "[21]\tvalidation_0-auc:0.94273\tvalidation_1-auc:0.81460                                                                 \n",
      "[22]\tvalidation_0-auc:0.94295\tvalidation_1-auc:0.81519                                                                 \n",
      "[23]\tvalidation_0-auc:0.94370\tvalidation_1-auc:0.81601                                                                 \n",
      "[24]\tvalidation_0-auc:0.94385\tvalidation_1-auc:0.81649                                                                 \n",
      "[25]\tvalidation_0-auc:0.94470\tvalidation_1-auc:0.81647                                                                 \n",
      "[26]\tvalidation_0-auc:0.94505\tvalidation_1-auc:0.81615                                                                 \n",
      "[27]\tvalidation_0-auc:0.94529\tvalidation_1-auc:0.81596                                                                 \n",
      "[28]\tvalidation_0-auc:0.94565\tvalidation_1-auc:0.81609                                                                 \n",
      "[29]\tvalidation_0-auc:0.94578\tvalidation_1-auc:0.81608                                                                 \n",
      "[30]\tvalidation_0-auc:0.94676\tvalidation_1-auc:0.81606                                                                 \n",
      "[31]\tvalidation_0-auc:0.94850\tvalidation_1-auc:0.81665                                                                 \n",
      "[32]\tvalidation_0-auc:0.94871\tvalidation_1-auc:0.81665                                                                 \n",
      "[33]\tvalidation_0-auc:0.94943\tvalidation_1-auc:0.81687                                                                 \n",
      "[34]\tvalidation_0-auc:0.95085\tvalidation_1-auc:0.81675                                                                 \n",
      "[35]\tvalidation_0-auc:0.95209\tvalidation_1-auc:0.81692                                                                 \n",
      "[36]\tvalidation_0-auc:0.95368\tvalidation_1-auc:0.81647                                                                 \n",
      "[37]\tvalidation_0-auc:0.95458\tvalidation_1-auc:0.81649                                                                 \n",
      "[38]\tvalidation_0-auc:0.95454\tvalidation_1-auc:0.81638                                                                 \n",
      "[39]\tvalidation_0-auc:0.95471\tvalidation_1-auc:0.81628                                                                 \n",
      "[40]\tvalidation_0-auc:0.95479\tvalidation_1-auc:0.81616                                                                 \n",
      "[41]\tvalidation_0-auc:0.95535\tvalidation_1-auc:0.81602                                                                 \n",
      "[42]\tvalidation_0-auc:0.95539\tvalidation_1-auc:0.81575                                                                 \n",
      "[43]\tvalidation_0-auc:0.95582\tvalidation_1-auc:0.81546                                                                 \n",
      "[44]\tvalidation_0-auc:0.95601\tvalidation_1-auc:0.81542                                                                 \n",
      "[45]\tvalidation_0-auc:0.95802\tvalidation_1-auc:0.81508                                                                 \n",
      "[46]\tvalidation_0-auc:0.95833\tvalidation_1-auc:0.81477                                                                 \n",
      "[47]\tvalidation_0-auc:0.95840\tvalidation_1-auc:0.81476                                                                 \n",
      "[48]\tvalidation_0-auc:0.95886\tvalidation_1-auc:0.81442                                                                 \n",
      "[49]\tvalidation_0-auc:0.95895\tvalidation_1-auc:0.81423                                                                 \n",
      "[50]\tvalidation_0-auc:0.96077\tvalidation_1-auc:0.81412                                                                 \n",
      "[51]\tvalidation_0-auc:0.96114\tvalidation_1-auc:0.81394                                                                 \n",
      "[52]\tvalidation_0-auc:0.96123\tvalidation_1-auc:0.81386                                                                 \n",
      "[53]\tvalidation_0-auc:0.96133\tvalidation_1-auc:0.81364                                                                 \n",
      "[54]\tvalidation_0-auc:0.96166\tvalidation_1-auc:0.81352                                                                 \n",
      "[55]\tvalidation_0-auc:0.96184\tvalidation_1-auc:0.81344                                                                 \n",
      "[56]\tvalidation_0-auc:0.96267\tvalidation_1-auc:0.81268                                                                 \n",
      "[57]\tvalidation_0-auc:0.96335\tvalidation_1-auc:0.81238                                                                 \n",
      "[58]\tvalidation_0-auc:0.96386\tvalidation_1-auc:0.81228                                                                 \n",
      "[59]\tvalidation_0-auc:0.96417\tvalidation_1-auc:0.81223                                                                 \n",
      "[60]\tvalidation_0-auc:0.96428\tvalidation_1-auc:0.81228                                                                 \n",
      "[61]\tvalidation_0-auc:0.96431\tvalidation_1-auc:0.81184                                                                 \n",
      "[62]\tvalidation_0-auc:0.96470\tvalidation_1-auc:0.81190                                                                 \n",
      "[63]\tvalidation_0-auc:0.96503\tvalidation_1-auc:0.81164                                                                 \n",
      "[64]\tvalidation_0-auc:0.96538\tvalidation_1-auc:0.81134                                                                 \n",
      "[0]\tvalidation_0-auc:0.87525\tvalidation_1-auc:0.79855                                                                  \n",
      "[1]\tvalidation_0-auc:0.88479\tvalidation_1-auc:0.80354                                                                  \n",
      "[2]\tvalidation_0-auc:0.89717\tvalidation_1-auc:0.81872                                                                  \n",
      "[3]\tvalidation_0-auc:0.90051\tvalidation_1-auc:0.81509                                                                  \n",
      "[4]\tvalidation_0-auc:0.90336\tvalidation_1-auc:0.81753                                                                  \n",
      "[5]\tvalidation_0-auc:0.91217\tvalidation_1-auc:0.82297                                                                  \n",
      "[6]\tvalidation_0-auc:0.91879\tvalidation_1-auc:0.82205                                                                  \n",
      "[7]\tvalidation_0-auc:0.92253\tvalidation_1-auc:0.82274                                                                  \n",
      "[8]\tvalidation_0-auc:0.92611\tvalidation_1-auc:0.82461                                                                  \n",
      "[9]\tvalidation_0-auc:0.92874\tvalidation_1-auc:0.82497                                                                  \n",
      "[10]\tvalidation_0-auc:0.93097\tvalidation_1-auc:0.82655                                                                 \n",
      "[11]\tvalidation_0-auc:0.93324\tvalidation_1-auc:0.82732                                                                 \n",
      "[12]\tvalidation_0-auc:0.93470\tvalidation_1-auc:0.82745                                                                 \n",
      "[13]\tvalidation_0-auc:0.93578\tvalidation_1-auc:0.82769                                                                 \n",
      "[14]\tvalidation_0-auc:0.93806\tvalidation_1-auc:0.82702                                                                 \n",
      "[15]\tvalidation_0-auc:0.93931\tvalidation_1-auc:0.82843                                                                 \n",
      "[16]\tvalidation_0-auc:0.94061\tvalidation_1-auc:0.82840                                                                 \n",
      "[17]\tvalidation_0-auc:0.94216\tvalidation_1-auc:0.82767                                                                 \n",
      "[18]\tvalidation_0-auc:0.94348\tvalidation_1-auc:0.82850                                                                 \n",
      "[19]\tvalidation_0-auc:0.94479\tvalidation_1-auc:0.82803                                                                 \n",
      "[20]\tvalidation_0-auc:0.94533\tvalidation_1-auc:0.82770                                                                 \n",
      "[21]\tvalidation_0-auc:0.94595\tvalidation_1-auc:0.82754                                                                 \n",
      "[22]\tvalidation_0-auc:0.94645\tvalidation_1-auc:0.82723                                                                 \n",
      "[23]\tvalidation_0-auc:0.94668\tvalidation_1-auc:0.82746                                                                 \n",
      "[24]\tvalidation_0-auc:0.94699\tvalidation_1-auc:0.82747                                                                 \n",
      "[25]\tvalidation_0-auc:0.94779\tvalidation_1-auc:0.82746                                                                 \n",
      "[26]\tvalidation_0-auc:0.94830\tvalidation_1-auc:0.82734                                                                 \n",
      "[27]\tvalidation_0-auc:0.94847\tvalidation_1-auc:0.82697                                                                 \n",
      "[28]\tvalidation_0-auc:0.94897\tvalidation_1-auc:0.82677                                                                 \n",
      "[29]\tvalidation_0-auc:0.94905\tvalidation_1-auc:0.82646                                                                 \n",
      "[30]\tvalidation_0-auc:0.94942\tvalidation_1-auc:0.82679                                                                 \n",
      "[31]\tvalidation_0-auc:0.95187\tvalidation_1-auc:0.82616                                                                 \n",
      "[32]\tvalidation_0-auc:0.95242\tvalidation_1-auc:0.82599                                                                 \n",
      "[33]\tvalidation_0-auc:0.95281\tvalidation_1-auc:0.82591                                                                 \n",
      "[34]\tvalidation_0-auc:0.95356\tvalidation_1-auc:0.82559                                                                 \n",
      "[35]\tvalidation_0-auc:0.95374\tvalidation_1-auc:0.82562                                                                 \n",
      "[36]\tvalidation_0-auc:0.95400\tvalidation_1-auc:0.82529                                                                 \n",
      "[37]\tvalidation_0-auc:0.95447\tvalidation_1-auc:0.82513                                                                 \n",
      "[38]\tvalidation_0-auc:0.95496\tvalidation_1-auc:0.82518                                                                 \n",
      "[39]\tvalidation_0-auc:0.95514\tvalidation_1-auc:0.82499                                                                 \n",
      "[40]\tvalidation_0-auc:0.95528\tvalidation_1-auc:0.82484                                                                 \n",
      "[41]\tvalidation_0-auc:0.95546\tvalidation_1-auc:0.82459                                                                 \n",
      "[42]\tvalidation_0-auc:0.95682\tvalidation_1-auc:0.82444                                                                 \n",
      "[43]\tvalidation_0-auc:0.95695\tvalidation_1-auc:0.82438                                                                 \n",
      "[44]\tvalidation_0-auc:0.95714\tvalidation_1-auc:0.82353                                                                 \n",
      "[45]\tvalidation_0-auc:0.95732\tvalidation_1-auc:0.82304                                                                 \n",
      "[46]\tvalidation_0-auc:0.95744\tvalidation_1-auc:0.82275                                                                 \n",
      "[47]\tvalidation_0-auc:0.95799\tvalidation_1-auc:0.82264                                                                 \n",
      "[48]\tvalidation_0-auc:0.95808\tvalidation_1-auc:0.82246                                                                 \n",
      "[0]\tvalidation_0-auc:0.87439\tvalidation_1-auc:0.80444                                                                  \n",
      "[1]\tvalidation_0-auc:0.88548\tvalidation_1-auc:0.79601                                                                  \n",
      "[2]\tvalidation_0-auc:0.89302\tvalidation_1-auc:0.81619                                                                  \n",
      "[3]\tvalidation_0-auc:0.89694\tvalidation_1-auc:0.81184                                                                  \n",
      "[4]\tvalidation_0-auc:0.89871\tvalidation_1-auc:0.80799                                                                  \n",
      "[5]\tvalidation_0-auc:0.90527\tvalidation_1-auc:0.81588                                                                  \n",
      "[6]\tvalidation_0-auc:0.91144\tvalidation_1-auc:0.82079                                                                  \n",
      "[7]\tvalidation_0-auc:0.91672\tvalidation_1-auc:0.82323                                                                  \n",
      "[8]\tvalidation_0-auc:0.92145\tvalidation_1-auc:0.82541                                                                  \n",
      "[9]\tvalidation_0-auc:0.92492\tvalidation_1-auc:0.82434                                                                  \n",
      "[10]\tvalidation_0-auc:0.92944\tvalidation_1-auc:0.82600                                                                 \n",
      "[11]\tvalidation_0-auc:0.93223\tvalidation_1-auc:0.82745                                                                 \n",
      "[12]\tvalidation_0-auc:0.93451\tvalidation_1-auc:0.82847                                                                 \n",
      "[13]\tvalidation_0-auc:0.93578\tvalidation_1-auc:0.82971                                                                 \n",
      "[14]\tvalidation_0-auc:0.93700\tvalidation_1-auc:0.82969                                                                 \n",
      "[15]\tvalidation_0-auc:0.93814\tvalidation_1-auc:0.83046                                                                 \n",
      "[16]\tvalidation_0-auc:0.94021\tvalidation_1-auc:0.83151                                                                 \n",
      "[17]\tvalidation_0-auc:0.94151\tvalidation_1-auc:0.83080                                                                 \n",
      "[18]\tvalidation_0-auc:0.94256\tvalidation_1-auc:0.82988                                                                 \n",
      "[19]\tvalidation_0-auc:0.94394\tvalidation_1-auc:0.83041                                                                 \n",
      "[20]\tvalidation_0-auc:0.94479\tvalidation_1-auc:0.83112                                                                 \n",
      "[21]\tvalidation_0-auc:0.94567\tvalidation_1-auc:0.83127                                                                 \n",
      "[22]\tvalidation_0-auc:0.94612\tvalidation_1-auc:0.83173                                                                 \n",
      "[23]\tvalidation_0-auc:0.94683\tvalidation_1-auc:0.83255                                                                 \n",
      "[24]\tvalidation_0-auc:0.94816\tvalidation_1-auc:0.83275                                                                 \n",
      "[25]\tvalidation_0-auc:0.94893\tvalidation_1-auc:0.83303                                                                 \n",
      "[26]\tvalidation_0-auc:0.94909\tvalidation_1-auc:0.83318                                                                 \n",
      "[27]\tvalidation_0-auc:0.94959\tvalidation_1-auc:0.83248                                                                 \n",
      "[28]\tvalidation_0-auc:0.95012\tvalidation_1-auc:0.83236                                                                 \n",
      "[29]\tvalidation_0-auc:0.95024\tvalidation_1-auc:0.83228                                                                 \n",
      "[30]\tvalidation_0-auc:0.95075\tvalidation_1-auc:0.83206                                                                 \n",
      "[31]\tvalidation_0-auc:0.95218\tvalidation_1-auc:0.83166                                                                 \n",
      "[32]\tvalidation_0-auc:0.95275\tvalidation_1-auc:0.83204                                                                 \n",
      "[33]\tvalidation_0-auc:0.95329\tvalidation_1-auc:0.83185                                                                 \n",
      "[34]\tvalidation_0-auc:0.95362\tvalidation_1-auc:0.83190                                                                 \n",
      "[35]\tvalidation_0-auc:0.95587\tvalidation_1-auc:0.83136                                                                 \n",
      "[36]\tvalidation_0-auc:0.95688\tvalidation_1-auc:0.83090                                                                 \n",
      "[37]\tvalidation_0-auc:0.95801\tvalidation_1-auc:0.83071                                                                 \n",
      "[38]\tvalidation_0-auc:0.95808\tvalidation_1-auc:0.83085                                                                 \n",
      "[39]\tvalidation_0-auc:0.95821\tvalidation_1-auc:0.83091                                                                 \n",
      "[40]\tvalidation_0-auc:0.95858\tvalidation_1-auc:0.83082                                                                 \n",
      "[41]\tvalidation_0-auc:0.95872\tvalidation_1-auc:0.83069                                                                 \n",
      "[42]\tvalidation_0-auc:0.95914\tvalidation_1-auc:0.83046                                                                 \n",
      "[43]\tvalidation_0-auc:0.95931\tvalidation_1-auc:0.83008                                                                 \n",
      "[44]\tvalidation_0-auc:0.95940\tvalidation_1-auc:0.83010                                                                 \n",
      "[45]\tvalidation_0-auc:0.96002\tvalidation_1-auc:0.83018                                                                 \n",
      "[46]\tvalidation_0-auc:0.96018\tvalidation_1-auc:0.83023                                                                 \n",
      "[47]\tvalidation_0-auc:0.96158\tvalidation_1-auc:0.82981                                                                 \n",
      "[48]\tvalidation_0-auc:0.96206\tvalidation_1-auc:0.82978                                                                 \n",
      "[49]\tvalidation_0-auc:0.96284\tvalidation_1-auc:0.82946                                                                 \n",
      "[50]\tvalidation_0-auc:0.96398\tvalidation_1-auc:0.82893                                                                 \n",
      "[51]\tvalidation_0-auc:0.96466\tvalidation_1-auc:0.82897                                                                 \n",
      "[52]\tvalidation_0-auc:0.96481\tvalidation_1-auc:0.82872                                                                 \n",
      "[53]\tvalidation_0-auc:0.96542\tvalidation_1-auc:0.82874                                                                 \n",
      "[54]\tvalidation_0-auc:0.96625\tvalidation_1-auc:0.82795                                                                 \n",
      "[55]\tvalidation_0-auc:0.96631\tvalidation_1-auc:0.82777                                                                 \n",
      "[0]\tvalidation_0-auc:0.84537\tvalidation_1-auc:0.80649                                                                  \n",
      "[1]\tvalidation_0-auc:0.85257\tvalidation_1-auc:0.80183                                                                  \n",
      "[2]\tvalidation_0-auc:0.85927\tvalidation_1-auc:0.80975                                                                  \n",
      "[3]\tvalidation_0-auc:0.85563\tvalidation_1-auc:0.80450                                                                  \n",
      "[4]\tvalidation_0-auc:0.85420\tvalidation_1-auc:0.79975                                                                  \n",
      "[5]\tvalidation_0-auc:0.85558\tvalidation_1-auc:0.80053                                                                  \n",
      "[6]\tvalidation_0-auc:0.86108\tvalidation_1-auc:0.80583                                                                  \n",
      "[7]\tvalidation_0-auc:0.86311\tvalidation_1-auc:0.80613                                                                  \n",
      "[8]\tvalidation_0-auc:0.86840\tvalidation_1-auc:0.80947                                                                  \n",
      "[9]\tvalidation_0-auc:0.86798\tvalidation_1-auc:0.80760                                                                  \n",
      "[10]\tvalidation_0-auc:0.87154\tvalidation_1-auc:0.81032                                                                 \n",
      "[11]\tvalidation_0-auc:0.87168\tvalidation_1-auc:0.81029                                                                 \n",
      "[12]\tvalidation_0-auc:0.87191\tvalidation_1-auc:0.80949                                                                 \n",
      "[13]\tvalidation_0-auc:0.87530\tvalidation_1-auc:0.81205                                                                 \n",
      "[14]\tvalidation_0-auc:0.87602\tvalidation_1-auc:0.81100                                                                 \n",
      "[15]\tvalidation_0-auc:0.87870\tvalidation_1-auc:0.81357                                                                 \n",
      "[16]\tvalidation_0-auc:0.88048\tvalidation_1-auc:0.81526                                                                 \n",
      "[17]\tvalidation_0-auc:0.88118\tvalidation_1-auc:0.81451                                                                 \n",
      "[18]\tvalidation_0-auc:0.88186\tvalidation_1-auc:0.81399                                                                 \n",
      "[19]\tvalidation_0-auc:0.88344\tvalidation_1-auc:0.81608                                                                 \n",
      "[20]\tvalidation_0-auc:0.88491\tvalidation_1-auc:0.81682                                                                 \n",
      "[21]\tvalidation_0-auc:0.88614\tvalidation_1-auc:0.81761                                                                 \n",
      "[22]\tvalidation_0-auc:0.88751\tvalidation_1-auc:0.81855                                                                 \n",
      "[23]\tvalidation_0-auc:0.88852\tvalidation_1-auc:0.81906                                                                 \n",
      "[24]\tvalidation_0-auc:0.88930\tvalidation_1-auc:0.81991                                                                 \n",
      "[25]\tvalidation_0-auc:0.89041\tvalidation_1-auc:0.82050                                                                 \n",
      "[26]\tvalidation_0-auc:0.89109\tvalidation_1-auc:0.82035                                                                 \n",
      "[27]\tvalidation_0-auc:0.89141\tvalidation_1-auc:0.81970                                                                 \n",
      "[28]\tvalidation_0-auc:0.89208\tvalidation_1-auc:0.82005                                                                 \n",
      "[29]\tvalidation_0-auc:0.89231\tvalidation_1-auc:0.81954                                                                 \n",
      "[30]\tvalidation_0-auc:0.89320\tvalidation_1-auc:0.81946                                                                 \n",
      "[31]\tvalidation_0-auc:0.89422\tvalidation_1-auc:0.81958                                                                 \n",
      "[32]\tvalidation_0-auc:0.89479\tvalidation_1-auc:0.81998                                                                 \n",
      "[33]\tvalidation_0-auc:0.89521\tvalidation_1-auc:0.82039                                                                 \n",
      "[34]\tvalidation_0-auc:0.89551\tvalidation_1-auc:0.82087                                                                 \n",
      "[35]\tvalidation_0-auc:0.89582\tvalidation_1-auc:0.82101                                                                 \n",
      "[36]\tvalidation_0-auc:0.89658\tvalidation_1-auc:0.82140                                                                 \n",
      "[37]\tvalidation_0-auc:0.89733\tvalidation_1-auc:0.82149                                                                 \n",
      "[38]\tvalidation_0-auc:0.89746\tvalidation_1-auc:0.82161                                                                 \n",
      "[39]\tvalidation_0-auc:0.89786\tvalidation_1-auc:0.82181                                                                 \n",
      "[40]\tvalidation_0-auc:0.89879\tvalidation_1-auc:0.82196                                                                 \n",
      "[41]\tvalidation_0-auc:0.89923\tvalidation_1-auc:0.82220                                                                 \n",
      "[42]\tvalidation_0-auc:0.89938\tvalidation_1-auc:0.82212                                                                 \n",
      "[43]\tvalidation_0-auc:0.89987\tvalidation_1-auc:0.82218                                                                 \n",
      "[44]\tvalidation_0-auc:0.89994\tvalidation_1-auc:0.82216                                                                 \n",
      "[45]\tvalidation_0-auc:0.90018\tvalidation_1-auc:0.82220                                                                 \n",
      "[46]\tvalidation_0-auc:0.90066\tvalidation_1-auc:0.82219                                                                 \n",
      "[47]\tvalidation_0-auc:0.90106\tvalidation_1-auc:0.82216                                                                 \n",
      "[48]\tvalidation_0-auc:0.90151\tvalidation_1-auc:0.82191                                                                 \n",
      "[49]\tvalidation_0-auc:0.90186\tvalidation_1-auc:0.82183                                                                 \n",
      "[50]\tvalidation_0-auc:0.90228\tvalidation_1-auc:0.82207                                                                 \n",
      "[51]\tvalidation_0-auc:0.90271\tvalidation_1-auc:0.82237                                                                 \n",
      "[52]\tvalidation_0-auc:0.90285\tvalidation_1-auc:0.82234                                                                 \n",
      "[53]\tvalidation_0-auc:0.90305\tvalidation_1-auc:0.82248                                                                 \n",
      "[54]\tvalidation_0-auc:0.90333\tvalidation_1-auc:0.82231                                                                 \n",
      "[55]\tvalidation_0-auc:0.90409\tvalidation_1-auc:0.82263                                                                 \n",
      "[56]\tvalidation_0-auc:0.90472\tvalidation_1-auc:0.82258                                                                 \n",
      "[57]\tvalidation_0-auc:0.90503\tvalidation_1-auc:0.82259                                                                 \n",
      "[58]\tvalidation_0-auc:0.90530\tvalidation_1-auc:0.82265                                                                 \n",
      "[59]\tvalidation_0-auc:0.90573\tvalidation_1-auc:0.82276                                                                 \n",
      "[60]\tvalidation_0-auc:0.90640\tvalidation_1-auc:0.82295                                                                 \n",
      "[61]\tvalidation_0-auc:0.90682\tvalidation_1-auc:0.82290                                                                 \n",
      "[62]\tvalidation_0-auc:0.90692\tvalidation_1-auc:0.82286                                                                 \n",
      "[63]\tvalidation_0-auc:0.90707\tvalidation_1-auc:0.82287                                                                 \n",
      "[64]\tvalidation_0-auc:0.90746\tvalidation_1-auc:0.82279                                                                 \n",
      "[65]\tvalidation_0-auc:0.90794\tvalidation_1-auc:0.82276                                                                 \n",
      "[66]\tvalidation_0-auc:0.90801\tvalidation_1-auc:0.82265                                                                 \n",
      "[67]\tvalidation_0-auc:0.90806\tvalidation_1-auc:0.82290                                                                 \n",
      "[68]\tvalidation_0-auc:0.90856\tvalidation_1-auc:0.82287                                                                 \n",
      "[69]\tvalidation_0-auc:0.90872\tvalidation_1-auc:0.82289                                                                 \n",
      "[70]\tvalidation_0-auc:0.90892\tvalidation_1-auc:0.82291                                                                 \n",
      "[71]\tvalidation_0-auc:0.90910\tvalidation_1-auc:0.82275                                                                 \n",
      "[72]\tvalidation_0-auc:0.90975\tvalidation_1-auc:0.82251                                                                 \n",
      "[73]\tvalidation_0-auc:0.90987\tvalidation_1-auc:0.82242                                                                 \n",
      "[74]\tvalidation_0-auc:0.91037\tvalidation_1-auc:0.82261                                                                 \n",
      "[75]\tvalidation_0-auc:0.91052\tvalidation_1-auc:0.82269                                                                 \n",
      "[76]\tvalidation_0-auc:0.91107\tvalidation_1-auc:0.82257                                                                 \n",
      "[77]\tvalidation_0-auc:0.91158\tvalidation_1-auc:0.82255                                                                 \n",
      "[78]\tvalidation_0-auc:0.91173\tvalidation_1-auc:0.82261                                                                 \n",
      "[79]\tvalidation_0-auc:0.91183\tvalidation_1-auc:0.82255                                                                 \n",
      "[80]\tvalidation_0-auc:0.91189\tvalidation_1-auc:0.82250                                                                 \n",
      "[81]\tvalidation_0-auc:0.91210\tvalidation_1-auc:0.82242                                                                 \n",
      "[82]\tvalidation_0-auc:0.91220\tvalidation_1-auc:0.82229                                                                 \n",
      "[83]\tvalidation_0-auc:0.91247\tvalidation_1-auc:0.82239                                                                 \n",
      "[84]\tvalidation_0-auc:0.91299\tvalidation_1-auc:0.82235                                                                 \n",
      "[85]\tvalidation_0-auc:0.91339\tvalidation_1-auc:0.82215                                                                 \n",
      "[86]\tvalidation_0-auc:0.91343\tvalidation_1-auc:0.82220                                                                 \n",
      "[87]\tvalidation_0-auc:0.91376\tvalidation_1-auc:0.82211                                                                 \n",
      "[88]\tvalidation_0-auc:0.91385\tvalidation_1-auc:0.82199                                                                 \n",
      "[89]\tvalidation_0-auc:0.91407\tvalidation_1-auc:0.82188                                                                 \n",
      "[0]\tvalidation_0-auc:0.83860\tvalidation_1-auc:0.81419                                                                  \n",
      "[1]\tvalidation_0-auc:0.84833\tvalidation_1-auc:0.82411                                                                  \n",
      "[2]\tvalidation_0-auc:0.85727\tvalidation_1-auc:0.83226                                                                  \n",
      "[3]\tvalidation_0-auc:0.85412\tvalidation_1-auc:0.83298                                                                  \n",
      "[4]\tvalidation_0-auc:0.85111\tvalidation_1-auc:0.83055                                                                  \n",
      "[5]\tvalidation_0-auc:0.85265\tvalidation_1-auc:0.82751                                                                  \n",
      "[6]\tvalidation_0-auc:0.86037\tvalidation_1-auc:0.83254                                                                  \n",
      "[7]\tvalidation_0-auc:0.86058\tvalidation_1-auc:0.83060                                                                  \n",
      "[8]\tvalidation_0-auc:0.86634\tvalidation_1-auc:0.83525                                                                  \n",
      "[9]\tvalidation_0-auc:0.86523\tvalidation_1-auc:0.83496                                                                  \n",
      "[10]\tvalidation_0-auc:0.86911\tvalidation_1-auc:0.83766                                                                 \n",
      "[11]\tvalidation_0-auc:0.86908\tvalidation_1-auc:0.83667                                                                 \n",
      "[12]\tvalidation_0-auc:0.86889\tvalidation_1-auc:0.83652                                                                 \n",
      "[13]\tvalidation_0-auc:0.87278\tvalidation_1-auc:0.83777                                                                 \n",
      "[14]\tvalidation_0-auc:0.87263\tvalidation_1-auc:0.83772                                                                 \n",
      "[15]\tvalidation_0-auc:0.87613\tvalidation_1-auc:0.83869                                                                 \n",
      "[16]\tvalidation_0-auc:0.87831\tvalidation_1-auc:0.84009                                                                 \n",
      "[17]\tvalidation_0-auc:0.87857\tvalidation_1-auc:0.83967                                                                 \n",
      "[18]\tvalidation_0-auc:0.87891\tvalidation_1-auc:0.83951                                                                 \n",
      "[19]\tvalidation_0-auc:0.88040\tvalidation_1-auc:0.84055                                                                 \n",
      "[20]\tvalidation_0-auc:0.88218\tvalidation_1-auc:0.84147                                                                 \n",
      "[21]\tvalidation_0-auc:0.88352\tvalidation_1-auc:0.84166                                                                 \n",
      "[22]\tvalidation_0-auc:0.88491\tvalidation_1-auc:0.84163                                                                 \n",
      "[23]\tvalidation_0-auc:0.88605\tvalidation_1-auc:0.84217                                                                 \n",
      "[24]\tvalidation_0-auc:0.88697\tvalidation_1-auc:0.84240                                                                 \n",
      "[25]\tvalidation_0-auc:0.88768\tvalidation_1-auc:0.84248                                                                 \n",
      "[26]\tvalidation_0-auc:0.88816\tvalidation_1-auc:0.84262                                                                 \n",
      "[27]\tvalidation_0-auc:0.88827\tvalidation_1-auc:0.84280                                                                 \n",
      "[28]\tvalidation_0-auc:0.88880\tvalidation_1-auc:0.84272                                                                 \n",
      "[29]\tvalidation_0-auc:0.88885\tvalidation_1-auc:0.84273                                                                 \n",
      "[30]\tvalidation_0-auc:0.88970\tvalidation_1-auc:0.84308                                                                 \n",
      "[31]\tvalidation_0-auc:0.89038\tvalidation_1-auc:0.84302                                                                 \n",
      "[32]\tvalidation_0-auc:0.89127\tvalidation_1-auc:0.84304                                                                 \n",
      "[33]\tvalidation_0-auc:0.89188\tvalidation_1-auc:0.84316                                                                 \n",
      "[34]\tvalidation_0-auc:0.89222\tvalidation_1-auc:0.84316                                                                 \n",
      "[35]\tvalidation_0-auc:0.89298\tvalidation_1-auc:0.84274                                                                 \n",
      "[36]\tvalidation_0-auc:0.89375\tvalidation_1-auc:0.84283                                                                 \n",
      "[37]\tvalidation_0-auc:0.89454\tvalidation_1-auc:0.84244                                                                 \n",
      "[38]\tvalidation_0-auc:0.89483\tvalidation_1-auc:0.84242                                                                 \n",
      "[39]\tvalidation_0-auc:0.89501\tvalidation_1-auc:0.84223                                                                 \n",
      "[40]\tvalidation_0-auc:0.89555\tvalidation_1-auc:0.84214                                                                 \n",
      "[41]\tvalidation_0-auc:0.89630\tvalidation_1-auc:0.84203                                                                 \n",
      "[42]\tvalidation_0-auc:0.89646\tvalidation_1-auc:0.84213                                                                 \n",
      "[43]\tvalidation_0-auc:0.89722\tvalidation_1-auc:0.84212                                                                 \n",
      "[44]\tvalidation_0-auc:0.89742\tvalidation_1-auc:0.84186                                                                 \n",
      "[45]\tvalidation_0-auc:0.89776\tvalidation_1-auc:0.84165                                                                 \n",
      "[46]\tvalidation_0-auc:0.89794\tvalidation_1-auc:0.84169                                                                 \n",
      "[47]\tvalidation_0-auc:0.89837\tvalidation_1-auc:0.84159                                                                 \n",
      "[48]\tvalidation_0-auc:0.89887\tvalidation_1-auc:0.84162                                                                 \n",
      "[49]\tvalidation_0-auc:0.89892\tvalidation_1-auc:0.84154                                                                 \n",
      "[50]\tvalidation_0-auc:0.89949\tvalidation_1-auc:0.84156                                                                 \n",
      "[51]\tvalidation_0-auc:0.89973\tvalidation_1-auc:0.84153                                                                 \n",
      "[52]\tvalidation_0-auc:0.89981\tvalidation_1-auc:0.84135                                                                 \n",
      "[53]\tvalidation_0-auc:0.90013\tvalidation_1-auc:0.84146                                                                 \n",
      "[54]\tvalidation_0-auc:0.90052\tvalidation_1-auc:0.84156                                                                 \n",
      "[55]\tvalidation_0-auc:0.90082\tvalidation_1-auc:0.84163                                                                 \n",
      "[56]\tvalidation_0-auc:0.90117\tvalidation_1-auc:0.84151                                                                 \n",
      "[57]\tvalidation_0-auc:0.90138\tvalidation_1-auc:0.84144                                                                 \n",
      "[58]\tvalidation_0-auc:0.90177\tvalidation_1-auc:0.84119                                                                 \n",
      "[59]\tvalidation_0-auc:0.90208\tvalidation_1-auc:0.84126                                                                 \n",
      "[60]\tvalidation_0-auc:0.90238\tvalidation_1-auc:0.84100                                                                 \n",
      "[61]\tvalidation_0-auc:0.90257\tvalidation_1-auc:0.84105                                                                 \n",
      "[62]\tvalidation_0-auc:0.90292\tvalidation_1-auc:0.84112                                                                 \n",
      "[63]\tvalidation_0-auc:0.90328\tvalidation_1-auc:0.84090                                                                 \n",
      "[0]\tvalidation_0-auc:0.83942\tvalidation_1-auc:0.81613                                                                  \n",
      "[1]\tvalidation_0-auc:0.84639\tvalidation_1-auc:0.81262                                                                  \n",
      "[2]\tvalidation_0-auc:0.85410\tvalidation_1-auc:0.82279                                                                  \n",
      "[3]\tvalidation_0-auc:0.85185\tvalidation_1-auc:0.81767                                                                  \n",
      "[4]\tvalidation_0-auc:0.85177\tvalidation_1-auc:0.81392                                                                  \n",
      "[5]\tvalidation_0-auc:0.85461\tvalidation_1-auc:0.81349                                                                  \n",
      "[6]\tvalidation_0-auc:0.85983\tvalidation_1-auc:0.82075                                                                  \n",
      "[7]\tvalidation_0-auc:0.86106\tvalidation_1-auc:0.82102                                                                  \n",
      "[8]\tvalidation_0-auc:0.86572\tvalidation_1-auc:0.82510                                                                  \n",
      "[9]\tvalidation_0-auc:0.86571\tvalidation_1-auc:0.82343                                                                  \n",
      "[10]\tvalidation_0-auc:0.86913\tvalidation_1-auc:0.82620                                                                 \n",
      "[11]\tvalidation_0-auc:0.87033\tvalidation_1-auc:0.82577                                                                 \n",
      "[12]\tvalidation_0-auc:0.87130\tvalidation_1-auc:0.82491                                                                 \n",
      "[13]\tvalidation_0-auc:0.87463\tvalidation_1-auc:0.82718                                                                 \n",
      "[14]\tvalidation_0-auc:0.87506\tvalidation_1-auc:0.82659                                                                 \n",
      "[15]\tvalidation_0-auc:0.87788\tvalidation_1-auc:0.82858                                                                 \n",
      "[16]\tvalidation_0-auc:0.88019\tvalidation_1-auc:0.83060                                                                 \n",
      "[17]\tvalidation_0-auc:0.88081\tvalidation_1-auc:0.83039                                                                 \n",
      "[18]\tvalidation_0-auc:0.88164\tvalidation_1-auc:0.82972                                                                 \n",
      "[19]\tvalidation_0-auc:0.88316\tvalidation_1-auc:0.83141                                                                 \n",
      "[20]\tvalidation_0-auc:0.88511\tvalidation_1-auc:0.83240                                                                 \n",
      "[21]\tvalidation_0-auc:0.88668\tvalidation_1-auc:0.83363                                                                 \n",
      "[22]\tvalidation_0-auc:0.88787\tvalidation_1-auc:0.83454                                                                 \n",
      "[23]\tvalidation_0-auc:0.88876\tvalidation_1-auc:0.83589                                                                 \n",
      "[24]\tvalidation_0-auc:0.88965\tvalidation_1-auc:0.83669                                                                 \n",
      "[25]\tvalidation_0-auc:0.89097\tvalidation_1-auc:0.83702                                                                 \n",
      "[26]\tvalidation_0-auc:0.89167\tvalidation_1-auc:0.83660                                                                 \n",
      "[27]\tvalidation_0-auc:0.89227\tvalidation_1-auc:0.83620                                                                 \n",
      "[28]\tvalidation_0-auc:0.89317\tvalidation_1-auc:0.83648                                                                 \n",
      "[29]\tvalidation_0-auc:0.89329\tvalidation_1-auc:0.83645                                                                 \n",
      "[30]\tvalidation_0-auc:0.89382\tvalidation_1-auc:0.83615                                                                 \n",
      "[31]\tvalidation_0-auc:0.89434\tvalidation_1-auc:0.83577                                                                 \n",
      "[32]\tvalidation_0-auc:0.89509\tvalidation_1-auc:0.83638                                                                 \n",
      "[33]\tvalidation_0-auc:0.89585\tvalidation_1-auc:0.83673                                                                 \n",
      "[34]\tvalidation_0-auc:0.89604\tvalidation_1-auc:0.83705                                                                 \n",
      "[35]\tvalidation_0-auc:0.89674\tvalidation_1-auc:0.83765                                                                 \n",
      "[36]\tvalidation_0-auc:0.89729\tvalidation_1-auc:0.83805                                                                 \n",
      "[37]\tvalidation_0-auc:0.89788\tvalidation_1-auc:0.83845                                                                 \n",
      "[38]\tvalidation_0-auc:0.89831\tvalidation_1-auc:0.83853                                                                 \n",
      "[39]\tvalidation_0-auc:0.89939\tvalidation_1-auc:0.83890                                                                 \n",
      "[40]\tvalidation_0-auc:0.89965\tvalidation_1-auc:0.83893                                                                 \n",
      "[41]\tvalidation_0-auc:0.90074\tvalidation_1-auc:0.83906                                                                 \n",
      "[42]\tvalidation_0-auc:0.90082\tvalidation_1-auc:0.83899                                                                 \n",
      "[43]\tvalidation_0-auc:0.90092\tvalidation_1-auc:0.83909                                                                 \n",
      "[44]\tvalidation_0-auc:0.90099\tvalidation_1-auc:0.83910                                                                 \n",
      "[45]\tvalidation_0-auc:0.90148\tvalidation_1-auc:0.83910                                                                 \n",
      "[46]\tvalidation_0-auc:0.90162\tvalidation_1-auc:0.83919                                                                 \n",
      "[47]\tvalidation_0-auc:0.90192\tvalidation_1-auc:0.83913                                                                 \n",
      "[48]\tvalidation_0-auc:0.90237\tvalidation_1-auc:0.83926                                                                 \n",
      "[49]\tvalidation_0-auc:0.90249\tvalidation_1-auc:0.83927                                                                 \n",
      "[50]\tvalidation_0-auc:0.90345\tvalidation_1-auc:0.83947                                                                 \n",
      "[51]\tvalidation_0-auc:0.90429\tvalidation_1-auc:0.83929                                                                 \n",
      "[52]\tvalidation_0-auc:0.90482\tvalidation_1-auc:0.83906                                                                 \n",
      "[53]\tvalidation_0-auc:0.90496\tvalidation_1-auc:0.83932                                                                 \n",
      "[54]\tvalidation_0-auc:0.90520\tvalidation_1-auc:0.83933                                                                 \n",
      "[55]\tvalidation_0-auc:0.90572\tvalidation_1-auc:0.83943                                                                 \n",
      "[56]\tvalidation_0-auc:0.90592\tvalidation_1-auc:0.83950                                                                 \n",
      "[57]\tvalidation_0-auc:0.90598\tvalidation_1-auc:0.83952                                                                 \n",
      "[58]\tvalidation_0-auc:0.90683\tvalidation_1-auc:0.83953                                                                 \n",
      "[59]\tvalidation_0-auc:0.90749\tvalidation_1-auc:0.83942                                                                 \n",
      "[60]\tvalidation_0-auc:0.90764\tvalidation_1-auc:0.83956                                                                 \n",
      "[61]\tvalidation_0-auc:0.90795\tvalidation_1-auc:0.83972                                                                 \n",
      "[62]\tvalidation_0-auc:0.90808\tvalidation_1-auc:0.83969                                                                 \n",
      "[63]\tvalidation_0-auc:0.90839\tvalidation_1-auc:0.83957                                                                 \n",
      "[64]\tvalidation_0-auc:0.90859\tvalidation_1-auc:0.83970                                                                 \n",
      "[65]\tvalidation_0-auc:0.90894\tvalidation_1-auc:0.83948                                                                 \n",
      "[66]\tvalidation_0-auc:0.90898\tvalidation_1-auc:0.83948                                                                 \n",
      "[67]\tvalidation_0-auc:0.90924\tvalidation_1-auc:0.83946                                                                 \n",
      "[68]\tvalidation_0-auc:0.90936\tvalidation_1-auc:0.83942                                                                 \n",
      "[69]\tvalidation_0-auc:0.90983\tvalidation_1-auc:0.83917                                                                 \n",
      "[70]\tvalidation_0-auc:0.91013\tvalidation_1-auc:0.83918                                                                 \n",
      "[71]\tvalidation_0-auc:0.91028\tvalidation_1-auc:0.83916                                                                 \n",
      "[72]\tvalidation_0-auc:0.91044\tvalidation_1-auc:0.83912                                                                 \n",
      "[73]\tvalidation_0-auc:0.91060\tvalidation_1-auc:0.83903                                                                 \n",
      "[74]\tvalidation_0-auc:0.91112\tvalidation_1-auc:0.83911                                                                 \n",
      "[75]\tvalidation_0-auc:0.91149\tvalidation_1-auc:0.83908                                                                 \n",
      "[76]\tvalidation_0-auc:0.91224\tvalidation_1-auc:0.83917                                                                 \n",
      "[77]\tvalidation_0-auc:0.91238\tvalidation_1-auc:0.83912                                                                 \n",
      "[78]\tvalidation_0-auc:0.91267\tvalidation_1-auc:0.83885                                                                 \n",
      "[79]\tvalidation_0-auc:0.91274\tvalidation_1-auc:0.83879                                                                 \n",
      "[80]\tvalidation_0-auc:0.91281\tvalidation_1-auc:0.83878                                                                 \n",
      "[81]\tvalidation_0-auc:0.91300\tvalidation_1-auc:0.83871                                                                 \n",
      "[82]\tvalidation_0-auc:0.91314\tvalidation_1-auc:0.83873                                                                 \n",
      "[83]\tvalidation_0-auc:0.91365\tvalidation_1-auc:0.83852                                                                 \n",
      "[84]\tvalidation_0-auc:0.91374\tvalidation_1-auc:0.83848                                                                 \n",
      "[85]\tvalidation_0-auc:0.91412\tvalidation_1-auc:0.83833                                                                 \n",
      "[86]\tvalidation_0-auc:0.91511\tvalidation_1-auc:0.83808                                                                 \n",
      "[87]\tvalidation_0-auc:0.91581\tvalidation_1-auc:0.83787                                                                 \n",
      "[88]\tvalidation_0-auc:0.91599\tvalidation_1-auc:0.83778                                                                 \n",
      "[89]\tvalidation_0-auc:0.91625\tvalidation_1-auc:0.83760                                                                 \n",
      "[90]\tvalidation_0-auc:0.91653\tvalidation_1-auc:0.83759                                                                 \n",
      "[91]\tvalidation_0-auc:0.91680\tvalidation_1-auc:0.83749                                                                 \n",
      "[0]\tvalidation_0-auc:0.84579\tvalidation_1-auc:0.80789                                                                  \n",
      "[1]\tvalidation_0-auc:0.85419\tvalidation_1-auc:0.80117                                                                  \n",
      "[2]\tvalidation_0-auc:0.86044\tvalidation_1-auc:0.80977                                                                  \n",
      "[3]\tvalidation_0-auc:0.85875\tvalidation_1-auc:0.80556                                                                  \n",
      "[4]\tvalidation_0-auc:0.85703\tvalidation_1-auc:0.80055                                                                  \n",
      "[5]\tvalidation_0-auc:0.86024\tvalidation_1-auc:0.80323                                                                  \n",
      "[6]\tvalidation_0-auc:0.86751\tvalidation_1-auc:0.80672                                                                  \n",
      "[7]\tvalidation_0-auc:0.86854\tvalidation_1-auc:0.80659                                                                  \n",
      "[8]\tvalidation_0-auc:0.87309\tvalidation_1-auc:0.81094                                                                  \n",
      "[9]\tvalidation_0-auc:0.87262\tvalidation_1-auc:0.80936                                                                  \n",
      "[10]\tvalidation_0-auc:0.87616\tvalidation_1-auc:0.81252                                                                 \n",
      "[11]\tvalidation_0-auc:0.87735\tvalidation_1-auc:0.81218                                                                 \n",
      "[12]\tvalidation_0-auc:0.87801\tvalidation_1-auc:0.81206                                                                 \n",
      "[13]\tvalidation_0-auc:0.88196\tvalidation_1-auc:0.81352                                                                 \n",
      "[14]\tvalidation_0-auc:0.88285\tvalidation_1-auc:0.81267                                                                 \n",
      "[15]\tvalidation_0-auc:0.88580\tvalidation_1-auc:0.81457                                                                 \n",
      "[16]\tvalidation_0-auc:0.88662\tvalidation_1-auc:0.81405                                                                 \n",
      "[17]\tvalidation_0-auc:0.88743\tvalidation_1-auc:0.81289                                                                 \n",
      "[18]\tvalidation_0-auc:0.88772\tvalidation_1-auc:0.81202                                                                 \n",
      "[19]\tvalidation_0-auc:0.88934\tvalidation_1-auc:0.81480                                                                 \n",
      "[20]\tvalidation_0-auc:0.89099\tvalidation_1-auc:0.81615                                                                 \n",
      "[21]\tvalidation_0-auc:0.89204\tvalidation_1-auc:0.81730                                                                 \n",
      "[22]\tvalidation_0-auc:0.89318\tvalidation_1-auc:0.81860                                                                 \n",
      "[23]\tvalidation_0-auc:0.89371\tvalidation_1-auc:0.81957                                                                 \n",
      "[24]\tvalidation_0-auc:0.89467\tvalidation_1-auc:0.82030                                                                 \n",
      "[25]\tvalidation_0-auc:0.89514\tvalidation_1-auc:0.82123                                                                 \n",
      "[26]\tvalidation_0-auc:0.89531\tvalidation_1-auc:0.82075                                                                 \n",
      "[27]\tvalidation_0-auc:0.89584\tvalidation_1-auc:0.82027                                                                 \n",
      "[28]\tvalidation_0-auc:0.89651\tvalidation_1-auc:0.82098                                                                 \n",
      "[29]\tvalidation_0-auc:0.89668\tvalidation_1-auc:0.82039                                                                 \n",
      "[30]\tvalidation_0-auc:0.89741\tvalidation_1-auc:0.82022                                                                 \n",
      "[31]\tvalidation_0-auc:0.89859\tvalidation_1-auc:0.81990                                                                 \n",
      "[32]\tvalidation_0-auc:0.90010\tvalidation_1-auc:0.82017                                                                 \n",
      "[33]\tvalidation_0-auc:0.90091\tvalidation_1-auc:0.82069                                                                 \n",
      "[34]\tvalidation_0-auc:0.90122\tvalidation_1-auc:0.82099                                                                 \n",
      "[35]\tvalidation_0-auc:0.90183\tvalidation_1-auc:0.82112                                                                 \n",
      "[36]\tvalidation_0-auc:0.90241\tvalidation_1-auc:0.82120                                                                 \n",
      "[37]\tvalidation_0-auc:0.90281\tvalidation_1-auc:0.82133                                                                 \n",
      "[38]\tvalidation_0-auc:0.90318\tvalidation_1-auc:0.82135                                                                 \n",
      "[39]\tvalidation_0-auc:0.90374\tvalidation_1-auc:0.82189                                                                 \n",
      "[40]\tvalidation_0-auc:0.90383\tvalidation_1-auc:0.82183                                                                 \n",
      "[41]\tvalidation_0-auc:0.90445\tvalidation_1-auc:0.82183                                                                 \n",
      "[42]\tvalidation_0-auc:0.90469\tvalidation_1-auc:0.82172                                                                 \n",
      "[43]\tvalidation_0-auc:0.90523\tvalidation_1-auc:0.82132                                                                 \n",
      "[44]\tvalidation_0-auc:0.90532\tvalidation_1-auc:0.82119                                                                 \n",
      "[45]\tvalidation_0-auc:0.90602\tvalidation_1-auc:0.82150                                                                 \n",
      "[46]\tvalidation_0-auc:0.90621\tvalidation_1-auc:0.82138                                                                 \n",
      "[47]\tvalidation_0-auc:0.90642\tvalidation_1-auc:0.82136                                                                 \n",
      "[48]\tvalidation_0-auc:0.90655\tvalidation_1-auc:0.82130                                                                 \n",
      "[49]\tvalidation_0-auc:0.90731\tvalidation_1-auc:0.82138                                                                 \n",
      "[50]\tvalidation_0-auc:0.90758\tvalidation_1-auc:0.82131                                                                 \n",
      "[51]\tvalidation_0-auc:0.90846\tvalidation_1-auc:0.82140                                                                 \n",
      "[52]\tvalidation_0-auc:0.90868\tvalidation_1-auc:0.82121                                                                 \n",
      "[53]\tvalidation_0-auc:0.90886\tvalidation_1-auc:0.82124                                                                 \n",
      "[54]\tvalidation_0-auc:0.90946\tvalidation_1-auc:0.82118                                                                 \n",
      "[55]\tvalidation_0-auc:0.90951\tvalidation_1-auc:0.82143                                                                 \n",
      "[56]\tvalidation_0-auc:0.90959\tvalidation_1-auc:0.82153                                                                 \n",
      "[57]\tvalidation_0-auc:0.90972\tvalidation_1-auc:0.82122                                                                 \n",
      "[58]\tvalidation_0-auc:0.91062\tvalidation_1-auc:0.82104                                                                 \n",
      "[59]\tvalidation_0-auc:0.91079\tvalidation_1-auc:0.82111                                                                 \n",
      "[60]\tvalidation_0-auc:0.91113\tvalidation_1-auc:0.82139                                                                 \n",
      "[61]\tvalidation_0-auc:0.91181\tvalidation_1-auc:0.82142                                                                 \n",
      "[62]\tvalidation_0-auc:0.91186\tvalidation_1-auc:0.82127                                                                 \n",
      "[63]\tvalidation_0-auc:0.91201\tvalidation_1-auc:0.82123                                                                 \n",
      "[64]\tvalidation_0-auc:0.91240\tvalidation_1-auc:0.82139                                                                 \n",
      "[65]\tvalidation_0-auc:0.91257\tvalidation_1-auc:0.82139                                                                 \n",
      "[66]\tvalidation_0-auc:0.91273\tvalidation_1-auc:0.82115                                                                 \n",
      "[67]\tvalidation_0-auc:0.91339\tvalidation_1-auc:0.82103                                                                 \n",
      "[68]\tvalidation_0-auc:0.91441\tvalidation_1-auc:0.82100                                                                 \n",
      "[69]\tvalidation_0-auc:0.91496\tvalidation_1-auc:0.82111                                                                 \n",
      "[0]\tvalidation_0-auc:0.84098\tvalidation_1-auc:0.81077                                                                  \n",
      "[1]\tvalidation_0-auc:0.85066\tvalidation_1-auc:0.82509                                                                  \n",
      "[2]\tvalidation_0-auc:0.85925\tvalidation_1-auc:0.83454                                                                  \n",
      "[3]\tvalidation_0-auc:0.85671\tvalidation_1-auc:0.83313                                                                  \n",
      "[4]\tvalidation_0-auc:0.85567\tvalidation_1-auc:0.83090                                                                  \n",
      "[5]\tvalidation_0-auc:0.85724\tvalidation_1-auc:0.83030                                                                  \n",
      "[6]\tvalidation_0-auc:0.86480\tvalidation_1-auc:0.83548                                                                  \n",
      "[7]\tvalidation_0-auc:0.86486\tvalidation_1-auc:0.83457                                                                  \n",
      "[8]\tvalidation_0-auc:0.87064\tvalidation_1-auc:0.83804                                                                  \n",
      "[9]\tvalidation_0-auc:0.87028\tvalidation_1-auc:0.83817                                                                  \n",
      "[10]\tvalidation_0-auc:0.87418\tvalidation_1-auc:0.84019                                                                 \n",
      "[11]\tvalidation_0-auc:0.87481\tvalidation_1-auc:0.83943                                                                 \n",
      "[12]\tvalidation_0-auc:0.87548\tvalidation_1-auc:0.83914                                                                 \n",
      "[13]\tvalidation_0-auc:0.87996\tvalidation_1-auc:0.84026                                                                 \n",
      "[14]\tvalidation_0-auc:0.88073\tvalidation_1-auc:0.83992                                                                 \n",
      "[15]\tvalidation_0-auc:0.88341\tvalidation_1-auc:0.84097                                                                 \n",
      "[16]\tvalidation_0-auc:0.88409\tvalidation_1-auc:0.83994                                                                 \n",
      "[17]\tvalidation_0-auc:0.88449\tvalidation_1-auc:0.83979                                                                 \n",
      "[18]\tvalidation_0-auc:0.88472\tvalidation_1-auc:0.83949                                                                 \n",
      "[19]\tvalidation_0-auc:0.88634\tvalidation_1-auc:0.84088                                                                 \n",
      "[20]\tvalidation_0-auc:0.88871\tvalidation_1-auc:0.84162                                                                 \n",
      "[21]\tvalidation_0-auc:0.89001\tvalidation_1-auc:0.84255                                                                 \n",
      "[22]\tvalidation_0-auc:0.89094\tvalidation_1-auc:0.84254                                                                 \n",
      "[23]\tvalidation_0-auc:0.89176\tvalidation_1-auc:0.84236                                                                 \n",
      "[24]\tvalidation_0-auc:0.89243\tvalidation_1-auc:0.84271                                                                 \n",
      "[25]\tvalidation_0-auc:0.89342\tvalidation_1-auc:0.84266                                                                 \n",
      "[26]\tvalidation_0-auc:0.89383\tvalidation_1-auc:0.84252                                                                 \n",
      "[27]\tvalidation_0-auc:0.89397\tvalidation_1-auc:0.84251                                                                 \n",
      "[28]\tvalidation_0-auc:0.89494\tvalidation_1-auc:0.84236                                                                 \n",
      "[29]\tvalidation_0-auc:0.89565\tvalidation_1-auc:0.84181                                                                 \n",
      "[30]\tvalidation_0-auc:0.89631\tvalidation_1-auc:0.84203                                                                 \n",
      "[31]\tvalidation_0-auc:0.89679\tvalidation_1-auc:0.84211                                                                 \n",
      "[32]\tvalidation_0-auc:0.89796\tvalidation_1-auc:0.84189                                                                 \n",
      "[33]\tvalidation_0-auc:0.89901\tvalidation_1-auc:0.84141                                                                 \n",
      "[34]\tvalidation_0-auc:0.89944\tvalidation_1-auc:0.84152                                                                 \n",
      "[35]\tvalidation_0-auc:0.90083\tvalidation_1-auc:0.84154                                                                 \n",
      "[36]\tvalidation_0-auc:0.90138\tvalidation_1-auc:0.84133                                                                 \n",
      "[37]\tvalidation_0-auc:0.90168\tvalidation_1-auc:0.84134                                                                 \n",
      "[38]\tvalidation_0-auc:0.90223\tvalidation_1-auc:0.84137                                                                 \n",
      "[39]\tvalidation_0-auc:0.90259\tvalidation_1-auc:0.84113                                                                 \n",
      "[40]\tvalidation_0-auc:0.90340\tvalidation_1-auc:0.84056                                                                 \n",
      "[41]\tvalidation_0-auc:0.90372\tvalidation_1-auc:0.84032                                                                 \n",
      "[42]\tvalidation_0-auc:0.90396\tvalidation_1-auc:0.84018                                                                 \n",
      "[43]\tvalidation_0-auc:0.90441\tvalidation_1-auc:0.84039                                                                 \n",
      "[44]\tvalidation_0-auc:0.90454\tvalidation_1-auc:0.84014                                                                 \n",
      "[45]\tvalidation_0-auc:0.90492\tvalidation_1-auc:0.84006                                                                 \n",
      "[46]\tvalidation_0-auc:0.90536\tvalidation_1-auc:0.83981                                                                 \n",
      "[47]\tvalidation_0-auc:0.90568\tvalidation_1-auc:0.83974                                                                 \n",
      "[48]\tvalidation_0-auc:0.90579\tvalidation_1-auc:0.83954                                                                 \n",
      "[49]\tvalidation_0-auc:0.90588\tvalidation_1-auc:0.83939                                                                 \n",
      "[50]\tvalidation_0-auc:0.90693\tvalidation_1-auc:0.83935                                                                 \n",
      "[51]\tvalidation_0-auc:0.90740\tvalidation_1-auc:0.83917                                                                 \n",
      "[52]\tvalidation_0-auc:0.90769\tvalidation_1-auc:0.83913                                                                 \n",
      "[53]\tvalidation_0-auc:0.90802\tvalidation_1-auc:0.83938                                                                 \n",
      "[54]\tvalidation_0-auc:0.90812\tvalidation_1-auc:0.83917                                                                 \n",
      "[0]\tvalidation_0-auc:0.83959\tvalidation_1-auc:0.81811                                                                  \n",
      "[1]\tvalidation_0-auc:0.84579\tvalidation_1-auc:0.81282                                                                  \n",
      "[2]\tvalidation_0-auc:0.85386\tvalidation_1-auc:0.82055                                                                  \n",
      "[3]\tvalidation_0-auc:0.85283\tvalidation_1-auc:0.81623                                                                  \n",
      "[4]\tvalidation_0-auc:0.85320\tvalidation_1-auc:0.81258                                                                  \n",
      "[5]\tvalidation_0-auc:0.85434\tvalidation_1-auc:0.81326                                                                  \n",
      "[6]\tvalidation_0-auc:0.86050\tvalidation_1-auc:0.82171                                                                  \n",
      "[7]\tvalidation_0-auc:0.86238\tvalidation_1-auc:0.82013                                                                  \n",
      "[8]\tvalidation_0-auc:0.86781\tvalidation_1-auc:0.82462                                                                  \n",
      "[9]\tvalidation_0-auc:0.86826\tvalidation_1-auc:0.82384                                                                  \n",
      "[10]\tvalidation_0-auc:0.87156\tvalidation_1-auc:0.82690                                                                 \n",
      "[11]\tvalidation_0-auc:0.87334\tvalidation_1-auc:0.82633                                                                 \n",
      "[12]\tvalidation_0-auc:0.87455\tvalidation_1-auc:0.82592                                                                 \n",
      "[13]\tvalidation_0-auc:0.87862\tvalidation_1-auc:0.82849                                                                 \n",
      "[14]\tvalidation_0-auc:0.87916\tvalidation_1-auc:0.82813                                                                 \n",
      "[15]\tvalidation_0-auc:0.88209\tvalidation_1-auc:0.83049                                                                 \n",
      "[16]\tvalidation_0-auc:0.88296\tvalidation_1-auc:0.82970                                                                 \n",
      "[17]\tvalidation_0-auc:0.88333\tvalidation_1-auc:0.82911                                                                 \n",
      "[18]\tvalidation_0-auc:0.88397\tvalidation_1-auc:0.82803                                                                 \n",
      "[19]\tvalidation_0-auc:0.88628\tvalidation_1-auc:0.83000                                                                 \n",
      "[20]\tvalidation_0-auc:0.88870\tvalidation_1-auc:0.83186                                                                 \n",
      "[21]\tvalidation_0-auc:0.89022\tvalidation_1-auc:0.83325                                                                 \n",
      "[22]\tvalidation_0-auc:0.89177\tvalidation_1-auc:0.83442                                                                 \n",
      "[23]\tvalidation_0-auc:0.89279\tvalidation_1-auc:0.83570                                                                 \n",
      "[24]\tvalidation_0-auc:0.89383\tvalidation_1-auc:0.83651                                                                 \n",
      "[25]\tvalidation_0-auc:0.89478\tvalidation_1-auc:0.83711                                                                 \n",
      "[26]\tvalidation_0-auc:0.89502\tvalidation_1-auc:0.83675                                                                 \n",
      "[27]\tvalidation_0-auc:0.89539\tvalidation_1-auc:0.83687                                                                 \n",
      "[28]\tvalidation_0-auc:0.89648\tvalidation_1-auc:0.83730                                                                 \n",
      "[29]\tvalidation_0-auc:0.89672\tvalidation_1-auc:0.83744                                                                 \n",
      "[30]\tvalidation_0-auc:0.89767\tvalidation_1-auc:0.83758                                                                 \n",
      "[31]\tvalidation_0-auc:0.89906\tvalidation_1-auc:0.83767                                                                 \n",
      "[32]\tvalidation_0-auc:0.89981\tvalidation_1-auc:0.83846                                                                 \n",
      "[33]\tvalidation_0-auc:0.90102\tvalidation_1-auc:0.83861                                                                 \n",
      "[34]\tvalidation_0-auc:0.90145\tvalidation_1-auc:0.83889                                                                 \n",
      "[35]\tvalidation_0-auc:0.90294\tvalidation_1-auc:0.83870                                                                 \n",
      "[36]\tvalidation_0-auc:0.90333\tvalidation_1-auc:0.83886                                                                 \n",
      "[37]\tvalidation_0-auc:0.90436\tvalidation_1-auc:0.83881                                                                 \n",
      "[38]\tvalidation_0-auc:0.90511\tvalidation_1-auc:0.83869                                                                 \n",
      "[39]\tvalidation_0-auc:0.90555\tvalidation_1-auc:0.83872                                                                 \n",
      "[40]\tvalidation_0-auc:0.90614\tvalidation_1-auc:0.83841                                                                 \n",
      "[41]\tvalidation_0-auc:0.90650\tvalidation_1-auc:0.83873                                                                 \n",
      "[42]\tvalidation_0-auc:0.90677\tvalidation_1-auc:0.83867                                                                 \n",
      "[43]\tvalidation_0-auc:0.90708\tvalidation_1-auc:0.83859                                                                 \n",
      "[44]\tvalidation_0-auc:0.90727\tvalidation_1-auc:0.83854                                                                 \n",
      "[45]\tvalidation_0-auc:0.90790\tvalidation_1-auc:0.83859                                                                 \n",
      "[46]\tvalidation_0-auc:0.90809\tvalidation_1-auc:0.83869                                                                 \n",
      "[47]\tvalidation_0-auc:0.90826\tvalidation_1-auc:0.83877                                                                 \n",
      "[48]\tvalidation_0-auc:0.90880\tvalidation_1-auc:0.83884                                                                 \n",
      "[49]\tvalidation_0-auc:0.90924\tvalidation_1-auc:0.83897                                                                 \n",
      "[50]\tvalidation_0-auc:0.91044\tvalidation_1-auc:0.83874                                                                 \n",
      "[51]\tvalidation_0-auc:0.91136\tvalidation_1-auc:0.83878                                                                 \n",
      "[52]\tvalidation_0-auc:0.91150\tvalidation_1-auc:0.83877                                                                 \n",
      "[53]\tvalidation_0-auc:0.91164\tvalidation_1-auc:0.83879                                                                 \n",
      "[54]\tvalidation_0-auc:0.91183\tvalidation_1-auc:0.83871                                                                 \n",
      "[55]\tvalidation_0-auc:0.91211\tvalidation_1-auc:0.83872                                                                 \n",
      "[56]\tvalidation_0-auc:0.91242\tvalidation_1-auc:0.83884                                                                 \n",
      "[57]\tvalidation_0-auc:0.91262\tvalidation_1-auc:0.83872                                                                 \n",
      "[58]\tvalidation_0-auc:0.91376\tvalidation_1-auc:0.83822                                                                 \n",
      "[59]\tvalidation_0-auc:0.91410\tvalidation_1-auc:0.83823                                                                 \n",
      "[60]\tvalidation_0-auc:0.91455\tvalidation_1-auc:0.83825                                                                 \n",
      "[61]\tvalidation_0-auc:0.91551\tvalidation_1-auc:0.83829                                                                 \n",
      "[62]\tvalidation_0-auc:0.91571\tvalidation_1-auc:0.83827                                                                 \n",
      "[63]\tvalidation_0-auc:0.91625\tvalidation_1-auc:0.83815                                                                 \n",
      "[64]\tvalidation_0-auc:0.91668\tvalidation_1-auc:0.83817                                                                 \n",
      "[65]\tvalidation_0-auc:0.91754\tvalidation_1-auc:0.83831                                                                 \n",
      "[66]\tvalidation_0-auc:0.91771\tvalidation_1-auc:0.83831                                                                 \n",
      "[67]\tvalidation_0-auc:0.91818\tvalidation_1-auc:0.83854                                                                 \n",
      "[68]\tvalidation_0-auc:0.91859\tvalidation_1-auc:0.83852                                                                 \n",
      "[69]\tvalidation_0-auc:0.91894\tvalidation_1-auc:0.83851                                                                 \n",
      "[70]\tvalidation_0-auc:0.91956\tvalidation_1-auc:0.83867                                                                 \n",
      "[71]\tvalidation_0-auc:0.91968\tvalidation_1-auc:0.83859                                                                 \n",
      "[72]\tvalidation_0-auc:0.92010\tvalidation_1-auc:0.83851                                                                 \n",
      "[73]\tvalidation_0-auc:0.92024\tvalidation_1-auc:0.83852                                                                 \n",
      "[74]\tvalidation_0-auc:0.92040\tvalidation_1-auc:0.83843                                                                 \n",
      "[75]\tvalidation_0-auc:0.92060\tvalidation_1-auc:0.83834                                                                 \n",
      "[76]\tvalidation_0-auc:0.92137\tvalidation_1-auc:0.83814                                                                 \n",
      "[77]\tvalidation_0-auc:0.92190\tvalidation_1-auc:0.83786                                                                 \n",
      "[78]\tvalidation_0-auc:0.92198\tvalidation_1-auc:0.83785                                                                 \n",
      "[79]\tvalidation_0-auc:0.92204\tvalidation_1-auc:0.83777                                                                 \n",
      "[0]\tvalidation_0-auc:0.87366\tvalidation_1-auc:0.79786                                                                  \n",
      "[1]\tvalidation_0-auc:0.88143\tvalidation_1-auc:0.79132                                                                  \n",
      "[2]\tvalidation_0-auc:0.88970\tvalidation_1-auc:0.80707                                                                  \n",
      "[3]\tvalidation_0-auc:0.89180\tvalidation_1-auc:0.80440                                                                  \n",
      "[4]\tvalidation_0-auc:0.89239\tvalidation_1-auc:0.79928                                                                  \n",
      "[5]\tvalidation_0-auc:0.89694\tvalidation_1-auc:0.80662                                                                  \n",
      "[6]\tvalidation_0-auc:0.90176\tvalidation_1-auc:0.81033                                                                  \n",
      "[7]\tvalidation_0-auc:0.90437\tvalidation_1-auc:0.81173                                                                  \n",
      "[8]\tvalidation_0-auc:0.90691\tvalidation_1-auc:0.81240                                                                  \n",
      "[9]\tvalidation_0-auc:0.90785\tvalidation_1-auc:0.80904                                                                  \n",
      "[10]\tvalidation_0-auc:0.91004\tvalidation_1-auc:0.81081                                                                 \n",
      "[11]\tvalidation_0-auc:0.91206\tvalidation_1-auc:0.81305                                                                 \n",
      "[12]\tvalidation_0-auc:0.91389\tvalidation_1-auc:0.81376                                                                 \n",
      "[13]\tvalidation_0-auc:0.91520\tvalidation_1-auc:0.81418                                                                 \n",
      "[14]\tvalidation_0-auc:0.91663\tvalidation_1-auc:0.81341                                                                 \n",
      "[15]\tvalidation_0-auc:0.91779\tvalidation_1-auc:0.81435                                                                 \n",
      "[16]\tvalidation_0-auc:0.91950\tvalidation_1-auc:0.81468                                                                 \n",
      "[17]\tvalidation_0-auc:0.92078\tvalidation_1-auc:0.81404                                                                 \n",
      "[18]\tvalidation_0-auc:0.92154\tvalidation_1-auc:0.81356                                                                 \n",
      "[19]\tvalidation_0-auc:0.92270\tvalidation_1-auc:0.81387                                                                 \n",
      "[20]\tvalidation_0-auc:0.92371\tvalidation_1-auc:0.81450                                                                 \n",
      "[21]\tvalidation_0-auc:0.92474\tvalidation_1-auc:0.81498                                                                 \n",
      "[22]\tvalidation_0-auc:0.92540\tvalidation_1-auc:0.81557                                                                 \n",
      "[23]\tvalidation_0-auc:0.92588\tvalidation_1-auc:0.81603                                                                 \n",
      "[24]\tvalidation_0-auc:0.92653\tvalidation_1-auc:0.81630                                                                 \n",
      "[25]\tvalidation_0-auc:0.92788\tvalidation_1-auc:0.81623                                                                 \n",
      "[26]\tvalidation_0-auc:0.92860\tvalidation_1-auc:0.81601                                                                 \n",
      "[27]\tvalidation_0-auc:0.92920\tvalidation_1-auc:0.81554                                                                 \n",
      "[28]\tvalidation_0-auc:0.93001\tvalidation_1-auc:0.81595                                                                 \n",
      "[29]\tvalidation_0-auc:0.93038\tvalidation_1-auc:0.81531                                                                 \n",
      "[30]\tvalidation_0-auc:0.93094\tvalidation_1-auc:0.81497                                                                 \n",
      "[31]\tvalidation_0-auc:0.93160\tvalidation_1-auc:0.81535                                                                 \n",
      "[32]\tvalidation_0-auc:0.93236\tvalidation_1-auc:0.81546                                                                 \n",
      "[33]\tvalidation_0-auc:0.93308\tvalidation_1-auc:0.81560                                                                 \n",
      "[34]\tvalidation_0-auc:0.93375\tvalidation_1-auc:0.81547                                                                 \n",
      "[35]\tvalidation_0-auc:0.93460\tvalidation_1-auc:0.81577                                                                 \n",
      "[36]\tvalidation_0-auc:0.93527\tvalidation_1-auc:0.81582                                                                 \n",
      "[37]\tvalidation_0-auc:0.93569\tvalidation_1-auc:0.81584                                                                 \n",
      "[38]\tvalidation_0-auc:0.93619\tvalidation_1-auc:0.81581                                                                 \n",
      "[39]\tvalidation_0-auc:0.93646\tvalidation_1-auc:0.81596                                                                 \n",
      "[40]\tvalidation_0-auc:0.93687\tvalidation_1-auc:0.81560                                                                 \n",
      "[41]\tvalidation_0-auc:0.93725\tvalidation_1-auc:0.81611                                                                 \n",
      "[42]\tvalidation_0-auc:0.93760\tvalidation_1-auc:0.81630                                                                 \n",
      "[43]\tvalidation_0-auc:0.93808\tvalidation_1-auc:0.81613                                                                 \n",
      "[44]\tvalidation_0-auc:0.93828\tvalidation_1-auc:0.81580                                                                 \n",
      "[45]\tvalidation_0-auc:0.93879\tvalidation_1-auc:0.81588                                                                 \n",
      "[46]\tvalidation_0-auc:0.93920\tvalidation_1-auc:0.81582                                                                 \n",
      "[47]\tvalidation_0-auc:0.93948\tvalidation_1-auc:0.81586                                                                 \n",
      "[48]\tvalidation_0-auc:0.93972\tvalidation_1-auc:0.81564                                                                 \n",
      "[49]\tvalidation_0-auc:0.93996\tvalidation_1-auc:0.81542                                                                 \n",
      "[50]\tvalidation_0-auc:0.94021\tvalidation_1-auc:0.81551                                                                 \n",
      "[51]\tvalidation_0-auc:0.94054\tvalidation_1-auc:0.81585                                                                 \n",
      "[52]\tvalidation_0-auc:0.94070\tvalidation_1-auc:0.81587                                                                 \n",
      "[53]\tvalidation_0-auc:0.94087\tvalidation_1-auc:0.81592                                                                 \n",
      "[54]\tvalidation_0-auc:0.94095\tvalidation_1-auc:0.81564                                                                 \n",
      "[55]\tvalidation_0-auc:0.94121\tvalidation_1-auc:0.81562                                                                 \n",
      "[56]\tvalidation_0-auc:0.94194\tvalidation_1-auc:0.81589                                                                 \n",
      "[57]\tvalidation_0-auc:0.94216\tvalidation_1-auc:0.81600                                                                 \n",
      "[58]\tvalidation_0-auc:0.94238\tvalidation_1-auc:0.81612                                                                 \n",
      "[59]\tvalidation_0-auc:0.94265\tvalidation_1-auc:0.81616                                                                 \n",
      "[60]\tvalidation_0-auc:0.94321\tvalidation_1-auc:0.81631                                                                 \n",
      "[61]\tvalidation_0-auc:0.94342\tvalidation_1-auc:0.81621                                                                 \n",
      "[62]\tvalidation_0-auc:0.94345\tvalidation_1-auc:0.81604                                                                 \n",
      "[63]\tvalidation_0-auc:0.94353\tvalidation_1-auc:0.81612                                                                 \n",
      "[64]\tvalidation_0-auc:0.94415\tvalidation_1-auc:0.81648                                                                 \n",
      "[65]\tvalidation_0-auc:0.94445\tvalidation_1-auc:0.81621                                                                 \n",
      "[66]\tvalidation_0-auc:0.94476\tvalidation_1-auc:0.81632                                                                 \n",
      "[67]\tvalidation_0-auc:0.94502\tvalidation_1-auc:0.81636                                                                 \n",
      "[68]\tvalidation_0-auc:0.94518\tvalidation_1-auc:0.81638                                                                 \n",
      "[69]\tvalidation_0-auc:0.94559\tvalidation_1-auc:0.81643                                                                 \n",
      "[70]\tvalidation_0-auc:0.94572\tvalidation_1-auc:0.81648                                                                 \n",
      "[71]\tvalidation_0-auc:0.94597\tvalidation_1-auc:0.81649                                                                 \n",
      "[72]\tvalidation_0-auc:0.94644\tvalidation_1-auc:0.81674                                                                 \n",
      "[73]\tvalidation_0-auc:0.94662\tvalidation_1-auc:0.81688                                                                 \n",
      "[74]\tvalidation_0-auc:0.94694\tvalidation_1-auc:0.81694                                                                 \n",
      "[75]\tvalidation_0-auc:0.94710\tvalidation_1-auc:0.81696                                                                 \n",
      "[76]\tvalidation_0-auc:0.94742\tvalidation_1-auc:0.81686                                                                 \n",
      "[77]\tvalidation_0-auc:0.94762\tvalidation_1-auc:0.81674                                                                 \n",
      "[78]\tvalidation_0-auc:0.94784\tvalidation_1-auc:0.81659                                                                 \n",
      "[79]\tvalidation_0-auc:0.94797\tvalidation_1-auc:0.81663                                                                 \n",
      "[80]\tvalidation_0-auc:0.94816\tvalidation_1-auc:0.81665                                                                 \n",
      "[81]\tvalidation_0-auc:0.94862\tvalidation_1-auc:0.81659                                                                 \n",
      "[82]\tvalidation_0-auc:0.94871\tvalidation_1-auc:0.81659                                                                 \n",
      "[83]\tvalidation_0-auc:0.94903\tvalidation_1-auc:0.81656                                                                 \n",
      "[84]\tvalidation_0-auc:0.94939\tvalidation_1-auc:0.81646                                                                 \n",
      "[85]\tvalidation_0-auc:0.95013\tvalidation_1-auc:0.81614                                                                 \n",
      "[86]\tvalidation_0-auc:0.95077\tvalidation_1-auc:0.81624                                                                 \n",
      "[87]\tvalidation_0-auc:0.95084\tvalidation_1-auc:0.81618                                                                 \n",
      "[88]\tvalidation_0-auc:0.95105\tvalidation_1-auc:0.81606                                                                 \n",
      "[89]\tvalidation_0-auc:0.95150\tvalidation_1-auc:0.81592                                                                 \n",
      "[90]\tvalidation_0-auc:0.95168\tvalidation_1-auc:0.81585                                                                 \n",
      "[91]\tvalidation_0-auc:0.95203\tvalidation_1-auc:0.81574                                                                 \n",
      "[92]\tvalidation_0-auc:0.95208\tvalidation_1-auc:0.81574                                                                 \n",
      "[93]\tvalidation_0-auc:0.95260\tvalidation_1-auc:0.81556                                                                 \n",
      "[94]\tvalidation_0-auc:0.95272\tvalidation_1-auc:0.81555                                                                 \n",
      "[95]\tvalidation_0-auc:0.95303\tvalidation_1-auc:0.81539                                                                 \n",
      "[96]\tvalidation_0-auc:0.95319\tvalidation_1-auc:0.81525                                                                 \n",
      "[97]\tvalidation_0-auc:0.95328\tvalidation_1-auc:0.81525                                                                 \n",
      "[98]\tvalidation_0-auc:0.95355\tvalidation_1-auc:0.81527                                                                 \n",
      "[99]\tvalidation_0-auc:0.95391\tvalidation_1-auc:0.81524                                                                 \n",
      "[0]\tvalidation_0-auc:0.86802\tvalidation_1-auc:0.80715                                                                  \n",
      "[1]\tvalidation_0-auc:0.87469\tvalidation_1-auc:0.80546                                                                  \n",
      "[2]\tvalidation_0-auc:0.88344\tvalidation_1-auc:0.82764                                                                  \n",
      "[3]\tvalidation_0-auc:0.88550\tvalidation_1-auc:0.82487                                                                  \n",
      "[4]\tvalidation_0-auc:0.88560\tvalidation_1-auc:0.82532                                                                  \n",
      "[5]\tvalidation_0-auc:0.89198\tvalidation_1-auc:0.82803                                                                  \n",
      "[6]\tvalidation_0-auc:0.89750\tvalidation_1-auc:0.82900                                                                  \n",
      "[7]\tvalidation_0-auc:0.90092\tvalidation_1-auc:0.82986                                                                  \n",
      "[8]\tvalidation_0-auc:0.90380\tvalidation_1-auc:0.83242                                                                  \n",
      "[9]\tvalidation_0-auc:0.90514\tvalidation_1-auc:0.83238                                                                  \n",
      "[10]\tvalidation_0-auc:0.90739\tvalidation_1-auc:0.83470                                                                 \n",
      "[11]\tvalidation_0-auc:0.90920\tvalidation_1-auc:0.83380                                                                 \n",
      "[12]\tvalidation_0-auc:0.91061\tvalidation_1-auc:0.83433                                                                 \n",
      "[13]\tvalidation_0-auc:0.91194\tvalidation_1-auc:0.83463                                                                 \n",
      "[14]\tvalidation_0-auc:0.91395\tvalidation_1-auc:0.83509                                                                 \n",
      "[15]\tvalidation_0-auc:0.91548\tvalidation_1-auc:0.83535                                                                 \n",
      "[16]\tvalidation_0-auc:0.91682\tvalidation_1-auc:0.83499                                                                 \n",
      "[17]\tvalidation_0-auc:0.91869\tvalidation_1-auc:0.83550                                                                 \n",
      "[18]\tvalidation_0-auc:0.92041\tvalidation_1-auc:0.83529                                                                 \n",
      "[19]\tvalidation_0-auc:0.92129\tvalidation_1-auc:0.83560                                                                 \n",
      "[20]\tvalidation_0-auc:0.92224\tvalidation_1-auc:0.83587                                                                 \n",
      "[21]\tvalidation_0-auc:0.92327\tvalidation_1-auc:0.83628                                                                 \n",
      "[22]\tvalidation_0-auc:0.92423\tvalidation_1-auc:0.83668                                                                 \n",
      "[23]\tvalidation_0-auc:0.92462\tvalidation_1-auc:0.83767                                                                 \n",
      "[24]\tvalidation_0-auc:0.92561\tvalidation_1-auc:0.83745                                                                 \n",
      "[25]\tvalidation_0-auc:0.92647\tvalidation_1-auc:0.83753                                                                 \n",
      "[26]\tvalidation_0-auc:0.92719\tvalidation_1-auc:0.83798                                                                 \n",
      "[27]\tvalidation_0-auc:0.92823\tvalidation_1-auc:0.83838                                                                 \n",
      "[28]\tvalidation_0-auc:0.92862\tvalidation_1-auc:0.83828                                                                 \n",
      "[29]\tvalidation_0-auc:0.92888\tvalidation_1-auc:0.83871                                                                 \n",
      "[30]\tvalidation_0-auc:0.92937\tvalidation_1-auc:0.83847                                                                 \n",
      "[31]\tvalidation_0-auc:0.93053\tvalidation_1-auc:0.83846                                                                 \n",
      "[32]\tvalidation_0-auc:0.93156\tvalidation_1-auc:0.83840                                                                 \n",
      "[33]\tvalidation_0-auc:0.93199\tvalidation_1-auc:0.83833                                                                 \n",
      "[34]\tvalidation_0-auc:0.93294\tvalidation_1-auc:0.83774                                                                 \n",
      "[35]\tvalidation_0-auc:0.93321\tvalidation_1-auc:0.83797                                                                 \n",
      "[36]\tvalidation_0-auc:0.93385\tvalidation_1-auc:0.83774                                                                 \n",
      "[37]\tvalidation_0-auc:0.93438\tvalidation_1-auc:0.83771                                                                 \n",
      "[38]\tvalidation_0-auc:0.93485\tvalidation_1-auc:0.83771                                                                 \n",
      "[39]\tvalidation_0-auc:0.93518\tvalidation_1-auc:0.83791                                                                 \n",
      "[40]\tvalidation_0-auc:0.93581\tvalidation_1-auc:0.83815                                                                 \n",
      "[41]\tvalidation_0-auc:0.93620\tvalidation_1-auc:0.83837                                                                 \n",
      "[42]\tvalidation_0-auc:0.93638\tvalidation_1-auc:0.83829                                                                 \n",
      "[43]\tvalidation_0-auc:0.93691\tvalidation_1-auc:0.83829                                                                 \n",
      "[44]\tvalidation_0-auc:0.93724\tvalidation_1-auc:0.83851                                                                 \n",
      "[45]\tvalidation_0-auc:0.93783\tvalidation_1-auc:0.83861                                                                 \n",
      "[46]\tvalidation_0-auc:0.93810\tvalidation_1-auc:0.83869                                                                 \n",
      "[47]\tvalidation_0-auc:0.93823\tvalidation_1-auc:0.83860                                                                 \n",
      "[48]\tvalidation_0-auc:0.93859\tvalidation_1-auc:0.83869                                                                 \n",
      "[49]\tvalidation_0-auc:0.93884\tvalidation_1-auc:0.83868                                                                 \n",
      "[50]\tvalidation_0-auc:0.93912\tvalidation_1-auc:0.83841                                                                 \n",
      "[51]\tvalidation_0-auc:0.93938\tvalidation_1-auc:0.83834                                                                 \n",
      "[52]\tvalidation_0-auc:0.93946\tvalidation_1-auc:0.83834                                                                 \n",
      "[53]\tvalidation_0-auc:0.93965\tvalidation_1-auc:0.83814                                                                 \n",
      "[54]\tvalidation_0-auc:0.93969\tvalidation_1-auc:0.83811                                                                 \n",
      "[55]\tvalidation_0-auc:0.93987\tvalidation_1-auc:0.83796                                                                 \n",
      "[56]\tvalidation_0-auc:0.94034\tvalidation_1-auc:0.83788                                                                 \n",
      "[57]\tvalidation_0-auc:0.94046\tvalidation_1-auc:0.83782                                                                 \n",
      "[58]\tvalidation_0-auc:0.94098\tvalidation_1-auc:0.83767                                                                 \n",
      "[59]\tvalidation_0-auc:0.94122\tvalidation_1-auc:0.83766                                                                 \n",
      "[0]\tvalidation_0-auc:0.86840\tvalidation_1-auc:0.80960                                                                  \n",
      "[1]\tvalidation_0-auc:0.87556\tvalidation_1-auc:0.80364                                                                  \n",
      "[2]\tvalidation_0-auc:0.88179\tvalidation_1-auc:0.81663                                                                  \n",
      "[3]\tvalidation_0-auc:0.88332\tvalidation_1-auc:0.81203                                                                  \n",
      "[4]\tvalidation_0-auc:0.88467\tvalidation_1-auc:0.80825                                                                  \n",
      "[5]\tvalidation_0-auc:0.88992\tvalidation_1-auc:0.81432                                                                  \n",
      "[6]\tvalidation_0-auc:0.89461\tvalidation_1-auc:0.81722                                                                  \n",
      "[7]\tvalidation_0-auc:0.89851\tvalidation_1-auc:0.81998                                                                  \n",
      "[8]\tvalidation_0-auc:0.90213\tvalidation_1-auc:0.82305                                                                  \n",
      "[9]\tvalidation_0-auc:0.90349\tvalidation_1-auc:0.82217                                                                  \n",
      "[10]\tvalidation_0-auc:0.90600\tvalidation_1-auc:0.82430                                                                 \n",
      "[11]\tvalidation_0-auc:0.90745\tvalidation_1-auc:0.82582                                                                 \n",
      "[12]\tvalidation_0-auc:0.90919\tvalidation_1-auc:0.82760                                                                 \n",
      "[13]\tvalidation_0-auc:0.91111\tvalidation_1-auc:0.82745                                                                 \n",
      "[14]\tvalidation_0-auc:0.91276\tvalidation_1-auc:0.82618                                                                 \n",
      "[15]\tvalidation_0-auc:0.91474\tvalidation_1-auc:0.82728                                                                 \n",
      "[16]\tvalidation_0-auc:0.91621\tvalidation_1-auc:0.82858                                                                 \n",
      "[17]\tvalidation_0-auc:0.91786\tvalidation_1-auc:0.82849                                                                 \n",
      "[18]\tvalidation_0-auc:0.91922\tvalidation_1-auc:0.82807                                                                 \n",
      "[19]\tvalidation_0-auc:0.92032\tvalidation_1-auc:0.82863                                                                 \n",
      "[20]\tvalidation_0-auc:0.92181\tvalidation_1-auc:0.82903                                                                 \n",
      "[21]\tvalidation_0-auc:0.92291\tvalidation_1-auc:0.82902                                                                 \n",
      "[22]\tvalidation_0-auc:0.92362\tvalidation_1-auc:0.82955                                                                 \n",
      "[23]\tvalidation_0-auc:0.92446\tvalidation_1-auc:0.83038                                                                 \n",
      "[24]\tvalidation_0-auc:0.92532\tvalidation_1-auc:0.83054                                                                 \n",
      "[25]\tvalidation_0-auc:0.92606\tvalidation_1-auc:0.83023                                                                 \n",
      "[26]\tvalidation_0-auc:0.92701\tvalidation_1-auc:0.83023                                                                 \n",
      "[27]\tvalidation_0-auc:0.92780\tvalidation_1-auc:0.82999                                                                 \n",
      "[28]\tvalidation_0-auc:0.92886\tvalidation_1-auc:0.83045                                                                 \n",
      "[29]\tvalidation_0-auc:0.92954\tvalidation_1-auc:0.83080                                                                 \n",
      "[30]\tvalidation_0-auc:0.93042\tvalidation_1-auc:0.83085                                                                 \n",
      "[31]\tvalidation_0-auc:0.93106\tvalidation_1-auc:0.83122                                                                 \n",
      "[32]\tvalidation_0-auc:0.93159\tvalidation_1-auc:0.83151                                                                 \n",
      "[33]\tvalidation_0-auc:0.93211\tvalidation_1-auc:0.83191                                                                 \n",
      "[34]\tvalidation_0-auc:0.93296\tvalidation_1-auc:0.83238                                                                 \n",
      "[35]\tvalidation_0-auc:0.93358\tvalidation_1-auc:0.83245                                                                 \n",
      "[36]\tvalidation_0-auc:0.93429\tvalidation_1-auc:0.83265                                                                 \n",
      "[37]\tvalidation_0-auc:0.93472\tvalidation_1-auc:0.83265                                                                 \n",
      "[38]\tvalidation_0-auc:0.93522\tvalidation_1-auc:0.83297                                                                 \n",
      "[39]\tvalidation_0-auc:0.93555\tvalidation_1-auc:0.83334                                                                 \n",
      "[40]\tvalidation_0-auc:0.93612\tvalidation_1-auc:0.83340                                                                 \n",
      "[41]\tvalidation_0-auc:0.93646\tvalidation_1-auc:0.83365                                                                 \n",
      "[42]\tvalidation_0-auc:0.93716\tvalidation_1-auc:0.83395                                                                 \n",
      "[43]\tvalidation_0-auc:0.93772\tvalidation_1-auc:0.83346                                                                 \n",
      "[44]\tvalidation_0-auc:0.93832\tvalidation_1-auc:0.83309                                                                 \n",
      "[45]\tvalidation_0-auc:0.93878\tvalidation_1-auc:0.83312                                                                 \n",
      "[46]\tvalidation_0-auc:0.93913\tvalidation_1-auc:0.83324                                                                 \n",
      "[47]\tvalidation_0-auc:0.93959\tvalidation_1-auc:0.83303                                                                 \n",
      "[48]\tvalidation_0-auc:0.94005\tvalidation_1-auc:0.83302                                                                 \n",
      "[49]\tvalidation_0-auc:0.94031\tvalidation_1-auc:0.83325                                                                 \n",
      "[50]\tvalidation_0-auc:0.94075\tvalidation_1-auc:0.83338                                                                 \n",
      "[51]\tvalidation_0-auc:0.94118\tvalidation_1-auc:0.83357                                                                 \n",
      "[52]\tvalidation_0-auc:0.94127\tvalidation_1-auc:0.83363                                                                 \n",
      "[53]\tvalidation_0-auc:0.94180\tvalidation_1-auc:0.83374                                                                 \n",
      "[54]\tvalidation_0-auc:0.94195\tvalidation_1-auc:0.83381                                                                 \n",
      "[55]\tvalidation_0-auc:0.94226\tvalidation_1-auc:0.83381                                                                 \n",
      "[56]\tvalidation_0-auc:0.94250\tvalidation_1-auc:0.83381                                                                 \n",
      "[57]\tvalidation_0-auc:0.94275\tvalidation_1-auc:0.83395                                                                 \n",
      "[58]\tvalidation_0-auc:0.94310\tvalidation_1-auc:0.83389                                                                 \n",
      "[59]\tvalidation_0-auc:0.94318\tvalidation_1-auc:0.83410                                                                 \n",
      "[60]\tvalidation_0-auc:0.94357\tvalidation_1-auc:0.83409                                                                 \n",
      "[61]\tvalidation_0-auc:0.94471\tvalidation_1-auc:0.83389                                                                 \n",
      "[62]\tvalidation_0-auc:0.94487\tvalidation_1-auc:0.83382                                                                 \n",
      "[63]\tvalidation_0-auc:0.94506\tvalidation_1-auc:0.83367                                                                 \n",
      "[64]\tvalidation_0-auc:0.94526\tvalidation_1-auc:0.83386                                                                 \n",
      "[65]\tvalidation_0-auc:0.94600\tvalidation_1-auc:0.83367                                                                 \n",
      "[66]\tvalidation_0-auc:0.94623\tvalidation_1-auc:0.83349                                                                 \n",
      "[67]\tvalidation_0-auc:0.94627\tvalidation_1-auc:0.83349                                                                 \n",
      "[68]\tvalidation_0-auc:0.94635\tvalidation_1-auc:0.83358                                                                 \n",
      "[69]\tvalidation_0-auc:0.94669\tvalidation_1-auc:0.83365                                                                 \n",
      "[70]\tvalidation_0-auc:0.94687\tvalidation_1-auc:0.83365                                                                 \n",
      "[71]\tvalidation_0-auc:0.94701\tvalidation_1-auc:0.83392                                                                 \n",
      "[72]\tvalidation_0-auc:0.94732\tvalidation_1-auc:0.83379                                                                 \n",
      "[73]\tvalidation_0-auc:0.94755\tvalidation_1-auc:0.83380                                                                 \n",
      "[74]\tvalidation_0-auc:0.94805\tvalidation_1-auc:0.83367                                                                 \n",
      "[75]\tvalidation_0-auc:0.94819\tvalidation_1-auc:0.83378                                                                 \n",
      "[76]\tvalidation_0-auc:0.94853\tvalidation_1-auc:0.83365                                                                 \n",
      "[77]\tvalidation_0-auc:0.94870\tvalidation_1-auc:0.83377                                                                 \n",
      "[78]\tvalidation_0-auc:0.94880\tvalidation_1-auc:0.83377                                                                 \n",
      "[79]\tvalidation_0-auc:0.94890\tvalidation_1-auc:0.83383                                                                 \n",
      "[80]\tvalidation_0-auc:0.94898\tvalidation_1-auc:0.83378                                                                 \n",
      "[81]\tvalidation_0-auc:0.94922\tvalidation_1-auc:0.83367                                                                 \n",
      "[82]\tvalidation_0-auc:0.94927\tvalidation_1-auc:0.83362                                                                 \n",
      "[83]\tvalidation_0-auc:0.94951\tvalidation_1-auc:0.83356                                                                 \n",
      "[84]\tvalidation_0-auc:0.95016\tvalidation_1-auc:0.83323                                                                 \n",
      "[85]\tvalidation_0-auc:0.95056\tvalidation_1-auc:0.83322                                                                 \n",
      "[86]\tvalidation_0-auc:0.95071\tvalidation_1-auc:0.83310                                                                 \n",
      "[87]\tvalidation_0-auc:0.95097\tvalidation_1-auc:0.83284                                                                 \n",
      "[88]\tvalidation_0-auc:0.95129\tvalidation_1-auc:0.83276                                                                 \n",
      "[89]\tvalidation_0-auc:0.95196\tvalidation_1-auc:0.83247                                                                 \n",
      "[0]\tvalidation_0-auc:0.84735\tvalidation_1-auc:0.80284                                                                  \n",
      "[1]\tvalidation_0-auc:0.85139\tvalidation_1-auc:0.80546                                                                  \n",
      "[2]\tvalidation_0-auc:0.85675\tvalidation_1-auc:0.81294                                                                  \n",
      "[3]\tvalidation_0-auc:0.86005\tvalidation_1-auc:0.81444                                                                  \n",
      "[4]\tvalidation_0-auc:0.86741\tvalidation_1-auc:0.81814                                                                  \n",
      "[5]\tvalidation_0-auc:0.86953\tvalidation_1-auc:0.81905                                                                  \n",
      "[6]\tvalidation_0-auc:0.87090\tvalidation_1-auc:0.82059                                                                  \n",
      "[7]\tvalidation_0-auc:0.87178\tvalidation_1-auc:0.82031                                                                  \n",
      "[8]\tvalidation_0-auc:0.87332\tvalidation_1-auc:0.82130                                                                  \n",
      "[9]\tvalidation_0-auc:0.87484\tvalidation_1-auc:0.82097                                                                  \n",
      "[10]\tvalidation_0-auc:0.87674\tvalidation_1-auc:0.82117                                                                 \n",
      "[11]\tvalidation_0-auc:0.87777\tvalidation_1-auc:0.82224                                                                 \n",
      "[12]\tvalidation_0-auc:0.87935\tvalidation_1-auc:0.82219                                                                 \n",
      "[13]\tvalidation_0-auc:0.88052\tvalidation_1-auc:0.82208                                                                 \n",
      "[14]\tvalidation_0-auc:0.88160\tvalidation_1-auc:0.82247                                                                 \n",
      "[15]\tvalidation_0-auc:0.88224\tvalidation_1-auc:0.82221                                                                 \n",
      "[16]\tvalidation_0-auc:0.88281\tvalidation_1-auc:0.82264                                                                 \n",
      "[17]\tvalidation_0-auc:0.88346\tvalidation_1-auc:0.82300                                                                 \n",
      "[18]\tvalidation_0-auc:0.88455\tvalidation_1-auc:0.82340                                                                 \n",
      "[19]\tvalidation_0-auc:0.88488\tvalidation_1-auc:0.82352                                                                 \n",
      "[20]\tvalidation_0-auc:0.88532\tvalidation_1-auc:0.82377                                                                 \n",
      "[21]\tvalidation_0-auc:0.88559\tvalidation_1-auc:0.82387                                                                 \n",
      "[22]\tvalidation_0-auc:0.88643\tvalidation_1-auc:0.82406                                                                 \n",
      "[23]\tvalidation_0-auc:0.88735\tvalidation_1-auc:0.82362                                                                 \n",
      "[24]\tvalidation_0-auc:0.88787\tvalidation_1-auc:0.82398                                                                 \n",
      "[25]\tvalidation_0-auc:0.88824\tvalidation_1-auc:0.82413                                                                 \n",
      "[26]\tvalidation_0-auc:0.88955\tvalidation_1-auc:0.82430                                                                 \n",
      "[27]\tvalidation_0-auc:0.88987\tvalidation_1-auc:0.82432                                                                 \n",
      "[28]\tvalidation_0-auc:0.89010\tvalidation_1-auc:0.82436                                                                 \n",
      "[29]\tvalidation_0-auc:0.89062\tvalidation_1-auc:0.82432                                                                 \n",
      "[30]\tvalidation_0-auc:0.89121\tvalidation_1-auc:0.82460                                                                 \n",
      "[31]\tvalidation_0-auc:0.89194\tvalidation_1-auc:0.82446                                                                 \n",
      "[32]\tvalidation_0-auc:0.89282\tvalidation_1-auc:0.82438                                                                 \n",
      "[33]\tvalidation_0-auc:0.89292\tvalidation_1-auc:0.82432                                                                 \n",
      "[34]\tvalidation_0-auc:0.89306\tvalidation_1-auc:0.82417                                                                 \n",
      "[35]\tvalidation_0-auc:0.89346\tvalidation_1-auc:0.82423                                                                 \n",
      "[36]\tvalidation_0-auc:0.89386\tvalidation_1-auc:0.82415                                                                 \n",
      "[37]\tvalidation_0-auc:0.89396\tvalidation_1-auc:0.82408                                                                 \n",
      "[38]\tvalidation_0-auc:0.89449\tvalidation_1-auc:0.82407                                                                 \n",
      "[39]\tvalidation_0-auc:0.89520\tvalidation_1-auc:0.82381                                                                 \n",
      "[40]\tvalidation_0-auc:0.89565\tvalidation_1-auc:0.82373                                                                 \n",
      "[41]\tvalidation_0-auc:0.89615\tvalidation_1-auc:0.82352                                                                 \n",
      "[42]\tvalidation_0-auc:0.89656\tvalidation_1-auc:0.82349                                                                 \n",
      "[43]\tvalidation_0-auc:0.89678\tvalidation_1-auc:0.82342                                                                 \n",
      "[44]\tvalidation_0-auc:0.89691\tvalidation_1-auc:0.82323                                                                 \n",
      "[45]\tvalidation_0-auc:0.89752\tvalidation_1-auc:0.82321                                                                 \n",
      "[46]\tvalidation_0-auc:0.89795\tvalidation_1-auc:0.82321                                                                 \n",
      "[47]\tvalidation_0-auc:0.89804\tvalidation_1-auc:0.82303                                                                 \n",
      "[48]\tvalidation_0-auc:0.89845\tvalidation_1-auc:0.82276                                                                 \n",
      "[49]\tvalidation_0-auc:0.89876\tvalidation_1-auc:0.82260                                                                 \n",
      "[50]\tvalidation_0-auc:0.89935\tvalidation_1-auc:0.82236                                                                 \n",
      "[51]\tvalidation_0-auc:0.89951\tvalidation_1-auc:0.82253                                                                 \n",
      "[52]\tvalidation_0-auc:0.89962\tvalidation_1-auc:0.82220                                                                 \n",
      "[53]\tvalidation_0-auc:0.89984\tvalidation_1-auc:0.82197                                                                 \n",
      "[54]\tvalidation_0-auc:0.90006\tvalidation_1-auc:0.82204                                                                 \n",
      "[55]\tvalidation_0-auc:0.90043\tvalidation_1-auc:0.82242                                                                 \n",
      "[56]\tvalidation_0-auc:0.90122\tvalidation_1-auc:0.82218                                                                 \n",
      "[57]\tvalidation_0-auc:0.90125\tvalidation_1-auc:0.82214                                                                 \n",
      "[58]\tvalidation_0-auc:0.90188\tvalidation_1-auc:0.82178                                                                 \n",
      "[59]\tvalidation_0-auc:0.90220\tvalidation_1-auc:0.82132                                                                 \n",
      "[60]\tvalidation_0-auc:0.90272\tvalidation_1-auc:0.82129                                                                 \n",
      "[0]\tvalidation_0-auc:0.83953\tvalidation_1-auc:0.81382                                                                  \n",
      "[1]\tvalidation_0-auc:0.84691\tvalidation_1-auc:0.82342                                                                  \n",
      "[2]\tvalidation_0-auc:0.85316\tvalidation_1-auc:0.83104                                                                  \n",
      "[3]\tvalidation_0-auc:0.85685\tvalidation_1-auc:0.83285                                                                  \n",
      "[4]\tvalidation_0-auc:0.85906\tvalidation_1-auc:0.83294                                                                  \n",
      "[5]\tvalidation_0-auc:0.86146\tvalidation_1-auc:0.83294                                                                  \n",
      "[6]\tvalidation_0-auc:0.86303\tvalidation_1-auc:0.83391                                                                  \n",
      "[7]\tvalidation_0-auc:0.86491\tvalidation_1-auc:0.83436                                                                  \n",
      "[8]\tvalidation_0-auc:0.86846\tvalidation_1-auc:0.83503                                                                  \n",
      "[9]\tvalidation_0-auc:0.86996\tvalidation_1-auc:0.83492                                                                  \n",
      "[10]\tvalidation_0-auc:0.87179\tvalidation_1-auc:0.83528                                                                 \n",
      "[11]\tvalidation_0-auc:0.87345\tvalidation_1-auc:0.83621                                                                 \n",
      "[12]\tvalidation_0-auc:0.87471\tvalidation_1-auc:0.83681                                                                 \n",
      "[13]\tvalidation_0-auc:0.87621\tvalidation_1-auc:0.83688                                                                 \n",
      "[14]\tvalidation_0-auc:0.87744\tvalidation_1-auc:0.83836                                                                 \n",
      "[15]\tvalidation_0-auc:0.87789\tvalidation_1-auc:0.83866                                                                 \n",
      "[16]\tvalidation_0-auc:0.87941\tvalidation_1-auc:0.83887                                                                 \n",
      "[17]\tvalidation_0-auc:0.88049\tvalidation_1-auc:0.83894                                                                 \n",
      "[18]\tvalidation_0-auc:0.88092\tvalidation_1-auc:0.83909                                                                 \n",
      "[19]\tvalidation_0-auc:0.88163\tvalidation_1-auc:0.83928                                                                 \n",
      "[20]\tvalidation_0-auc:0.88268\tvalidation_1-auc:0.83927                                                                 \n",
      "[21]\tvalidation_0-auc:0.88318\tvalidation_1-auc:0.83941                                                                 \n",
      "[22]\tvalidation_0-auc:0.88393\tvalidation_1-auc:0.83998                                                                 \n",
      "[23]\tvalidation_0-auc:0.88441\tvalidation_1-auc:0.84043                                                                 \n",
      "[24]\tvalidation_0-auc:0.88466\tvalidation_1-auc:0.84069                                                                 \n",
      "[25]\tvalidation_0-auc:0.88518\tvalidation_1-auc:0.84055                                                                 \n",
      "[26]\tvalidation_0-auc:0.88558\tvalidation_1-auc:0.84076                                                                 \n",
      "[27]\tvalidation_0-auc:0.88568\tvalidation_1-auc:0.84090                                                                 \n",
      "[28]\tvalidation_0-auc:0.88612\tvalidation_1-auc:0.84087                                                                 \n",
      "[29]\tvalidation_0-auc:0.88657\tvalidation_1-auc:0.84095                                                                 \n",
      "[30]\tvalidation_0-auc:0.88716\tvalidation_1-auc:0.84147                                                                 \n",
      "[31]\tvalidation_0-auc:0.88734\tvalidation_1-auc:0.84142                                                                 \n",
      "[32]\tvalidation_0-auc:0.88810\tvalidation_1-auc:0.84130                                                                 \n",
      "[33]\tvalidation_0-auc:0.88850\tvalidation_1-auc:0.84139                                                                 \n",
      "[34]\tvalidation_0-auc:0.88923\tvalidation_1-auc:0.84153                                                                 \n",
      "[35]\tvalidation_0-auc:0.88951\tvalidation_1-auc:0.84133                                                                 \n",
      "[36]\tvalidation_0-auc:0.88984\tvalidation_1-auc:0.84125                                                                 \n",
      "[37]\tvalidation_0-auc:0.89077\tvalidation_1-auc:0.84115                                                                 \n",
      "[38]\tvalidation_0-auc:0.89122\tvalidation_1-auc:0.84083                                                                 \n",
      "[39]\tvalidation_0-auc:0.89145\tvalidation_1-auc:0.84090                                                                 \n",
      "[40]\tvalidation_0-auc:0.89216\tvalidation_1-auc:0.84070                                                                 \n",
      "[41]\tvalidation_0-auc:0.89252\tvalidation_1-auc:0.84055                                                                 \n",
      "[42]\tvalidation_0-auc:0.89301\tvalidation_1-auc:0.84037                                                                 \n",
      "[43]\tvalidation_0-auc:0.89340\tvalidation_1-auc:0.84047                                                                 \n",
      "[44]\tvalidation_0-auc:0.89439\tvalidation_1-auc:0.84070                                                                 \n",
      "[45]\tvalidation_0-auc:0.89505\tvalidation_1-auc:0.84037                                                                 \n",
      "[46]\tvalidation_0-auc:0.89553\tvalidation_1-auc:0.84036                                                                 \n",
      "[47]\tvalidation_0-auc:0.89588\tvalidation_1-auc:0.84031                                                                 \n",
      "[48]\tvalidation_0-auc:0.89609\tvalidation_1-auc:0.84020                                                                 \n",
      "[49]\tvalidation_0-auc:0.89621\tvalidation_1-auc:0.84011                                                                 \n",
      "[50]\tvalidation_0-auc:0.89647\tvalidation_1-auc:0.83984                                                                 \n",
      "[51]\tvalidation_0-auc:0.89672\tvalidation_1-auc:0.83977                                                                 \n",
      "[52]\tvalidation_0-auc:0.89691\tvalidation_1-auc:0.83966                                                                 \n",
      "[53]\tvalidation_0-auc:0.89710\tvalidation_1-auc:0.83960                                                                 \n",
      "[54]\tvalidation_0-auc:0.89775\tvalidation_1-auc:0.83944                                                                 \n",
      "[55]\tvalidation_0-auc:0.89782\tvalidation_1-auc:0.83934                                                                 \n",
      "[56]\tvalidation_0-auc:0.89827\tvalidation_1-auc:0.83900                                                                 \n",
      "[57]\tvalidation_0-auc:0.89853\tvalidation_1-auc:0.83884                                                                 \n",
      "[58]\tvalidation_0-auc:0.89872\tvalidation_1-auc:0.83861                                                                 \n",
      "[59]\tvalidation_0-auc:0.89892\tvalidation_1-auc:0.83852                                                                 \n",
      "[60]\tvalidation_0-auc:0.89925\tvalidation_1-auc:0.83862                                                                 \n",
      "[61]\tvalidation_0-auc:0.89979\tvalidation_1-auc:0.83860                                                                 \n",
      "[62]\tvalidation_0-auc:0.89994\tvalidation_1-auc:0.83861                                                                 \n",
      "[63]\tvalidation_0-auc:0.90070\tvalidation_1-auc:0.83871                                                                 \n",
      "[64]\tvalidation_0-auc:0.90099\tvalidation_1-auc:0.83855                                                                 \n",
      "[0]\tvalidation_0-auc:0.83806\tvalidation_1-auc:0.81873                                                                  \n",
      "[1]\tvalidation_0-auc:0.84470\tvalidation_1-auc:0.82119                                                                  \n",
      "[2]\tvalidation_0-auc:0.85244\tvalidation_1-auc:0.82529                                                                  \n",
      "[3]\tvalidation_0-auc:0.85684\tvalidation_1-auc:0.83089                                                                  \n",
      "[4]\tvalidation_0-auc:0.86165\tvalidation_1-auc:0.83374                                                                  \n",
      "[5]\tvalidation_0-auc:0.86475\tvalidation_1-auc:0.83435                                                                  \n",
      "[6]\tvalidation_0-auc:0.86668\tvalidation_1-auc:0.83466                                                                  \n",
      "[7]\tvalidation_0-auc:0.86892\tvalidation_1-auc:0.83403                                                                  \n",
      "[8]\tvalidation_0-auc:0.87079\tvalidation_1-auc:0.83483                                                                  \n",
      "[9]\tvalidation_0-auc:0.87202\tvalidation_1-auc:0.83500                                                                  \n",
      "[10]\tvalidation_0-auc:0.87371\tvalidation_1-auc:0.83527                                                                 \n",
      "[11]\tvalidation_0-auc:0.87532\tvalidation_1-auc:0.83545                                                                 \n",
      "[12]\tvalidation_0-auc:0.87665\tvalidation_1-auc:0.83565                                                                 \n",
      "[13]\tvalidation_0-auc:0.87771\tvalidation_1-auc:0.83629                                                                 \n",
      "[14]\tvalidation_0-auc:0.87878\tvalidation_1-auc:0.83693                                                                 \n",
      "[15]\tvalidation_0-auc:0.87963\tvalidation_1-auc:0.83748                                                                 \n",
      "[16]\tvalidation_0-auc:0.88077\tvalidation_1-auc:0.83796                                                                 \n",
      "[17]\tvalidation_0-auc:0.88259\tvalidation_1-auc:0.83775                                                                 \n",
      "[18]\tvalidation_0-auc:0.88331\tvalidation_1-auc:0.83767                                                                 \n",
      "[19]\tvalidation_0-auc:0.88406\tvalidation_1-auc:0.83828                                                                 \n",
      "[20]\tvalidation_0-auc:0.88526\tvalidation_1-auc:0.83860                                                                 \n",
      "[21]\tvalidation_0-auc:0.88645\tvalidation_1-auc:0.83891                                                                 \n",
      "[22]\tvalidation_0-auc:0.88772\tvalidation_1-auc:0.83939                                                                 \n",
      "[23]\tvalidation_0-auc:0.88824\tvalidation_1-auc:0.83973                                                                 \n",
      "[24]\tvalidation_0-auc:0.88936\tvalidation_1-auc:0.83956                                                                 \n",
      "[25]\tvalidation_0-auc:0.89024\tvalidation_1-auc:0.83946                                                                 \n",
      "[26]\tvalidation_0-auc:0.89071\tvalidation_1-auc:0.83930                                                                 \n",
      "[27]\tvalidation_0-auc:0.89101\tvalidation_1-auc:0.83939                                                                 \n",
      "[28]\tvalidation_0-auc:0.89190\tvalidation_1-auc:0.83964                                                                 \n",
      "[29]\tvalidation_0-auc:0.89312\tvalidation_1-auc:0.83938                                                                 \n",
      "[30]\tvalidation_0-auc:0.89335\tvalidation_1-auc:0.83945                                                                 \n",
      "[31]\tvalidation_0-auc:0.89444\tvalidation_1-auc:0.83951                                                                 \n",
      "[32]\tvalidation_0-auc:0.89479\tvalidation_1-auc:0.83955                                                                 \n",
      "[33]\tvalidation_0-auc:0.89522\tvalidation_1-auc:0.83943                                                                 \n",
      "[34]\tvalidation_0-auc:0.89555\tvalidation_1-auc:0.83958                                                                 \n",
      "[35]\tvalidation_0-auc:0.89615\tvalidation_1-auc:0.83962                                                                 \n",
      "[36]\tvalidation_0-auc:0.89701\tvalidation_1-auc:0.83934                                                                 \n",
      "[37]\tvalidation_0-auc:0.89720\tvalidation_1-auc:0.83942                                                                 \n",
      "[38]\tvalidation_0-auc:0.89839\tvalidation_1-auc:0.83970                                                                 \n",
      "[39]\tvalidation_0-auc:0.89875\tvalidation_1-auc:0.83941                                                                 \n",
      "[40]\tvalidation_0-auc:0.89945\tvalidation_1-auc:0.83921                                                                 \n",
      "[41]\tvalidation_0-auc:0.90053\tvalidation_1-auc:0.83915                                                                 \n",
      "[42]\tvalidation_0-auc:0.90070\tvalidation_1-auc:0.83928                                                                 \n",
      "[43]\tvalidation_0-auc:0.90117\tvalidation_1-auc:0.83922                                                                 \n",
      "[44]\tvalidation_0-auc:0.90175\tvalidation_1-auc:0.83876                                                                 \n",
      "[45]\tvalidation_0-auc:0.90229\tvalidation_1-auc:0.83859                                                                 \n",
      "[46]\tvalidation_0-auc:0.90266\tvalidation_1-auc:0.83842                                                                 \n",
      "[47]\tvalidation_0-auc:0.90326\tvalidation_1-auc:0.83854                                                                 \n",
      "[48]\tvalidation_0-auc:0.90335\tvalidation_1-auc:0.83854                                                                 \n",
      "[49]\tvalidation_0-auc:0.90364\tvalidation_1-auc:0.83862                                                                 \n",
      "[50]\tvalidation_0-auc:0.90406\tvalidation_1-auc:0.83876                                                                 \n",
      "[51]\tvalidation_0-auc:0.90440\tvalidation_1-auc:0.83862                                                                 \n",
      "[52]\tvalidation_0-auc:0.90464\tvalidation_1-auc:0.83873                                                                 \n",
      "[53]\tvalidation_0-auc:0.90492\tvalidation_1-auc:0.83859                                                                 \n",
      "[0]\tvalidation_0-auc:0.88299\tvalidation_1-auc:0.79142                                                                  \n",
      "[1]\tvalidation_0-auc:0.89226\tvalidation_1-auc:0.80088                                                                  \n",
      "[2]\tvalidation_0-auc:0.89529\tvalidation_1-auc:0.81129                                                                  \n",
      "[3]\tvalidation_0-auc:0.90316\tvalidation_1-auc:0.81104                                                                  \n",
      "[4]\tvalidation_0-auc:0.90789\tvalidation_1-auc:0.81187                                                                  \n",
      "[5]\tvalidation_0-auc:0.91285\tvalidation_1-auc:0.81130                                                                  \n",
      "[6]\tvalidation_0-auc:0.91596\tvalidation_1-auc:0.81469                                                                  \n",
      "[7]\tvalidation_0-auc:0.92030\tvalidation_1-auc:0.81451                                                                  \n",
      "[8]\tvalidation_0-auc:0.92312\tvalidation_1-auc:0.81477                                                                  \n",
      "[9]\tvalidation_0-auc:0.92652\tvalidation_1-auc:0.81438                                                                  \n",
      "[10]\tvalidation_0-auc:0.92872\tvalidation_1-auc:0.81393                                                                 \n",
      "[11]\tvalidation_0-auc:0.93007\tvalidation_1-auc:0.81393                                                                 \n",
      "[12]\tvalidation_0-auc:0.93224\tvalidation_1-auc:0.81383                                                                 \n",
      "[13]\tvalidation_0-auc:0.93422\tvalidation_1-auc:0.81421                                                                 \n",
      "[14]\tvalidation_0-auc:0.93593\tvalidation_1-auc:0.81407                                                                 \n",
      "[15]\tvalidation_0-auc:0.93753\tvalidation_1-auc:0.81406                                                                 \n",
      "[16]\tvalidation_0-auc:0.93933\tvalidation_1-auc:0.81395                                                                 \n",
      "[17]\tvalidation_0-auc:0.94005\tvalidation_1-auc:0.81369                                                                 \n",
      "[18]\tvalidation_0-auc:0.94080\tvalidation_1-auc:0.81390                                                                 \n",
      "[19]\tvalidation_0-auc:0.94159\tvalidation_1-auc:0.81446                                                                 \n",
      "[20]\tvalidation_0-auc:0.94197\tvalidation_1-auc:0.81425                                                                 \n",
      "[21]\tvalidation_0-auc:0.94273\tvalidation_1-auc:0.81408                                                                 \n",
      "[22]\tvalidation_0-auc:0.94338\tvalidation_1-auc:0.81419                                                                 \n",
      "[23]\tvalidation_0-auc:0.94370\tvalidation_1-auc:0.81440                                                                 \n",
      "[24]\tvalidation_0-auc:0.94512\tvalidation_1-auc:0.81421                                                                 \n",
      "[25]\tvalidation_0-auc:0.94559\tvalidation_1-auc:0.81448                                                                 \n",
      "[26]\tvalidation_0-auc:0.94603\tvalidation_1-auc:0.81409                                                                 \n",
      "[27]\tvalidation_0-auc:0.94675\tvalidation_1-auc:0.81364                                                                 \n",
      "[28]\tvalidation_0-auc:0.94720\tvalidation_1-auc:0.81382                                                                 \n",
      "[29]\tvalidation_0-auc:0.94727\tvalidation_1-auc:0.81387                                                                 \n",
      "[30]\tvalidation_0-auc:0.94735\tvalidation_1-auc:0.81384                                                                 \n",
      "[31]\tvalidation_0-auc:0.94752\tvalidation_1-auc:0.81380                                                                 \n",
      "[32]\tvalidation_0-auc:0.94847\tvalidation_1-auc:0.81339                                                                 \n",
      "[33]\tvalidation_0-auc:0.95008\tvalidation_1-auc:0.81359                                                                 \n",
      "[34]\tvalidation_0-auc:0.95037\tvalidation_1-auc:0.81359                                                                 \n",
      "[35]\tvalidation_0-auc:0.95048\tvalidation_1-auc:0.81359                                                                 \n",
      "[36]\tvalidation_0-auc:0.95074\tvalidation_1-auc:0.81328                                                                 \n",
      "[37]\tvalidation_0-auc:0.95163\tvalidation_1-auc:0.81264                                                                 \n",
      "[38]\tvalidation_0-auc:0.95175\tvalidation_1-auc:0.81232                                                                 \n",
      "[0]\tvalidation_0-auc:0.87881\tvalidation_1-auc:0.79719                                                                  \n",
      "[1]\tvalidation_0-auc:0.88694\tvalidation_1-auc:0.80998                                                                  \n",
      "[2]\tvalidation_0-auc:0.89315\tvalidation_1-auc:0.82228                                                                  \n",
      "[3]\tvalidation_0-auc:0.90155\tvalidation_1-auc:0.82466                                                                  \n",
      "[4]\tvalidation_0-auc:0.90845\tvalidation_1-auc:0.82824                                                                  \n",
      "[5]\tvalidation_0-auc:0.91179\tvalidation_1-auc:0.82875                                                                  \n",
      "[6]\tvalidation_0-auc:0.91631\tvalidation_1-auc:0.82853                                                                  \n",
      "[7]\tvalidation_0-auc:0.92027\tvalidation_1-auc:0.82897                                                                  \n",
      "[8]\tvalidation_0-auc:0.92341\tvalidation_1-auc:0.82932                                                                  \n",
      "[9]\tvalidation_0-auc:0.92626\tvalidation_1-auc:0.82890                                                                  \n",
      "[10]\tvalidation_0-auc:0.92902\tvalidation_1-auc:0.82873                                                                 \n",
      "[11]\tvalidation_0-auc:0.93154\tvalidation_1-auc:0.82746                                                                 \n",
      "[12]\tvalidation_0-auc:0.93312\tvalidation_1-auc:0.82789                                                                 \n",
      "[13]\tvalidation_0-auc:0.93456\tvalidation_1-auc:0.82830                                                                 \n",
      "[14]\tvalidation_0-auc:0.93639\tvalidation_1-auc:0.82800                                                                 \n",
      "[15]\tvalidation_0-auc:0.93783\tvalidation_1-auc:0.82839                                                                 \n",
      "[16]\tvalidation_0-auc:0.93922\tvalidation_1-auc:0.82848                                                                 \n",
      "[17]\tvalidation_0-auc:0.94009\tvalidation_1-auc:0.82859                                                                 \n",
      "[18]\tvalidation_0-auc:0.94071\tvalidation_1-auc:0.82844                                                                 \n",
      "[19]\tvalidation_0-auc:0.94169\tvalidation_1-auc:0.82858                                                                 \n",
      "[20]\tvalidation_0-auc:0.94241\tvalidation_1-auc:0.82813                                                                 \n",
      "[21]\tvalidation_0-auc:0.94329\tvalidation_1-auc:0.82844                                                                 \n",
      "[22]\tvalidation_0-auc:0.94372\tvalidation_1-auc:0.82811                                                                 \n",
      "[23]\tvalidation_0-auc:0.94401\tvalidation_1-auc:0.82779                                                                 \n",
      "[24]\tvalidation_0-auc:0.94452\tvalidation_1-auc:0.82772                                                                 \n",
      "[25]\tvalidation_0-auc:0.94484\tvalidation_1-auc:0.82738                                                                 \n",
      "[26]\tvalidation_0-auc:0.94751\tvalidation_1-auc:0.82796                                                                 \n",
      "[27]\tvalidation_0-auc:0.94854\tvalidation_1-auc:0.82845                                                                 \n",
      "[28]\tvalidation_0-auc:0.94870\tvalidation_1-auc:0.82851                                                                 \n",
      "[29]\tvalidation_0-auc:0.94904\tvalidation_1-auc:0.82844                                                                 \n",
      "[30]\tvalidation_0-auc:0.94944\tvalidation_1-auc:0.82821                                                                 \n",
      "[31]\tvalidation_0-auc:0.94954\tvalidation_1-auc:0.82819                                                                 \n",
      "[32]\tvalidation_0-auc:0.95022\tvalidation_1-auc:0.82792                                                                 \n",
      "[33]\tvalidation_0-auc:0.95038\tvalidation_1-auc:0.82797                                                                 \n",
      "[34]\tvalidation_0-auc:0.95069\tvalidation_1-auc:0.82794                                                                 \n",
      "[35]\tvalidation_0-auc:0.95108\tvalidation_1-auc:0.82788                                                                 \n",
      "[36]\tvalidation_0-auc:0.95153\tvalidation_1-auc:0.82752                                                                 \n",
      "[37]\tvalidation_0-auc:0.95163\tvalidation_1-auc:0.82738                                                                 \n",
      "[38]\tvalidation_0-auc:0.95178\tvalidation_1-auc:0.82740                                                                 \n",
      "[0]\tvalidation_0-auc:0.87491\tvalidation_1-auc:0.80531                                                                  \n",
      "[1]\tvalidation_0-auc:0.88474\tvalidation_1-auc:0.81866                                                                  \n",
      "[2]\tvalidation_0-auc:0.89268\tvalidation_1-auc:0.82436                                                                  \n",
      "[3]\tvalidation_0-auc:0.89747\tvalidation_1-auc:0.82538                                                                  \n",
      "[4]\tvalidation_0-auc:0.90407\tvalidation_1-auc:0.82835                                                                  \n",
      "[5]\tvalidation_0-auc:0.90783\tvalidation_1-auc:0.82750                                                                  \n",
      "[6]\tvalidation_0-auc:0.91214\tvalidation_1-auc:0.82587                                                                  \n",
      "[7]\tvalidation_0-auc:0.91569\tvalidation_1-auc:0.82549                                                                  \n",
      "[8]\tvalidation_0-auc:0.91896\tvalidation_1-auc:0.82608                                                                  \n",
      "[9]\tvalidation_0-auc:0.92312\tvalidation_1-auc:0.82630                                                                  \n",
      "[10]\tvalidation_0-auc:0.92578\tvalidation_1-auc:0.82492                                                                 \n",
      "[11]\tvalidation_0-auc:0.92881\tvalidation_1-auc:0.82587                                                                 \n",
      "[12]\tvalidation_0-auc:0.93092\tvalidation_1-auc:0.82646                                                                 \n",
      "[13]\tvalidation_0-auc:0.93219\tvalidation_1-auc:0.82687                                                                 \n",
      "[14]\tvalidation_0-auc:0.93403\tvalidation_1-auc:0.82754                                                                 \n",
      "[15]\tvalidation_0-auc:0.93595\tvalidation_1-auc:0.82745                                                                 \n",
      "[16]\tvalidation_0-auc:0.93730\tvalidation_1-auc:0.82790                                                                 \n",
      "[17]\tvalidation_0-auc:0.93872\tvalidation_1-auc:0.82835                                                                 \n",
      "[18]\tvalidation_0-auc:0.94017\tvalidation_1-auc:0.82830                                                                 \n",
      "[19]\tvalidation_0-auc:0.94134\tvalidation_1-auc:0.82818                                                                 \n",
      "[20]\tvalidation_0-auc:0.94323\tvalidation_1-auc:0.82808                                                                 \n",
      "[21]\tvalidation_0-auc:0.94414\tvalidation_1-auc:0.82838                                                                 \n",
      "[22]\tvalidation_0-auc:0.94472\tvalidation_1-auc:0.82871                                                                 \n",
      "[23]\tvalidation_0-auc:0.94531\tvalidation_1-auc:0.82893                                                                 \n",
      "[24]\tvalidation_0-auc:0.94639\tvalidation_1-auc:0.82984                                                                 \n",
      "[25]\tvalidation_0-auc:0.94704\tvalidation_1-auc:0.82990                                                                 \n",
      "[26]\tvalidation_0-auc:0.94879\tvalidation_1-auc:0.82964                                                                 \n",
      "[27]\tvalidation_0-auc:0.95006\tvalidation_1-auc:0.82976                                                                 \n",
      "[28]\tvalidation_0-auc:0.95043\tvalidation_1-auc:0.82996                                                                 \n",
      "[29]\tvalidation_0-auc:0.95147\tvalidation_1-auc:0.82973                                                                 \n",
      "[30]\tvalidation_0-auc:0.95165\tvalidation_1-auc:0.83001                                                                 \n",
      "[31]\tvalidation_0-auc:0.95206\tvalidation_1-auc:0.82987                                                                 \n",
      "[32]\tvalidation_0-auc:0.95315\tvalidation_1-auc:0.82953                                                                 \n",
      "[33]\tvalidation_0-auc:0.95345\tvalidation_1-auc:0.82967                                                                 \n",
      "[34]\tvalidation_0-auc:0.95375\tvalidation_1-auc:0.82962                                                                 \n",
      "[35]\tvalidation_0-auc:0.95446\tvalidation_1-auc:0.82937                                                                 \n",
      "[36]\tvalidation_0-auc:0.95459\tvalidation_1-auc:0.82928                                                                 \n",
      "[37]\tvalidation_0-auc:0.95547\tvalidation_1-auc:0.82942                                                                 \n",
      "[38]\tvalidation_0-auc:0.95551\tvalidation_1-auc:0.82961                                                                 \n",
      "[39]\tvalidation_0-auc:0.95581\tvalidation_1-auc:0.82953                                                                 \n",
      "[40]\tvalidation_0-auc:0.95640\tvalidation_1-auc:0.82943                                                                 \n",
      "[41]\tvalidation_0-auc:0.95662\tvalidation_1-auc:0.82936                                                                 \n",
      "[42]\tvalidation_0-auc:0.95705\tvalidation_1-auc:0.82926                                                                 \n",
      "[43]\tvalidation_0-auc:0.95721\tvalidation_1-auc:0.82935                                                                 \n",
      "[44]\tvalidation_0-auc:0.95728\tvalidation_1-auc:0.82925                                                                 \n",
      "[45]\tvalidation_0-auc:0.95817\tvalidation_1-auc:0.82942                                                                 \n",
      "[46]\tvalidation_0-auc:0.95831\tvalidation_1-auc:0.82923                                                                 \n",
      "[47]\tvalidation_0-auc:0.95863\tvalidation_1-auc:0.82937                                                                 \n",
      "[48]\tvalidation_0-auc:0.95873\tvalidation_1-auc:0.82952                                                                 \n",
      "[49]\tvalidation_0-auc:0.95886\tvalidation_1-auc:0.82950                                                                 \n",
      "[50]\tvalidation_0-auc:0.95960\tvalidation_1-auc:0.82933                                                                 \n",
      "[51]\tvalidation_0-auc:0.95968\tvalidation_1-auc:0.82944                                                                 \n",
      "[52]\tvalidation_0-auc:0.95994\tvalidation_1-auc:0.82938                                                                 \n",
      "[53]\tvalidation_0-auc:0.96002\tvalidation_1-auc:0.82946                                                                 \n",
      "[54]\tvalidation_0-auc:0.96016\tvalidation_1-auc:0.82925                                                                 \n",
      "[55]\tvalidation_0-auc:0.96082\tvalidation_1-auc:0.82877                                                                 \n",
      "[56]\tvalidation_0-auc:0.96146\tvalidation_1-auc:0.82889                                                                 \n",
      "[57]\tvalidation_0-auc:0.96209\tvalidation_1-auc:0.82867                                                                 \n",
      "[58]\tvalidation_0-auc:0.96233\tvalidation_1-auc:0.82878                                                                 \n",
      "[59]\tvalidation_0-auc:0.96241\tvalidation_1-auc:0.82855                                                                 \n",
      "[60]\tvalidation_0-auc:0.96245\tvalidation_1-auc:0.82850                                                                 \n",
      "[0]\tvalidation_0-auc:0.87999\tvalidation_1-auc:0.79199                                                                  \n",
      "[1]\tvalidation_0-auc:0.89231\tvalidation_1-auc:0.79055                                                                  \n",
      "[2]\tvalidation_0-auc:0.89818\tvalidation_1-auc:0.80196                                                                  \n",
      "[3]\tvalidation_0-auc:0.89880\tvalidation_1-auc:0.79815                                                                  \n",
      "[4]\tvalidation_0-auc:0.89833\tvalidation_1-auc:0.79336                                                                  \n",
      "[5]\tvalidation_0-auc:0.90398\tvalidation_1-auc:0.80349                                                                  \n",
      "[6]\tvalidation_0-auc:0.90728\tvalidation_1-auc:0.80695                                                                  \n",
      "[7]\tvalidation_0-auc:0.90816\tvalidation_1-auc:0.80510                                                                  \n",
      "[8]\tvalidation_0-auc:0.91098\tvalidation_1-auc:0.80712                                                                  \n",
      "[9]\tvalidation_0-auc:0.91085\tvalidation_1-auc:0.80462                                                                  \n",
      "[10]\tvalidation_0-auc:0.91272\tvalidation_1-auc:0.80718                                                                 \n",
      "[11]\tvalidation_0-auc:0.91510\tvalidation_1-auc:0.80969                                                                 \n",
      "[12]\tvalidation_0-auc:0.91724\tvalidation_1-auc:0.81168                                                                 \n",
      "[13]\tvalidation_0-auc:0.91945\tvalidation_1-auc:0.81166                                                                 \n",
      "[14]\tvalidation_0-auc:0.92059\tvalidation_1-auc:0.81027                                                                 \n",
      "[15]\tvalidation_0-auc:0.92242\tvalidation_1-auc:0.81027                                                                 \n",
      "[16]\tvalidation_0-auc:0.92423\tvalidation_1-auc:0.81198                                                                 \n",
      "[17]\tvalidation_0-auc:0.92549\tvalidation_1-auc:0.81087                                                                 \n",
      "[18]\tvalidation_0-auc:0.92596\tvalidation_1-auc:0.81077                                                                 \n",
      "[19]\tvalidation_0-auc:0.92726\tvalidation_1-auc:0.81221                                                                 \n",
      "[20]\tvalidation_0-auc:0.92821\tvalidation_1-auc:0.81272                                                                 \n",
      "[21]\tvalidation_0-auc:0.92928\tvalidation_1-auc:0.81308                                                                 \n",
      "[22]\tvalidation_0-auc:0.92993\tvalidation_1-auc:0.81413                                                                 \n",
      "[23]\tvalidation_0-auc:0.93021\tvalidation_1-auc:0.81473                                                                 \n",
      "[24]\tvalidation_0-auc:0.93102\tvalidation_1-auc:0.81538                                                                 \n",
      "[25]\tvalidation_0-auc:0.93207\tvalidation_1-auc:0.81619                                                                 \n",
      "[26]\tvalidation_0-auc:0.93247\tvalidation_1-auc:0.81539                                                                 \n",
      "[27]\tvalidation_0-auc:0.93282\tvalidation_1-auc:0.81477                                                                 \n",
      "[28]\tvalidation_0-auc:0.93334\tvalidation_1-auc:0.81464                                                                 \n",
      "[29]\tvalidation_0-auc:0.93344\tvalidation_1-auc:0.81384                                                                 \n",
      "[30]\tvalidation_0-auc:0.93421\tvalidation_1-auc:0.81315                                                                 \n",
      "[31]\tvalidation_0-auc:0.93457\tvalidation_1-auc:0.81259                                                                 \n",
      "[32]\tvalidation_0-auc:0.93543\tvalidation_1-auc:0.81322                                                                 \n",
      "[33]\tvalidation_0-auc:0.93623\tvalidation_1-auc:0.81310                                                                 \n",
      "[34]\tvalidation_0-auc:0.93707\tvalidation_1-auc:0.81343                                                                 \n",
      "[35]\tvalidation_0-auc:0.93781\tvalidation_1-auc:0.81369                                                                 \n",
      "[36]\tvalidation_0-auc:0.93851\tvalidation_1-auc:0.81389                                                                 \n",
      "[37]\tvalidation_0-auc:0.93922\tvalidation_1-auc:0.81447                                                                 \n",
      "[38]\tvalidation_0-auc:0.93975\tvalidation_1-auc:0.81462                                                                 \n",
      "[39]\tvalidation_0-auc:0.94022\tvalidation_1-auc:0.81453                                                                 \n",
      "[40]\tvalidation_0-auc:0.94094\tvalidation_1-auc:0.81425                                                                 \n",
      "[41]\tvalidation_0-auc:0.94165\tvalidation_1-auc:0.81465                                                                 \n",
      "[42]\tvalidation_0-auc:0.94207\tvalidation_1-auc:0.81424                                                                 \n",
      "[43]\tvalidation_0-auc:0.94258\tvalidation_1-auc:0.81373                                                                 \n",
      "[44]\tvalidation_0-auc:0.94272\tvalidation_1-auc:0.81350                                                                 \n",
      "[45]\tvalidation_0-auc:0.94336\tvalidation_1-auc:0.81375                                                                 \n",
      "[46]\tvalidation_0-auc:0.94375\tvalidation_1-auc:0.81319                                                                 \n",
      "[47]\tvalidation_0-auc:0.94407\tvalidation_1-auc:0.81315                                                                 \n",
      "[48]\tvalidation_0-auc:0.94440\tvalidation_1-auc:0.81261                                                                 \n",
      "[49]\tvalidation_0-auc:0.94463\tvalidation_1-auc:0.81226                                                                 \n",
      "[50]\tvalidation_0-auc:0.94524\tvalidation_1-auc:0.81254                                                                 \n",
      "[51]\tvalidation_0-auc:0.94573\tvalidation_1-auc:0.81290                                                                 \n",
      "[52]\tvalidation_0-auc:0.94591\tvalidation_1-auc:0.81237                                                                 \n",
      "[53]\tvalidation_0-auc:0.94611\tvalidation_1-auc:0.81276                                                                 \n",
      "[54]\tvalidation_0-auc:0.94644\tvalidation_1-auc:0.81253                                                                 \n",
      "[55]\tvalidation_0-auc:0.94678\tvalidation_1-auc:0.81272                                                                 \n",
      "[0]\tvalidation_0-auc:0.87483\tvalidation_1-auc:0.80422                                                                  \n",
      "[1]\tvalidation_0-auc:0.89388\tvalidation_1-auc:0.81232                                                                  \n",
      "[2]\tvalidation_0-auc:0.89834\tvalidation_1-auc:0.82525                                                                  \n",
      "[3]\tvalidation_0-auc:0.89731\tvalidation_1-auc:0.82463                                                                  \n",
      "[4]\tvalidation_0-auc:0.89542\tvalidation_1-auc:0.82059                                                                  \n",
      "[5]\tvalidation_0-auc:0.90246\tvalidation_1-auc:0.82627                                                                  \n",
      "[6]\tvalidation_0-auc:0.90672\tvalidation_1-auc:0.82871                                                                  \n",
      "[7]\tvalidation_0-auc:0.90896\tvalidation_1-auc:0.82770                                                                  \n",
      "[8]\tvalidation_0-auc:0.91138\tvalidation_1-auc:0.83020                                                                  \n",
      "[9]\tvalidation_0-auc:0.91060\tvalidation_1-auc:0.82942                                                                  \n",
      "[10]\tvalidation_0-auc:0.91254\tvalidation_1-auc:0.83133                                                                 \n",
      "[11]\tvalidation_0-auc:0.91467\tvalidation_1-auc:0.83267                                                                 \n",
      "[12]\tvalidation_0-auc:0.91714\tvalidation_1-auc:0.83238                                                                 \n",
      "[13]\tvalidation_0-auc:0.91944\tvalidation_1-auc:0.83273                                                                 \n",
      "[14]\tvalidation_0-auc:0.92050\tvalidation_1-auc:0.83154                                                                 \n",
      "[15]\tvalidation_0-auc:0.92246\tvalidation_1-auc:0.83183                                                                 \n",
      "[16]\tvalidation_0-auc:0.92413\tvalidation_1-auc:0.83250                                                                 \n",
      "[17]\tvalidation_0-auc:0.92533\tvalidation_1-auc:0.83274                                                                 \n",
      "[18]\tvalidation_0-auc:0.92620\tvalidation_1-auc:0.83170                                                                 \n",
      "[19]\tvalidation_0-auc:0.92745\tvalidation_1-auc:0.83169                                                                 \n",
      "[20]\tvalidation_0-auc:0.92879\tvalidation_1-auc:0.83218                                                                 \n",
      "[21]\tvalidation_0-auc:0.92987\tvalidation_1-auc:0.83274                                                                 \n",
      "[22]\tvalidation_0-auc:0.93073\tvalidation_1-auc:0.83312                                                                 \n",
      "[23]\tvalidation_0-auc:0.93107\tvalidation_1-auc:0.83410                                                                 \n",
      "[24]\tvalidation_0-auc:0.93198\tvalidation_1-auc:0.83465                                                                 \n",
      "[25]\tvalidation_0-auc:0.93286\tvalidation_1-auc:0.83449                                                                 \n",
      "[26]\tvalidation_0-auc:0.93338\tvalidation_1-auc:0.83450                                                                 \n",
      "[27]\tvalidation_0-auc:0.93376\tvalidation_1-auc:0.83475                                                                 \n",
      "[28]\tvalidation_0-auc:0.93437\tvalidation_1-auc:0.83512                                                                 \n",
      "[29]\tvalidation_0-auc:0.93436\tvalidation_1-auc:0.83510                                                                 \n",
      "[30]\tvalidation_0-auc:0.93494\tvalidation_1-auc:0.83452                                                                 \n",
      "[31]\tvalidation_0-auc:0.93559\tvalidation_1-auc:0.83412                                                                 \n",
      "[32]\tvalidation_0-auc:0.93645\tvalidation_1-auc:0.83427                                                                 \n",
      "[33]\tvalidation_0-auc:0.93726\tvalidation_1-auc:0.83425                                                                 \n",
      "[34]\tvalidation_0-auc:0.93796\tvalidation_1-auc:0.83452                                                                 \n",
      "[35]\tvalidation_0-auc:0.93855\tvalidation_1-auc:0.83436                                                                 \n",
      "[36]\tvalidation_0-auc:0.93923\tvalidation_1-auc:0.83444                                                                 \n",
      "[37]\tvalidation_0-auc:0.93976\tvalidation_1-auc:0.83448                                                                 \n",
      "[38]\tvalidation_0-auc:0.94034\tvalidation_1-auc:0.83459                                                                 \n",
      "[39]\tvalidation_0-auc:0.94079\tvalidation_1-auc:0.83466                                                                 \n",
      "[40]\tvalidation_0-auc:0.94120\tvalidation_1-auc:0.83445                                                                 \n",
      "[41]\tvalidation_0-auc:0.94183\tvalidation_1-auc:0.83469                                                                 \n",
      "[42]\tvalidation_0-auc:0.94231\tvalidation_1-auc:0.83482                                                                 \n",
      "[43]\tvalidation_0-auc:0.94278\tvalidation_1-auc:0.83459                                                                 \n",
      "[44]\tvalidation_0-auc:0.94293\tvalidation_1-auc:0.83465                                                                 \n",
      "[45]\tvalidation_0-auc:0.94335\tvalidation_1-auc:0.83473                                                                 \n",
      "[46]\tvalidation_0-auc:0.94364\tvalidation_1-auc:0.83456                                                                 \n",
      "[47]\tvalidation_0-auc:0.94421\tvalidation_1-auc:0.83468                                                                 \n",
      "[48]\tvalidation_0-auc:0.94446\tvalidation_1-auc:0.83459                                                                 \n",
      "[49]\tvalidation_0-auc:0.94482\tvalidation_1-auc:0.83463                                                                 \n",
      "[50]\tvalidation_0-auc:0.94529\tvalidation_1-auc:0.83478                                                                 \n",
      "[51]\tvalidation_0-auc:0.94582\tvalidation_1-auc:0.83517                                                                 \n",
      "[52]\tvalidation_0-auc:0.94610\tvalidation_1-auc:0.83534                                                                 \n",
      "[53]\tvalidation_0-auc:0.94639\tvalidation_1-auc:0.83566                                                                 \n",
      "[54]\tvalidation_0-auc:0.94688\tvalidation_1-auc:0.83561                                                                 \n",
      "[55]\tvalidation_0-auc:0.94705\tvalidation_1-auc:0.83574                                                                 \n",
      "[56]\tvalidation_0-auc:0.94742\tvalidation_1-auc:0.83573                                                                 \n",
      "[57]\tvalidation_0-auc:0.94770\tvalidation_1-auc:0.83606                                                                 \n",
      "[58]\tvalidation_0-auc:0.94818\tvalidation_1-auc:0.83639                                                                 \n",
      "[59]\tvalidation_0-auc:0.94853\tvalidation_1-auc:0.83630                                                                 \n",
      "[60]\tvalidation_0-auc:0.94896\tvalidation_1-auc:0.83619                                                                 \n",
      "[61]\tvalidation_0-auc:0.94941\tvalidation_1-auc:0.83632                                                                 \n",
      "[62]\tvalidation_0-auc:0.94979\tvalidation_1-auc:0.83647                                                                 \n",
      "[63]\tvalidation_0-auc:0.95037\tvalidation_1-auc:0.83623                                                                 \n",
      "[64]\tvalidation_0-auc:0.95068\tvalidation_1-auc:0.83625                                                                 \n",
      "[65]\tvalidation_0-auc:0.95115\tvalidation_1-auc:0.83626                                                                 \n",
      "[66]\tvalidation_0-auc:0.95136\tvalidation_1-auc:0.83613                                                                 \n",
      "[67]\tvalidation_0-auc:0.95158\tvalidation_1-auc:0.83617                                                                 \n",
      "[68]\tvalidation_0-auc:0.95205\tvalidation_1-auc:0.83631                                                                 \n",
      "[69]\tvalidation_0-auc:0.95218\tvalidation_1-auc:0.83627                                                                 \n",
      "[70]\tvalidation_0-auc:0.95245\tvalidation_1-auc:0.83636                                                                 \n",
      "[71]\tvalidation_0-auc:0.95277\tvalidation_1-auc:0.83662                                                                 \n",
      "[72]\tvalidation_0-auc:0.95318\tvalidation_1-auc:0.83680                                                                 \n",
      "[73]\tvalidation_0-auc:0.95358\tvalidation_1-auc:0.83657                                                                 \n",
      "[74]\tvalidation_0-auc:0.95389\tvalidation_1-auc:0.83666                                                                 \n",
      "[75]\tvalidation_0-auc:0.95403\tvalidation_1-auc:0.83675                                                                 \n",
      "[76]\tvalidation_0-auc:0.95425\tvalidation_1-auc:0.83676                                                                 \n",
      "[77]\tvalidation_0-auc:0.95429\tvalidation_1-auc:0.83684                                                                 \n",
      "[78]\tvalidation_0-auc:0.95431\tvalidation_1-auc:0.83688                                                                 \n",
      "[79]\tvalidation_0-auc:0.95454\tvalidation_1-auc:0.83671                                                                 \n",
      "[80]\tvalidation_0-auc:0.95483\tvalidation_1-auc:0.83676                                                                 \n",
      "[81]\tvalidation_0-auc:0.95515\tvalidation_1-auc:0.83668                                                                 \n",
      "[82]\tvalidation_0-auc:0.95546\tvalidation_1-auc:0.83673                                                                 \n",
      "[83]\tvalidation_0-auc:0.95581\tvalidation_1-auc:0.83680                                                                 \n",
      "[84]\tvalidation_0-auc:0.95606\tvalidation_1-auc:0.83675                                                                 \n",
      "[85]\tvalidation_0-auc:0.95631\tvalidation_1-auc:0.83667                                                                 \n",
      "[86]\tvalidation_0-auc:0.95649\tvalidation_1-auc:0.83679                                                                 \n",
      "[87]\tvalidation_0-auc:0.95666\tvalidation_1-auc:0.83681                                                                 \n",
      "[88]\tvalidation_0-auc:0.95683\tvalidation_1-auc:0.83679                                                                 \n",
      "[89]\tvalidation_0-auc:0.95706\tvalidation_1-auc:0.83659                                                                 \n",
      "[90]\tvalidation_0-auc:0.95745\tvalidation_1-auc:0.83671                                                                 \n",
      "[91]\tvalidation_0-auc:0.95768\tvalidation_1-auc:0.83661                                                                 \n",
      "[92]\tvalidation_0-auc:0.95789\tvalidation_1-auc:0.83653                                                                 \n",
      "[93]\tvalidation_0-auc:0.95807\tvalidation_1-auc:0.83636                                                                 \n",
      "[94]\tvalidation_0-auc:0.95830\tvalidation_1-auc:0.83638                                                                 \n",
      "[95]\tvalidation_0-auc:0.95860\tvalidation_1-auc:0.83636                                                                 \n",
      "[96]\tvalidation_0-auc:0.95901\tvalidation_1-auc:0.83617                                                                 \n",
      "[97]\tvalidation_0-auc:0.95900\tvalidation_1-auc:0.83620                                                                 \n",
      "[98]\tvalidation_0-auc:0.95932\tvalidation_1-auc:0.83615                                                                 \n",
      "[99]\tvalidation_0-auc:0.95948\tvalidation_1-auc:0.83623                                                                 \n",
      "[0]\tvalidation_0-auc:0.87526\tvalidation_1-auc:0.80189                                                                  \n",
      "[1]\tvalidation_0-auc:0.89272\tvalidation_1-auc:0.79538                                                                  \n",
      "[2]\tvalidation_0-auc:0.89466\tvalidation_1-auc:0.81130                                                                  \n",
      "[3]\tvalidation_0-auc:0.89574\tvalidation_1-auc:0.80612                                                                  \n",
      "[4]\tvalidation_0-auc:0.89381\tvalidation_1-auc:0.80269                                                                  \n",
      "[5]\tvalidation_0-auc:0.89869\tvalidation_1-auc:0.81209                                                                  \n",
      "[6]\tvalidation_0-auc:0.90169\tvalidation_1-auc:0.81676                                                                  \n",
      "[7]\tvalidation_0-auc:0.90393\tvalidation_1-auc:0.81320                                                                  \n",
      "[8]\tvalidation_0-auc:0.90783\tvalidation_1-auc:0.81662                                                                  \n",
      "[9]\tvalidation_0-auc:0.90833\tvalidation_1-auc:0.81545                                                                  \n",
      "[10]\tvalidation_0-auc:0.91001\tvalidation_1-auc:0.81769                                                                 \n",
      "[11]\tvalidation_0-auc:0.91372\tvalidation_1-auc:0.82061                                                                 \n",
      "[12]\tvalidation_0-auc:0.91623\tvalidation_1-auc:0.82294                                                                 \n",
      "[13]\tvalidation_0-auc:0.91836\tvalidation_1-auc:0.82369                                                                 \n",
      "[14]\tvalidation_0-auc:0.91928\tvalidation_1-auc:0.82288                                                                 \n",
      "[15]\tvalidation_0-auc:0.92086\tvalidation_1-auc:0.82443                                                                 \n",
      "[16]\tvalidation_0-auc:0.92283\tvalidation_1-auc:0.82513                                                                 \n",
      "[17]\tvalidation_0-auc:0.92389\tvalidation_1-auc:0.82412                                                                 \n",
      "[18]\tvalidation_0-auc:0.92474\tvalidation_1-auc:0.82323                                                                 \n",
      "[19]\tvalidation_0-auc:0.92605\tvalidation_1-auc:0.82369                                                                 \n",
      "[20]\tvalidation_0-auc:0.92696\tvalidation_1-auc:0.82442                                                                 \n",
      "[21]\tvalidation_0-auc:0.92790\tvalidation_1-auc:0.82474                                                                 \n",
      "[22]\tvalidation_0-auc:0.92863\tvalidation_1-auc:0.82557                                                                 \n",
      "[23]\tvalidation_0-auc:0.92894\tvalidation_1-auc:0.82660                                                                 \n",
      "[24]\tvalidation_0-auc:0.92995\tvalidation_1-auc:0.82738                                                                 \n",
      "[25]\tvalidation_0-auc:0.93107\tvalidation_1-auc:0.82746                                                                 \n",
      "[26]\tvalidation_0-auc:0.93154\tvalidation_1-auc:0.82701                                                                 \n",
      "[27]\tvalidation_0-auc:0.93197\tvalidation_1-auc:0.82633                                                                 \n",
      "[28]\tvalidation_0-auc:0.93254\tvalidation_1-auc:0.82677                                                                 \n",
      "[29]\tvalidation_0-auc:0.93271\tvalidation_1-auc:0.82657                                                                 \n",
      "[30]\tvalidation_0-auc:0.93326\tvalidation_1-auc:0.82600                                                                 \n",
      "[31]\tvalidation_0-auc:0.93390\tvalidation_1-auc:0.82546                                                                 \n",
      "[32]\tvalidation_0-auc:0.93470\tvalidation_1-auc:0.82585                                                                 \n",
      "[33]\tvalidation_0-auc:0.93561\tvalidation_1-auc:0.82614                                                                 \n",
      "[34]\tvalidation_0-auc:0.93653\tvalidation_1-auc:0.82660                                                                 \n",
      "[35]\tvalidation_0-auc:0.93699\tvalidation_1-auc:0.82711                                                                 \n",
      "[36]\tvalidation_0-auc:0.93788\tvalidation_1-auc:0.82734                                                                 \n",
      "[37]\tvalidation_0-auc:0.93876\tvalidation_1-auc:0.82735                                                                 \n",
      "[38]\tvalidation_0-auc:0.93935\tvalidation_1-auc:0.82761                                                                 \n",
      "[39]\tvalidation_0-auc:0.93997\tvalidation_1-auc:0.82782                                                                 \n",
      "[40]\tvalidation_0-auc:0.94048\tvalidation_1-auc:0.82752                                                                 \n",
      "[41]\tvalidation_0-auc:0.94125\tvalidation_1-auc:0.82778                                                                 \n",
      "[42]\tvalidation_0-auc:0.94159\tvalidation_1-auc:0.82767                                                                 \n",
      "[43]\tvalidation_0-auc:0.94229\tvalidation_1-auc:0.82700                                                                 \n",
      "[44]\tvalidation_0-auc:0.94227\tvalidation_1-auc:0.82706                                                                 \n",
      "[45]\tvalidation_0-auc:0.94297\tvalidation_1-auc:0.82696                                                                 \n",
      "[46]\tvalidation_0-auc:0.94334\tvalidation_1-auc:0.82679                                                                 \n",
      "[47]\tvalidation_0-auc:0.94388\tvalidation_1-auc:0.82642                                                                 \n",
      "[48]\tvalidation_0-auc:0.94424\tvalidation_1-auc:0.82615                                                                 \n",
      "[49]\tvalidation_0-auc:0.94442\tvalidation_1-auc:0.82572                                                                 \n",
      "[50]\tvalidation_0-auc:0.94491\tvalidation_1-auc:0.82580                                                                 \n",
      "[51]\tvalidation_0-auc:0.94553\tvalidation_1-auc:0.82590                                                                 \n",
      "[52]\tvalidation_0-auc:0.94578\tvalidation_1-auc:0.82574                                                                 \n",
      "[53]\tvalidation_0-auc:0.94603\tvalidation_1-auc:0.82629                                                                 \n",
      "[54]\tvalidation_0-auc:0.94662\tvalidation_1-auc:0.82620                                                                 \n",
      "[55]\tvalidation_0-auc:0.94698\tvalidation_1-auc:0.82675                                                                 \n",
      "[56]\tvalidation_0-auc:0.94736\tvalidation_1-auc:0.82680                                                                 \n",
      "[57]\tvalidation_0-auc:0.94769\tvalidation_1-auc:0.82728                                                                 \n",
      "[58]\tvalidation_0-auc:0.94833\tvalidation_1-auc:0.82733                                                                 \n",
      "[59]\tvalidation_0-auc:0.94864\tvalidation_1-auc:0.82752                                                                 \n",
      "[60]\tvalidation_0-auc:0.94920\tvalidation_1-auc:0.82771                                                                 \n",
      "[61]\tvalidation_0-auc:0.94967\tvalidation_1-auc:0.82791                                                                 \n",
      "[62]\tvalidation_0-auc:0.95007\tvalidation_1-auc:0.82773                                                                 \n",
      "[63]\tvalidation_0-auc:0.95056\tvalidation_1-auc:0.82742                                                                 \n",
      "[64]\tvalidation_0-auc:0.95089\tvalidation_1-auc:0.82764                                                                 \n",
      "[65]\tvalidation_0-auc:0.95151\tvalidation_1-auc:0.82753                                                                 \n",
      "[66]\tvalidation_0-auc:0.95191\tvalidation_1-auc:0.82728                                                                 \n",
      "[67]\tvalidation_0-auc:0.95210\tvalidation_1-auc:0.82785                                                                 \n",
      "[68]\tvalidation_0-auc:0.95256\tvalidation_1-auc:0.82756                                                                 \n",
      "[69]\tvalidation_0-auc:0.95275\tvalidation_1-auc:0.82795                                                                 \n",
      "[70]\tvalidation_0-auc:0.95340\tvalidation_1-auc:0.82805                                                                 \n",
      "[71]\tvalidation_0-auc:0.95387\tvalidation_1-auc:0.82824                                                                 \n",
      "[72]\tvalidation_0-auc:0.95441\tvalidation_1-auc:0.82810                                                                 \n",
      "[73]\tvalidation_0-auc:0.95492\tvalidation_1-auc:0.82778                                                                 \n",
      "[74]\tvalidation_0-auc:0.95542\tvalidation_1-auc:0.82781                                                                 \n",
      "[75]\tvalidation_0-auc:0.95570\tvalidation_1-auc:0.82808                                                                 \n",
      "[76]\tvalidation_0-auc:0.95594\tvalidation_1-auc:0.82827                                                                 \n",
      "[77]\tvalidation_0-auc:0.95606\tvalidation_1-auc:0.82847                                                                 \n",
      "[78]\tvalidation_0-auc:0.95609\tvalidation_1-auc:0.82881                                                                 \n",
      "[79]\tvalidation_0-auc:0.95645\tvalidation_1-auc:0.82869                                                                 \n",
      "[80]\tvalidation_0-auc:0.95670\tvalidation_1-auc:0.82863                                                                 \n",
      "[81]\tvalidation_0-auc:0.95697\tvalidation_1-auc:0.82885                                                                 \n",
      "[82]\tvalidation_0-auc:0.95720\tvalidation_1-auc:0.82910                                                                 \n",
      "[83]\tvalidation_0-auc:0.95756\tvalidation_1-auc:0.82936                                                                 \n",
      "[84]\tvalidation_0-auc:0.95780\tvalidation_1-auc:0.82949                                                                 \n",
      "[85]\tvalidation_0-auc:0.95805\tvalidation_1-auc:0.82967                                                                 \n",
      "[86]\tvalidation_0-auc:0.95825\tvalidation_1-auc:0.82988                                                                 \n",
      "[87]\tvalidation_0-auc:0.95839\tvalidation_1-auc:0.82982                                                                 \n",
      "[88]\tvalidation_0-auc:0.95851\tvalidation_1-auc:0.82986                                                                 \n",
      "[89]\tvalidation_0-auc:0.95867\tvalidation_1-auc:0.83003                                                                 \n",
      "[90]\tvalidation_0-auc:0.95896\tvalidation_1-auc:0.83008                                                                 \n",
      "[91]\tvalidation_0-auc:0.95919\tvalidation_1-auc:0.83025                                                                 \n",
      "[92]\tvalidation_0-auc:0.95938\tvalidation_1-auc:0.83038                                                                 \n",
      "[93]\tvalidation_0-auc:0.95972\tvalidation_1-auc:0.83031                                                                 \n",
      "[94]\tvalidation_0-auc:0.95989\tvalidation_1-auc:0.83030                                                                 \n",
      "[95]\tvalidation_0-auc:0.96011\tvalidation_1-auc:0.83051                                                                 \n",
      "[96]\tvalidation_0-auc:0.96038\tvalidation_1-auc:0.83044                                                                 \n",
      "[97]\tvalidation_0-auc:0.96048\tvalidation_1-auc:0.83040                                                                 \n",
      "[98]\tvalidation_0-auc:0.96070\tvalidation_1-auc:0.83033                                                                 \n",
      "[99]\tvalidation_0-auc:0.96083\tvalidation_1-auc:0.83027                                                                 \n",
      "[0]\tvalidation_0-auc:0.89140\tvalidation_1-auc:0.79133                                                                  \n",
      "[1]\tvalidation_0-auc:0.90263\tvalidation_1-auc:0.80144                                                                  \n",
      "[2]\tvalidation_0-auc:0.90733\tvalidation_1-auc:0.81131                                                                  \n",
      "[3]\tvalidation_0-auc:0.91470\tvalidation_1-auc:0.80962                                                                  \n",
      "[4]\tvalidation_0-auc:0.92161\tvalidation_1-auc:0.81127                                                                  \n",
      "[5]\tvalidation_0-auc:0.92638\tvalidation_1-auc:0.81084                                                                  \n",
      "[6]\tvalidation_0-auc:0.92996\tvalidation_1-auc:0.81222                                                                  \n",
      "[7]\tvalidation_0-auc:0.93275\tvalidation_1-auc:0.81237                                                                  \n",
      "[8]\tvalidation_0-auc:0.93622\tvalidation_1-auc:0.81167                                                                  \n",
      "[9]\tvalidation_0-auc:0.93907\tvalidation_1-auc:0.81183                                                                  \n",
      "[10]\tvalidation_0-auc:0.94223\tvalidation_1-auc:0.81219                                                                 \n",
      "[11]\tvalidation_0-auc:0.94414\tvalidation_1-auc:0.81180                                                                 \n",
      "[12]\tvalidation_0-auc:0.94680\tvalidation_1-auc:0.81194                                                                 \n",
      "[13]\tvalidation_0-auc:0.94881\tvalidation_1-auc:0.81118                                                                 \n",
      "[14]\tvalidation_0-auc:0.95099\tvalidation_1-auc:0.81111                                                                 \n",
      "[15]\tvalidation_0-auc:0.95227\tvalidation_1-auc:0.81117                                                                 \n",
      "[16]\tvalidation_0-auc:0.95353\tvalidation_1-auc:0.81151                                                                 \n",
      "[17]\tvalidation_0-auc:0.95448\tvalidation_1-auc:0.81195                                                                 \n",
      "[18]\tvalidation_0-auc:0.95548\tvalidation_1-auc:0.81268                                                                 \n",
      "[19]\tvalidation_0-auc:0.95652\tvalidation_1-auc:0.81233                                                                 \n",
      "[20]\tvalidation_0-auc:0.95730\tvalidation_1-auc:0.81245                                                                 \n",
      "[21]\tvalidation_0-auc:0.95775\tvalidation_1-auc:0.81248                                                                 \n",
      "[22]\tvalidation_0-auc:0.95877\tvalidation_1-auc:0.81267                                                                 \n",
      "[23]\tvalidation_0-auc:0.95932\tvalidation_1-auc:0.81278                                                                 \n",
      "[24]\tvalidation_0-auc:0.95977\tvalidation_1-auc:0.81290                                                                 \n",
      "[25]\tvalidation_0-auc:0.96026\tvalidation_1-auc:0.81301                                                                 \n",
      "[26]\tvalidation_0-auc:0.96040\tvalidation_1-auc:0.81283                                                                 \n",
      "[27]\tvalidation_0-auc:0.96133\tvalidation_1-auc:0.81265                                                                 \n",
      "[28]\tvalidation_0-auc:0.96158\tvalidation_1-auc:0.81235                                                                 \n",
      "[29]\tvalidation_0-auc:0.96179\tvalidation_1-auc:0.81232                                                                 \n",
      "[30]\tvalidation_0-auc:0.96227\tvalidation_1-auc:0.81161                                                                 \n",
      "[31]\tvalidation_0-auc:0.96286\tvalidation_1-auc:0.81148                                                                 \n",
      "[32]\tvalidation_0-auc:0.96309\tvalidation_1-auc:0.81134                                                                 \n",
      "[33]\tvalidation_0-auc:0.96361\tvalidation_1-auc:0.81139                                                                 \n",
      "[34]\tvalidation_0-auc:0.96402\tvalidation_1-auc:0.81143                                                                 \n",
      "[35]\tvalidation_0-auc:0.96417\tvalidation_1-auc:0.81161                                                                 \n",
      "[36]\tvalidation_0-auc:0.96447\tvalidation_1-auc:0.81146                                                                 \n",
      "[37]\tvalidation_0-auc:0.96463\tvalidation_1-auc:0.81120                                                                 \n",
      "[38]\tvalidation_0-auc:0.96469\tvalidation_1-auc:0.81089                                                                 \n",
      "[39]\tvalidation_0-auc:0.96581\tvalidation_1-auc:0.81092                                                                 \n",
      "[40]\tvalidation_0-auc:0.96622\tvalidation_1-auc:0.81036                                                                 \n",
      "[41]\tvalidation_0-auc:0.96727\tvalidation_1-auc:0.80982                                                                 \n",
      "[42]\tvalidation_0-auc:0.96760\tvalidation_1-auc:0.81018                                                                 \n",
      "[43]\tvalidation_0-auc:0.96771\tvalidation_1-auc:0.81002                                                                 \n",
      "[44]\tvalidation_0-auc:0.96783\tvalidation_1-auc:0.81005                                                                 \n",
      "[45]\tvalidation_0-auc:0.96896\tvalidation_1-auc:0.80987                                                                 \n",
      "[46]\tvalidation_0-auc:0.96905\tvalidation_1-auc:0.80980                                                                 \n",
      "[47]\tvalidation_0-auc:0.96910\tvalidation_1-auc:0.80958                                                                 \n",
      "[48]\tvalidation_0-auc:0.97112\tvalidation_1-auc:0.80903                                                                 \n",
      "[49]\tvalidation_0-auc:0.97193\tvalidation_1-auc:0.80857                                                                 \n",
      "[50]\tvalidation_0-auc:0.97247\tvalidation_1-auc:0.80817                                                                 \n",
      "[51]\tvalidation_0-auc:0.97335\tvalidation_1-auc:0.80798                                                                 \n",
      "[52]\tvalidation_0-auc:0.97365\tvalidation_1-auc:0.80798                                                                 \n",
      "[53]\tvalidation_0-auc:0.97384\tvalidation_1-auc:0.80766                                                                 \n",
      "[54]\tvalidation_0-auc:0.97406\tvalidation_1-auc:0.80772                                                                 \n",
      "[55]\tvalidation_0-auc:0.97411\tvalidation_1-auc:0.80740                                                                 \n",
      "[0]\tvalidation_0-auc:0.88611\tvalidation_1-auc:0.79572                                                                  \n",
      "[1]\tvalidation_0-auc:0.90013\tvalidation_1-auc:0.80638                                                                  \n",
      "[2]\tvalidation_0-auc:0.90515\tvalidation_1-auc:0.81919                                                                  \n",
      "[3]\tvalidation_0-auc:0.91496\tvalidation_1-auc:0.82248                                                                  \n",
      "[4]\tvalidation_0-auc:0.92096\tvalidation_1-auc:0.82478                                                                  \n",
      "[5]\tvalidation_0-auc:0.92452\tvalidation_1-auc:0.82454                                                                  \n",
      "[6]\tvalidation_0-auc:0.93108\tvalidation_1-auc:0.82432                                                                  \n",
      "[7]\tvalidation_0-auc:0.93465\tvalidation_1-auc:0.82390                                                                  \n",
      "[8]\tvalidation_0-auc:0.93791\tvalidation_1-auc:0.82503                                                                  \n",
      "[9]\tvalidation_0-auc:0.94098\tvalidation_1-auc:0.82571                                                                  \n",
      "[10]\tvalidation_0-auc:0.94331\tvalidation_1-auc:0.82562                                                                 \n",
      "[11]\tvalidation_0-auc:0.94508\tvalidation_1-auc:0.82615                                                                 \n",
      "[12]\tvalidation_0-auc:0.94752\tvalidation_1-auc:0.82627                                                                 \n",
      "[13]\tvalidation_0-auc:0.94953\tvalidation_1-auc:0.82651                                                                 \n",
      "[14]\tvalidation_0-auc:0.95111\tvalidation_1-auc:0.82702                                                                 \n",
      "[15]\tvalidation_0-auc:0.95238\tvalidation_1-auc:0.82682                                                                 \n",
      "[16]\tvalidation_0-auc:0.95334\tvalidation_1-auc:0.82685                                                                 \n",
      "[17]\tvalidation_0-auc:0.95455\tvalidation_1-auc:0.82671                                                                 \n",
      "[18]\tvalidation_0-auc:0.95645\tvalidation_1-auc:0.82678                                                                 \n",
      "[19]\tvalidation_0-auc:0.95757\tvalidation_1-auc:0.82591                                                                 \n",
      "[20]\tvalidation_0-auc:0.95834\tvalidation_1-auc:0.82581                                                                 \n",
      "[21]\tvalidation_0-auc:0.95901\tvalidation_1-auc:0.82578                                                                 \n",
      "[22]\tvalidation_0-auc:0.95948\tvalidation_1-auc:0.82574                                                                 \n",
      "[23]\tvalidation_0-auc:0.96006\tvalidation_1-auc:0.82544                                                                 \n",
      "[24]\tvalidation_0-auc:0.96029\tvalidation_1-auc:0.82531                                                                 \n",
      "[25]\tvalidation_0-auc:0.96110\tvalidation_1-auc:0.82530                                                                 \n",
      "[26]\tvalidation_0-auc:0.96208\tvalidation_1-auc:0.82527                                                                 \n",
      "[27]\tvalidation_0-auc:0.96277\tvalidation_1-auc:0.82489                                                                 \n",
      "[28]\tvalidation_0-auc:0.96328\tvalidation_1-auc:0.82459                                                                 \n",
      "[29]\tvalidation_0-auc:0.96362\tvalidation_1-auc:0.82430                                                                 \n",
      "[30]\tvalidation_0-auc:0.96499\tvalidation_1-auc:0.82422                                                                 \n",
      "[31]\tvalidation_0-auc:0.96589\tvalidation_1-auc:0.82457                                                                 \n",
      "[32]\tvalidation_0-auc:0.96631\tvalidation_1-auc:0.82458                                                                 \n",
      "[33]\tvalidation_0-auc:0.96648\tvalidation_1-auc:0.82429                                                                 \n",
      "[34]\tvalidation_0-auc:0.96659\tvalidation_1-auc:0.82430                                                                 \n",
      "[35]\tvalidation_0-auc:0.96666\tvalidation_1-auc:0.82402                                                                 \n",
      "[36]\tvalidation_0-auc:0.96678\tvalidation_1-auc:0.82336                                                                 \n",
      "[37]\tvalidation_0-auc:0.96706\tvalidation_1-auc:0.82309                                                                 \n",
      "[38]\tvalidation_0-auc:0.96771\tvalidation_1-auc:0.82254                                                                 \n",
      "[39]\tvalidation_0-auc:0.96795\tvalidation_1-auc:0.82218                                                                 \n",
      "[40]\tvalidation_0-auc:0.97002\tvalidation_1-auc:0.82158                                                                 \n",
      "[41]\tvalidation_0-auc:0.97018\tvalidation_1-auc:0.82111                                                                 \n",
      "[42]\tvalidation_0-auc:0.97026\tvalidation_1-auc:0.82096                                                                 \n",
      "[43]\tvalidation_0-auc:0.97044\tvalidation_1-auc:0.82067                                                                 \n",
      "[44]\tvalidation_0-auc:0.97100\tvalidation_1-auc:0.82063                                                                 \n",
      "[0]\tvalidation_0-auc:0.88550\tvalidation_1-auc:0.79823                                                                  \n",
      "[1]\tvalidation_0-auc:0.89851\tvalidation_1-auc:0.81447                                                                  \n",
      "[2]\tvalidation_0-auc:0.90591\tvalidation_1-auc:0.81931                                                                  \n",
      "[3]\tvalidation_0-auc:0.91153\tvalidation_1-auc:0.82239                                                                  \n",
      "[4]\tvalidation_0-auc:0.91724\tvalidation_1-auc:0.82552                                                                  \n",
      "[5]\tvalidation_0-auc:0.92207\tvalidation_1-auc:0.82460                                                                  \n",
      "[6]\tvalidation_0-auc:0.92578\tvalidation_1-auc:0.82407                                                                  \n",
      "[7]\tvalidation_0-auc:0.92964\tvalidation_1-auc:0.82460                                                                  \n",
      "[8]\tvalidation_0-auc:0.93431\tvalidation_1-auc:0.82478                                                                  \n",
      "[9]\tvalidation_0-auc:0.93695\tvalidation_1-auc:0.82533                                                                  \n",
      "[10]\tvalidation_0-auc:0.93993\tvalidation_1-auc:0.82395                                                                 \n",
      "[11]\tvalidation_0-auc:0.94291\tvalidation_1-auc:0.82429                                                                 \n",
      "[12]\tvalidation_0-auc:0.94530\tvalidation_1-auc:0.82473                                                                 \n",
      "[13]\tvalidation_0-auc:0.94805\tvalidation_1-auc:0.82546                                                                 \n",
      "[14]\tvalidation_0-auc:0.94988\tvalidation_1-auc:0.82504                                                                 \n",
      "[15]\tvalidation_0-auc:0.95142\tvalidation_1-auc:0.82599                                                                 \n",
      "[16]\tvalidation_0-auc:0.95260\tvalidation_1-auc:0.82653                                                                 \n",
      "[17]\tvalidation_0-auc:0.95424\tvalidation_1-auc:0.82632                                                                 \n",
      "[18]\tvalidation_0-auc:0.95569\tvalidation_1-auc:0.82658                                                                 \n",
      "[19]\tvalidation_0-auc:0.95653\tvalidation_1-auc:0.82707                                                                 \n",
      "[20]\tvalidation_0-auc:0.95730\tvalidation_1-auc:0.82736                                                                 \n",
      "[21]\tvalidation_0-auc:0.95832\tvalidation_1-auc:0.82696                                                                 \n",
      "[22]\tvalidation_0-auc:0.95903\tvalidation_1-auc:0.82704                                                                 \n",
      "[23]\tvalidation_0-auc:0.95990\tvalidation_1-auc:0.82745                                                                 \n",
      "[24]\tvalidation_0-auc:0.96055\tvalidation_1-auc:0.82734                                                                 \n",
      "[25]\tvalidation_0-auc:0.96107\tvalidation_1-auc:0.82737                                                                 \n",
      "[26]\tvalidation_0-auc:0.96193\tvalidation_1-auc:0.82722                                                                 \n",
      "[27]\tvalidation_0-auc:0.96315\tvalidation_1-auc:0.82662                                                                 \n",
      "[28]\tvalidation_0-auc:0.96365\tvalidation_1-auc:0.82680                                                                 \n",
      "[29]\tvalidation_0-auc:0.96443\tvalidation_1-auc:0.82632                                                                 \n",
      "[30]\tvalidation_0-auc:0.96534\tvalidation_1-auc:0.82613                                                                 \n",
      "[31]\tvalidation_0-auc:0.96754\tvalidation_1-auc:0.82606                                                                 \n",
      "[32]\tvalidation_0-auc:0.96804\tvalidation_1-auc:0.82607                                                                 \n",
      "[33]\tvalidation_0-auc:0.96836\tvalidation_1-auc:0.82618                                                                 \n",
      "[34]\tvalidation_0-auc:0.96976\tvalidation_1-auc:0.82539                                                                 \n",
      "[35]\tvalidation_0-auc:0.97069\tvalidation_1-auc:0.82499                                                                 \n",
      "[36]\tvalidation_0-auc:0.97095\tvalidation_1-auc:0.82521                                                                 \n",
      "[37]\tvalidation_0-auc:0.97125\tvalidation_1-auc:0.82528                                                                 \n",
      "[38]\tvalidation_0-auc:0.97159\tvalidation_1-auc:0.82526                                                                 \n",
      "[39]\tvalidation_0-auc:0.97217\tvalidation_1-auc:0.82517                                                                 \n",
      "[40]\tvalidation_0-auc:0.97230\tvalidation_1-auc:0.82518                                                                 \n",
      "[41]\tvalidation_0-auc:0.97257\tvalidation_1-auc:0.82535                                                                 \n",
      "[42]\tvalidation_0-auc:0.97294\tvalidation_1-auc:0.82483                                                                 \n",
      "[43]\tvalidation_0-auc:0.97299\tvalidation_1-auc:0.82479                                                                 \n",
      "[44]\tvalidation_0-auc:0.97305\tvalidation_1-auc:0.82479                                                                 \n",
      "[45]\tvalidation_0-auc:0.97521\tvalidation_1-auc:0.82511                                                                 \n",
      "[46]\tvalidation_0-auc:0.97545\tvalidation_1-auc:0.82483                                                                 \n",
      "[47]\tvalidation_0-auc:0.97578\tvalidation_1-auc:0.82498                                                                 \n",
      "[48]\tvalidation_0-auc:0.97590\tvalidation_1-auc:0.82532                                                                 \n",
      "[49]\tvalidation_0-auc:0.97643\tvalidation_1-auc:0.82515                                                                 \n",
      "[50]\tvalidation_0-auc:0.97650\tvalidation_1-auc:0.82507                                                                 \n",
      "[51]\tvalidation_0-auc:0.97655\tvalidation_1-auc:0.82506                                                                 \n",
      "[52]\tvalidation_0-auc:0.97662\tvalidation_1-auc:0.82496                                                                 \n",
      "[53]\tvalidation_0-auc:0.97702\tvalidation_1-auc:0.82477                                                                 \n",
      "[0]\tvalidation_0-auc:0.85285\tvalidation_1-auc:0.80536                                                                  \n",
      "[1]\tvalidation_0-auc:0.85977\tvalidation_1-auc:0.80071                                                                  \n",
      "[2]\tvalidation_0-auc:0.86472\tvalidation_1-auc:0.81218                                                                  \n",
      "[3]\tvalidation_0-auc:0.86041\tvalidation_1-auc:0.80764                                                                  \n",
      "[4]\tvalidation_0-auc:0.85811\tvalidation_1-auc:0.80302                                                                  \n",
      "[5]\tvalidation_0-auc:0.85843\tvalidation_1-auc:0.80516                                                                  \n",
      "[6]\tvalidation_0-auc:0.86366\tvalidation_1-auc:0.80975                                                                  \n",
      "[7]\tvalidation_0-auc:0.86350\tvalidation_1-auc:0.80751                                                                  \n",
      "[8]\tvalidation_0-auc:0.86697\tvalidation_1-auc:0.80979                                                                  \n",
      "[9]\tvalidation_0-auc:0.86642\tvalidation_1-auc:0.80749                                                                  \n",
      "[10]\tvalidation_0-auc:0.86831\tvalidation_1-auc:0.80941                                                                 \n",
      "[11]\tvalidation_0-auc:0.86799\tvalidation_1-auc:0.80867                                                                 \n",
      "[12]\tvalidation_0-auc:0.86810\tvalidation_1-auc:0.80769                                                                 \n",
      "[13]\tvalidation_0-auc:0.87043\tvalidation_1-auc:0.80949                                                                 \n",
      "[14]\tvalidation_0-auc:0.87024\tvalidation_1-auc:0.80872                                                                 \n",
      "[15]\tvalidation_0-auc:0.87250\tvalidation_1-auc:0.81062                                                                 \n",
      "[16]\tvalidation_0-auc:0.87440\tvalidation_1-auc:0.81215                                                                 \n",
      "[17]\tvalidation_0-auc:0.87414\tvalidation_1-auc:0.81137                                                                 \n",
      "[18]\tvalidation_0-auc:0.87398\tvalidation_1-auc:0.81038                                                                 \n",
      "[19]\tvalidation_0-auc:0.87562\tvalidation_1-auc:0.81210                                                                 \n",
      "[20]\tvalidation_0-auc:0.87750\tvalidation_1-auc:0.81324                                                                 \n",
      "[21]\tvalidation_0-auc:0.87847\tvalidation_1-auc:0.81409                                                                 \n",
      "[22]\tvalidation_0-auc:0.87964\tvalidation_1-auc:0.81504                                                                 \n",
      "[23]\tvalidation_0-auc:0.88061\tvalidation_1-auc:0.81586                                                                 \n",
      "[24]\tvalidation_0-auc:0.88176\tvalidation_1-auc:0.81662                                                                 \n",
      "[25]\tvalidation_0-auc:0.88262\tvalidation_1-auc:0.81727                                                                 \n",
      "[26]\tvalidation_0-auc:0.88269\tvalidation_1-auc:0.81650                                                                 \n",
      "[27]\tvalidation_0-auc:0.88251\tvalidation_1-auc:0.81590                                                                 \n",
      "[28]\tvalidation_0-auc:0.88392\tvalidation_1-auc:0.81672                                                                 \n",
      "[29]\tvalidation_0-auc:0.88374\tvalidation_1-auc:0.81617                                                                 \n",
      "[30]\tvalidation_0-auc:0.88392\tvalidation_1-auc:0.81605                                                                 \n",
      "[31]\tvalidation_0-auc:0.88398\tvalidation_1-auc:0.81567                                                                 \n",
      "[32]\tvalidation_0-auc:0.88531\tvalidation_1-auc:0.81612                                                                 \n",
      "[33]\tvalidation_0-auc:0.88635\tvalidation_1-auc:0.81669                                                                 \n",
      "[34]\tvalidation_0-auc:0.88736\tvalidation_1-auc:0.81740                                                                 \n",
      "[35]\tvalidation_0-auc:0.88845\tvalidation_1-auc:0.81811                                                                 \n",
      "[36]\tvalidation_0-auc:0.88938\tvalidation_1-auc:0.81859                                                                 \n",
      "[37]\tvalidation_0-auc:0.89006\tvalidation_1-auc:0.81910                                                                 \n",
      "[38]\tvalidation_0-auc:0.89065\tvalidation_1-auc:0.81951                                                                 \n",
      "[39]\tvalidation_0-auc:0.89129\tvalidation_1-auc:0.81977                                                                 \n",
      "[40]\tvalidation_0-auc:0.89152\tvalidation_1-auc:0.81944                                                                 \n",
      "[41]\tvalidation_0-auc:0.89231\tvalidation_1-auc:0.81969                                                                 \n",
      "[42]\tvalidation_0-auc:0.89220\tvalidation_1-auc:0.81934                                                                 \n",
      "[43]\tvalidation_0-auc:0.89231\tvalidation_1-auc:0.81900                                                                 \n",
      "[44]\tvalidation_0-auc:0.89224\tvalidation_1-auc:0.81874                                                                 \n",
      "[45]\tvalidation_0-auc:0.89286\tvalidation_1-auc:0.81906                                                                 \n",
      "[46]\tvalidation_0-auc:0.89306\tvalidation_1-auc:0.81879                                                                 \n",
      "[47]\tvalidation_0-auc:0.89334\tvalidation_1-auc:0.81859                                                                 \n",
      "[48]\tvalidation_0-auc:0.89340\tvalidation_1-auc:0.81833                                                                 \n",
      "[49]\tvalidation_0-auc:0.89357\tvalidation_1-auc:0.81794                                                                 \n",
      "[50]\tvalidation_0-auc:0.89422\tvalidation_1-auc:0.81850                                                                 \n",
      "[51]\tvalidation_0-auc:0.89470\tvalidation_1-auc:0.81895                                                                 \n",
      "[52]\tvalidation_0-auc:0.89495\tvalidation_1-auc:0.81871                                                                 \n",
      "[53]\tvalidation_0-auc:0.89544\tvalidation_1-auc:0.81913                                                                 \n",
      "[54]\tvalidation_0-auc:0.89575\tvalidation_1-auc:0.81874                                                                 \n",
      "[55]\tvalidation_0-auc:0.89614\tvalidation_1-auc:0.81912                                                                 \n",
      "[56]\tvalidation_0-auc:0.89652\tvalidation_1-auc:0.81940                                                                 \n",
      "[57]\tvalidation_0-auc:0.89670\tvalidation_1-auc:0.81922                                                                 \n",
      "[58]\tvalidation_0-auc:0.89732\tvalidation_1-auc:0.81952                                                                 \n",
      "[59]\tvalidation_0-auc:0.89786\tvalidation_1-auc:0.81973                                                                 \n",
      "[60]\tvalidation_0-auc:0.89800\tvalidation_1-auc:0.81958                                                                 \n",
      "[61]\tvalidation_0-auc:0.89844\tvalidation_1-auc:0.81966                                                                 \n",
      "[62]\tvalidation_0-auc:0.89865\tvalidation_1-auc:0.81956                                                                 \n",
      "[63]\tvalidation_0-auc:0.89885\tvalidation_1-auc:0.81943                                                                 \n",
      "[64]\tvalidation_0-auc:0.89917\tvalidation_1-auc:0.81962                                                                 \n",
      "[65]\tvalidation_0-auc:0.89961\tvalidation_1-auc:0.81995                                                                 \n",
      "[66]\tvalidation_0-auc:0.89981\tvalidation_1-auc:0.81995                                                                 \n",
      "[67]\tvalidation_0-auc:0.90006\tvalidation_1-auc:0.82016                                                                 \n",
      "[68]\tvalidation_0-auc:0.90033\tvalidation_1-auc:0.82011                                                                 \n",
      "[69]\tvalidation_0-auc:0.90056\tvalidation_1-auc:0.82028                                                                 \n",
      "[70]\tvalidation_0-auc:0.90090\tvalidation_1-auc:0.82026                                                                 \n",
      "[71]\tvalidation_0-auc:0.90103\tvalidation_1-auc:0.82011                                                                 \n",
      "[72]\tvalidation_0-auc:0.90155\tvalidation_1-auc:0.82032                                                                 \n",
      "[73]\tvalidation_0-auc:0.90178\tvalidation_1-auc:0.82023                                                                 \n",
      "[74]\tvalidation_0-auc:0.90222\tvalidation_1-auc:0.82042                                                                 \n",
      "[75]\tvalidation_0-auc:0.90236\tvalidation_1-auc:0.82060                                                                 \n",
      "[76]\tvalidation_0-auc:0.90254\tvalidation_1-auc:0.82080                                                                 \n",
      "[77]\tvalidation_0-auc:0.90267\tvalidation_1-auc:0.82116                                                                 \n",
      "[78]\tvalidation_0-auc:0.90280\tvalidation_1-auc:0.82143                                                                 \n",
      "[79]\tvalidation_0-auc:0.90299\tvalidation_1-auc:0.82131                                                                 \n",
      "[80]\tvalidation_0-auc:0.90310\tvalidation_1-auc:0.82111                                                                 \n",
      "[81]\tvalidation_0-auc:0.90340\tvalidation_1-auc:0.82136                                                                 \n",
      "[82]\tvalidation_0-auc:0.90351\tvalidation_1-auc:0.82112                                                                 \n",
      "[83]\tvalidation_0-auc:0.90378\tvalidation_1-auc:0.82112                                                                 \n",
      "[84]\tvalidation_0-auc:0.90394\tvalidation_1-auc:0.82121                                                                 \n",
      "[85]\tvalidation_0-auc:0.90435\tvalidation_1-auc:0.82125                                                                 \n",
      "[86]\tvalidation_0-auc:0.90449\tvalidation_1-auc:0.82144                                                                 \n",
      "[87]\tvalidation_0-auc:0.90470\tvalidation_1-auc:0.82135                                                                 \n",
      "[88]\tvalidation_0-auc:0.90480\tvalidation_1-auc:0.82154                                                                 \n",
      "[89]\tvalidation_0-auc:0.90499\tvalidation_1-auc:0.82161                                                                 \n",
      "[90]\tvalidation_0-auc:0.90516\tvalidation_1-auc:0.82171                                                                 \n",
      "[91]\tvalidation_0-auc:0.90530\tvalidation_1-auc:0.82165                                                                 \n",
      "[92]\tvalidation_0-auc:0.90541\tvalidation_1-auc:0.82194                                                                 \n",
      "[93]\tvalidation_0-auc:0.90578\tvalidation_1-auc:0.82194                                                                 \n",
      "[94]\tvalidation_0-auc:0.90587\tvalidation_1-auc:0.82192                                                                 \n",
      "[95]\tvalidation_0-auc:0.90609\tvalidation_1-auc:0.82191                                                                 \n",
      "[96]\tvalidation_0-auc:0.90619\tvalidation_1-auc:0.82195                                                                 \n",
      "[97]\tvalidation_0-auc:0.90626\tvalidation_1-auc:0.82214                                                                 \n",
      "[98]\tvalidation_0-auc:0.90639\tvalidation_1-auc:0.82225                                                                 \n",
      "[99]\tvalidation_0-auc:0.90670\tvalidation_1-auc:0.82227                                                                 \n",
      "[0]\tvalidation_0-auc:0.84465\tvalidation_1-auc:0.81336                                                                  \n",
      "[1]\tvalidation_0-auc:0.85166\tvalidation_1-auc:0.82066                                                                  \n",
      "[2]\tvalidation_0-auc:0.85883\tvalidation_1-auc:0.83174                                                                  \n",
      "[3]\tvalidation_0-auc:0.85510\tvalidation_1-auc:0.83154                                                                  \n",
      "[4]\tvalidation_0-auc:0.85196\tvalidation_1-auc:0.82872                                                                  \n",
      "[5]\tvalidation_0-auc:0.85239\tvalidation_1-auc:0.82674                                                                  \n",
      "[6]\tvalidation_0-auc:0.85970\tvalidation_1-auc:0.83204                                                                  \n",
      "[7]\tvalidation_0-auc:0.85955\tvalidation_1-auc:0.82965                                                                  \n",
      "[8]\tvalidation_0-auc:0.86425\tvalidation_1-auc:0.83380                                                                  \n",
      "[9]\tvalidation_0-auc:0.86255\tvalidation_1-auc:0.83276                                                                  \n",
      "[10]\tvalidation_0-auc:0.86551\tvalidation_1-auc:0.83634                                                                 \n",
      "[11]\tvalidation_0-auc:0.86514\tvalidation_1-auc:0.83551                                                                 \n",
      "[12]\tvalidation_0-auc:0.86526\tvalidation_1-auc:0.83365                                                                 \n",
      "[13]\tvalidation_0-auc:0.86836\tvalidation_1-auc:0.83610                                                                 \n",
      "[14]\tvalidation_0-auc:0.86809\tvalidation_1-auc:0.83547                                                                 \n",
      "[15]\tvalidation_0-auc:0.87072\tvalidation_1-auc:0.83681                                                                 \n",
      "[16]\tvalidation_0-auc:0.87315\tvalidation_1-auc:0.83805                                                                 \n",
      "[17]\tvalidation_0-auc:0.87289\tvalidation_1-auc:0.83704                                                                 \n",
      "[18]\tvalidation_0-auc:0.87302\tvalidation_1-auc:0.83636                                                                 \n",
      "[19]\tvalidation_0-auc:0.87459\tvalidation_1-auc:0.83759                                                                 \n",
      "[20]\tvalidation_0-auc:0.87724\tvalidation_1-auc:0.83813                                                                 \n",
      "[21]\tvalidation_0-auc:0.87871\tvalidation_1-auc:0.83851                                                                 \n",
      "[22]\tvalidation_0-auc:0.87994\tvalidation_1-auc:0.83921                                                                 \n",
      "[23]\tvalidation_0-auc:0.88104\tvalidation_1-auc:0.84046                                                                 \n",
      "[24]\tvalidation_0-auc:0.88198\tvalidation_1-auc:0.84090                                                                 \n",
      "[25]\tvalidation_0-auc:0.88325\tvalidation_1-auc:0.84154                                                                 \n",
      "[26]\tvalidation_0-auc:0.88322\tvalidation_1-auc:0.84129                                                                 \n",
      "[27]\tvalidation_0-auc:0.88286\tvalidation_1-auc:0.84113                                                                 \n",
      "[28]\tvalidation_0-auc:0.88392\tvalidation_1-auc:0.84175                                                                 \n",
      "[29]\tvalidation_0-auc:0.88370\tvalidation_1-auc:0.84198                                                                 \n",
      "[30]\tvalidation_0-auc:0.88405\tvalidation_1-auc:0.84175                                                                 \n",
      "[31]\tvalidation_0-auc:0.88415\tvalidation_1-auc:0.84157                                                                 \n",
      "[32]\tvalidation_0-auc:0.88569\tvalidation_1-auc:0.84165                                                                 \n",
      "[33]\tvalidation_0-auc:0.88664\tvalidation_1-auc:0.84210                                                                 \n",
      "[34]\tvalidation_0-auc:0.88755\tvalidation_1-auc:0.84215                                                                 \n",
      "[35]\tvalidation_0-auc:0.88836\tvalidation_1-auc:0.84193                                                                 \n",
      "[36]\tvalidation_0-auc:0.88913\tvalidation_1-auc:0.84187                                                                 \n",
      "[37]\tvalidation_0-auc:0.89005\tvalidation_1-auc:0.84177                                                                 \n",
      "[38]\tvalidation_0-auc:0.89048\tvalidation_1-auc:0.84208                                                                 \n",
      "[39]\tvalidation_0-auc:0.89131\tvalidation_1-auc:0.84238                                                                 \n",
      "[40]\tvalidation_0-auc:0.89172\tvalidation_1-auc:0.84217                                                                 \n",
      "[41]\tvalidation_0-auc:0.89242\tvalidation_1-auc:0.84219                                                                 \n",
      "[42]\tvalidation_0-auc:0.89232\tvalidation_1-auc:0.84240                                                                 \n",
      "[43]\tvalidation_0-auc:0.89245\tvalidation_1-auc:0.84235                                                                 \n",
      "[44]\tvalidation_0-auc:0.89254\tvalidation_1-auc:0.84251                                                                 \n",
      "[45]\tvalidation_0-auc:0.89317\tvalidation_1-auc:0.84246                                                                 \n",
      "[46]\tvalidation_0-auc:0.89337\tvalidation_1-auc:0.84272                                                                 \n",
      "[47]\tvalidation_0-auc:0.89384\tvalidation_1-auc:0.84290                                                                 \n",
      "[48]\tvalidation_0-auc:0.89376\tvalidation_1-auc:0.84271                                                                 \n",
      "[49]\tvalidation_0-auc:0.89385\tvalidation_1-auc:0.84291                                                                 \n",
      "[50]\tvalidation_0-auc:0.89462\tvalidation_1-auc:0.84314                                                                 \n",
      "[51]\tvalidation_0-auc:0.89538\tvalidation_1-auc:0.84322                                                                 \n",
      "[52]\tvalidation_0-auc:0.89554\tvalidation_1-auc:0.84341                                                                 \n",
      "[53]\tvalidation_0-auc:0.89601\tvalidation_1-auc:0.84335                                                                 \n",
      "[54]\tvalidation_0-auc:0.89639\tvalidation_1-auc:0.84328                                                                 \n",
      "[55]\tvalidation_0-auc:0.89676\tvalidation_1-auc:0.84353                                                                 \n",
      "[56]\tvalidation_0-auc:0.89729\tvalidation_1-auc:0.84349                                                                 \n",
      "[57]\tvalidation_0-auc:0.89762\tvalidation_1-auc:0.84359                                                                 \n",
      "[58]\tvalidation_0-auc:0.89807\tvalidation_1-auc:0.84360                                                                 \n",
      "[59]\tvalidation_0-auc:0.89842\tvalidation_1-auc:0.84358                                                                 \n",
      "[60]\tvalidation_0-auc:0.89840\tvalidation_1-auc:0.84361                                                                 \n",
      "[61]\tvalidation_0-auc:0.89886\tvalidation_1-auc:0.84357                                                                 \n",
      "[62]\tvalidation_0-auc:0.89922\tvalidation_1-auc:0.84353                                                                 \n",
      "[63]\tvalidation_0-auc:0.89961\tvalidation_1-auc:0.84341                                                                 \n",
      "[64]\tvalidation_0-auc:0.89995\tvalidation_1-auc:0.84355                                                                 \n",
      "[65]\tvalidation_0-auc:0.90034\tvalidation_1-auc:0.84366                                                                 \n",
      "[66]\tvalidation_0-auc:0.90065\tvalidation_1-auc:0.84367                                                                 \n",
      "[67]\tvalidation_0-auc:0.90091\tvalidation_1-auc:0.84371                                                                 \n",
      "[68]\tvalidation_0-auc:0.90124\tvalidation_1-auc:0.84386                                                                 \n",
      "[69]\tvalidation_0-auc:0.90141\tvalidation_1-auc:0.84400                                                                 \n",
      "[70]\tvalidation_0-auc:0.90179\tvalidation_1-auc:0.84417                                                                 \n",
      "[71]\tvalidation_0-auc:0.90217\tvalidation_1-auc:0.84428                                                                 \n",
      "[72]\tvalidation_0-auc:0.90260\tvalidation_1-auc:0.84436                                                                 \n",
      "[73]\tvalidation_0-auc:0.90293\tvalidation_1-auc:0.84408                                                                 \n",
      "[74]\tvalidation_0-auc:0.90337\tvalidation_1-auc:0.84415                                                                 \n",
      "[75]\tvalidation_0-auc:0.90354\tvalidation_1-auc:0.84421                                                                 \n",
      "[76]\tvalidation_0-auc:0.90361\tvalidation_1-auc:0.84424                                                                 \n",
      "[77]\tvalidation_0-auc:0.90370\tvalidation_1-auc:0.84413                                                                 \n",
      "[78]\tvalidation_0-auc:0.90382\tvalidation_1-auc:0.84413                                                                 \n",
      "[79]\tvalidation_0-auc:0.90408\tvalidation_1-auc:0.84422                                                                 \n",
      "[80]\tvalidation_0-auc:0.90420\tvalidation_1-auc:0.84435                                                                 \n",
      "[81]\tvalidation_0-auc:0.90444\tvalidation_1-auc:0.84442                                                                 \n",
      "[82]\tvalidation_0-auc:0.90450\tvalidation_1-auc:0.84444                                                                 \n",
      "[83]\tvalidation_0-auc:0.90484\tvalidation_1-auc:0.84449                                                                 \n",
      "[84]\tvalidation_0-auc:0.90499\tvalidation_1-auc:0.84448                                                                 \n",
      "[85]\tvalidation_0-auc:0.90537\tvalidation_1-auc:0.84446                                                                 \n",
      "[86]\tvalidation_0-auc:0.90555\tvalidation_1-auc:0.84452                                                                 \n",
      "[87]\tvalidation_0-auc:0.90566\tvalidation_1-auc:0.84457                                                                 \n",
      "[88]\tvalidation_0-auc:0.90573\tvalidation_1-auc:0.84456                                                                 \n",
      "[89]\tvalidation_0-auc:0.90619\tvalidation_1-auc:0.84464                                                                 \n",
      "[90]\tvalidation_0-auc:0.90627\tvalidation_1-auc:0.84463                                                                 \n",
      "[91]\tvalidation_0-auc:0.90639\tvalidation_1-auc:0.84454                                                                 \n",
      "[92]\tvalidation_0-auc:0.90650\tvalidation_1-auc:0.84445                                                                 \n",
      "[93]\tvalidation_0-auc:0.90674\tvalidation_1-auc:0.84442                                                                 \n",
      "[94]\tvalidation_0-auc:0.90679\tvalidation_1-auc:0.84437                                                                 \n",
      "[95]\tvalidation_0-auc:0.90719\tvalidation_1-auc:0.84442                                                                 \n",
      "[96]\tvalidation_0-auc:0.90759\tvalidation_1-auc:0.84439                                                                 \n",
      "[97]\tvalidation_0-auc:0.90766\tvalidation_1-auc:0.84441                                                                 \n",
      "[98]\tvalidation_0-auc:0.90775\tvalidation_1-auc:0.84430                                                                 \n",
      "[99]\tvalidation_0-auc:0.90787\tvalidation_1-auc:0.84431                                                                 \n",
      "[0]\tvalidation_0-auc:0.84570\tvalidation_1-auc:0.81279                                                                  \n",
      "[1]\tvalidation_0-auc:0.85189\tvalidation_1-auc:0.80966                                                                  \n",
      "[2]\tvalidation_0-auc:0.85616\tvalidation_1-auc:0.81722                                                                  \n",
      "[3]\tvalidation_0-auc:0.85308\tvalidation_1-auc:0.81273                                                                  \n",
      "[4]\tvalidation_0-auc:0.85201\tvalidation_1-auc:0.80889                                                                  \n",
      "[5]\tvalidation_0-auc:0.85226\tvalidation_1-auc:0.80663                                                                  \n",
      "[6]\tvalidation_0-auc:0.85788\tvalidation_1-auc:0.81376                                                                  \n",
      "[7]\tvalidation_0-auc:0.85776\tvalidation_1-auc:0.81233                                                                  \n",
      "[8]\tvalidation_0-auc:0.86305\tvalidation_1-auc:0.81744                                                                  \n",
      "[9]\tvalidation_0-auc:0.86226\tvalidation_1-auc:0.81567                                                                  \n",
      "[10]\tvalidation_0-auc:0.86499\tvalidation_1-auc:0.81937                                                                 \n",
      "[11]\tvalidation_0-auc:0.86499\tvalidation_1-auc:0.81779                                                                 \n",
      "[12]\tvalidation_0-auc:0.86498\tvalidation_1-auc:0.81678                                                                 \n",
      "[13]\tvalidation_0-auc:0.86812\tvalidation_1-auc:0.82015                                                                 \n",
      "[14]\tvalidation_0-auc:0.86823\tvalidation_1-auc:0.81880                                                                 \n",
      "[15]\tvalidation_0-auc:0.87073\tvalidation_1-auc:0.82097                                                                 \n",
      "[16]\tvalidation_0-auc:0.87290\tvalidation_1-auc:0.82265                                                                 \n",
      "[17]\tvalidation_0-auc:0.87265\tvalidation_1-auc:0.82198                                                                 \n",
      "[18]\tvalidation_0-auc:0.87304\tvalidation_1-auc:0.82079                                                                 \n",
      "[19]\tvalidation_0-auc:0.87462\tvalidation_1-auc:0.82242                                                                 \n",
      "[20]\tvalidation_0-auc:0.87629\tvalidation_1-auc:0.82384                                                                 \n",
      "[21]\tvalidation_0-auc:0.87770\tvalidation_1-auc:0.82531                                                                 \n",
      "[22]\tvalidation_0-auc:0.87882\tvalidation_1-auc:0.82605                                                                 \n",
      "[23]\tvalidation_0-auc:0.87978\tvalidation_1-auc:0.82746                                                                 \n",
      "[24]\tvalidation_0-auc:0.88074\tvalidation_1-auc:0.82825                                                                 \n",
      "[25]\tvalidation_0-auc:0.88178\tvalidation_1-auc:0.82877                                                                 \n",
      "[26]\tvalidation_0-auc:0.88186\tvalidation_1-auc:0.82861                                                                 \n",
      "[27]\tvalidation_0-auc:0.88171\tvalidation_1-auc:0.82823                                                                 \n",
      "[28]\tvalidation_0-auc:0.88256\tvalidation_1-auc:0.82901                                                                 \n",
      "[29]\tvalidation_0-auc:0.88263\tvalidation_1-auc:0.82826                                                                 \n",
      "[30]\tvalidation_0-auc:0.88284\tvalidation_1-auc:0.82763                                                                 \n",
      "[31]\tvalidation_0-auc:0.88309\tvalidation_1-auc:0.82735                                                                 \n",
      "[32]\tvalidation_0-auc:0.88428\tvalidation_1-auc:0.82846                                                                 \n",
      "[33]\tvalidation_0-auc:0.88504\tvalidation_1-auc:0.82906                                                                 \n",
      "[34]\tvalidation_0-auc:0.88590\tvalidation_1-auc:0.82933                                                                 \n",
      "[35]\tvalidation_0-auc:0.88703\tvalidation_1-auc:0.82987                                                                 \n",
      "[36]\tvalidation_0-auc:0.88796\tvalidation_1-auc:0.83055                                                                 \n",
      "[37]\tvalidation_0-auc:0.88881\tvalidation_1-auc:0.83089                                                                 \n",
      "[38]\tvalidation_0-auc:0.88948\tvalidation_1-auc:0.83122                                                                 \n",
      "[39]\tvalidation_0-auc:0.89013\tvalidation_1-auc:0.83155                                                                 \n",
      "[40]\tvalidation_0-auc:0.89047\tvalidation_1-auc:0.83162                                                                 \n",
      "[41]\tvalidation_0-auc:0.89111\tvalidation_1-auc:0.83208                                                                 \n",
      "[42]\tvalidation_0-auc:0.89151\tvalidation_1-auc:0.83200                                                                 \n",
      "[43]\tvalidation_0-auc:0.89208\tvalidation_1-auc:0.83178                                                                 \n",
      "[44]\tvalidation_0-auc:0.89211\tvalidation_1-auc:0.83165                                                                 \n",
      "[45]\tvalidation_0-auc:0.89267\tvalidation_1-auc:0.83190                                                                 \n",
      "[46]\tvalidation_0-auc:0.89314\tvalidation_1-auc:0.83160                                                                 \n",
      "[47]\tvalidation_0-auc:0.89355\tvalidation_1-auc:0.83149                                                                 \n",
      "[48]\tvalidation_0-auc:0.89376\tvalidation_1-auc:0.83132                                                                 \n",
      "[49]\tvalidation_0-auc:0.89431\tvalidation_1-auc:0.83109                                                                 \n",
      "[50]\tvalidation_0-auc:0.89504\tvalidation_1-auc:0.83155                                                                 \n",
      "[51]\tvalidation_0-auc:0.89582\tvalidation_1-auc:0.83206                                                                 \n",
      "[52]\tvalidation_0-auc:0.89598\tvalidation_1-auc:0.83201                                                                 \n",
      "[53]\tvalidation_0-auc:0.89643\tvalidation_1-auc:0.83235                                                                 \n",
      "[54]\tvalidation_0-auc:0.89667\tvalidation_1-auc:0.83216                                                                 \n",
      "[55]\tvalidation_0-auc:0.89714\tvalidation_1-auc:0.83265                                                                 \n",
      "[56]\tvalidation_0-auc:0.89759\tvalidation_1-auc:0.83320                                                                 \n",
      "[57]\tvalidation_0-auc:0.89783\tvalidation_1-auc:0.83316                                                                 \n",
      "[58]\tvalidation_0-auc:0.89834\tvalidation_1-auc:0.83339                                                                 \n",
      "[59]\tvalidation_0-auc:0.89877\tvalidation_1-auc:0.83370                                                                 \n",
      "[60]\tvalidation_0-auc:0.89901\tvalidation_1-auc:0.83364                                                                 \n",
      "[61]\tvalidation_0-auc:0.89959\tvalidation_1-auc:0.83380                                                                 \n",
      "[62]\tvalidation_0-auc:0.89972\tvalidation_1-auc:0.83369                                                                 \n",
      "[63]\tvalidation_0-auc:0.90022\tvalidation_1-auc:0.83348                                                                 \n",
      "[64]\tvalidation_0-auc:0.90085\tvalidation_1-auc:0.83374                                                                 \n",
      "[65]\tvalidation_0-auc:0.90121\tvalidation_1-auc:0.83390                                                                 \n",
      "[66]\tvalidation_0-auc:0.90137\tvalidation_1-auc:0.83374                                                                 \n",
      "[67]\tvalidation_0-auc:0.90157\tvalidation_1-auc:0.83410                                                                 \n",
      "[68]\tvalidation_0-auc:0.90211\tvalidation_1-auc:0.83425                                                                 \n",
      "[69]\tvalidation_0-auc:0.90239\tvalidation_1-auc:0.83462                                                                 \n",
      "[70]\tvalidation_0-auc:0.90274\tvalidation_1-auc:0.83492                                                                 \n",
      "[71]\tvalidation_0-auc:0.90280\tvalidation_1-auc:0.83466                                                                 \n",
      "[72]\tvalidation_0-auc:0.90318\tvalidation_1-auc:0.83473                                                                 \n",
      "[73]\tvalidation_0-auc:0.90363\tvalidation_1-auc:0.83460                                                                 \n",
      "[74]\tvalidation_0-auc:0.90406\tvalidation_1-auc:0.83484                                                                 \n",
      "[75]\tvalidation_0-auc:0.90428\tvalidation_1-auc:0.83515                                                                 \n",
      "[76]\tvalidation_0-auc:0.90452\tvalidation_1-auc:0.83551                                                                 \n",
      "[77]\tvalidation_0-auc:0.90482\tvalidation_1-auc:0.83568                                                                 \n",
      "[78]\tvalidation_0-auc:0.90497\tvalidation_1-auc:0.83587                                                                 \n",
      "[79]\tvalidation_0-auc:0.90509\tvalidation_1-auc:0.83590                                                                 \n",
      "[80]\tvalidation_0-auc:0.90537\tvalidation_1-auc:0.83569                                                                 \n",
      "[81]\tvalidation_0-auc:0.90565\tvalidation_1-auc:0.83582                                                                 \n",
      "[82]\tvalidation_0-auc:0.90577\tvalidation_1-auc:0.83574                                                                 \n",
      "[83]\tvalidation_0-auc:0.90610\tvalidation_1-auc:0.83599                                                                 \n",
      "[84]\tvalidation_0-auc:0.90629\tvalidation_1-auc:0.83615                                                                 \n",
      "[85]\tvalidation_0-auc:0.90647\tvalidation_1-auc:0.83630                                                                 \n",
      "[86]\tvalidation_0-auc:0.90664\tvalidation_1-auc:0.83656                                                                 \n",
      "[87]\tvalidation_0-auc:0.90681\tvalidation_1-auc:0.83654                                                                 \n",
      "[88]\tvalidation_0-auc:0.90699\tvalidation_1-auc:0.83665                                                                 \n",
      "[89]\tvalidation_0-auc:0.90715\tvalidation_1-auc:0.83691                                                                 \n",
      "[90]\tvalidation_0-auc:0.90730\tvalidation_1-auc:0.83705                                                                 \n",
      "[91]\tvalidation_0-auc:0.90766\tvalidation_1-auc:0.83715                                                                 \n",
      "[92]\tvalidation_0-auc:0.90806\tvalidation_1-auc:0.83726                                                                 \n",
      "[93]\tvalidation_0-auc:0.90858\tvalidation_1-auc:0.83731                                                                 \n",
      "[94]\tvalidation_0-auc:0.90873\tvalidation_1-auc:0.83730                                                                 \n",
      "[95]\tvalidation_0-auc:0.90890\tvalidation_1-auc:0.83755                                                                 \n",
      "[96]\tvalidation_0-auc:0.90918\tvalidation_1-auc:0.83769                                                                 \n",
      "[97]\tvalidation_0-auc:0.90935\tvalidation_1-auc:0.83780                                                                 \n",
      "[98]\tvalidation_0-auc:0.90978\tvalidation_1-auc:0.83801                                                                 \n",
      "[99]\tvalidation_0-auc:0.91001\tvalidation_1-auc:0.83800                                                                 \n",
      "[0]\tvalidation_0-auc:0.87757\tvalidation_1-auc:0.79052                                                                  \n",
      "[1]\tvalidation_0-auc:0.88394\tvalidation_1-auc:0.80195                                                                  \n",
      "[2]\tvalidation_0-auc:0.88636\tvalidation_1-auc:0.81235                                                                  \n",
      "[3]\tvalidation_0-auc:0.88957\tvalidation_1-auc:0.81228                                                                  \n",
      "[4]\tvalidation_0-auc:0.89054\tvalidation_1-auc:0.81250                                                                  \n",
      "[5]\tvalidation_0-auc:0.89304\tvalidation_1-auc:0.81185                                                                  \n",
      "[6]\tvalidation_0-auc:0.89682\tvalidation_1-auc:0.81390                                                                  \n",
      "[7]\tvalidation_0-auc:0.89858\tvalidation_1-auc:0.81476                                                                  \n",
      "[8]\tvalidation_0-auc:0.90071\tvalidation_1-auc:0.81433                                                                  \n",
      "[9]\tvalidation_0-auc:0.90336\tvalidation_1-auc:0.81427                                                                  \n",
      "[10]\tvalidation_0-auc:0.90474\tvalidation_1-auc:0.81505                                                                 \n",
      "[11]\tvalidation_0-auc:0.90612\tvalidation_1-auc:0.81560                                                                 \n",
      "[12]\tvalidation_0-auc:0.90734\tvalidation_1-auc:0.81539                                                                 \n",
      "[13]\tvalidation_0-auc:0.90927\tvalidation_1-auc:0.81572                                                                 \n",
      "[14]\tvalidation_0-auc:0.91039\tvalidation_1-auc:0.81653                                                                 \n",
      "[15]\tvalidation_0-auc:0.91159\tvalidation_1-auc:0.81645                                                                 \n",
      "[16]\tvalidation_0-auc:0.91241\tvalidation_1-auc:0.81723                                                                 \n",
      "[17]\tvalidation_0-auc:0.91344\tvalidation_1-auc:0.81656                                                                 \n",
      "[18]\tvalidation_0-auc:0.91461\tvalidation_1-auc:0.81680                                                                 \n",
      "[19]\tvalidation_0-auc:0.91563\tvalidation_1-auc:0.81692                                                                 \n",
      "[20]\tvalidation_0-auc:0.91684\tvalidation_1-auc:0.81720                                                                 \n",
      "[21]\tvalidation_0-auc:0.91816\tvalidation_1-auc:0.81734                                                                 \n",
      "[22]\tvalidation_0-auc:0.91943\tvalidation_1-auc:0.81768                                                                 \n",
      "[23]\tvalidation_0-auc:0.91995\tvalidation_1-auc:0.81794                                                                 \n",
      "[24]\tvalidation_0-auc:0.92073\tvalidation_1-auc:0.81778                                                                 \n",
      "[25]\tvalidation_0-auc:0.92176\tvalidation_1-auc:0.81751                                                                 \n",
      "[26]\tvalidation_0-auc:0.92256\tvalidation_1-auc:0.81746                                                                 \n",
      "[27]\tvalidation_0-auc:0.92325\tvalidation_1-auc:0.81760                                                                 \n",
      "[28]\tvalidation_0-auc:0.92380\tvalidation_1-auc:0.81779                                                                 \n",
      "[29]\tvalidation_0-auc:0.92444\tvalidation_1-auc:0.81767                                                                 \n",
      "[30]\tvalidation_0-auc:0.92532\tvalidation_1-auc:0.81693                                                                 \n",
      "[31]\tvalidation_0-auc:0.92613\tvalidation_1-auc:0.81701                                                                 \n",
      "[32]\tvalidation_0-auc:0.92685\tvalidation_1-auc:0.81699                                                                 \n",
      "[33]\tvalidation_0-auc:0.92743\tvalidation_1-auc:0.81702                                                                 \n",
      "[34]\tvalidation_0-auc:0.92790\tvalidation_1-auc:0.81699                                                                 \n",
      "[35]\tvalidation_0-auc:0.92844\tvalidation_1-auc:0.81693                                                                 \n",
      "[36]\tvalidation_0-auc:0.92902\tvalidation_1-auc:0.81679                                                                 \n",
      "[37]\tvalidation_0-auc:0.92961\tvalidation_1-auc:0.81654                                                                 \n",
      "[38]\tvalidation_0-auc:0.93014\tvalidation_1-auc:0.81653                                                                 \n",
      "[39]\tvalidation_0-auc:0.93078\tvalidation_1-auc:0.81641                                                                 \n",
      "[40]\tvalidation_0-auc:0.93139\tvalidation_1-auc:0.81639                                                                 \n",
      "[41]\tvalidation_0-auc:0.93222\tvalidation_1-auc:0.81629                                                                 \n",
      "[42]\tvalidation_0-auc:0.93257\tvalidation_1-auc:0.81652                                                                 \n",
      "[43]\tvalidation_0-auc:0.93310\tvalidation_1-auc:0.81639                                                                 \n",
      "[44]\tvalidation_0-auc:0.93348\tvalidation_1-auc:0.81642                                                                 \n",
      "[45]\tvalidation_0-auc:0.93407\tvalidation_1-auc:0.81618                                                                 \n",
      "[46]\tvalidation_0-auc:0.93458\tvalidation_1-auc:0.81627                                                                 \n",
      "[47]\tvalidation_0-auc:0.93492\tvalidation_1-auc:0.81634                                                                 \n",
      "[48]\tvalidation_0-auc:0.93520\tvalidation_1-auc:0.81632                                                                 \n",
      "[49]\tvalidation_0-auc:0.93547\tvalidation_1-auc:0.81611                                                                 \n",
      "[50]\tvalidation_0-auc:0.93575\tvalidation_1-auc:0.81614                                                                 \n",
      "[51]\tvalidation_0-auc:0.93598\tvalidation_1-auc:0.81612                                                                 \n",
      "[52]\tvalidation_0-auc:0.93639\tvalidation_1-auc:0.81601                                                                 \n",
      "[53]\tvalidation_0-auc:0.93678\tvalidation_1-auc:0.81593                                                                 \n",
      "[0]\tvalidation_0-auc:0.87085\tvalidation_1-auc:0.79504                                                                  \n",
      "[1]\tvalidation_0-auc:0.87716\tvalidation_1-auc:0.80424                                                                  \n",
      "[2]\tvalidation_0-auc:0.88285\tvalidation_1-auc:0.81956                                                                  \n",
      "[3]\tvalidation_0-auc:0.88538\tvalidation_1-auc:0.82178                                                                  \n",
      "[4]\tvalidation_0-auc:0.88731\tvalidation_1-auc:0.82222                                                                  \n",
      "[5]\tvalidation_0-auc:0.88818\tvalidation_1-auc:0.82160                                                                  \n",
      "[6]\tvalidation_0-auc:0.89353\tvalidation_1-auc:0.82167                                                                  \n",
      "[7]\tvalidation_0-auc:0.89612\tvalidation_1-auc:0.82338                                                                  \n",
      "[8]\tvalidation_0-auc:0.89871\tvalidation_1-auc:0.82463                                                                  \n",
      "[9]\tvalidation_0-auc:0.90129\tvalidation_1-auc:0.82790                                                                  \n",
      "[10]\tvalidation_0-auc:0.90253\tvalidation_1-auc:0.82932                                                                 \n",
      "[11]\tvalidation_0-auc:0.90408\tvalidation_1-auc:0.82945                                                                 \n",
      "[12]\tvalidation_0-auc:0.90523\tvalidation_1-auc:0.82956                                                                 \n",
      "[13]\tvalidation_0-auc:0.90700\tvalidation_1-auc:0.82951                                                                 \n",
      "[14]\tvalidation_0-auc:0.90859\tvalidation_1-auc:0.82973                                                                 \n",
      "[15]\tvalidation_0-auc:0.90984\tvalidation_1-auc:0.82969                                                                 \n",
      "[16]\tvalidation_0-auc:0.91136\tvalidation_1-auc:0.82980                                                                 \n",
      "[17]\tvalidation_0-auc:0.91315\tvalidation_1-auc:0.83080                                                                 \n",
      "[18]\tvalidation_0-auc:0.91460\tvalidation_1-auc:0.83078                                                                 \n",
      "[19]\tvalidation_0-auc:0.91574\tvalidation_1-auc:0.83102                                                                 \n",
      "[20]\tvalidation_0-auc:0.91668\tvalidation_1-auc:0.83069                                                                 \n",
      "[21]\tvalidation_0-auc:0.91770\tvalidation_1-auc:0.83024                                                                 \n",
      "[22]\tvalidation_0-auc:0.91851\tvalidation_1-auc:0.83063                                                                 \n",
      "[23]\tvalidation_0-auc:0.91896\tvalidation_1-auc:0.83116                                                                 \n",
      "[24]\tvalidation_0-auc:0.91976\tvalidation_1-auc:0.83186                                                                 \n",
      "[25]\tvalidation_0-auc:0.92070\tvalidation_1-auc:0.83215                                                                 \n",
      "[26]\tvalidation_0-auc:0.92159\tvalidation_1-auc:0.83212                                                                 \n",
      "[27]\tvalidation_0-auc:0.92254\tvalidation_1-auc:0.83278                                                                 \n",
      "[28]\tvalidation_0-auc:0.92345\tvalidation_1-auc:0.83353                                                                 \n",
      "[29]\tvalidation_0-auc:0.92446\tvalidation_1-auc:0.83387                                                                 \n",
      "[30]\tvalidation_0-auc:0.92539\tvalidation_1-auc:0.83429                                                                 \n",
      "[31]\tvalidation_0-auc:0.92616\tvalidation_1-auc:0.83407                                                                 \n",
      "[32]\tvalidation_0-auc:0.92699\tvalidation_1-auc:0.83390                                                                 \n",
      "[33]\tvalidation_0-auc:0.92753\tvalidation_1-auc:0.83414                                                                 \n",
      "[34]\tvalidation_0-auc:0.92823\tvalidation_1-auc:0.83410                                                                 \n",
      "[35]\tvalidation_0-auc:0.92899\tvalidation_1-auc:0.83403                                                                 \n",
      "[36]\tvalidation_0-auc:0.93002\tvalidation_1-auc:0.83382                                                                 \n",
      "[37]\tvalidation_0-auc:0.93080\tvalidation_1-auc:0.83400                                                                 \n",
      "[38]\tvalidation_0-auc:0.93148\tvalidation_1-auc:0.83433                                                                 \n",
      "[39]\tvalidation_0-auc:0.93205\tvalidation_1-auc:0.83451                                                                 \n",
      "[40]\tvalidation_0-auc:0.93277\tvalidation_1-auc:0.83470                                                                 \n",
      "[41]\tvalidation_0-auc:0.93326\tvalidation_1-auc:0.83452                                                                 \n",
      "[42]\tvalidation_0-auc:0.93349\tvalidation_1-auc:0.83442                                                                 \n",
      "[43]\tvalidation_0-auc:0.93385\tvalidation_1-auc:0.83450                                                                 \n",
      "[44]\tvalidation_0-auc:0.93410\tvalidation_1-auc:0.83476                                                                 \n",
      "[45]\tvalidation_0-auc:0.93484\tvalidation_1-auc:0.83476                                                                 \n",
      "[46]\tvalidation_0-auc:0.93514\tvalidation_1-auc:0.83497                                                                 \n",
      "[47]\tvalidation_0-auc:0.93544\tvalidation_1-auc:0.83500                                                                 \n",
      "[48]\tvalidation_0-auc:0.93573\tvalidation_1-auc:0.83482                                                                 \n",
      "[49]\tvalidation_0-auc:0.93639\tvalidation_1-auc:0.83472                                                                 \n",
      "[50]\tvalidation_0-auc:0.93670\tvalidation_1-auc:0.83435                                                                 \n",
      "[51]\tvalidation_0-auc:0.93699\tvalidation_1-auc:0.83410                                                                 \n",
      "[52]\tvalidation_0-auc:0.93723\tvalidation_1-auc:0.83421                                                                 \n",
      "[53]\tvalidation_0-auc:0.93751\tvalidation_1-auc:0.83401                                                                 \n",
      "[54]\tvalidation_0-auc:0.93784\tvalidation_1-auc:0.83404                                                                 \n",
      "[55]\tvalidation_0-auc:0.93795\tvalidation_1-auc:0.83405                                                                 \n",
      "[56]\tvalidation_0-auc:0.93817\tvalidation_1-auc:0.83390                                                                 \n",
      "[57]\tvalidation_0-auc:0.93828\tvalidation_1-auc:0.83398                                                                 \n",
      "[58]\tvalidation_0-auc:0.93841\tvalidation_1-auc:0.83402                                                                 \n",
      "[59]\tvalidation_0-auc:0.93853\tvalidation_1-auc:0.83398                                                                 \n",
      "[60]\tvalidation_0-auc:0.93885\tvalidation_1-auc:0.83386                                                                 \n",
      "[61]\tvalidation_0-auc:0.93903\tvalidation_1-auc:0.83377                                                                 \n",
      "[62]\tvalidation_0-auc:0.93913\tvalidation_1-auc:0.83373                                                                 \n",
      "[63]\tvalidation_0-auc:0.93934\tvalidation_1-auc:0.83370                                                                 \n",
      "[64]\tvalidation_0-auc:0.93958\tvalidation_1-auc:0.83374                                                                 \n",
      "[65]\tvalidation_0-auc:0.93978\tvalidation_1-auc:0.83364                                                                 \n",
      "[66]\tvalidation_0-auc:0.94013\tvalidation_1-auc:0.83387                                                                 \n",
      "[67]\tvalidation_0-auc:0.94025\tvalidation_1-auc:0.83401                                                                 \n",
      "[68]\tvalidation_0-auc:0.94072\tvalidation_1-auc:0.83412                                                                 \n",
      "[69]\tvalidation_0-auc:0.94106\tvalidation_1-auc:0.83408                                                                 \n",
      "[70]\tvalidation_0-auc:0.94126\tvalidation_1-auc:0.83399                                                                 \n",
      "[71]\tvalidation_0-auc:0.94156\tvalidation_1-auc:0.83383                                                                 \n",
      "[72]\tvalidation_0-auc:0.94167\tvalidation_1-auc:0.83373                                                                 \n",
      "[73]\tvalidation_0-auc:0.94184\tvalidation_1-auc:0.83364                                                                 \n",
      "[74]\tvalidation_0-auc:0.94204\tvalidation_1-auc:0.83373                                                                 \n",
      "[75]\tvalidation_0-auc:0.94211\tvalidation_1-auc:0.83365                                                                 \n",
      "[76]\tvalidation_0-auc:0.94220\tvalidation_1-auc:0.83370                                                                 \n",
      "[77]\tvalidation_0-auc:0.94225\tvalidation_1-auc:0.83368                                                                 \n",
      "[0]\tvalidation_0-auc:0.87011\tvalidation_1-auc:0.81091                                                                  \n",
      "[1]\tvalidation_0-auc:0.87504\tvalidation_1-auc:0.81898                                                                  \n",
      "[2]\tvalidation_0-auc:0.88125\tvalidation_1-auc:0.82714                                                                  \n",
      "[3]\tvalidation_0-auc:0.88489\tvalidation_1-auc:0.82789                                                                  \n",
      "[4]\tvalidation_0-auc:0.88779\tvalidation_1-auc:0.82931                                                                  \n",
      "[5]\tvalidation_0-auc:0.88911\tvalidation_1-auc:0.82956                                                                  \n",
      "[6]\tvalidation_0-auc:0.89185\tvalidation_1-auc:0.82986                                                                  \n",
      "[7]\tvalidation_0-auc:0.89498\tvalidation_1-auc:0.82997                                                                  \n",
      "[8]\tvalidation_0-auc:0.89655\tvalidation_1-auc:0.82954                                                                  \n",
      "[9]\tvalidation_0-auc:0.89938\tvalidation_1-auc:0.83039                                                                  \n",
      "[10]\tvalidation_0-auc:0.90220\tvalidation_1-auc:0.83186                                                                 \n",
      "[11]\tvalidation_0-auc:0.90433\tvalidation_1-auc:0.83232                                                                 \n",
      "[12]\tvalidation_0-auc:0.90653\tvalidation_1-auc:0.83226                                                                 \n",
      "[13]\tvalidation_0-auc:0.90722\tvalidation_1-auc:0.83219                                                                 \n",
      "[14]\tvalidation_0-auc:0.90828\tvalidation_1-auc:0.83175                                                                 \n",
      "[15]\tvalidation_0-auc:0.90896\tvalidation_1-auc:0.83148                                                                 \n",
      "[16]\tvalidation_0-auc:0.90976\tvalidation_1-auc:0.83083                                                                 \n",
      "[17]\tvalidation_0-auc:0.91135\tvalidation_1-auc:0.83106                                                                 \n",
      "[18]\tvalidation_0-auc:0.91190\tvalidation_1-auc:0.83125                                                                 \n",
      "[19]\tvalidation_0-auc:0.91313\tvalidation_1-auc:0.83150                                                                 \n",
      "[20]\tvalidation_0-auc:0.91440\tvalidation_1-auc:0.83167                                                                 \n",
      "[21]\tvalidation_0-auc:0.91585\tvalidation_1-auc:0.83206                                                                 \n",
      "[22]\tvalidation_0-auc:0.91689\tvalidation_1-auc:0.83191                                                                 \n",
      "[23]\tvalidation_0-auc:0.91752\tvalidation_1-auc:0.83228                                                                 \n",
      "[24]\tvalidation_0-auc:0.91835\tvalidation_1-auc:0.83228                                                                 \n",
      "[25]\tvalidation_0-auc:0.91941\tvalidation_1-auc:0.83210                                                                 \n",
      "[26]\tvalidation_0-auc:0.92037\tvalidation_1-auc:0.83215                                                                 \n",
      "[27]\tvalidation_0-auc:0.92132\tvalidation_1-auc:0.83193                                                                 \n",
      "[28]\tvalidation_0-auc:0.92201\tvalidation_1-auc:0.83198                                                                 \n",
      "[29]\tvalidation_0-auc:0.92319\tvalidation_1-auc:0.83200                                                                 \n",
      "[30]\tvalidation_0-auc:0.92430\tvalidation_1-auc:0.83196                                                                 \n",
      "[31]\tvalidation_0-auc:0.92521\tvalidation_1-auc:0.83171                                                                 \n",
      "[32]\tvalidation_0-auc:0.92599\tvalidation_1-auc:0.83215                                                                 \n",
      "[33]\tvalidation_0-auc:0.92657\tvalidation_1-auc:0.83231                                                                 \n",
      "[34]\tvalidation_0-auc:0.92726\tvalidation_1-auc:0.83205                                                                 \n",
      "[35]\tvalidation_0-auc:0.92784\tvalidation_1-auc:0.83218                                                                 \n",
      "[36]\tvalidation_0-auc:0.92848\tvalidation_1-auc:0.83220                                                                 \n",
      "[37]\tvalidation_0-auc:0.92909\tvalidation_1-auc:0.83217                                                                 \n",
      "[38]\tvalidation_0-auc:0.92949\tvalidation_1-auc:0.83206                                                                 \n",
      "[39]\tvalidation_0-auc:0.92985\tvalidation_1-auc:0.83216                                                                 \n",
      "[40]\tvalidation_0-auc:0.93053\tvalidation_1-auc:0.83204                                                                 \n",
      "[41]\tvalidation_0-auc:0.93113\tvalidation_1-auc:0.83235                                                                 \n",
      "[42]\tvalidation_0-auc:0.93160\tvalidation_1-auc:0.83243                                                                 \n",
      "[43]\tvalidation_0-auc:0.93242\tvalidation_1-auc:0.83225                                                                 \n",
      "[44]\tvalidation_0-auc:0.93273\tvalidation_1-auc:0.83226                                                                 \n",
      "[45]\tvalidation_0-auc:0.93308\tvalidation_1-auc:0.83228                                                                 \n",
      "[46]\tvalidation_0-auc:0.93346\tvalidation_1-auc:0.83261                                                                 \n",
      "[47]\tvalidation_0-auc:0.93405\tvalidation_1-auc:0.83281                                                                 \n",
      "[48]\tvalidation_0-auc:0.93435\tvalidation_1-auc:0.83279                                                                 \n",
      "[49]\tvalidation_0-auc:0.93465\tvalidation_1-auc:0.83273                                                                 \n",
      "[50]\tvalidation_0-auc:0.93511\tvalidation_1-auc:0.83271                                                                 \n",
      "[51]\tvalidation_0-auc:0.93544\tvalidation_1-auc:0.83293                                                                 \n",
      "[52]\tvalidation_0-auc:0.93568\tvalidation_1-auc:0.83289                                                                 \n",
      "[53]\tvalidation_0-auc:0.93605\tvalidation_1-auc:0.83314                                                                 \n",
      "[54]\tvalidation_0-auc:0.93659\tvalidation_1-auc:0.83286                                                                 \n",
      "[55]\tvalidation_0-auc:0.93683\tvalidation_1-auc:0.83297                                                                 \n",
      "[56]\tvalidation_0-auc:0.93738\tvalidation_1-auc:0.83310                                                                 \n",
      "[57]\tvalidation_0-auc:0.93768\tvalidation_1-auc:0.83320                                                                 \n",
      "[58]\tvalidation_0-auc:0.93831\tvalidation_1-auc:0.83308                                                                 \n",
      "[59]\tvalidation_0-auc:0.93863\tvalidation_1-auc:0.83304                                                                 \n",
      "[60]\tvalidation_0-auc:0.93889\tvalidation_1-auc:0.83308                                                                 \n",
      "[61]\tvalidation_0-auc:0.93925\tvalidation_1-auc:0.83331                                                                 \n",
      "[62]\tvalidation_0-auc:0.93964\tvalidation_1-auc:0.83339                                                                 \n",
      "[63]\tvalidation_0-auc:0.93990\tvalidation_1-auc:0.83335                                                                 \n",
      "[64]\tvalidation_0-auc:0.94016\tvalidation_1-auc:0.83367                                                                 \n",
      "[65]\tvalidation_0-auc:0.94053\tvalidation_1-auc:0.83363                                                                 \n",
      "[66]\tvalidation_0-auc:0.94088\tvalidation_1-auc:0.83355                                                                 \n",
      "[67]\tvalidation_0-auc:0.94105\tvalidation_1-auc:0.83385                                                                 \n",
      "[68]\tvalidation_0-auc:0.94136\tvalidation_1-auc:0.83372                                                                 \n",
      "[69]\tvalidation_0-auc:0.94156\tvalidation_1-auc:0.83378                                                                 \n",
      "[70]\tvalidation_0-auc:0.94174\tvalidation_1-auc:0.83385                                                                 \n",
      "[71]\tvalidation_0-auc:0.94214\tvalidation_1-auc:0.83381                                                                 \n",
      "[72]\tvalidation_0-auc:0.94236\tvalidation_1-auc:0.83371                                                                 \n",
      "[73]\tvalidation_0-auc:0.94252\tvalidation_1-auc:0.83371                                                                 \n",
      "[74]\tvalidation_0-auc:0.94270\tvalidation_1-auc:0.83383                                                                 \n",
      "[75]\tvalidation_0-auc:0.94279\tvalidation_1-auc:0.83389                                                                 \n",
      "[76]\tvalidation_0-auc:0.94297\tvalidation_1-auc:0.83391                                                                 \n",
      "[77]\tvalidation_0-auc:0.94309\tvalidation_1-auc:0.83407                                                                 \n",
      "[78]\tvalidation_0-auc:0.94317\tvalidation_1-auc:0.83403                                                                 \n",
      "[79]\tvalidation_0-auc:0.94330\tvalidation_1-auc:0.83400                                                                 \n",
      "[80]\tvalidation_0-auc:0.94342\tvalidation_1-auc:0.83397                                                                 \n",
      "[81]\tvalidation_0-auc:0.94365\tvalidation_1-auc:0.83402                                                                 \n",
      "[82]\tvalidation_0-auc:0.94390\tvalidation_1-auc:0.83408                                                                 \n",
      "[83]\tvalidation_0-auc:0.94417\tvalidation_1-auc:0.83403                                                                 \n",
      "[84]\tvalidation_0-auc:0.94431\tvalidation_1-auc:0.83406                                                                 \n",
      "[85]\tvalidation_0-auc:0.94462\tvalidation_1-auc:0.83395                                                                 \n",
      "[86]\tvalidation_0-auc:0.94492\tvalidation_1-auc:0.83396                                                                 \n",
      "[87]\tvalidation_0-auc:0.94512\tvalidation_1-auc:0.83396                                                                 \n",
      "[88]\tvalidation_0-auc:0.94536\tvalidation_1-auc:0.83389                                                                 \n",
      "[89]\tvalidation_0-auc:0.94567\tvalidation_1-auc:0.83393                                                                 \n",
      "[90]\tvalidation_0-auc:0.94581\tvalidation_1-auc:0.83377                                                                 \n",
      "[91]\tvalidation_0-auc:0.94588\tvalidation_1-auc:0.83389                                                                 \n",
      "[92]\tvalidation_0-auc:0.94610\tvalidation_1-auc:0.83379                                                                 \n",
      "[93]\tvalidation_0-auc:0.94616\tvalidation_1-auc:0.83381                                                                 \n",
      "[94]\tvalidation_0-auc:0.94635\tvalidation_1-auc:0.83395                                                                 \n",
      "[95]\tvalidation_0-auc:0.94649\tvalidation_1-auc:0.83398                                                                 \n",
      "[96]\tvalidation_0-auc:0.94670\tvalidation_1-auc:0.83397                                                                 \n",
      "[97]\tvalidation_0-auc:0.94698\tvalidation_1-auc:0.83403                                                                 \n",
      "[98]\tvalidation_0-auc:0.94709\tvalidation_1-auc:0.83400                                                                 \n",
      "[99]\tvalidation_0-auc:0.94754\tvalidation_1-auc:0.83387                                                                 \n",
      "[0]\tvalidation_0-auc:0.83757\tvalidation_1-auc:0.80694                                                                  \n",
      "[1]\tvalidation_0-auc:0.84454\tvalidation_1-auc:0.80395                                                                  \n",
      "[2]\tvalidation_0-auc:0.84999\tvalidation_1-auc:0.80963                                                                  \n",
      "[3]\tvalidation_0-auc:0.84770\tvalidation_1-auc:0.80389                                                                  \n",
      "[4]\tvalidation_0-auc:0.84572\tvalidation_1-auc:0.79967                                                                  \n",
      "[5]\tvalidation_0-auc:0.85124\tvalidation_1-auc:0.80413                                                                  \n",
      "[6]\tvalidation_0-auc:0.85440\tvalidation_1-auc:0.80718                                                                  \n",
      "[7]\tvalidation_0-auc:0.85685\tvalidation_1-auc:0.80740                                                                  \n",
      "[8]\tvalidation_0-auc:0.86044\tvalidation_1-auc:0.81073                                                                  \n",
      "[9]\tvalidation_0-auc:0.85949\tvalidation_1-auc:0.80848                                                                  \n",
      "[10]\tvalidation_0-auc:0.86118\tvalidation_1-auc:0.81041                                                                 \n",
      "[11]\tvalidation_0-auc:0.86224\tvalidation_1-auc:0.80921                                                                 \n",
      "[12]\tvalidation_0-auc:0.86468\tvalidation_1-auc:0.81156                                                                 \n",
      "[13]\tvalidation_0-auc:0.86657\tvalidation_1-auc:0.81392                                                                 \n",
      "[14]\tvalidation_0-auc:0.86667\tvalidation_1-auc:0.81301                                                                 \n",
      "[15]\tvalidation_0-auc:0.86869\tvalidation_1-auc:0.81424                                                                 \n",
      "[16]\tvalidation_0-auc:0.87042\tvalidation_1-auc:0.81581                                                                 \n",
      "[17]\tvalidation_0-auc:0.87089\tvalidation_1-auc:0.81526                                                                 \n",
      "[18]\tvalidation_0-auc:0.87132\tvalidation_1-auc:0.81494                                                                 \n",
      "[19]\tvalidation_0-auc:0.87244\tvalidation_1-auc:0.81595                                                                 \n",
      "[20]\tvalidation_0-auc:0.87364\tvalidation_1-auc:0.81634                                                                 \n",
      "[21]\tvalidation_0-auc:0.87455\tvalidation_1-auc:0.81718                                                                 \n",
      "[22]\tvalidation_0-auc:0.87511\tvalidation_1-auc:0.81817                                                                 \n",
      "[23]\tvalidation_0-auc:0.87556\tvalidation_1-auc:0.81878                                                                 \n",
      "[24]\tvalidation_0-auc:0.87643\tvalidation_1-auc:0.81937                                                                 \n",
      "[25]\tvalidation_0-auc:0.87712\tvalidation_1-auc:0.81973                                                                 \n",
      "[26]\tvalidation_0-auc:0.87719\tvalidation_1-auc:0.81953                                                                 \n",
      "[27]\tvalidation_0-auc:0.87772\tvalidation_1-auc:0.81919                                                                 \n",
      "[28]\tvalidation_0-auc:0.87849\tvalidation_1-auc:0.81998                                                                 \n",
      "[29]\tvalidation_0-auc:0.87867\tvalidation_1-auc:0.81979                                                                 \n",
      "[30]\tvalidation_0-auc:0.87926\tvalidation_1-auc:0.81950                                                                 \n",
      "[31]\tvalidation_0-auc:0.87956\tvalidation_1-auc:0.81905                                                                 \n",
      "[32]\tvalidation_0-auc:0.88030\tvalidation_1-auc:0.81942                                                                 \n",
      "[33]\tvalidation_0-auc:0.88088\tvalidation_1-auc:0.82000                                                                 \n",
      "[34]\tvalidation_0-auc:0.88144\tvalidation_1-auc:0.82035                                                                 \n",
      "[35]\tvalidation_0-auc:0.88177\tvalidation_1-auc:0.82029                                                                 \n",
      "[36]\tvalidation_0-auc:0.88224\tvalidation_1-auc:0.82042                                                                 \n",
      "[37]\tvalidation_0-auc:0.88277\tvalidation_1-auc:0.82102                                                                 \n",
      "[38]\tvalidation_0-auc:0.88296\tvalidation_1-auc:0.82114                                                                 \n",
      "[39]\tvalidation_0-auc:0.88329\tvalidation_1-auc:0.82123                                                                 \n",
      "[40]\tvalidation_0-auc:0.88374\tvalidation_1-auc:0.82122                                                                 \n",
      "[41]\tvalidation_0-auc:0.88408\tvalidation_1-auc:0.82139                                                                 \n",
      "[42]\tvalidation_0-auc:0.88451\tvalidation_1-auc:0.82139                                                                 \n",
      "[43]\tvalidation_0-auc:0.88495\tvalidation_1-auc:0.82133                                                                 \n",
      "[44]\tvalidation_0-auc:0.88517\tvalidation_1-auc:0.82118                                                                 \n",
      "[45]\tvalidation_0-auc:0.88560\tvalidation_1-auc:0.82151                                                                 \n",
      "[46]\tvalidation_0-auc:0.88574\tvalidation_1-auc:0.82151                                                                 \n",
      "[47]\tvalidation_0-auc:0.88617\tvalidation_1-auc:0.82159                                                                 \n",
      "[48]\tvalidation_0-auc:0.88636\tvalidation_1-auc:0.82180                                                                 \n",
      "[49]\tvalidation_0-auc:0.88685\tvalidation_1-auc:0.82153                                                                 \n",
      "[50]\tvalidation_0-auc:0.88697\tvalidation_1-auc:0.82169                                                                 \n",
      "[51]\tvalidation_0-auc:0.88737\tvalidation_1-auc:0.82209                                                                 \n",
      "[52]\tvalidation_0-auc:0.88747\tvalidation_1-auc:0.82205                                                                 \n",
      "[53]\tvalidation_0-auc:0.88770\tvalidation_1-auc:0.82238                                                                 \n",
      "[54]\tvalidation_0-auc:0.88813\tvalidation_1-auc:0.82238                                                                 \n",
      "[55]\tvalidation_0-auc:0.88857\tvalidation_1-auc:0.82291                                                                 \n",
      "[56]\tvalidation_0-auc:0.88865\tvalidation_1-auc:0.82296                                                                 \n",
      "[57]\tvalidation_0-auc:0.88898\tvalidation_1-auc:0.82320                                                                 \n",
      "[58]\tvalidation_0-auc:0.88912\tvalidation_1-auc:0.82344                                                                 \n",
      "[59]\tvalidation_0-auc:0.88946\tvalidation_1-auc:0.82360                                                                 \n",
      "[60]\tvalidation_0-auc:0.88978\tvalidation_1-auc:0.82364                                                                 \n",
      "[61]\tvalidation_0-auc:0.88989\tvalidation_1-auc:0.82368                                                                 \n",
      "[62]\tvalidation_0-auc:0.89019\tvalidation_1-auc:0.82354                                                                 \n",
      "[63]\tvalidation_0-auc:0.89047\tvalidation_1-auc:0.82347                                                                 \n",
      "[64]\tvalidation_0-auc:0.89089\tvalidation_1-auc:0.82342                                                                 \n",
      "[65]\tvalidation_0-auc:0.89116\tvalidation_1-auc:0.82350                                                                 \n",
      "[66]\tvalidation_0-auc:0.89143\tvalidation_1-auc:0.82358                                                                 \n",
      "[67]\tvalidation_0-auc:0.89153\tvalidation_1-auc:0.82381                                                                 \n",
      "[68]\tvalidation_0-auc:0.89206\tvalidation_1-auc:0.82359                                                                 \n",
      "[69]\tvalidation_0-auc:0.89233\tvalidation_1-auc:0.82365                                                                 \n",
      "[70]\tvalidation_0-auc:0.89267\tvalidation_1-auc:0.82374                                                                 \n",
      "[71]\tvalidation_0-auc:0.89286\tvalidation_1-auc:0.82410                                                                 \n",
      "[72]\tvalidation_0-auc:0.89306\tvalidation_1-auc:0.82421                                                                 \n",
      "[73]\tvalidation_0-auc:0.89344\tvalidation_1-auc:0.82420                                                                 \n",
      "[74]\tvalidation_0-auc:0.89372\tvalidation_1-auc:0.82424                                                                 \n",
      "[75]\tvalidation_0-auc:0.89420\tvalidation_1-auc:0.82418                                                                 \n",
      "[76]\tvalidation_0-auc:0.89437\tvalidation_1-auc:0.82442                                                                 \n",
      "[77]\tvalidation_0-auc:0.89471\tvalidation_1-auc:0.82442                                                                 \n",
      "[78]\tvalidation_0-auc:0.89504\tvalidation_1-auc:0.82427                                                                 \n",
      "[79]\tvalidation_0-auc:0.89524\tvalidation_1-auc:0.82433                                                                 \n",
      "[80]\tvalidation_0-auc:0.89531\tvalidation_1-auc:0.82430                                                                 \n",
      "[81]\tvalidation_0-auc:0.89549\tvalidation_1-auc:0.82434                                                                 \n",
      "[82]\tvalidation_0-auc:0.89558\tvalidation_1-auc:0.82436                                                                 \n",
      "[83]\tvalidation_0-auc:0.89607\tvalidation_1-auc:0.82420                                                                 \n",
      "[84]\tvalidation_0-auc:0.89627\tvalidation_1-auc:0.82420                                                                 \n",
      "[85]\tvalidation_0-auc:0.89676\tvalidation_1-auc:0.82396                                                                 \n",
      "[86]\tvalidation_0-auc:0.89682\tvalidation_1-auc:0.82397                                                                 \n",
      "[87]\tvalidation_0-auc:0.89689\tvalidation_1-auc:0.82407                                                                 \n",
      "[88]\tvalidation_0-auc:0.89695\tvalidation_1-auc:0.82409                                                                 \n",
      "[89]\tvalidation_0-auc:0.89716\tvalidation_1-auc:0.82417                                                                 \n",
      "[90]\tvalidation_0-auc:0.89731\tvalidation_1-auc:0.82424                                                                 \n",
      "[91]\tvalidation_0-auc:0.89737\tvalidation_1-auc:0.82433                                                                 \n",
      "[92]\tvalidation_0-auc:0.89763\tvalidation_1-auc:0.82444                                                                 \n",
      "[93]\tvalidation_0-auc:0.89773\tvalidation_1-auc:0.82449                                                                 \n",
      "[94]\tvalidation_0-auc:0.89781\tvalidation_1-auc:0.82455                                                                 \n",
      "[95]\tvalidation_0-auc:0.89790\tvalidation_1-auc:0.82456                                                                 \n",
      "[96]\tvalidation_0-auc:0.89816\tvalidation_1-auc:0.82448                                                                 \n",
      "[97]\tvalidation_0-auc:0.89823\tvalidation_1-auc:0.82448                                                                 \n",
      "[98]\tvalidation_0-auc:0.89853\tvalidation_1-auc:0.82444                                                                 \n",
      "[99]\tvalidation_0-auc:0.89895\tvalidation_1-auc:0.82403                                                                 \n",
      "[0]\tvalidation_0-auc:0.83294\tvalidation_1-auc:0.81508                                                                  \n",
      "[1]\tvalidation_0-auc:0.84009\tvalidation_1-auc:0.82191                                                                  \n",
      "[2]\tvalidation_0-auc:0.84782\tvalidation_1-auc:0.82943                                                                  \n",
      "[3]\tvalidation_0-auc:0.84405\tvalidation_1-auc:0.83064                                                                  \n",
      "[4]\tvalidation_0-auc:0.83967\tvalidation_1-auc:0.82705                                                                  \n",
      "[5]\tvalidation_0-auc:0.84755\tvalidation_1-auc:0.83374                                                                  \n",
      "[6]\tvalidation_0-auc:0.85244\tvalidation_1-auc:0.83664                                                                  \n",
      "[7]\tvalidation_0-auc:0.85256\tvalidation_1-auc:0.83440                                                                  \n",
      "[8]\tvalidation_0-auc:0.85682\tvalidation_1-auc:0.83844                                                                  \n",
      "[9]\tvalidation_0-auc:0.85508\tvalidation_1-auc:0.83810                                                                  \n",
      "[10]\tvalidation_0-auc:0.85788\tvalidation_1-auc:0.84094                                                                 \n",
      "[11]\tvalidation_0-auc:0.85773\tvalidation_1-auc:0.84038                                                                 \n",
      "[12]\tvalidation_0-auc:0.86087\tvalidation_1-auc:0.84153                                                                 \n",
      "[13]\tvalidation_0-auc:0.86282\tvalidation_1-auc:0.84231                                                                 \n",
      "[14]\tvalidation_0-auc:0.86263\tvalidation_1-auc:0.84253                                                                 \n",
      "[15]\tvalidation_0-auc:0.86468\tvalidation_1-auc:0.84276                                                                 \n",
      "[16]\tvalidation_0-auc:0.86658\tvalidation_1-auc:0.84344                                                                 \n",
      "[17]\tvalidation_0-auc:0.86651\tvalidation_1-auc:0.84357                                                                 \n",
      "[18]\tvalidation_0-auc:0.86719\tvalidation_1-auc:0.84384                                                                 \n",
      "[19]\tvalidation_0-auc:0.86864\tvalidation_1-auc:0.84413                                                                 \n",
      "[20]\tvalidation_0-auc:0.87031\tvalidation_1-auc:0.84371                                                                 \n",
      "[21]\tvalidation_0-auc:0.87157\tvalidation_1-auc:0.84358                                                                 \n",
      "[22]\tvalidation_0-auc:0.87245\tvalidation_1-auc:0.84386                                                                 \n",
      "[23]\tvalidation_0-auc:0.87329\tvalidation_1-auc:0.84438                                                                 \n",
      "[24]\tvalidation_0-auc:0.87406\tvalidation_1-auc:0.84433                                                                 \n",
      "[25]\tvalidation_0-auc:0.87501\tvalidation_1-auc:0.84438                                                                 \n",
      "[26]\tvalidation_0-auc:0.87488\tvalidation_1-auc:0.84471                                                                 \n",
      "[27]\tvalidation_0-auc:0.87512\tvalidation_1-auc:0.84513                                                                 \n",
      "[28]\tvalidation_0-auc:0.87565\tvalidation_1-auc:0.84522                                                                 \n",
      "[29]\tvalidation_0-auc:0.87572\tvalidation_1-auc:0.84539                                                                 \n",
      "[30]\tvalidation_0-auc:0.87609\tvalidation_1-auc:0.84541                                                                 \n",
      "[31]\tvalidation_0-auc:0.87690\tvalidation_1-auc:0.84556                                                                 \n",
      "[32]\tvalidation_0-auc:0.87758\tvalidation_1-auc:0.84564                                                                 \n",
      "[33]\tvalidation_0-auc:0.87782\tvalidation_1-auc:0.84566                                                                 \n",
      "[34]\tvalidation_0-auc:0.87814\tvalidation_1-auc:0.84578                                                                 \n",
      "[35]\tvalidation_0-auc:0.87893\tvalidation_1-auc:0.84559                                                                 \n",
      "[36]\tvalidation_0-auc:0.87943\tvalidation_1-auc:0.84528                                                                 \n",
      "[37]\tvalidation_0-auc:0.87999\tvalidation_1-auc:0.84542                                                                 \n",
      "[38]\tvalidation_0-auc:0.88016\tvalidation_1-auc:0.84537                                                                 \n",
      "[39]\tvalidation_0-auc:0.88049\tvalidation_1-auc:0.84522                                                                 \n",
      "[40]\tvalidation_0-auc:0.88101\tvalidation_1-auc:0.84539                                                                 \n",
      "[41]\tvalidation_0-auc:0.88119\tvalidation_1-auc:0.84522                                                                 \n",
      "[42]\tvalidation_0-auc:0.88155\tvalidation_1-auc:0.84531                                                                 \n",
      "[43]\tvalidation_0-auc:0.88208\tvalidation_1-auc:0.84521                                                                 \n",
      "[44]\tvalidation_0-auc:0.88219\tvalidation_1-auc:0.84520                                                                 \n",
      "[45]\tvalidation_0-auc:0.88242\tvalidation_1-auc:0.84520                                                                 \n",
      "[46]\tvalidation_0-auc:0.88259\tvalidation_1-auc:0.84522                                                                 \n",
      "[47]\tvalidation_0-auc:0.88291\tvalidation_1-auc:0.84528                                                                 \n",
      "[48]\tvalidation_0-auc:0.88325\tvalidation_1-auc:0.84534                                                                 \n",
      "[49]\tvalidation_0-auc:0.88346\tvalidation_1-auc:0.84534                                                                 \n",
      "[50]\tvalidation_0-auc:0.88371\tvalidation_1-auc:0.84528                                                                 \n",
      "[51]\tvalidation_0-auc:0.88382\tvalidation_1-auc:0.84533                                                                 \n",
      "[52]\tvalidation_0-auc:0.88388\tvalidation_1-auc:0.84535                                                                 \n",
      "[53]\tvalidation_0-auc:0.88433\tvalidation_1-auc:0.84527                                                                 \n",
      "[54]\tvalidation_0-auc:0.88492\tvalidation_1-auc:0.84567                                                                 \n",
      "[55]\tvalidation_0-auc:0.88493\tvalidation_1-auc:0.84562                                                                 \n",
      "[56]\tvalidation_0-auc:0.88523\tvalidation_1-auc:0.84543                                                                 \n",
      "[57]\tvalidation_0-auc:0.88523\tvalidation_1-auc:0.84552                                                                 \n",
      "[58]\tvalidation_0-auc:0.88562\tvalidation_1-auc:0.84540                                                                 \n",
      "[59]\tvalidation_0-auc:0.88569\tvalidation_1-auc:0.84545                                                                 \n",
      "[60]\tvalidation_0-auc:0.88609\tvalidation_1-auc:0.84526                                                                 \n",
      "[61]\tvalidation_0-auc:0.88627\tvalidation_1-auc:0.84509                                                                 \n",
      "[62]\tvalidation_0-auc:0.88653\tvalidation_1-auc:0.84527                                                                 \n",
      "[63]\tvalidation_0-auc:0.88710\tvalidation_1-auc:0.84520                                                                 \n",
      "[64]\tvalidation_0-auc:0.88718\tvalidation_1-auc:0.84505                                                                 \n",
      "[0]\tvalidation_0-auc:0.83039\tvalidation_1-auc:0.81460                                                                  \n",
      "[1]\tvalidation_0-auc:0.83640\tvalidation_1-auc:0.80914                                                                  \n",
      "[2]\tvalidation_0-auc:0.84285\tvalidation_1-auc:0.81564                                                                  \n",
      "[3]\tvalidation_0-auc:0.83973\tvalidation_1-auc:0.81065                                                                  \n",
      "[4]\tvalidation_0-auc:0.83879\tvalidation_1-auc:0.80855                                                                  \n",
      "[5]\tvalidation_0-auc:0.84575\tvalidation_1-auc:0.81680                                                                  \n",
      "[6]\tvalidation_0-auc:0.84953\tvalidation_1-auc:0.82214                                                                  \n",
      "[7]\tvalidation_0-auc:0.85122\tvalidation_1-auc:0.82317                                                                  \n",
      "[8]\tvalidation_0-auc:0.85546\tvalidation_1-auc:0.82591                                                                  \n",
      "[9]\tvalidation_0-auc:0.85479\tvalidation_1-auc:0.82497                                                                  \n",
      "[10]\tvalidation_0-auc:0.85695\tvalidation_1-auc:0.82792                                                                 \n",
      "[11]\tvalidation_0-auc:0.85763\tvalidation_1-auc:0.82706                                                                 \n",
      "[12]\tvalidation_0-auc:0.86031\tvalidation_1-auc:0.82938                                                                 \n",
      "[13]\tvalidation_0-auc:0.86214\tvalidation_1-auc:0.83048                                                                 \n",
      "[14]\tvalidation_0-auc:0.86250\tvalidation_1-auc:0.83012                                                                 \n",
      "[15]\tvalidation_0-auc:0.86465\tvalidation_1-auc:0.83134                                                                 \n",
      "[16]\tvalidation_0-auc:0.86622\tvalidation_1-auc:0.83256                                                                 \n",
      "[17]\tvalidation_0-auc:0.86658\tvalidation_1-auc:0.83170                                                                 \n",
      "[18]\tvalidation_0-auc:0.86772\tvalidation_1-auc:0.83111                                                                 \n",
      "[19]\tvalidation_0-auc:0.86903\tvalidation_1-auc:0.83227                                                                 \n",
      "[20]\tvalidation_0-auc:0.87037\tvalidation_1-auc:0.83308                                                                 \n",
      "[21]\tvalidation_0-auc:0.87162\tvalidation_1-auc:0.83365                                                                 \n",
      "[22]\tvalidation_0-auc:0.87276\tvalidation_1-auc:0.83433                                                                 \n",
      "[23]\tvalidation_0-auc:0.87334\tvalidation_1-auc:0.83521                                                                 \n",
      "[24]\tvalidation_0-auc:0.87413\tvalidation_1-auc:0.83551                                                                 \n",
      "[25]\tvalidation_0-auc:0.87490\tvalidation_1-auc:0.83593                                                                 \n",
      "[26]\tvalidation_0-auc:0.87527\tvalidation_1-auc:0.83551                                                                 \n",
      "[27]\tvalidation_0-auc:0.87561\tvalidation_1-auc:0.83544                                                                 \n",
      "[28]\tvalidation_0-auc:0.87615\tvalidation_1-auc:0.83572                                                                 \n",
      "[29]\tvalidation_0-auc:0.87650\tvalidation_1-auc:0.83566                                                                 \n",
      "[30]\tvalidation_0-auc:0.87710\tvalidation_1-auc:0.83557                                                                 \n",
      "[31]\tvalidation_0-auc:0.87749\tvalidation_1-auc:0.83533                                                                 \n",
      "[32]\tvalidation_0-auc:0.87821\tvalidation_1-auc:0.83606                                                                 \n",
      "[33]\tvalidation_0-auc:0.87850\tvalidation_1-auc:0.83656                                                                 \n",
      "[34]\tvalidation_0-auc:0.87915\tvalidation_1-auc:0.83682                                                                 \n",
      "[35]\tvalidation_0-auc:0.87954\tvalidation_1-auc:0.83698                                                                 \n",
      "[36]\tvalidation_0-auc:0.88017\tvalidation_1-auc:0.83737                                                                 \n",
      "[37]\tvalidation_0-auc:0.88056\tvalidation_1-auc:0.83772                                                                 \n",
      "[38]\tvalidation_0-auc:0.88131\tvalidation_1-auc:0.83827                                                                 \n",
      "[39]\tvalidation_0-auc:0.88161\tvalidation_1-auc:0.83875                                                                 \n",
      "[40]\tvalidation_0-auc:0.88215\tvalidation_1-auc:0.83881                                                                 \n",
      "[41]\tvalidation_0-auc:0.88295\tvalidation_1-auc:0.83880                                                                 \n",
      "[42]\tvalidation_0-auc:0.88350\tvalidation_1-auc:0.83865                                                                 \n",
      "[43]\tvalidation_0-auc:0.88379\tvalidation_1-auc:0.83862                                                                 \n",
      "[44]\tvalidation_0-auc:0.88420\tvalidation_1-auc:0.83848                                                                 \n",
      "[45]\tvalidation_0-auc:0.88500\tvalidation_1-auc:0.83868                                                                 \n",
      "[46]\tvalidation_0-auc:0.88512\tvalidation_1-auc:0.83873                                                                 \n",
      "[47]\tvalidation_0-auc:0.88585\tvalidation_1-auc:0.83849                                                                 \n",
      "[48]\tvalidation_0-auc:0.88659\tvalidation_1-auc:0.83855                                                                 \n",
      "[49]\tvalidation_0-auc:0.88668\tvalidation_1-auc:0.83865                                                                 \n",
      "[50]\tvalidation_0-auc:0.88704\tvalidation_1-auc:0.83878                                                                 \n",
      "[51]\tvalidation_0-auc:0.88767\tvalidation_1-auc:0.83876                                                                 \n",
      "[52]\tvalidation_0-auc:0.88809\tvalidation_1-auc:0.83877                                                                 \n",
      "[53]\tvalidation_0-auc:0.88820\tvalidation_1-auc:0.83899                                                                 \n",
      "[54]\tvalidation_0-auc:0.88839\tvalidation_1-auc:0.83898                                                                 \n",
      "[55]\tvalidation_0-auc:0.88891\tvalidation_1-auc:0.83895                                                                 \n",
      "[56]\tvalidation_0-auc:0.88913\tvalidation_1-auc:0.83903                                                                 \n",
      "[57]\tvalidation_0-auc:0.88922\tvalidation_1-auc:0.83921                                                                 \n",
      "[58]\tvalidation_0-auc:0.88943\tvalidation_1-auc:0.83916                                                                 \n",
      "[59]\tvalidation_0-auc:0.88969\tvalidation_1-auc:0.83930                                                                 \n",
      "[60]\tvalidation_0-auc:0.88978\tvalidation_1-auc:0.83949                                                                 \n",
      "[61]\tvalidation_0-auc:0.88989\tvalidation_1-auc:0.83957                                                                 \n",
      "[62]\tvalidation_0-auc:0.89005\tvalidation_1-auc:0.83962                                                                 \n",
      "[63]\tvalidation_0-auc:0.89017\tvalidation_1-auc:0.83963                                                                 \n",
      "[64]\tvalidation_0-auc:0.89049\tvalidation_1-auc:0.83973                                                                 \n",
      "[65]\tvalidation_0-auc:0.89112\tvalidation_1-auc:0.83980                                                                 \n",
      "[66]\tvalidation_0-auc:0.89129\tvalidation_1-auc:0.83981                                                                 \n",
      "[67]\tvalidation_0-auc:0.89142\tvalidation_1-auc:0.83985                                                                 \n",
      "[68]\tvalidation_0-auc:0.89174\tvalidation_1-auc:0.83980                                                                 \n",
      "[69]\tvalidation_0-auc:0.89182\tvalidation_1-auc:0.83988                                                                 \n",
      "[70]\tvalidation_0-auc:0.89200\tvalidation_1-auc:0.83994                                                                 \n",
      "[71]\tvalidation_0-auc:0.89214\tvalidation_1-auc:0.84000                                                                 \n",
      "[72]\tvalidation_0-auc:0.89253\tvalidation_1-auc:0.83994                                                                 \n",
      "[73]\tvalidation_0-auc:0.89278\tvalidation_1-auc:0.84006                                                                 \n",
      "[74]\tvalidation_0-auc:0.89308\tvalidation_1-auc:0.84008                                                                 \n",
      "[75]\tvalidation_0-auc:0.89314\tvalidation_1-auc:0.84016                                                                 \n",
      "[76]\tvalidation_0-auc:0.89337\tvalidation_1-auc:0.84026                                                                 \n",
      "[77]\tvalidation_0-auc:0.89384\tvalidation_1-auc:0.84015                                                                 \n",
      "[78]\tvalidation_0-auc:0.89400\tvalidation_1-auc:0.84017                                                                 \n",
      "[79]\tvalidation_0-auc:0.89411\tvalidation_1-auc:0.84011                                                                 \n",
      "[80]\tvalidation_0-auc:0.89418\tvalidation_1-auc:0.84006                                                                 \n",
      "[81]\tvalidation_0-auc:0.89490\tvalidation_1-auc:0.84004                                                                 \n",
      "[82]\tvalidation_0-auc:0.89526\tvalidation_1-auc:0.84001                                                                 \n",
      "[83]\tvalidation_0-auc:0.89552\tvalidation_1-auc:0.83989                                                                 \n",
      "[84]\tvalidation_0-auc:0.89600\tvalidation_1-auc:0.83988                                                                 \n",
      "[85]\tvalidation_0-auc:0.89614\tvalidation_1-auc:0.83982                                                                 \n",
      "[86]\tvalidation_0-auc:0.89637\tvalidation_1-auc:0.83986                                                                 \n",
      "[87]\tvalidation_0-auc:0.89649\tvalidation_1-auc:0.83989                                                                 \n",
      "[88]\tvalidation_0-auc:0.89664\tvalidation_1-auc:0.83982                                                                 \n",
      "[89]\tvalidation_0-auc:0.89670\tvalidation_1-auc:0.83983                                                                 \n",
      "[90]\tvalidation_0-auc:0.89674\tvalidation_1-auc:0.83988                                                                 \n",
      "[91]\tvalidation_0-auc:0.89705\tvalidation_1-auc:0.83979                                                                 \n",
      "[92]\tvalidation_0-auc:0.89748\tvalidation_1-auc:0.83970                                                                 \n",
      "[93]\tvalidation_0-auc:0.89758\tvalidation_1-auc:0.83976                                                                 \n",
      "[94]\tvalidation_0-auc:0.89783\tvalidation_1-auc:0.83973                                                                 \n",
      "[95]\tvalidation_0-auc:0.89788\tvalidation_1-auc:0.83969                                                                 \n",
      "[96]\tvalidation_0-auc:0.89814\tvalidation_1-auc:0.83968                                                                 \n",
      "[97]\tvalidation_0-auc:0.89825\tvalidation_1-auc:0.83979                                                                 \n",
      "[98]\tvalidation_0-auc:0.89834\tvalidation_1-auc:0.83979                                                                 \n",
      "[99]\tvalidation_0-auc:0.89841\tvalidation_1-auc:0.83981                                                                 \n",
      "[0]\tvalidation_0-auc:0.81452\tvalidation_1-auc:0.71225                                                                  \n",
      "[1]\tvalidation_0-auc:0.84549\tvalidation_1-auc:0.74312                                                                  \n",
      "[2]\tvalidation_0-auc:0.87985\tvalidation_1-auc:0.79116                                                                  \n",
      "[3]\tvalidation_0-auc:0.88357\tvalidation_1-auc:0.78698                                                                  \n",
      "[4]\tvalidation_0-auc:0.88810\tvalidation_1-auc:0.78254                                                                  \n",
      "[5]\tvalidation_0-auc:0.89135\tvalidation_1-auc:0.78124                                                                  \n",
      "[6]\tvalidation_0-auc:0.90342\tvalidation_1-auc:0.78999                                                                  \n",
      "[7]\tvalidation_0-auc:0.90542\tvalidation_1-auc:0.79011                                                                  \n",
      "[8]\tvalidation_0-auc:0.91304\tvalidation_1-auc:0.79707                                                                  \n",
      "[9]\tvalidation_0-auc:0.91457\tvalidation_1-auc:0.79625                                                                  \n",
      "[10]\tvalidation_0-auc:0.91967\tvalidation_1-auc:0.80165                                                                 \n",
      "[11]\tvalidation_0-auc:0.92335\tvalidation_1-auc:0.80016                                                                 \n",
      "[12]\tvalidation_0-auc:0.92402\tvalidation_1-auc:0.79898                                                                 \n",
      "[13]\tvalidation_0-auc:0.92670\tvalidation_1-auc:0.79806                                                                 \n",
      "[14]\tvalidation_0-auc:0.93090\tvalidation_1-auc:0.79679                                                                 \n",
      "[15]\tvalidation_0-auc:0.93299\tvalidation_1-auc:0.79612                                                                 \n",
      "[16]\tvalidation_0-auc:0.93445\tvalidation_1-auc:0.79458                                                                 \n",
      "[17]\tvalidation_0-auc:0.93499\tvalidation_1-auc:0.79440                                                                 \n",
      "[18]\tvalidation_0-auc:0.93593\tvalidation_1-auc:0.79422                                                                 \n",
      "[19]\tvalidation_0-auc:0.93880\tvalidation_1-auc:0.79881                                                                 \n",
      "[20]\tvalidation_0-auc:0.94294\tvalidation_1-auc:0.80068                                                                 \n",
      "[21]\tvalidation_0-auc:0.94553\tvalidation_1-auc:0.80339                                                                 \n",
      "[22]\tvalidation_0-auc:0.94695\tvalidation_1-auc:0.80537                                                                 \n",
      "[23]\tvalidation_0-auc:0.94822\tvalidation_1-auc:0.80701                                                                 \n",
      "[24]\tvalidation_0-auc:0.94854\tvalidation_1-auc:0.80610                                                                 \n",
      "[25]\tvalidation_0-auc:0.95076\tvalidation_1-auc:0.80635                                                                 \n",
      "[26]\tvalidation_0-auc:0.95117\tvalidation_1-auc:0.80603                                                                 \n",
      "[27]\tvalidation_0-auc:0.95152\tvalidation_1-auc:0.80580                                                                 \n",
      "[28]\tvalidation_0-auc:0.95270\tvalidation_1-auc:0.80738                                                                 \n",
      "[29]\tvalidation_0-auc:0.95303\tvalidation_1-auc:0.80689                                                                 \n",
      "[30]\tvalidation_0-auc:0.95426\tvalidation_1-auc:0.80683                                                                 \n",
      "[31]\tvalidation_0-auc:0.95543\tvalidation_1-auc:0.80652                                                                 \n",
      "[32]\tvalidation_0-auc:0.95693\tvalidation_1-auc:0.80735                                                                 \n",
      "[33]\tvalidation_0-auc:0.95823\tvalidation_1-auc:0.80784                                                                 \n",
      "[34]\tvalidation_0-auc:0.95915\tvalidation_1-auc:0.80890                                                                 \n",
      "[35]\tvalidation_0-auc:0.96025\tvalidation_1-auc:0.80908                                                                 \n",
      "[36]\tvalidation_0-auc:0.96101\tvalidation_1-auc:0.80922                                                                 \n",
      "[37]\tvalidation_0-auc:0.96116\tvalidation_1-auc:0.80898                                                                 \n",
      "[38]\tvalidation_0-auc:0.96171\tvalidation_1-auc:0.80912                                                                 \n",
      "[39]\tvalidation_0-auc:0.96215\tvalidation_1-auc:0.80957                                                                 \n",
      "[40]\tvalidation_0-auc:0.96225\tvalidation_1-auc:0.80915                                                                 \n",
      "[41]\tvalidation_0-auc:0.96279\tvalidation_1-auc:0.80906                                                                 \n",
      "[42]\tvalidation_0-auc:0.96289\tvalidation_1-auc:0.80870                                                                 \n",
      "[43]\tvalidation_0-auc:0.96325\tvalidation_1-auc:0.80867                                                                 \n",
      "[44]\tvalidation_0-auc:0.96345\tvalidation_1-auc:0.80831                                                                 \n",
      "[45]\tvalidation_0-auc:0.96410\tvalidation_1-auc:0.80842                                                                 \n",
      "[46]\tvalidation_0-auc:0.96421\tvalidation_1-auc:0.80829                                                                 \n",
      "[47]\tvalidation_0-auc:0.96435\tvalidation_1-auc:0.80840                                                                 \n",
      "[48]\tvalidation_0-auc:0.96455\tvalidation_1-auc:0.80827                                                                 \n",
      "[49]\tvalidation_0-auc:0.96482\tvalidation_1-auc:0.80760                                                                 \n",
      "[50]\tvalidation_0-auc:0.96490\tvalidation_1-auc:0.80742                                                                 \n",
      "[51]\tvalidation_0-auc:0.96564\tvalidation_1-auc:0.80773                                                                 \n",
      "[52]\tvalidation_0-auc:0.96572\tvalidation_1-auc:0.80771                                                                 \n",
      "[53]\tvalidation_0-auc:0.96597\tvalidation_1-auc:0.80798                                                                 \n",
      "[54]\tvalidation_0-auc:0.96609\tvalidation_1-auc:0.80778                                                                 \n",
      "[55]\tvalidation_0-auc:0.96633\tvalidation_1-auc:0.80824                                                                 \n",
      "[56]\tvalidation_0-auc:0.96673\tvalidation_1-auc:0.80737                                                                 \n",
      "[57]\tvalidation_0-auc:0.96694\tvalidation_1-auc:0.80712                                                                 \n",
      "[58]\tvalidation_0-auc:0.96747\tvalidation_1-auc:0.80712                                                                 \n",
      "[59]\tvalidation_0-auc:0.96793\tvalidation_1-auc:0.80729                                                                 \n",
      "[60]\tvalidation_0-auc:0.96803\tvalidation_1-auc:0.80710                                                                 \n",
      "[61]\tvalidation_0-auc:0.96921\tvalidation_1-auc:0.80734                                                                 \n",
      "[62]\tvalidation_0-auc:0.96940\tvalidation_1-auc:0.80694                                                                 \n",
      "[63]\tvalidation_0-auc:0.96986\tvalidation_1-auc:0.80681                                                                 \n",
      "[64]\tvalidation_0-auc:0.97018\tvalidation_1-auc:0.80677                                                                 \n",
      "[65]\tvalidation_0-auc:0.97047\tvalidation_1-auc:0.80695                                                                 \n",
      "[66]\tvalidation_0-auc:0.97053\tvalidation_1-auc:0.80682                                                                 \n",
      "[67]\tvalidation_0-auc:0.97055\tvalidation_1-auc:0.80655                                                                 \n",
      "[68]\tvalidation_0-auc:0.97059\tvalidation_1-auc:0.80666                                                                 \n",
      "[69]\tvalidation_0-auc:0.97066\tvalidation_1-auc:0.80693                                                                 \n",
      "[0]\tvalidation_0-auc:0.80667\tvalidation_1-auc:0.72340                                                                  \n",
      "[1]\tvalidation_0-auc:0.84081\tvalidation_1-auc:0.75496                                                                  \n",
      "[2]\tvalidation_0-auc:0.87843\tvalidation_1-auc:0.80616                                                                  \n",
      "[3]\tvalidation_0-auc:0.88274\tvalidation_1-auc:0.80460                                                                  \n",
      "[4]\tvalidation_0-auc:0.88626\tvalidation_1-auc:0.80537                                                                  \n",
      "[5]\tvalidation_0-auc:0.89185\tvalidation_1-auc:0.80476                                                                  \n",
      "[6]\tvalidation_0-auc:0.90465\tvalidation_1-auc:0.81536                                                                  \n",
      "[7]\tvalidation_0-auc:0.90699\tvalidation_1-auc:0.81610                                                                  \n",
      "[8]\tvalidation_0-auc:0.91621\tvalidation_1-auc:0.82195                                                                  \n",
      "[9]\tvalidation_0-auc:0.91732\tvalidation_1-auc:0.82298                                                                  \n",
      "[10]\tvalidation_0-auc:0.92272\tvalidation_1-auc:0.82737                                                                 \n",
      "[11]\tvalidation_0-auc:0.92606\tvalidation_1-auc:0.82717                                                                 \n",
      "[12]\tvalidation_0-auc:0.92657\tvalidation_1-auc:0.82677                                                                 \n",
      "[13]\tvalidation_0-auc:0.93066\tvalidation_1-auc:0.82474                                                                 \n",
      "[14]\tvalidation_0-auc:0.93276\tvalidation_1-auc:0.82368                                                                 \n",
      "[15]\tvalidation_0-auc:0.93432\tvalidation_1-auc:0.82275                                                                 \n",
      "[16]\tvalidation_0-auc:0.93588\tvalidation_1-auc:0.82087                                                                 \n",
      "[17]\tvalidation_0-auc:0.93640\tvalidation_1-auc:0.82018                                                                 \n",
      "[18]\tvalidation_0-auc:0.93803\tvalidation_1-auc:0.81886                                                                 \n",
      "[19]\tvalidation_0-auc:0.94055\tvalidation_1-auc:0.82233                                                                 \n",
      "[20]\tvalidation_0-auc:0.94421\tvalidation_1-auc:0.82557                                                                 \n",
      "[21]\tvalidation_0-auc:0.94632\tvalidation_1-auc:0.82798                                                                 \n",
      "[22]\tvalidation_0-auc:0.94779\tvalidation_1-auc:0.82982                                                                 \n",
      "[23]\tvalidation_0-auc:0.94832\tvalidation_1-auc:0.83059                                                                 \n",
      "[24]\tvalidation_0-auc:0.94910\tvalidation_1-auc:0.83019                                                                 \n",
      "[25]\tvalidation_0-auc:0.95133\tvalidation_1-auc:0.83099                                                                 \n",
      "[26]\tvalidation_0-auc:0.95154\tvalidation_1-auc:0.83093                                                                 \n",
      "[27]\tvalidation_0-auc:0.95206\tvalidation_1-auc:0.82998                                                                 \n",
      "[28]\tvalidation_0-auc:0.95304\tvalidation_1-auc:0.83036                                                                 \n",
      "[29]\tvalidation_0-auc:0.95314\tvalidation_1-auc:0.82993                                                                 \n",
      "[30]\tvalidation_0-auc:0.95382\tvalidation_1-auc:0.82913                                                                 \n",
      "[31]\tvalidation_0-auc:0.95437\tvalidation_1-auc:0.82929                                                                 \n",
      "[32]\tvalidation_0-auc:0.95565\tvalidation_1-auc:0.82966                                                                 \n",
      "[33]\tvalidation_0-auc:0.95656\tvalidation_1-auc:0.82968                                                                 \n",
      "[34]\tvalidation_0-auc:0.95768\tvalidation_1-auc:0.83018                                                                 \n",
      "[35]\tvalidation_0-auc:0.95824\tvalidation_1-auc:0.83097                                                                 \n",
      "[36]\tvalidation_0-auc:0.95877\tvalidation_1-auc:0.83097                                                                 \n",
      "[37]\tvalidation_0-auc:0.95935\tvalidation_1-auc:0.83035                                                                 \n",
      "[38]\tvalidation_0-auc:0.96014\tvalidation_1-auc:0.83025                                                                 \n",
      "[39]\tvalidation_0-auc:0.96065\tvalidation_1-auc:0.83024                                                                 \n",
      "[40]\tvalidation_0-auc:0.96094\tvalidation_1-auc:0.83002                                                                 \n",
      "[41]\tvalidation_0-auc:0.96185\tvalidation_1-auc:0.82938                                                                 \n",
      "[42]\tvalidation_0-auc:0.96192\tvalidation_1-auc:0.82930                                                                 \n",
      "[43]\tvalidation_0-auc:0.96298\tvalidation_1-auc:0.82798                                                                 \n",
      "[44]\tvalidation_0-auc:0.96314\tvalidation_1-auc:0.82793                                                                 \n",
      "[45]\tvalidation_0-auc:0.96378\tvalidation_1-auc:0.82790                                                                 \n",
      "[46]\tvalidation_0-auc:0.96392\tvalidation_1-auc:0.82763                                                                 \n",
      "[47]\tvalidation_0-auc:0.96512\tvalidation_1-auc:0.82719                                                                 \n",
      "[48]\tvalidation_0-auc:0.96521\tvalidation_1-auc:0.82697                                                                 \n",
      "[49]\tvalidation_0-auc:0.96531\tvalidation_1-auc:0.82697                                                                 \n",
      "[50]\tvalidation_0-auc:0.96590\tvalidation_1-auc:0.82672                                                                 \n",
      "[51]\tvalidation_0-auc:0.96644\tvalidation_1-auc:0.82653                                                                 \n",
      "[52]\tvalidation_0-auc:0.96651\tvalidation_1-auc:0.82652                                                                 \n",
      "[53]\tvalidation_0-auc:0.96682\tvalidation_1-auc:0.82618                                                                 \n",
      "[54]\tvalidation_0-auc:0.96711\tvalidation_1-auc:0.82623                                                                 \n",
      "[55]\tvalidation_0-auc:0.96779\tvalidation_1-auc:0.82633                                                                 \n",
      "[0]\tvalidation_0-auc:0.81830\tvalidation_1-auc:0.72088                                                                  \n",
      "[1]\tvalidation_0-auc:0.84967\tvalidation_1-auc:0.75494                                                                  \n",
      "[2]\tvalidation_0-auc:0.88136\tvalidation_1-auc:0.80020                                                                  \n",
      "[3]\tvalidation_0-auc:0.88441\tvalidation_1-auc:0.79640                                                                  \n",
      "[4]\tvalidation_0-auc:0.88762\tvalidation_1-auc:0.79198                                                                  \n",
      "[5]\tvalidation_0-auc:0.89123\tvalidation_1-auc:0.79121                                                                  \n",
      "[6]\tvalidation_0-auc:0.90334\tvalidation_1-auc:0.80443                                                                  \n",
      "[7]\tvalidation_0-auc:0.90567\tvalidation_1-auc:0.80442                                                                  \n",
      "[8]\tvalidation_0-auc:0.91360\tvalidation_1-auc:0.81259                                                                  \n",
      "[9]\tvalidation_0-auc:0.91486\tvalidation_1-auc:0.81265                                                                  \n",
      "[10]\tvalidation_0-auc:0.92023\tvalidation_1-auc:0.81864                                                                 \n",
      "[11]\tvalidation_0-auc:0.92371\tvalidation_1-auc:0.81778                                                                 \n",
      "[12]\tvalidation_0-auc:0.92406\tvalidation_1-auc:0.81819                                                                 \n",
      "[13]\tvalidation_0-auc:0.92808\tvalidation_1-auc:0.81802                                                                 \n",
      "[14]\tvalidation_0-auc:0.93076\tvalidation_1-auc:0.81657                                                                 \n",
      "[15]\tvalidation_0-auc:0.93249\tvalidation_1-auc:0.81442                                                                 \n",
      "[16]\tvalidation_0-auc:0.93446\tvalidation_1-auc:0.81354                                                                 \n",
      "[17]\tvalidation_0-auc:0.93585\tvalidation_1-auc:0.81323                                                                 \n",
      "[18]\tvalidation_0-auc:0.93686\tvalidation_1-auc:0.81285                                                                 \n",
      "[19]\tvalidation_0-auc:0.93937\tvalidation_1-auc:0.81691                                                                 \n",
      "[20]\tvalidation_0-auc:0.94303\tvalidation_1-auc:0.81890                                                                 \n",
      "[21]\tvalidation_0-auc:0.94573\tvalidation_1-auc:0.82137                                                                 \n",
      "[22]\tvalidation_0-auc:0.94746\tvalidation_1-auc:0.82267                                                                 \n",
      "[23]\tvalidation_0-auc:0.94864\tvalidation_1-auc:0.82422                                                                 \n",
      "[24]\tvalidation_0-auc:0.94901\tvalidation_1-auc:0.82432                                                                 \n",
      "[25]\tvalidation_0-auc:0.95112\tvalidation_1-auc:0.82586                                                                 \n",
      "[26]\tvalidation_0-auc:0.95140\tvalidation_1-auc:0.82596                                                                 \n",
      "[27]\tvalidation_0-auc:0.95149\tvalidation_1-auc:0.82577                                                                 \n",
      "[28]\tvalidation_0-auc:0.95312\tvalidation_1-auc:0.82623                                                                 \n",
      "[29]\tvalidation_0-auc:0.95374\tvalidation_1-auc:0.82573                                                                 \n",
      "[30]\tvalidation_0-auc:0.95491\tvalidation_1-auc:0.82566                                                                 \n",
      "[31]\tvalidation_0-auc:0.95565\tvalidation_1-auc:0.82651                                                                 \n",
      "[32]\tvalidation_0-auc:0.95776\tvalidation_1-auc:0.82725                                                                 \n",
      "[33]\tvalidation_0-auc:0.95854\tvalidation_1-auc:0.82784                                                                 \n",
      "[34]\tvalidation_0-auc:0.95979\tvalidation_1-auc:0.82831                                                                 \n",
      "[35]\tvalidation_0-auc:0.96113\tvalidation_1-auc:0.82842                                                                 \n",
      "[36]\tvalidation_0-auc:0.96154\tvalidation_1-auc:0.82918                                                                 \n",
      "[37]\tvalidation_0-auc:0.96189\tvalidation_1-auc:0.82914                                                                 \n",
      "[38]\tvalidation_0-auc:0.96248\tvalidation_1-auc:0.82949                                                                 \n",
      "[39]\tvalidation_0-auc:0.96276\tvalidation_1-auc:0.82999                                                                 \n",
      "[40]\tvalidation_0-auc:0.96308\tvalidation_1-auc:0.82993                                                                 \n",
      "[41]\tvalidation_0-auc:0.96353\tvalidation_1-auc:0.83025                                                                 \n",
      "[42]\tvalidation_0-auc:0.96371\tvalidation_1-auc:0.83025                                                                 \n",
      "[43]\tvalidation_0-auc:0.96387\tvalidation_1-auc:0.83024                                                                 \n",
      "[44]\tvalidation_0-auc:0.96396\tvalidation_1-auc:0.83038                                                                 \n",
      "[45]\tvalidation_0-auc:0.96527\tvalidation_1-auc:0.82997                                                                 \n",
      "[46]\tvalidation_0-auc:0.96547\tvalidation_1-auc:0.82974                                                                 \n",
      "[47]\tvalidation_0-auc:0.96566\tvalidation_1-auc:0.82945                                                                 \n",
      "[48]\tvalidation_0-auc:0.96575\tvalidation_1-auc:0.82950                                                                 \n",
      "[49]\tvalidation_0-auc:0.96608\tvalidation_1-auc:0.82929                                                                 \n",
      "[50]\tvalidation_0-auc:0.96665\tvalidation_1-auc:0.82914                                                                 \n",
      "[51]\tvalidation_0-auc:0.96785\tvalidation_1-auc:0.82872                                                                 \n",
      "[52]\tvalidation_0-auc:0.96804\tvalidation_1-auc:0.82832                                                                 \n",
      "[53]\tvalidation_0-auc:0.96830\tvalidation_1-auc:0.82811                                                                 \n",
      "[54]\tvalidation_0-auc:0.96834\tvalidation_1-auc:0.82814                                                                 \n",
      "[55]\tvalidation_0-auc:0.96896\tvalidation_1-auc:0.82813                                                                 \n",
      "[56]\tvalidation_0-auc:0.96901\tvalidation_1-auc:0.82802                                                                 \n",
      "[57]\tvalidation_0-auc:0.96918\tvalidation_1-auc:0.82787                                                                 \n",
      "[58]\tvalidation_0-auc:0.96968\tvalidation_1-auc:0.82779                                                                 \n",
      "[59]\tvalidation_0-auc:0.97013\tvalidation_1-auc:0.82740                                                                 \n",
      "[60]\tvalidation_0-auc:0.97039\tvalidation_1-auc:0.82694                                                                 \n",
      "[61]\tvalidation_0-auc:0.97082\tvalidation_1-auc:0.82680                                                                 \n",
      "[62]\tvalidation_0-auc:0.97090\tvalidation_1-auc:0.82694                                                                 \n",
      "[63]\tvalidation_0-auc:0.97099\tvalidation_1-auc:0.82689                                                                 \n",
      "[64]\tvalidation_0-auc:0.97103\tvalidation_1-auc:0.82669                                                                 \n",
      "[65]\tvalidation_0-auc:0.97184\tvalidation_1-auc:0.82645                                                                 \n",
      "[66]\tvalidation_0-auc:0.97208\tvalidation_1-auc:0.82612                                                                 \n",
      "[67]\tvalidation_0-auc:0.97213\tvalidation_1-auc:0.82574                                                                 \n",
      "[68]\tvalidation_0-auc:0.97243\tvalidation_1-auc:0.82566                                                                 \n",
      "[69]\tvalidation_0-auc:0.97254\tvalidation_1-auc:0.82584                                                                 \n",
      "[70]\tvalidation_0-auc:0.97276\tvalidation_1-auc:0.82581                                                                 \n",
      "[71]\tvalidation_0-auc:0.97278\tvalidation_1-auc:0.82573                                                                 \n",
      "[72]\tvalidation_0-auc:0.97311\tvalidation_1-auc:0.82573                                                                 \n",
      "[73]\tvalidation_0-auc:0.97318\tvalidation_1-auc:0.82566                                                                 \n",
      "[74]\tvalidation_0-auc:0.97323\tvalidation_1-auc:0.82570                                                                 \n",
      "[0]\tvalidation_0-auc:0.85336\tvalidation_1-auc:0.80641                                                                  \n",
      "[1]\tvalidation_0-auc:0.85729\tvalidation_1-auc:0.80935                                                                  \n",
      "[2]\tvalidation_0-auc:0.86030\tvalidation_1-auc:0.81653                                                                  \n",
      "[3]\tvalidation_0-auc:0.86215\tvalidation_1-auc:0.81479                                                                  \n",
      "[4]\tvalidation_0-auc:0.86781\tvalidation_1-auc:0.81834                                                                  \n",
      "[5]\tvalidation_0-auc:0.87015\tvalidation_1-auc:0.81961                                                                  \n",
      "[6]\tvalidation_0-auc:0.87150\tvalidation_1-auc:0.82071                                                                  \n",
      "[7]\tvalidation_0-auc:0.87280\tvalidation_1-auc:0.82229                                                                  \n",
      "[8]\tvalidation_0-auc:0.87477\tvalidation_1-auc:0.82173                                                                  \n",
      "[9]\tvalidation_0-auc:0.87545\tvalidation_1-auc:0.81923                                                                  \n",
      "[10]\tvalidation_0-auc:0.87714\tvalidation_1-auc:0.82013                                                                 \n",
      "[11]\tvalidation_0-auc:0.87861\tvalidation_1-auc:0.82119                                                                 \n",
      "[12]\tvalidation_0-auc:0.88010\tvalidation_1-auc:0.82137                                                                 \n",
      "[13]\tvalidation_0-auc:0.88157\tvalidation_1-auc:0.82136                                                                 \n",
      "[14]\tvalidation_0-auc:0.88267\tvalidation_1-auc:0.81986                                                                 \n",
      "[15]\tvalidation_0-auc:0.88388\tvalidation_1-auc:0.82002                                                                 \n",
      "[16]\tvalidation_0-auc:0.88464\tvalidation_1-auc:0.82002                                                                 \n",
      "[17]\tvalidation_0-auc:0.88514\tvalidation_1-auc:0.81968                                                                 \n",
      "[18]\tvalidation_0-auc:0.88594\tvalidation_1-auc:0.81967                                                                 \n",
      "[19]\tvalidation_0-auc:0.88673\tvalidation_1-auc:0.81993                                                                 \n",
      "[20]\tvalidation_0-auc:0.88782\tvalidation_1-auc:0.82020                                                                 \n",
      "[21]\tvalidation_0-auc:0.88834\tvalidation_1-auc:0.82013                                                                 \n",
      "[22]\tvalidation_0-auc:0.88913\tvalidation_1-auc:0.82026                                                                 \n",
      "[23]\tvalidation_0-auc:0.88961\tvalidation_1-auc:0.82056                                                                 \n",
      "[24]\tvalidation_0-auc:0.89033\tvalidation_1-auc:0.82027                                                                 \n",
      "[25]\tvalidation_0-auc:0.89112\tvalidation_1-auc:0.82069                                                                 \n",
      "[26]\tvalidation_0-auc:0.89170\tvalidation_1-auc:0.82126                                                                 \n",
      "[27]\tvalidation_0-auc:0.89235\tvalidation_1-auc:0.82133                                                                 \n",
      "[28]\tvalidation_0-auc:0.89292\tvalidation_1-auc:0.82149                                                                 \n",
      "[29]\tvalidation_0-auc:0.89325\tvalidation_1-auc:0.82167                                                                 \n",
      "[30]\tvalidation_0-auc:0.89402\tvalidation_1-auc:0.82182                                                                 \n",
      "[31]\tvalidation_0-auc:0.89480\tvalidation_1-auc:0.82170                                                                 \n",
      "[32]\tvalidation_0-auc:0.89486\tvalidation_1-auc:0.82180                                                                 \n",
      "[33]\tvalidation_0-auc:0.89506\tvalidation_1-auc:0.82187                                                                 \n",
      "[34]\tvalidation_0-auc:0.89568\tvalidation_1-auc:0.82198                                                                 \n",
      "[35]\tvalidation_0-auc:0.89590\tvalidation_1-auc:0.82186                                                                 \n",
      "[36]\tvalidation_0-auc:0.89606\tvalidation_1-auc:0.82205                                                                 \n",
      "[37]\tvalidation_0-auc:0.89629\tvalidation_1-auc:0.82227                                                                 \n",
      "[0]\tvalidation_0-auc:0.84670\tvalidation_1-auc:0.81666                                                                  \n",
      "[1]\tvalidation_0-auc:0.85230\tvalidation_1-auc:0.82484                                                                  \n",
      "[2]\tvalidation_0-auc:0.85662\tvalidation_1-auc:0.83080                                                                  \n",
      "[3]\tvalidation_0-auc:0.86015\tvalidation_1-auc:0.83664                                                                  \n",
      "[4]\tvalidation_0-auc:0.86567\tvalidation_1-auc:0.83723                                                                  \n",
      "[5]\tvalidation_0-auc:0.86815\tvalidation_1-auc:0.83836                                                                  \n",
      "[6]\tvalidation_0-auc:0.86908\tvalidation_1-auc:0.83780                                                                  \n",
      "[7]\tvalidation_0-auc:0.87078\tvalidation_1-auc:0.83723                                                                  \n",
      "[8]\tvalidation_0-auc:0.87258\tvalidation_1-auc:0.83736                                                                  \n",
      "[9]\tvalidation_0-auc:0.87341\tvalidation_1-auc:0.83780                                                                  \n",
      "[10]\tvalidation_0-auc:0.87433\tvalidation_1-auc:0.83925                                                                 \n",
      "[11]\tvalidation_0-auc:0.87585\tvalidation_1-auc:0.83954                                                                 \n",
      "[12]\tvalidation_0-auc:0.87722\tvalidation_1-auc:0.83915                                                                 \n",
      "[13]\tvalidation_0-auc:0.87856\tvalidation_1-auc:0.83925                                                                 \n",
      "[14]\tvalidation_0-auc:0.87889\tvalidation_1-auc:0.84020                                                                 \n",
      "[15]\tvalidation_0-auc:0.88046\tvalidation_1-auc:0.84007                                                                 \n",
      "[16]\tvalidation_0-auc:0.88195\tvalidation_1-auc:0.83990                                                                 \n",
      "[17]\tvalidation_0-auc:0.88258\tvalidation_1-auc:0.84010                                                                 \n",
      "[18]\tvalidation_0-auc:0.88418\tvalidation_1-auc:0.84015                                                                 \n",
      "[19]\tvalidation_0-auc:0.88525\tvalidation_1-auc:0.84025                                                                 \n",
      "[20]\tvalidation_0-auc:0.88597\tvalidation_1-auc:0.84014                                                                 \n",
      "[21]\tvalidation_0-auc:0.88709\tvalidation_1-auc:0.84022                                                                 \n",
      "[22]\tvalidation_0-auc:0.88781\tvalidation_1-auc:0.84042                                                                 \n",
      "[23]\tvalidation_0-auc:0.88817\tvalidation_1-auc:0.84061                                                                 \n",
      "[24]\tvalidation_0-auc:0.88868\tvalidation_1-auc:0.84080                                                                 \n",
      "[25]\tvalidation_0-auc:0.88918\tvalidation_1-auc:0.84112                                                                 \n",
      "[26]\tvalidation_0-auc:0.89003\tvalidation_1-auc:0.84085                                                                 \n",
      "[27]\tvalidation_0-auc:0.89099\tvalidation_1-auc:0.84150                                                                 \n",
      "[28]\tvalidation_0-auc:0.89136\tvalidation_1-auc:0.84168                                                                 \n",
      "[29]\tvalidation_0-auc:0.89174\tvalidation_1-auc:0.84183                                                                 \n",
      "[30]\tvalidation_0-auc:0.89243\tvalidation_1-auc:0.84195                                                                 \n",
      "[31]\tvalidation_0-auc:0.89285\tvalidation_1-auc:0.84191                                                                 \n",
      "[32]\tvalidation_0-auc:0.89304\tvalidation_1-auc:0.84178                                                                 \n",
      "[33]\tvalidation_0-auc:0.89331\tvalidation_1-auc:0.84175                                                                 \n",
      "[34]\tvalidation_0-auc:0.89371\tvalidation_1-auc:0.84200                                                                 \n",
      "[35]\tvalidation_0-auc:0.89434\tvalidation_1-auc:0.84181                                                                 \n",
      "[36]\tvalidation_0-auc:0.89444\tvalidation_1-auc:0.84171                                                                 \n",
      "[37]\tvalidation_0-auc:0.89509\tvalidation_1-auc:0.84158                                                                 \n",
      "[38]\tvalidation_0-auc:0.89531\tvalidation_1-auc:0.84123                                                                 \n",
      "[39]\tvalidation_0-auc:0.89543\tvalidation_1-auc:0.84114                                                                 \n",
      "[40]\tvalidation_0-auc:0.89602\tvalidation_1-auc:0.84092                                                                 \n",
      "[41]\tvalidation_0-auc:0.89632\tvalidation_1-auc:0.84080                                                                 \n",
      "[42]\tvalidation_0-auc:0.89629\tvalidation_1-auc:0.84068                                                                 \n",
      "[43]\tvalidation_0-auc:0.89705\tvalidation_1-auc:0.84064                                                                 \n",
      "[44]\tvalidation_0-auc:0.89779\tvalidation_1-auc:0.84086                                                                 \n",
      "[45]\tvalidation_0-auc:0.89805\tvalidation_1-auc:0.84078                                                                 \n",
      "[46]\tvalidation_0-auc:0.89824\tvalidation_1-auc:0.84083                                                                 \n",
      "[47]\tvalidation_0-auc:0.89848\tvalidation_1-auc:0.84091                                                                 \n",
      "[48]\tvalidation_0-auc:0.89868\tvalidation_1-auc:0.84100                                                                 \n",
      "[49]\tvalidation_0-auc:0.89902\tvalidation_1-auc:0.84112                                                                 \n",
      "[50]\tvalidation_0-auc:0.89931\tvalidation_1-auc:0.84124                                                                 \n",
      "[51]\tvalidation_0-auc:0.89956\tvalidation_1-auc:0.84108                                                                 \n",
      "[52]\tvalidation_0-auc:0.89982\tvalidation_1-auc:0.84098                                                                 \n",
      "[53]\tvalidation_0-auc:0.90016\tvalidation_1-auc:0.84098                                                                 \n",
      "[54]\tvalidation_0-auc:0.90035\tvalidation_1-auc:0.84077                                                                 \n",
      "[55]\tvalidation_0-auc:0.90043\tvalidation_1-auc:0.84054                                                                 \n",
      "[56]\tvalidation_0-auc:0.90069\tvalidation_1-auc:0.84049                                                                 \n",
      "[57]\tvalidation_0-auc:0.90090\tvalidation_1-auc:0.84034                                                                 \n",
      "[58]\tvalidation_0-auc:0.90126\tvalidation_1-auc:0.84043                                                                 \n",
      "[59]\tvalidation_0-auc:0.90135\tvalidation_1-auc:0.84043                                                                 \n",
      "[60]\tvalidation_0-auc:0.90211\tvalidation_1-auc:0.84036                                                                 \n",
      "[61]\tvalidation_0-auc:0.90256\tvalidation_1-auc:0.84017                                                                 \n",
      "[62]\tvalidation_0-auc:0.90288\tvalidation_1-auc:0.84006                                                                 \n",
      "[63]\tvalidation_0-auc:0.90300\tvalidation_1-auc:0.84017                                                                 \n",
      "[64]\tvalidation_0-auc:0.90324\tvalidation_1-auc:0.84043                                                                 \n",
      "[0]\tvalidation_0-auc:0.84591\tvalidation_1-auc:0.81393                                                                  \n",
      "[1]\tvalidation_0-auc:0.85232\tvalidation_1-auc:0.82299                                                                  \n",
      "[2]\tvalidation_0-auc:0.85523\tvalidation_1-auc:0.82955                                                                  \n",
      "[3]\tvalidation_0-auc:0.85736\tvalidation_1-auc:0.82607                                                                  \n",
      "[4]\tvalidation_0-auc:0.86167\tvalidation_1-auc:0.82973                                                                  \n",
      "[5]\tvalidation_0-auc:0.86592\tvalidation_1-auc:0.83121                                                                  \n",
      "[6]\tvalidation_0-auc:0.86906\tvalidation_1-auc:0.83235                                                                  \n",
      "[7]\tvalidation_0-auc:0.87083\tvalidation_1-auc:0.83256                                                                  \n",
      "[8]\tvalidation_0-auc:0.87167\tvalidation_1-auc:0.83330                                                                  \n",
      "[9]\tvalidation_0-auc:0.87319\tvalidation_1-auc:0.83320                                                                  \n",
      "[10]\tvalidation_0-auc:0.87448\tvalidation_1-auc:0.83393                                                                 \n",
      "[11]\tvalidation_0-auc:0.87623\tvalidation_1-auc:0.83424                                                                 \n",
      "[12]\tvalidation_0-auc:0.87736\tvalidation_1-auc:0.83498                                                                 \n",
      "[13]\tvalidation_0-auc:0.87903\tvalidation_1-auc:0.83526                                                                 \n",
      "[14]\tvalidation_0-auc:0.87954\tvalidation_1-auc:0.83524                                                                 \n",
      "[15]\tvalidation_0-auc:0.88080\tvalidation_1-auc:0.83494                                                                 \n",
      "[16]\tvalidation_0-auc:0.88151\tvalidation_1-auc:0.83557                                                                 \n",
      "[17]\tvalidation_0-auc:0.88331\tvalidation_1-auc:0.83568                                                                 \n",
      "[18]\tvalidation_0-auc:0.88429\tvalidation_1-auc:0.83577                                                                 \n",
      "[19]\tvalidation_0-auc:0.88517\tvalidation_1-auc:0.83613                                                                 \n",
      "[20]\tvalidation_0-auc:0.88609\tvalidation_1-auc:0.83592                                                                 \n",
      "[21]\tvalidation_0-auc:0.88675\tvalidation_1-auc:0.83619                                                                 \n",
      "[22]\tvalidation_0-auc:0.88773\tvalidation_1-auc:0.83648                                                                 \n",
      "[23]\tvalidation_0-auc:0.88832\tvalidation_1-auc:0.83654                                                                 \n",
      "[24]\tvalidation_0-auc:0.88935\tvalidation_1-auc:0.83671                                                                 \n",
      "[25]\tvalidation_0-auc:0.88988\tvalidation_1-auc:0.83733                                                                 \n",
      "[26]\tvalidation_0-auc:0.89054\tvalidation_1-auc:0.83732                                                                 \n",
      "[27]\tvalidation_0-auc:0.89159\tvalidation_1-auc:0.83743                                                                 \n",
      "[28]\tvalidation_0-auc:0.89223\tvalidation_1-auc:0.83738                                                                 \n",
      "[29]\tvalidation_0-auc:0.89270\tvalidation_1-auc:0.83739                                                                 \n",
      "[30]\tvalidation_0-auc:0.89346\tvalidation_1-auc:0.83749                                                                 \n",
      "[31]\tvalidation_0-auc:0.89416\tvalidation_1-auc:0.83752                                                                 \n",
      "[32]\tvalidation_0-auc:0.89502\tvalidation_1-auc:0.83759                                                                 \n",
      "[33]\tvalidation_0-auc:0.89536\tvalidation_1-auc:0.83766                                                                 \n",
      "[34]\tvalidation_0-auc:0.89572\tvalidation_1-auc:0.83805                                                                 \n",
      "[35]\tvalidation_0-auc:0.89660\tvalidation_1-auc:0.83792                                                                 \n",
      "[36]\tvalidation_0-auc:0.89705\tvalidation_1-auc:0.83828                                                                 \n",
      "[37]\tvalidation_0-auc:0.89801\tvalidation_1-auc:0.83837                                                                 \n",
      "[38]\tvalidation_0-auc:0.89823\tvalidation_1-auc:0.83856                                                                 \n",
      "[39]\tvalidation_0-auc:0.89861\tvalidation_1-auc:0.83871                                                                 \n",
      "[40]\tvalidation_0-auc:0.89897\tvalidation_1-auc:0.83865                                                                 \n",
      "[41]\tvalidation_0-auc:0.89919\tvalidation_1-auc:0.83885                                                                 \n",
      "[42]\tvalidation_0-auc:0.89940\tvalidation_1-auc:0.83876                                                                 \n",
      "[43]\tvalidation_0-auc:0.89990\tvalidation_1-auc:0.83854                                                                 \n",
      "[44]\tvalidation_0-auc:0.90015\tvalidation_1-auc:0.83861                                                                 \n",
      "[45]\tvalidation_0-auc:0.90091\tvalidation_1-auc:0.83863                                                                 \n",
      "[46]\tvalidation_0-auc:0.90103\tvalidation_1-auc:0.83888                                                                 \n",
      "[47]\tvalidation_0-auc:0.90127\tvalidation_1-auc:0.83881                                                                 \n",
      "[48]\tvalidation_0-auc:0.90156\tvalidation_1-auc:0.83880                                                                 \n",
      "[49]\tvalidation_0-auc:0.90174\tvalidation_1-auc:0.83859                                                                 \n",
      "[50]\tvalidation_0-auc:0.90235\tvalidation_1-auc:0.83822                                                                 \n",
      "[51]\tvalidation_0-auc:0.90250\tvalidation_1-auc:0.83831                                                                 \n",
      "[52]\tvalidation_0-auc:0.90304\tvalidation_1-auc:0.83820                                                                 \n",
      "[53]\tvalidation_0-auc:0.90319\tvalidation_1-auc:0.83819                                                                 \n",
      "[54]\tvalidation_0-auc:0.90339\tvalidation_1-auc:0.83816                                                                 \n",
      "[55]\tvalidation_0-auc:0.90375\tvalidation_1-auc:0.83840                                                                 \n",
      "[56]\tvalidation_0-auc:0.90404\tvalidation_1-auc:0.83837                                                                 \n",
      "[57]\tvalidation_0-auc:0.90412\tvalidation_1-auc:0.83844                                                                 \n",
      "[58]\tvalidation_0-auc:0.90446\tvalidation_1-auc:0.83851                                                                 \n",
      "[59]\tvalidation_0-auc:0.90513\tvalidation_1-auc:0.83834                                                                 \n",
      "[60]\tvalidation_0-auc:0.90600\tvalidation_1-auc:0.83797                                                                 \n",
      "[61]\tvalidation_0-auc:0.90631\tvalidation_1-auc:0.83800                                                                 \n",
      "[62]\tvalidation_0-auc:0.90641\tvalidation_1-auc:0.83799                                                                 \n",
      "[63]\tvalidation_0-auc:0.90648\tvalidation_1-auc:0.83798                                                                 \n",
      "[64]\tvalidation_0-auc:0.90682\tvalidation_1-auc:0.83781                                                                 \n",
      "[65]\tvalidation_0-auc:0.90748\tvalidation_1-auc:0.83753                                                                 \n",
      "[66]\tvalidation_0-auc:0.90764\tvalidation_1-auc:0.83746                                                                 \n",
      "[67]\tvalidation_0-auc:0.90772\tvalidation_1-auc:0.83748                                                                 \n",
      "[68]\tvalidation_0-auc:0.90778\tvalidation_1-auc:0.83752                                                                 \n",
      "[69]\tvalidation_0-auc:0.90786\tvalidation_1-auc:0.83759                                                                 \n",
      "[70]\tvalidation_0-auc:0.90799\tvalidation_1-auc:0.83759                                                                 \n",
      "[71]\tvalidation_0-auc:0.90821\tvalidation_1-auc:0.83745                                                                 \n",
      "[72]\tvalidation_0-auc:0.90832\tvalidation_1-auc:0.83751                                                                 \n",
      "[73]\tvalidation_0-auc:0.90888\tvalidation_1-auc:0.83745                                                                 \n",
      "[74]\tvalidation_0-auc:0.90924\tvalidation_1-auc:0.83742                                                                 \n",
      "[75]\tvalidation_0-auc:0.90966\tvalidation_1-auc:0.83732                                                                 \n",
      "[76]\tvalidation_0-auc:0.90978\tvalidation_1-auc:0.83731                                                                 \n",
      "[0]\tvalidation_0-auc:0.89709\tvalidation_1-auc:0.79264                                                                  \n",
      "[1]\tvalidation_0-auc:0.90688\tvalidation_1-auc:0.80112                                                                  \n",
      "[2]\tvalidation_0-auc:0.91148\tvalidation_1-auc:0.81066                                                                  \n",
      "[3]\tvalidation_0-auc:0.91557\tvalidation_1-auc:0.81196                                                                  \n",
      "[4]\tvalidation_0-auc:0.91950\tvalidation_1-auc:0.80835                                                                  \n",
      "[5]\tvalidation_0-auc:0.92454\tvalidation_1-auc:0.80917                                                                  \n",
      "[6]\tvalidation_0-auc:0.92987\tvalidation_1-auc:0.81081                                                                  \n",
      "[7]\tvalidation_0-auc:0.93403\tvalidation_1-auc:0.81207                                                                  \n",
      "[8]\tvalidation_0-auc:0.93770\tvalidation_1-auc:0.81090                                                                  \n",
      "[9]\tvalidation_0-auc:0.94124\tvalidation_1-auc:0.81051                                                                  \n",
      "[10]\tvalidation_0-auc:0.94311\tvalidation_1-auc:0.81017                                                                 \n",
      "[11]\tvalidation_0-auc:0.94498\tvalidation_1-auc:0.80964                                                                 \n",
      "[12]\tvalidation_0-auc:0.94699\tvalidation_1-auc:0.80978                                                                 \n",
      "[13]\tvalidation_0-auc:0.94852\tvalidation_1-auc:0.81095                                                                 \n",
      "[14]\tvalidation_0-auc:0.95040\tvalidation_1-auc:0.81134                                                                 \n",
      "[15]\tvalidation_0-auc:0.95189\tvalidation_1-auc:0.81144                                                                 \n",
      "[16]\tvalidation_0-auc:0.95359\tvalidation_1-auc:0.81169                                                                 \n",
      "[17]\tvalidation_0-auc:0.95492\tvalidation_1-auc:0.81146                                                                 \n",
      "[18]\tvalidation_0-auc:0.95619\tvalidation_1-auc:0.81167                                                                 \n",
      "[19]\tvalidation_0-auc:0.95755\tvalidation_1-auc:0.81187                                                                 \n",
      "[20]\tvalidation_0-auc:0.95920\tvalidation_1-auc:0.81153                                                                 \n",
      "[21]\tvalidation_0-auc:0.95996\tvalidation_1-auc:0.81168                                                                 \n",
      "[22]\tvalidation_0-auc:0.96058\tvalidation_1-auc:0.81248                                                                 \n",
      "[23]\tvalidation_0-auc:0.96082\tvalidation_1-auc:0.81254                                                                 \n",
      "[24]\tvalidation_0-auc:0.96168\tvalidation_1-auc:0.81249                                                                 \n",
      "[25]\tvalidation_0-auc:0.96217\tvalidation_1-auc:0.81326                                                                 \n",
      "[26]\tvalidation_0-auc:0.96241\tvalidation_1-auc:0.81343                                                                 \n",
      "[27]\tvalidation_0-auc:0.96300\tvalidation_1-auc:0.81344                                                                 \n",
      "[28]\tvalidation_0-auc:0.96350\tvalidation_1-auc:0.81361                                                                 \n",
      "[29]\tvalidation_0-auc:0.96402\tvalidation_1-auc:0.81388                                                                 \n",
      "[30]\tvalidation_0-auc:0.96450\tvalidation_1-auc:0.81314                                                                 \n",
      "[31]\tvalidation_0-auc:0.96527\tvalidation_1-auc:0.81340                                                                 \n",
      "[32]\tvalidation_0-auc:0.96562\tvalidation_1-auc:0.81374                                                                 \n",
      "[33]\tvalidation_0-auc:0.96594\tvalidation_1-auc:0.81417                                                                 \n",
      "[34]\tvalidation_0-auc:0.96630\tvalidation_1-auc:0.81440                                                                 \n",
      "[35]\tvalidation_0-auc:0.96664\tvalidation_1-auc:0.81468                                                                 \n",
      "[36]\tvalidation_0-auc:0.96674\tvalidation_1-auc:0.81484                                                                 \n",
      "[37]\tvalidation_0-auc:0.96696\tvalidation_1-auc:0.81477                                                                 \n",
      "[38]\tvalidation_0-auc:0.96737\tvalidation_1-auc:0.81480                                                                 \n",
      "[39]\tvalidation_0-auc:0.96764\tvalidation_1-auc:0.81463                                                                 \n",
      "[40]\tvalidation_0-auc:0.96769\tvalidation_1-auc:0.81440                                                                 \n",
      "[41]\tvalidation_0-auc:0.96809\tvalidation_1-auc:0.81414                                                                 \n",
      "[42]\tvalidation_0-auc:0.96816\tvalidation_1-auc:0.81406                                                                 \n",
      "[43]\tvalidation_0-auc:0.96816\tvalidation_1-auc:0.81385                                                                 \n",
      "[44]\tvalidation_0-auc:0.96827\tvalidation_1-auc:0.81389                                                                 \n",
      "[45]\tvalidation_0-auc:0.96845\tvalidation_1-auc:0.81394                                                                 \n",
      "[46]\tvalidation_0-auc:0.96858\tvalidation_1-auc:0.81398                                                                 \n",
      "[47]\tvalidation_0-auc:0.96885\tvalidation_1-auc:0.81383                                                                 \n",
      "[48]\tvalidation_0-auc:0.96902\tvalidation_1-auc:0.81384                                                                 \n",
      "[49]\tvalidation_0-auc:0.96904\tvalidation_1-auc:0.81370                                                                 \n",
      "[50]\tvalidation_0-auc:0.96937\tvalidation_1-auc:0.81381                                                                 \n",
      "[51]\tvalidation_0-auc:0.96954\tvalidation_1-auc:0.81389                                                                 \n",
      "[52]\tvalidation_0-auc:0.96959\tvalidation_1-auc:0.81381                                                                 \n",
      "[53]\tvalidation_0-auc:0.96960\tvalidation_1-auc:0.81378                                                                 \n",
      "[54]\tvalidation_0-auc:0.96963\tvalidation_1-auc:0.81378                                                                 \n",
      "[55]\tvalidation_0-auc:0.97008\tvalidation_1-auc:0.81375                                                                 \n",
      "[56]\tvalidation_0-auc:0.97059\tvalidation_1-auc:0.81360                                                                 \n",
      "[57]\tvalidation_0-auc:0.97069\tvalidation_1-auc:0.81340                                                                 \n",
      "[58]\tvalidation_0-auc:0.97080\tvalidation_1-auc:0.81318                                                                 \n",
      "[59]\tvalidation_0-auc:0.97097\tvalidation_1-auc:0.81302                                                                 \n",
      "[60]\tvalidation_0-auc:0.97099\tvalidation_1-auc:0.81277                                                                 \n",
      "[61]\tvalidation_0-auc:0.97101\tvalidation_1-auc:0.81288                                                                 \n",
      "[62]\tvalidation_0-auc:0.97105\tvalidation_1-auc:0.81280                                                                 \n",
      "[63]\tvalidation_0-auc:0.97128\tvalidation_1-auc:0.81282                                                                 \n",
      "[64]\tvalidation_0-auc:0.97136\tvalidation_1-auc:0.81273                                                                 \n",
      "[65]\tvalidation_0-auc:0.97147\tvalidation_1-auc:0.81276                                                                 \n",
      "[66]\tvalidation_0-auc:0.97184\tvalidation_1-auc:0.81254                                                                 \n",
      "[0]\tvalidation_0-auc:0.89238\tvalidation_1-auc:0.79003                                                                  \n",
      "[1]\tvalidation_0-auc:0.90217\tvalidation_1-auc:0.80713                                                                  \n",
      "[2]\tvalidation_0-auc:0.91025\tvalidation_1-auc:0.81877                                                                  \n",
      "[3]\tvalidation_0-auc:0.91439\tvalidation_1-auc:0.81976                                                                  \n",
      "[4]\tvalidation_0-auc:0.92109\tvalidation_1-auc:0.82077                                                                  \n",
      "[5]\tvalidation_0-auc:0.92610\tvalidation_1-auc:0.82153                                                                  \n",
      "[6]\tvalidation_0-auc:0.93120\tvalidation_1-auc:0.82286                                                                  \n",
      "[7]\tvalidation_0-auc:0.93436\tvalidation_1-auc:0.82353                                                                  \n",
      "[8]\tvalidation_0-auc:0.93836\tvalidation_1-auc:0.82399                                                                  \n",
      "[9]\tvalidation_0-auc:0.94139\tvalidation_1-auc:0.82657                                                                  \n",
      "[10]\tvalidation_0-auc:0.94397\tvalidation_1-auc:0.82741                                                                 \n",
      "[11]\tvalidation_0-auc:0.94700\tvalidation_1-auc:0.82828                                                                 \n",
      "[12]\tvalidation_0-auc:0.94918\tvalidation_1-auc:0.82770                                                                 \n",
      "[13]\tvalidation_0-auc:0.95092\tvalidation_1-auc:0.82736                                                                 \n",
      "[14]\tvalidation_0-auc:0.95215\tvalidation_1-auc:0.82656                                                                 \n",
      "[15]\tvalidation_0-auc:0.95417\tvalidation_1-auc:0.82577                                                                 \n",
      "[16]\tvalidation_0-auc:0.95599\tvalidation_1-auc:0.82520                                                                 \n",
      "[17]\tvalidation_0-auc:0.95735\tvalidation_1-auc:0.82556                                                                 \n",
      "[18]\tvalidation_0-auc:0.95875\tvalidation_1-auc:0.82587                                                                 \n",
      "[19]\tvalidation_0-auc:0.95957\tvalidation_1-auc:0.82638                                                                 \n",
      "[20]\tvalidation_0-auc:0.96045\tvalidation_1-auc:0.82651                                                                 \n",
      "[21]\tvalidation_0-auc:0.96122\tvalidation_1-auc:0.82697                                                                 \n",
      "[22]\tvalidation_0-auc:0.96172\tvalidation_1-auc:0.82673                                                                 \n",
      "[23]\tvalidation_0-auc:0.96199\tvalidation_1-auc:0.82723                                                                 \n",
      "[24]\tvalidation_0-auc:0.96234\tvalidation_1-auc:0.82749                                                                 \n",
      "[25]\tvalidation_0-auc:0.96279\tvalidation_1-auc:0.82724                                                                 \n",
      "[26]\tvalidation_0-auc:0.96369\tvalidation_1-auc:0.82651                                                                 \n",
      "[27]\tvalidation_0-auc:0.96432\tvalidation_1-auc:0.82672                                                                 \n",
      "[28]\tvalidation_0-auc:0.96457\tvalidation_1-auc:0.82718                                                                 \n",
      "[29]\tvalidation_0-auc:0.96558\tvalidation_1-auc:0.82698                                                                 \n",
      "[30]\tvalidation_0-auc:0.96630\tvalidation_1-auc:0.82700                                                                 \n",
      "[31]\tvalidation_0-auc:0.96660\tvalidation_1-auc:0.82688                                                                 \n",
      "[32]\tvalidation_0-auc:0.96702\tvalidation_1-auc:0.82682                                                                 \n",
      "[33]\tvalidation_0-auc:0.96738\tvalidation_1-auc:0.82659                                                                 \n",
      "[34]\tvalidation_0-auc:0.96760\tvalidation_1-auc:0.82670                                                                 \n",
      "[35]\tvalidation_0-auc:0.96784\tvalidation_1-auc:0.82674                                                                 \n",
      "[36]\tvalidation_0-auc:0.96792\tvalidation_1-auc:0.82657                                                                 \n",
      "[37]\tvalidation_0-auc:0.96826\tvalidation_1-auc:0.82627                                                                 \n",
      "[38]\tvalidation_0-auc:0.96861\tvalidation_1-auc:0.82649                                                                 \n",
      "[39]\tvalidation_0-auc:0.96875\tvalidation_1-auc:0.82647                                                                 \n",
      "[40]\tvalidation_0-auc:0.96897\tvalidation_1-auc:0.82663                                                                 \n",
      "[41]\tvalidation_0-auc:0.96948\tvalidation_1-auc:0.82638                                                                 \n",
      "[0]\tvalidation_0-auc:0.89076\tvalidation_1-auc:0.79521                                                                  \n",
      "[1]\tvalidation_0-auc:0.90118\tvalidation_1-auc:0.81219                                                                  \n",
      "[2]\tvalidation_0-auc:0.90696\tvalidation_1-auc:0.82398                                                                  \n",
      "[3]\tvalidation_0-auc:0.91329\tvalidation_1-auc:0.82555                                                                  \n",
      "[4]\tvalidation_0-auc:0.91817\tvalidation_1-auc:0.82629                                                                  \n",
      "[5]\tvalidation_0-auc:0.92119\tvalidation_1-auc:0.82605                                                                  \n",
      "[6]\tvalidation_0-auc:0.92495\tvalidation_1-auc:0.82661                                                                  \n",
      "[7]\tvalidation_0-auc:0.92777\tvalidation_1-auc:0.82600                                                                  \n",
      "[8]\tvalidation_0-auc:0.93117\tvalidation_1-auc:0.82578                                                                  \n",
      "[9]\tvalidation_0-auc:0.93539\tvalidation_1-auc:0.82532                                                                  \n",
      "[10]\tvalidation_0-auc:0.93890\tvalidation_1-auc:0.82575                                                                 \n",
      "[11]\tvalidation_0-auc:0.94202\tvalidation_1-auc:0.82574                                                                 \n",
      "[12]\tvalidation_0-auc:0.94446\tvalidation_1-auc:0.82630                                                                 \n",
      "[13]\tvalidation_0-auc:0.94663\tvalidation_1-auc:0.82658                                                                 \n",
      "[14]\tvalidation_0-auc:0.94825\tvalidation_1-auc:0.82703                                                                 \n",
      "[15]\tvalidation_0-auc:0.94947\tvalidation_1-auc:0.82757                                                                 \n",
      "[16]\tvalidation_0-auc:0.95036\tvalidation_1-auc:0.82794                                                                 \n",
      "[17]\tvalidation_0-auc:0.95254\tvalidation_1-auc:0.82801                                                                 \n",
      "[18]\tvalidation_0-auc:0.95404\tvalidation_1-auc:0.82795                                                                 \n",
      "[19]\tvalidation_0-auc:0.95519\tvalidation_1-auc:0.82806                                                                 \n",
      "[20]\tvalidation_0-auc:0.95603\tvalidation_1-auc:0.82795                                                                 \n",
      "[21]\tvalidation_0-auc:0.95755\tvalidation_1-auc:0.82807                                                                 \n",
      "[22]\tvalidation_0-auc:0.95873\tvalidation_1-auc:0.82802                                                                 \n",
      "[23]\tvalidation_0-auc:0.95915\tvalidation_1-auc:0.82828                                                                 \n",
      "[24]\tvalidation_0-auc:0.95965\tvalidation_1-auc:0.82851                                                                 \n",
      "[25]\tvalidation_0-auc:0.96032\tvalidation_1-auc:0.82841                                                                 \n",
      "[26]\tvalidation_0-auc:0.96146\tvalidation_1-auc:0.82922                                                                 \n",
      "[27]\tvalidation_0-auc:0.96207\tvalidation_1-auc:0.82947                                                                 \n",
      "[28]\tvalidation_0-auc:0.96259\tvalidation_1-auc:0.82945                                                                 \n",
      "[29]\tvalidation_0-auc:0.96378\tvalidation_1-auc:0.82936                                                                 \n",
      "[30]\tvalidation_0-auc:0.96430\tvalidation_1-auc:0.82915                                                                 \n",
      "[31]\tvalidation_0-auc:0.96483\tvalidation_1-auc:0.82988                                                                 \n",
      "[32]\tvalidation_0-auc:0.96533\tvalidation_1-auc:0.83046                                                                 \n",
      "[33]\tvalidation_0-auc:0.96562\tvalidation_1-auc:0.83061                                                                 \n",
      "[34]\tvalidation_0-auc:0.96636\tvalidation_1-auc:0.83093                                                                 \n",
      "[35]\tvalidation_0-auc:0.96674\tvalidation_1-auc:0.83110                                                                 \n",
      "[36]\tvalidation_0-auc:0.96732\tvalidation_1-auc:0.83100                                                                 \n",
      "[37]\tvalidation_0-auc:0.96748\tvalidation_1-auc:0.83134                                                                 \n",
      "[38]\tvalidation_0-auc:0.96776\tvalidation_1-auc:0.83128                                                                 \n",
      "[39]\tvalidation_0-auc:0.96799\tvalidation_1-auc:0.83126                                                                 \n",
      "[40]\tvalidation_0-auc:0.96812\tvalidation_1-auc:0.83117                                                                 \n",
      "[41]\tvalidation_0-auc:0.96847\tvalidation_1-auc:0.83126                                                                 \n",
      "[42]\tvalidation_0-auc:0.96862\tvalidation_1-auc:0.83148                                                                 \n",
      "[43]\tvalidation_0-auc:0.96879\tvalidation_1-auc:0.83140                                                                 \n",
      "[44]\tvalidation_0-auc:0.96886\tvalidation_1-auc:0.83141                                                                 \n",
      "[45]\tvalidation_0-auc:0.96956\tvalidation_1-auc:0.83155                                                                 \n",
      "[46]\tvalidation_0-auc:0.96992\tvalidation_1-auc:0.83167                                                                 \n",
      "[47]\tvalidation_0-auc:0.97018\tvalidation_1-auc:0.83154                                                                 \n",
      "[48]\tvalidation_0-auc:0.97046\tvalidation_1-auc:0.83146                                                                 \n",
      "[49]\tvalidation_0-auc:0.97092\tvalidation_1-auc:0.83132                                                                 \n",
      "[50]\tvalidation_0-auc:0.97153\tvalidation_1-auc:0.83093                                                                 \n",
      "[51]\tvalidation_0-auc:0.97173\tvalidation_1-auc:0.83095                                                                 \n",
      "[52]\tvalidation_0-auc:0.97199\tvalidation_1-auc:0.83103                                                                 \n",
      "[53]\tvalidation_0-auc:0.97211\tvalidation_1-auc:0.83098                                                                 \n",
      "[54]\tvalidation_0-auc:0.97216\tvalidation_1-auc:0.83074                                                                 \n",
      "[55]\tvalidation_0-auc:0.97235\tvalidation_1-auc:0.83093                                                                 \n",
      "[56]\tvalidation_0-auc:0.97250\tvalidation_1-auc:0.83092                                                                 \n",
      "[57]\tvalidation_0-auc:0.97254\tvalidation_1-auc:0.83094                                                                 \n",
      "[58]\tvalidation_0-auc:0.97282\tvalidation_1-auc:0.83106                                                                 \n",
      "[59]\tvalidation_0-auc:0.97283\tvalidation_1-auc:0.83111                                                                 \n",
      "[60]\tvalidation_0-auc:0.97313\tvalidation_1-auc:0.83073                                                                 \n",
      "[61]\tvalidation_0-auc:0.97315\tvalidation_1-auc:0.83063                                                                 \n",
      "[62]\tvalidation_0-auc:0.97318\tvalidation_1-auc:0.83057                                                                 \n",
      "[63]\tvalidation_0-auc:0.97321\tvalidation_1-auc:0.83049                                                                 \n",
      "[64]\tvalidation_0-auc:0.97377\tvalidation_1-auc:0.83023                                                                 \n",
      "[65]\tvalidation_0-auc:0.97403\tvalidation_1-auc:0.83026                                                                 \n",
      "[66]\tvalidation_0-auc:0.97433\tvalidation_1-auc:0.83024                                                                 \n",
      "[67]\tvalidation_0-auc:0.97439\tvalidation_1-auc:0.83017                                                                 \n",
      "[68]\tvalidation_0-auc:0.97488\tvalidation_1-auc:0.83022                                                                 \n",
      "[69]\tvalidation_0-auc:0.97556\tvalidation_1-auc:0.82997                                                                 \n",
      "[70]\tvalidation_0-auc:0.97591\tvalidation_1-auc:0.82981                                                                 \n",
      "[71]\tvalidation_0-auc:0.97605\tvalidation_1-auc:0.82991                                                                 \n",
      "[72]\tvalidation_0-auc:0.97625\tvalidation_1-auc:0.82976                                                                 \n",
      "[73]\tvalidation_0-auc:0.97704\tvalidation_1-auc:0.82972                                                                 \n",
      "[74]\tvalidation_0-auc:0.97786\tvalidation_1-auc:0.82997                                                                 \n",
      "[75]\tvalidation_0-auc:0.97817\tvalidation_1-auc:0.83003                                                                 \n",
      "[76]\tvalidation_0-auc:0.97819\tvalidation_1-auc:0.82994                                                                 \n",
      "[0]\tvalidation_0-auc:0.87743\tvalidation_1-auc:0.79306                                                                  \n",
      "[1]\tvalidation_0-auc:0.88517\tvalidation_1-auc:0.80198                                                                  \n",
      "[2]\tvalidation_0-auc:0.88864\tvalidation_1-auc:0.81222                                                                  \n",
      "[3]\tvalidation_0-auc:0.89102\tvalidation_1-auc:0.81152                                                                  \n",
      "[4]\tvalidation_0-auc:0.89481\tvalidation_1-auc:0.81294                                                                  \n",
      "[5]\tvalidation_0-auc:0.89643\tvalidation_1-auc:0.81205                                                                  \n",
      "[6]\tvalidation_0-auc:0.89946\tvalidation_1-auc:0.81333                                                                  \n",
      "[7]\tvalidation_0-auc:0.90107\tvalidation_1-auc:0.81399                                                                  \n",
      "[8]\tvalidation_0-auc:0.90474\tvalidation_1-auc:0.81497                                                                  \n",
      "[9]\tvalidation_0-auc:0.90661\tvalidation_1-auc:0.81546                                                                  \n",
      "[10]\tvalidation_0-auc:0.90862\tvalidation_1-auc:0.81564                                                                 \n",
      "[11]\tvalidation_0-auc:0.91081\tvalidation_1-auc:0.81650                                                                 \n",
      "[12]\tvalidation_0-auc:0.91246\tvalidation_1-auc:0.81578                                                                 \n",
      "[13]\tvalidation_0-auc:0.91414\tvalidation_1-auc:0.81655                                                                 \n",
      "[14]\tvalidation_0-auc:0.91559\tvalidation_1-auc:0.81694                                                                 \n",
      "[15]\tvalidation_0-auc:0.91769\tvalidation_1-auc:0.81677                                                                 \n",
      "[16]\tvalidation_0-auc:0.91899\tvalidation_1-auc:0.81706                                                                 \n",
      "[17]\tvalidation_0-auc:0.92030\tvalidation_1-auc:0.81640                                                                 \n",
      "[18]\tvalidation_0-auc:0.92190\tvalidation_1-auc:0.81613                                                                 \n",
      "[19]\tvalidation_0-auc:0.92338\tvalidation_1-auc:0.81596                                                                 \n",
      "[20]\tvalidation_0-auc:0.92439\tvalidation_1-auc:0.81590                                                                 \n",
      "[21]\tvalidation_0-auc:0.92528\tvalidation_1-auc:0.81548                                                                 \n",
      "[22]\tvalidation_0-auc:0.92616\tvalidation_1-auc:0.81528                                                                 \n",
      "[23]\tvalidation_0-auc:0.92701\tvalidation_1-auc:0.81540                                                                 \n",
      "[24]\tvalidation_0-auc:0.92776\tvalidation_1-auc:0.81558                                                                 \n",
      "[25]\tvalidation_0-auc:0.92868\tvalidation_1-auc:0.81569                                                                 \n",
      "[26]\tvalidation_0-auc:0.92967\tvalidation_1-auc:0.81582                                                                 \n",
      "[27]\tvalidation_0-auc:0.93053\tvalidation_1-auc:0.81580                                                                 \n",
      "[28]\tvalidation_0-auc:0.93102\tvalidation_1-auc:0.81606                                                                 \n",
      "[29]\tvalidation_0-auc:0.93175\tvalidation_1-auc:0.81573                                                                 \n",
      "[30]\tvalidation_0-auc:0.93238\tvalidation_1-auc:0.81558                                                                 \n",
      "[31]\tvalidation_0-auc:0.93324\tvalidation_1-auc:0.81587                                                                 \n",
      "[32]\tvalidation_0-auc:0.93403\tvalidation_1-auc:0.81603                                                                 \n",
      "[33]\tvalidation_0-auc:0.93488\tvalidation_1-auc:0.81607                                                                 \n",
      "[34]\tvalidation_0-auc:0.93518\tvalidation_1-auc:0.81628                                                                 \n",
      "[35]\tvalidation_0-auc:0.93596\tvalidation_1-auc:0.81631                                                                 \n",
      "[36]\tvalidation_0-auc:0.93628\tvalidation_1-auc:0.81652                                                                 \n",
      "[37]\tvalidation_0-auc:0.93655\tvalidation_1-auc:0.81664                                                                 \n",
      "[38]\tvalidation_0-auc:0.93700\tvalidation_1-auc:0.81662                                                                 \n",
      "[39]\tvalidation_0-auc:0.93736\tvalidation_1-auc:0.81678                                                                 \n",
      "[40]\tvalidation_0-auc:0.93782\tvalidation_1-auc:0.81698                                                                 \n",
      "[41]\tvalidation_0-auc:0.93816\tvalidation_1-auc:0.81694                                                                 \n",
      "[42]\tvalidation_0-auc:0.93848\tvalidation_1-auc:0.81704                                                                 \n",
      "[43]\tvalidation_0-auc:0.93902\tvalidation_1-auc:0.81690                                                                 \n",
      "[44]\tvalidation_0-auc:0.93941\tvalidation_1-auc:0.81676                                                                 \n",
      "[45]\tvalidation_0-auc:0.93964\tvalidation_1-auc:0.81674                                                                 \n",
      "[46]\tvalidation_0-auc:0.93979\tvalidation_1-auc:0.81700                                                                 \n",
      "[0]\tvalidation_0-auc:0.87442\tvalidation_1-auc:0.79596                                                                  \n",
      "[1]\tvalidation_0-auc:0.88017\tvalidation_1-auc:0.80827                                                                  \n",
      "[2]\tvalidation_0-auc:0.88442\tvalidation_1-auc:0.82063                                                                  \n",
      "[3]\tvalidation_0-auc:0.88686\tvalidation_1-auc:0.82200                                                                  \n",
      "[4]\tvalidation_0-auc:0.88949\tvalidation_1-auc:0.82340                                                                  \n",
      "[5]\tvalidation_0-auc:0.89533\tvalidation_1-auc:0.82531                                                                  \n",
      "[6]\tvalidation_0-auc:0.89851\tvalidation_1-auc:0.82493                                                                  \n",
      "[7]\tvalidation_0-auc:0.90100\tvalidation_1-auc:0.82571                                                                  \n",
      "[8]\tvalidation_0-auc:0.90397\tvalidation_1-auc:0.82613                                                                  \n",
      "[9]\tvalidation_0-auc:0.90636\tvalidation_1-auc:0.82721                                                                  \n",
      "[10]\tvalidation_0-auc:0.90767\tvalidation_1-auc:0.82742                                                                 \n",
      "[11]\tvalidation_0-auc:0.90992\tvalidation_1-auc:0.82782                                                                 \n",
      "[12]\tvalidation_0-auc:0.91190\tvalidation_1-auc:0.82793                                                                 \n",
      "[13]\tvalidation_0-auc:0.91423\tvalidation_1-auc:0.82816                                                                 \n",
      "[14]\tvalidation_0-auc:0.91581\tvalidation_1-auc:0.82843                                                                 \n",
      "[15]\tvalidation_0-auc:0.91757\tvalidation_1-auc:0.82838                                                                 \n",
      "[16]\tvalidation_0-auc:0.91886\tvalidation_1-auc:0.82866                                                                 \n",
      "[17]\tvalidation_0-auc:0.92045\tvalidation_1-auc:0.82854                                                                 \n",
      "[18]\tvalidation_0-auc:0.92133\tvalidation_1-auc:0.82880                                                                 \n",
      "[19]\tvalidation_0-auc:0.92234\tvalidation_1-auc:0.82927                                                                 \n",
      "[20]\tvalidation_0-auc:0.92340\tvalidation_1-auc:0.82950                                                                 \n",
      "[21]\tvalidation_0-auc:0.92444\tvalidation_1-auc:0.82954                                                                 \n",
      "[22]\tvalidation_0-auc:0.92570\tvalidation_1-auc:0.83013                                                                 \n",
      "[23]\tvalidation_0-auc:0.92677\tvalidation_1-auc:0.82995                                                                 \n",
      "[24]\tvalidation_0-auc:0.92781\tvalidation_1-auc:0.83091                                                                 \n",
      "[25]\tvalidation_0-auc:0.92899\tvalidation_1-auc:0.83045                                                                 \n",
      "[26]\tvalidation_0-auc:0.92999\tvalidation_1-auc:0.83045                                                                 \n",
      "[27]\tvalidation_0-auc:0.93111\tvalidation_1-auc:0.83051                                                                 \n",
      "[28]\tvalidation_0-auc:0.93144\tvalidation_1-auc:0.83107                                                                 \n",
      "[29]\tvalidation_0-auc:0.93216\tvalidation_1-auc:0.83103                                                                 \n",
      "[30]\tvalidation_0-auc:0.93316\tvalidation_1-auc:0.83129                                                                 \n",
      "[31]\tvalidation_0-auc:0.93365\tvalidation_1-auc:0.83108                                                                 \n",
      "[32]\tvalidation_0-auc:0.93419\tvalidation_1-auc:0.83095                                                                 \n",
      "[33]\tvalidation_0-auc:0.93484\tvalidation_1-auc:0.83117                                                                 \n",
      "[34]\tvalidation_0-auc:0.93521\tvalidation_1-auc:0.83101                                                                 \n",
      "[35]\tvalidation_0-auc:0.93556\tvalidation_1-auc:0.83084                                                                 \n",
      "[36]\tvalidation_0-auc:0.93590\tvalidation_1-auc:0.83080                                                                 \n",
      "[37]\tvalidation_0-auc:0.93641\tvalidation_1-auc:0.83088                                                                 \n",
      "[38]\tvalidation_0-auc:0.93657\tvalidation_1-auc:0.83085                                                                 \n",
      "[39]\tvalidation_0-auc:0.93742\tvalidation_1-auc:0.83113                                                                 \n",
      "[40]\tvalidation_0-auc:0.93780\tvalidation_1-auc:0.83121                                                                 \n",
      "[41]\tvalidation_0-auc:0.93802\tvalidation_1-auc:0.83110                                                                 \n",
      "[42]\tvalidation_0-auc:0.93811\tvalidation_1-auc:0.83102                                                                 \n",
      "[43]\tvalidation_0-auc:0.93901\tvalidation_1-auc:0.83125                                                                 \n",
      "[44]\tvalidation_0-auc:0.93968\tvalidation_1-auc:0.83147                                                                 \n",
      "[45]\tvalidation_0-auc:0.94013\tvalidation_1-auc:0.83137                                                                 \n",
      "[46]\tvalidation_0-auc:0.94024\tvalidation_1-auc:0.83135                                                                 \n",
      "[47]\tvalidation_0-auc:0.94042\tvalidation_1-auc:0.83119                                                                 \n",
      "[48]\tvalidation_0-auc:0.94071\tvalidation_1-auc:0.83084                                                                 \n",
      "[49]\tvalidation_0-auc:0.94110\tvalidation_1-auc:0.83070                                                                 \n",
      "[50]\tvalidation_0-auc:0.94137\tvalidation_1-auc:0.83056                                                                 \n",
      "[51]\tvalidation_0-auc:0.94154\tvalidation_1-auc:0.83042                                                                 \n",
      "[52]\tvalidation_0-auc:0.94192\tvalidation_1-auc:0.83078                                                                 \n",
      "[53]\tvalidation_0-auc:0.94215\tvalidation_1-auc:0.83072                                                                 \n",
      "[54]\tvalidation_0-auc:0.94256\tvalidation_1-auc:0.83062                                                                 \n",
      "[55]\tvalidation_0-auc:0.94265\tvalidation_1-auc:0.83056                                                                 \n",
      "[56]\tvalidation_0-auc:0.94275\tvalidation_1-auc:0.83041                                                                 \n",
      "[57]\tvalidation_0-auc:0.94327\tvalidation_1-auc:0.83030                                                                 \n",
      "[58]\tvalidation_0-auc:0.94381\tvalidation_1-auc:0.83007                                                                 \n",
      "[59]\tvalidation_0-auc:0.94388\tvalidation_1-auc:0.82995                                                                 \n",
      "[60]\tvalidation_0-auc:0.94408\tvalidation_1-auc:0.82977                                                                 \n",
      "[61]\tvalidation_0-auc:0.94432\tvalidation_1-auc:0.82959                                                                 \n",
      "[62]\tvalidation_0-auc:0.94455\tvalidation_1-auc:0.82946                                                                 \n",
      "[63]\tvalidation_0-auc:0.94525\tvalidation_1-auc:0.82945                                                                 \n",
      "[64]\tvalidation_0-auc:0.94537\tvalidation_1-auc:0.82960                                                                 \n",
      "[65]\tvalidation_0-auc:0.94558\tvalidation_1-auc:0.82958                                                                 \n",
      "[66]\tvalidation_0-auc:0.94596\tvalidation_1-auc:0.82981                                                                 \n",
      "[67]\tvalidation_0-auc:0.94605\tvalidation_1-auc:0.82967                                                                 \n",
      "[68]\tvalidation_0-auc:0.94638\tvalidation_1-auc:0.82982                                                                 \n",
      "[69]\tvalidation_0-auc:0.94643\tvalidation_1-auc:0.82983                                                                 \n",
      "[70]\tvalidation_0-auc:0.94669\tvalidation_1-auc:0.82981                                                                 \n",
      "[71]\tvalidation_0-auc:0.94709\tvalidation_1-auc:0.82967                                                                 \n",
      "[72]\tvalidation_0-auc:0.94713\tvalidation_1-auc:0.82964                                                                 \n",
      "[73]\tvalidation_0-auc:0.94739\tvalidation_1-auc:0.82964                                                                 \n",
      "[74]\tvalidation_0-auc:0.94799\tvalidation_1-auc:0.82962                                                                 \n",
      "[0]\tvalidation_0-auc:0.87011\tvalidation_1-auc:0.81091                                                                  \n",
      "[1]\tvalidation_0-auc:0.87625\tvalidation_1-auc:0.82044                                                                  \n",
      "[2]\tvalidation_0-auc:0.88220\tvalidation_1-auc:0.82811                                                                  \n",
      "[3]\tvalidation_0-auc:0.88580\tvalidation_1-auc:0.82840                                                                  \n",
      "[4]\tvalidation_0-auc:0.88842\tvalidation_1-auc:0.82786                                                                  \n",
      "[5]\tvalidation_0-auc:0.89183\tvalidation_1-auc:0.82884                                                                  \n",
      "[6]\tvalidation_0-auc:0.89396\tvalidation_1-auc:0.83002                                                                  \n",
      "[7]\tvalidation_0-auc:0.89622\tvalidation_1-auc:0.82948                                                                  \n",
      "[8]\tvalidation_0-auc:0.90106\tvalidation_1-auc:0.83154                                                                  \n",
      "[9]\tvalidation_0-auc:0.90389\tvalidation_1-auc:0.83143                                                                  \n",
      "[10]\tvalidation_0-auc:0.90550\tvalidation_1-auc:0.83038                                                                 \n",
      "[11]\tvalidation_0-auc:0.90649\tvalidation_1-auc:0.83014                                                                 \n",
      "[12]\tvalidation_0-auc:0.90770\tvalidation_1-auc:0.82954                                                                 \n",
      "[13]\tvalidation_0-auc:0.90908\tvalidation_1-auc:0.82963                                                                 \n",
      "[14]\tvalidation_0-auc:0.91066\tvalidation_1-auc:0.82927                                                                 \n",
      "[15]\tvalidation_0-auc:0.91304\tvalidation_1-auc:0.82933                                                                 \n",
      "[16]\tvalidation_0-auc:0.91453\tvalidation_1-auc:0.82879                                                                 \n",
      "[17]\tvalidation_0-auc:0.91586\tvalidation_1-auc:0.82931                                                                 \n",
      "[18]\tvalidation_0-auc:0.91706\tvalidation_1-auc:0.82865                                                                 \n",
      "[19]\tvalidation_0-auc:0.91810\tvalidation_1-auc:0.82828                                                                 \n",
      "[20]\tvalidation_0-auc:0.91973\tvalidation_1-auc:0.82802                                                                 \n",
      "[21]\tvalidation_0-auc:0.92148\tvalidation_1-auc:0.82812                                                                 \n",
      "[22]\tvalidation_0-auc:0.92249\tvalidation_1-auc:0.82879                                                                 \n",
      "[23]\tvalidation_0-auc:0.92327\tvalidation_1-auc:0.82916                                                                 \n",
      "[24]\tvalidation_0-auc:0.92442\tvalidation_1-auc:0.82943                                                                 \n",
      "[25]\tvalidation_0-auc:0.92607\tvalidation_1-auc:0.82937                                                                 \n",
      "[26]\tvalidation_0-auc:0.92705\tvalidation_1-auc:0.82896                                                                 \n",
      "[27]\tvalidation_0-auc:0.92862\tvalidation_1-auc:0.82921                                                                 \n",
      "[28]\tvalidation_0-auc:0.92959\tvalidation_1-auc:0.82964                                                                 \n",
      "[29]\tvalidation_0-auc:0.93032\tvalidation_1-auc:0.83016                                                                 \n",
      "[30]\tvalidation_0-auc:0.93147\tvalidation_1-auc:0.83033                                                                 \n",
      "[31]\tvalidation_0-auc:0.93225\tvalidation_1-auc:0.83031                                                                 \n",
      "[32]\tvalidation_0-auc:0.93305\tvalidation_1-auc:0.83065                                                                 \n",
      "[33]\tvalidation_0-auc:0.93352\tvalidation_1-auc:0.83061                                                                 \n",
      "[34]\tvalidation_0-auc:0.93413\tvalidation_1-auc:0.83089                                                                 \n",
      "[35]\tvalidation_0-auc:0.93502\tvalidation_1-auc:0.83104                                                                 \n",
      "[36]\tvalidation_0-auc:0.93572\tvalidation_1-auc:0.83135                                                                 \n",
      "[37]\tvalidation_0-auc:0.93603\tvalidation_1-auc:0.83179                                                                 \n",
      "[38]\tvalidation_0-auc:0.93658\tvalidation_1-auc:0.83213                                                                 \n",
      "[39]\tvalidation_0-auc:0.93696\tvalidation_1-auc:0.83229                                                                 \n",
      "[40]\tvalidation_0-auc:0.93723\tvalidation_1-auc:0.83246                                                                 \n",
      "[41]\tvalidation_0-auc:0.93799\tvalidation_1-auc:0.83232                                                                 \n",
      "[42]\tvalidation_0-auc:0.93817\tvalidation_1-auc:0.83246                                                                 \n",
      "[43]\tvalidation_0-auc:0.93864\tvalidation_1-auc:0.83219                                                                 \n",
      "[44]\tvalidation_0-auc:0.93917\tvalidation_1-auc:0.83211                                                                 \n",
      "[45]\tvalidation_0-auc:0.93966\tvalidation_1-auc:0.83219                                                                 \n",
      "[46]\tvalidation_0-auc:0.94002\tvalidation_1-auc:0.83236                                                                 \n",
      "[47]\tvalidation_0-auc:0.94035\tvalidation_1-auc:0.83252                                                                 \n",
      "[48]\tvalidation_0-auc:0.94087\tvalidation_1-auc:0.83267                                                                 \n",
      "[49]\tvalidation_0-auc:0.94112\tvalidation_1-auc:0.83261                                                                 \n",
      "[50]\tvalidation_0-auc:0.94138\tvalidation_1-auc:0.83272                                                                 \n",
      "[51]\tvalidation_0-auc:0.94163\tvalidation_1-auc:0.83281                                                                 \n",
      "[52]\tvalidation_0-auc:0.94203\tvalidation_1-auc:0.83281                                                                 \n",
      "[53]\tvalidation_0-auc:0.94229\tvalidation_1-auc:0.83288                                                                 \n",
      "[54]\tvalidation_0-auc:0.94282\tvalidation_1-auc:0.83291                                                                 \n",
      "[55]\tvalidation_0-auc:0.94306\tvalidation_1-auc:0.83312                                                                 \n",
      "[56]\tvalidation_0-auc:0.94329\tvalidation_1-auc:0.83311                                                                 \n",
      "[57]\tvalidation_0-auc:0.94363\tvalidation_1-auc:0.83306                                                                 \n",
      "[58]\tvalidation_0-auc:0.94466\tvalidation_1-auc:0.83300                                                                 \n",
      "[59]\tvalidation_0-auc:0.94488\tvalidation_1-auc:0.83300                                                                 \n",
      "[60]\tvalidation_0-auc:0.94505\tvalidation_1-auc:0.83310                                                                 \n",
      "[61]\tvalidation_0-auc:0.94520\tvalidation_1-auc:0.83311                                                                 \n",
      "[62]\tvalidation_0-auc:0.94577\tvalidation_1-auc:0.83309                                                                 \n",
      "[63]\tvalidation_0-auc:0.94609\tvalidation_1-auc:0.83305                                                                 \n",
      "[64]\tvalidation_0-auc:0.94707\tvalidation_1-auc:0.83271                                                                 \n",
      "[65]\tvalidation_0-auc:0.94748\tvalidation_1-auc:0.83265                                                                 \n",
      "[66]\tvalidation_0-auc:0.94766\tvalidation_1-auc:0.83262                                                                 \n",
      "[67]\tvalidation_0-auc:0.94806\tvalidation_1-auc:0.83252                                                                 \n",
      "[68]\tvalidation_0-auc:0.94813\tvalidation_1-auc:0.83255                                                                 \n",
      "[69]\tvalidation_0-auc:0.94860\tvalidation_1-auc:0.83246                                                                 \n",
      "[70]\tvalidation_0-auc:0.94880\tvalidation_1-auc:0.83245                                                                 \n",
      "[71]\tvalidation_0-auc:0.94918\tvalidation_1-auc:0.83235                                                                 \n",
      "[72]\tvalidation_0-auc:0.94925\tvalidation_1-auc:0.83235                                                                 \n",
      "[73]\tvalidation_0-auc:0.94946\tvalidation_1-auc:0.83241                                                                 \n",
      "[74]\tvalidation_0-auc:0.94965\tvalidation_1-auc:0.83224                                                                 \n",
      "[75]\tvalidation_0-auc:0.95008\tvalidation_1-auc:0.83224                                                                 \n",
      "[76]\tvalidation_0-auc:0.95029\tvalidation_1-auc:0.83227                                                                 \n",
      "[77]\tvalidation_0-auc:0.95034\tvalidation_1-auc:0.83222                                                                 \n",
      "[78]\tvalidation_0-auc:0.95039\tvalidation_1-auc:0.83220                                                                 \n",
      "[79]\tvalidation_0-auc:0.95047\tvalidation_1-auc:0.83214                                                                 \n",
      "[80]\tvalidation_0-auc:0.95056\tvalidation_1-auc:0.83218                                                                 \n",
      "[81]\tvalidation_0-auc:0.95075\tvalidation_1-auc:0.83227                                                                 \n",
      "[82]\tvalidation_0-auc:0.95100\tvalidation_1-auc:0.83205                                                                 \n",
      "[83]\tvalidation_0-auc:0.95107\tvalidation_1-auc:0.83198                                                                 \n",
      "[84]\tvalidation_0-auc:0.95144\tvalidation_1-auc:0.83193                                                                 \n",
      "[85]\tvalidation_0-auc:0.95150\tvalidation_1-auc:0.83194                                                                 \n",
      "[0]\tvalidation_0-auc:0.84395\tvalidation_1-auc:0.80787                                                                  \n",
      "[1]\tvalidation_0-auc:0.84958\tvalidation_1-auc:0.80332                                                                  \n",
      "[2]\tvalidation_0-auc:0.85726\tvalidation_1-auc:0.81126                                                                  \n",
      "[3]\tvalidation_0-auc:0.85485\tvalidation_1-auc:0.80592                                                                  \n",
      "[4]\tvalidation_0-auc:0.85310\tvalidation_1-auc:0.80166                                                                  \n",
      "[5]\tvalidation_0-auc:0.85883\tvalidation_1-auc:0.80893                                                                  \n",
      "[6]\tvalidation_0-auc:0.86332\tvalidation_1-auc:0.81253                                                                  \n",
      "[7]\tvalidation_0-auc:0.86516\tvalidation_1-auc:0.81127                                                                  \n",
      "[8]\tvalidation_0-auc:0.86849\tvalidation_1-auc:0.81253                                                                  \n",
      "[9]\tvalidation_0-auc:0.86784\tvalidation_1-auc:0.81085                                                                  \n",
      "[10]\tvalidation_0-auc:0.87020\tvalidation_1-auc:0.81292                                                                 \n",
      "[11]\tvalidation_0-auc:0.87266\tvalidation_1-auc:0.81533                                                                 \n",
      "[12]\tvalidation_0-auc:0.87546\tvalidation_1-auc:0.81700                                                                 \n",
      "[13]\tvalidation_0-auc:0.87733\tvalidation_1-auc:0.81836                                                                 \n",
      "[14]\tvalidation_0-auc:0.87841\tvalidation_1-auc:0.81725                                                                 \n",
      "[15]\tvalidation_0-auc:0.88038\tvalidation_1-auc:0.81834                                                                 \n",
      "[16]\tvalidation_0-auc:0.88185\tvalidation_1-auc:0.81922                                                                 \n",
      "[17]\tvalidation_0-auc:0.88254\tvalidation_1-auc:0.81847                                                                 \n",
      "[18]\tvalidation_0-auc:0.88276\tvalidation_1-auc:0.81818                                                                 \n",
      "[19]\tvalidation_0-auc:0.88411\tvalidation_1-auc:0.81916                                                                 \n",
      "[20]\tvalidation_0-auc:0.88533\tvalidation_1-auc:0.81959                                                                 \n",
      "[21]\tvalidation_0-auc:0.88600\tvalidation_1-auc:0.82010                                                                 \n",
      "[22]\tvalidation_0-auc:0.88684\tvalidation_1-auc:0.82115                                                                 \n",
      "[23]\tvalidation_0-auc:0.88737\tvalidation_1-auc:0.82154                                                                 \n",
      "[24]\tvalidation_0-auc:0.88820\tvalidation_1-auc:0.82179                                                                 \n",
      "[25]\tvalidation_0-auc:0.88902\tvalidation_1-auc:0.82163                                                                 \n",
      "[26]\tvalidation_0-auc:0.88927\tvalidation_1-auc:0.82142                                                                 \n",
      "[27]\tvalidation_0-auc:0.88998\tvalidation_1-auc:0.82124                                                                 \n",
      "[28]\tvalidation_0-auc:0.89049\tvalidation_1-auc:0.82144                                                                 \n",
      "[29]\tvalidation_0-auc:0.89093\tvalidation_1-auc:0.82103                                                                 \n",
      "[30]\tvalidation_0-auc:0.89156\tvalidation_1-auc:0.82121                                                                 \n",
      "[31]\tvalidation_0-auc:0.89222\tvalidation_1-auc:0.82108                                                                 \n",
      "[32]\tvalidation_0-auc:0.89297\tvalidation_1-auc:0.82115                                                                 \n",
      "[33]\tvalidation_0-auc:0.89325\tvalidation_1-auc:0.82133                                                                 \n",
      "[34]\tvalidation_0-auc:0.89355\tvalidation_1-auc:0.82154                                                                 \n",
      "[35]\tvalidation_0-auc:0.89383\tvalidation_1-auc:0.82173                                                                 \n",
      "[36]\tvalidation_0-auc:0.89413\tvalidation_1-auc:0.82243                                                                 \n",
      "[37]\tvalidation_0-auc:0.89436\tvalidation_1-auc:0.82269                                                                 \n",
      "[38]\tvalidation_0-auc:0.89448\tvalidation_1-auc:0.82269                                                                 \n",
      "[39]\tvalidation_0-auc:0.89479\tvalidation_1-auc:0.82278                                                                 \n",
      "[40]\tvalidation_0-auc:0.89533\tvalidation_1-auc:0.82277                                                                 \n",
      "[41]\tvalidation_0-auc:0.89593\tvalidation_1-auc:0.82315                                                                 \n",
      "[42]\tvalidation_0-auc:0.89610\tvalidation_1-auc:0.82335                                                                 \n",
      "[43]\tvalidation_0-auc:0.89662\tvalidation_1-auc:0.82295                                                                 \n",
      "[44]\tvalidation_0-auc:0.89685\tvalidation_1-auc:0.82287                                                                 \n",
      "[45]\tvalidation_0-auc:0.89740\tvalidation_1-auc:0.82298                                                                 \n",
      "[46]\tvalidation_0-auc:0.89752\tvalidation_1-auc:0.82286                                                                 \n",
      "[47]\tvalidation_0-auc:0.89811\tvalidation_1-auc:0.82313                                                                 \n",
      "[48]\tvalidation_0-auc:0.89839\tvalidation_1-auc:0.82310                                                                 \n",
      "[49]\tvalidation_0-auc:0.89861\tvalidation_1-auc:0.82300                                                                 \n",
      "[50]\tvalidation_0-auc:0.89898\tvalidation_1-auc:0.82328                                                                 \n",
      "[51]\tvalidation_0-auc:0.89980\tvalidation_1-auc:0.82330                                                                 \n",
      "[52]\tvalidation_0-auc:0.89992\tvalidation_1-auc:0.82321                                                                 \n",
      "[53]\tvalidation_0-auc:0.90011\tvalidation_1-auc:0.82342                                                                 \n",
      "[54]\tvalidation_0-auc:0.90027\tvalidation_1-auc:0.82334                                                                 \n",
      "[55]\tvalidation_0-auc:0.90051\tvalidation_1-auc:0.82357                                                                 \n",
      "[56]\tvalidation_0-auc:0.90083\tvalidation_1-auc:0.82380                                                                 \n",
      "[57]\tvalidation_0-auc:0.90092\tvalidation_1-auc:0.82392                                                                 \n",
      "[58]\tvalidation_0-auc:0.90171\tvalidation_1-auc:0.82396                                                                 \n",
      "[59]\tvalidation_0-auc:0.90196\tvalidation_1-auc:0.82392                                                                 \n",
      "[60]\tvalidation_0-auc:0.90223\tvalidation_1-auc:0.82390                                                                 \n",
      "[61]\tvalidation_0-auc:0.90264\tvalidation_1-auc:0.82388                                                                 \n",
      "[62]\tvalidation_0-auc:0.90272\tvalidation_1-auc:0.82377                                                                 \n",
      "[63]\tvalidation_0-auc:0.90310\tvalidation_1-auc:0.82384                                                                 \n",
      "[64]\tvalidation_0-auc:0.90351\tvalidation_1-auc:0.82401                                                                 \n",
      "[65]\tvalidation_0-auc:0.90368\tvalidation_1-auc:0.82404                                                                 \n",
      "[66]\tvalidation_0-auc:0.90387\tvalidation_1-auc:0.82406                                                                 \n",
      "[67]\tvalidation_0-auc:0.90428\tvalidation_1-auc:0.82414                                                                 \n",
      "[68]\tvalidation_0-auc:0.90458\tvalidation_1-auc:0.82401                                                                 \n",
      "[69]\tvalidation_0-auc:0.90503\tvalidation_1-auc:0.82389                                                                 \n",
      "[70]\tvalidation_0-auc:0.90523\tvalidation_1-auc:0.82396                                                                 \n",
      "[71]\tvalidation_0-auc:0.90584\tvalidation_1-auc:0.82379                                                                 \n",
      "[72]\tvalidation_0-auc:0.90657\tvalidation_1-auc:0.82358                                                                 \n",
      "[73]\tvalidation_0-auc:0.90661\tvalidation_1-auc:0.82368                                                                 \n",
      "[74]\tvalidation_0-auc:0.90692\tvalidation_1-auc:0.82361                                                                 \n",
      "[75]\tvalidation_0-auc:0.90696\tvalidation_1-auc:0.82356                                                                 \n",
      "[76]\tvalidation_0-auc:0.90746\tvalidation_1-auc:0.82361                                                                 \n",
      "[77]\tvalidation_0-auc:0.90752\tvalidation_1-auc:0.82363                                                                 \n",
      "[78]\tvalidation_0-auc:0.90777\tvalidation_1-auc:0.82367                                                                 \n",
      "[79]\tvalidation_0-auc:0.90789\tvalidation_1-auc:0.82358                                                                 \n",
      "[80]\tvalidation_0-auc:0.90794\tvalidation_1-auc:0.82344                                                                 \n",
      "[81]\tvalidation_0-auc:0.90833\tvalidation_1-auc:0.82335                                                                 \n",
      "[82]\tvalidation_0-auc:0.90838\tvalidation_1-auc:0.82332                                                                 \n",
      "[83]\tvalidation_0-auc:0.90843\tvalidation_1-auc:0.82328                                                                 \n",
      "[84]\tvalidation_0-auc:0.90878\tvalidation_1-auc:0.82325                                                                 \n",
      "[85]\tvalidation_0-auc:0.90920\tvalidation_1-auc:0.82315                                                                 \n",
      "[86]\tvalidation_0-auc:0.90931\tvalidation_1-auc:0.82322                                                                 \n",
      "[87]\tvalidation_0-auc:0.90938\tvalidation_1-auc:0.82320                                                                 \n",
      "[88]\tvalidation_0-auc:0.90964\tvalidation_1-auc:0.82321                                                                 \n",
      "[89]\tvalidation_0-auc:0.90969\tvalidation_1-auc:0.82309                                                                 \n",
      "[90]\tvalidation_0-auc:0.91002\tvalidation_1-auc:0.82297                                                                 \n",
      "[91]\tvalidation_0-auc:0.91012\tvalidation_1-auc:0.82287                                                                 \n",
      "[92]\tvalidation_0-auc:0.91077\tvalidation_1-auc:0.82294                                                                 \n",
      "[93]\tvalidation_0-auc:0.91093\tvalidation_1-auc:0.82299                                                                 \n",
      "[94]\tvalidation_0-auc:0.91148\tvalidation_1-auc:0.82287                                                                 \n",
      "[95]\tvalidation_0-auc:0.91162\tvalidation_1-auc:0.82302                                                                 \n",
      "[96]\tvalidation_0-auc:0.91194\tvalidation_1-auc:0.82292                                                                 \n",
      "[97]\tvalidation_0-auc:0.91202\tvalidation_1-auc:0.82288                                                                 \n",
      "[0]\tvalidation_0-auc:0.83940\tvalidation_1-auc:0.81279                                                                  \n",
      "[1]\tvalidation_0-auc:0.84660\tvalidation_1-auc:0.82178                                                                  \n",
      "[2]\tvalidation_0-auc:0.85504\tvalidation_1-auc:0.83077                                                                  \n",
      "[3]\tvalidation_0-auc:0.85143\tvalidation_1-auc:0.83165                                                                  \n",
      "[4]\tvalidation_0-auc:0.84799\tvalidation_1-auc:0.82920                                                                  \n",
      "[5]\tvalidation_0-auc:0.85590\tvalidation_1-auc:0.83551                                                                  \n",
      "[6]\tvalidation_0-auc:0.86160\tvalidation_1-auc:0.83845                                                                  \n",
      "[7]\tvalidation_0-auc:0.86264\tvalidation_1-auc:0.83642                                                                  \n",
      "[8]\tvalidation_0-auc:0.86721\tvalidation_1-auc:0.83923                                                                  \n",
      "[9]\tvalidation_0-auc:0.86603\tvalidation_1-auc:0.83935                                                                  \n",
      "[10]\tvalidation_0-auc:0.86875\tvalidation_1-auc:0.84219                                                                 \n",
      "[11]\tvalidation_0-auc:0.87218\tvalidation_1-auc:0.84197                                                                 \n",
      "[12]\tvalidation_0-auc:0.87408\tvalidation_1-auc:0.84275                                                                 \n",
      "[13]\tvalidation_0-auc:0.87611\tvalidation_1-auc:0.84283                                                                 \n",
      "[14]\tvalidation_0-auc:0.87630\tvalidation_1-auc:0.84289                                                                 \n",
      "[15]\tvalidation_0-auc:0.87799\tvalidation_1-auc:0.84300                                                                 \n",
      "[16]\tvalidation_0-auc:0.87994\tvalidation_1-auc:0.84356                                                                 \n",
      "[17]\tvalidation_0-auc:0.88047\tvalidation_1-auc:0.84360                                                                 \n",
      "[18]\tvalidation_0-auc:0.88146\tvalidation_1-auc:0.84352                                                                 \n",
      "[19]\tvalidation_0-auc:0.88307\tvalidation_1-auc:0.84357                                                                 \n",
      "[20]\tvalidation_0-auc:0.88447\tvalidation_1-auc:0.84367                                                                 \n",
      "[21]\tvalidation_0-auc:0.88539\tvalidation_1-auc:0.84342                                                                 \n",
      "[22]\tvalidation_0-auc:0.88587\tvalidation_1-auc:0.84380                                                                 \n",
      "[23]\tvalidation_0-auc:0.88647\tvalidation_1-auc:0.84434                                                                 \n",
      "[24]\tvalidation_0-auc:0.88700\tvalidation_1-auc:0.84437                                                                 \n",
      "[25]\tvalidation_0-auc:0.88791\tvalidation_1-auc:0.84443                                                                 \n",
      "[26]\tvalidation_0-auc:0.88805\tvalidation_1-auc:0.84452                                                                 \n",
      "[27]\tvalidation_0-auc:0.88858\tvalidation_1-auc:0.84461                                                                 \n",
      "[28]\tvalidation_0-auc:0.88880\tvalidation_1-auc:0.84482                                                                 \n",
      "[29]\tvalidation_0-auc:0.88896\tvalidation_1-auc:0.84512                                                                 \n",
      "[30]\tvalidation_0-auc:0.88969\tvalidation_1-auc:0.84498                                                                 \n",
      "[31]\tvalidation_0-auc:0.89049\tvalidation_1-auc:0.84510                                                                 \n",
      "[32]\tvalidation_0-auc:0.89113\tvalidation_1-auc:0.84501                                                                 \n",
      "[33]\tvalidation_0-auc:0.89132\tvalidation_1-auc:0.84509                                                                 \n",
      "[34]\tvalidation_0-auc:0.89167\tvalidation_1-auc:0.84539                                                                 \n",
      "[35]\tvalidation_0-auc:0.89241\tvalidation_1-auc:0.84516                                                                 \n",
      "[36]\tvalidation_0-auc:0.89258\tvalidation_1-auc:0.84513                                                                 \n",
      "[37]\tvalidation_0-auc:0.89279\tvalidation_1-auc:0.84508                                                                 \n",
      "[38]\tvalidation_0-auc:0.89296\tvalidation_1-auc:0.84513                                                                 \n",
      "[39]\tvalidation_0-auc:0.89294\tvalidation_1-auc:0.84497                                                                 \n",
      "[40]\tvalidation_0-auc:0.89364\tvalidation_1-auc:0.84484                                                                 \n",
      "[41]\tvalidation_0-auc:0.89395\tvalidation_1-auc:0.84462                                                                 \n",
      "[42]\tvalidation_0-auc:0.89451\tvalidation_1-auc:0.84451                                                                 \n",
      "[43]\tvalidation_0-auc:0.89498\tvalidation_1-auc:0.84484                                                                 \n",
      "[44]\tvalidation_0-auc:0.89528\tvalidation_1-auc:0.84478                                                                 \n",
      "[45]\tvalidation_0-auc:0.89562\tvalidation_1-auc:0.84495                                                                 \n",
      "[46]\tvalidation_0-auc:0.89592\tvalidation_1-auc:0.84492                                                                 \n",
      "[47]\tvalidation_0-auc:0.89650\tvalidation_1-auc:0.84498                                                                 \n",
      "[48]\tvalidation_0-auc:0.89685\tvalidation_1-auc:0.84481                                                                 \n",
      "[49]\tvalidation_0-auc:0.89693\tvalidation_1-auc:0.84471                                                                 \n",
      "[50]\tvalidation_0-auc:0.89740\tvalidation_1-auc:0.84459                                                                 \n",
      "[51]\tvalidation_0-auc:0.89788\tvalidation_1-auc:0.84459                                                                 \n",
      "[52]\tvalidation_0-auc:0.89816\tvalidation_1-auc:0.84440                                                                 \n",
      "[53]\tvalidation_0-auc:0.89850\tvalidation_1-auc:0.84445                                                                 \n",
      "[54]\tvalidation_0-auc:0.89898\tvalidation_1-auc:0.84442                                                                 \n",
      "[55]\tvalidation_0-auc:0.89908\tvalidation_1-auc:0.84446                                                                 \n",
      "[56]\tvalidation_0-auc:0.89955\tvalidation_1-auc:0.84425                                                                 \n",
      "[57]\tvalidation_0-auc:0.89972\tvalidation_1-auc:0.84423                                                                 \n",
      "[58]\tvalidation_0-auc:0.90009\tvalidation_1-auc:0.84403                                                                 \n",
      "[59]\tvalidation_0-auc:0.90034\tvalidation_1-auc:0.84399                                                                 \n",
      "[60]\tvalidation_0-auc:0.90048\tvalidation_1-auc:0.84387                                                                 \n",
      "[61]\tvalidation_0-auc:0.90070\tvalidation_1-auc:0.84379                                                                 \n",
      "[62]\tvalidation_0-auc:0.90104\tvalidation_1-auc:0.84364                                                                 \n",
      "[63]\tvalidation_0-auc:0.90135\tvalidation_1-auc:0.84355                                                                 \n",
      "[64]\tvalidation_0-auc:0.90165\tvalidation_1-auc:0.84347                                                                 \n",
      "[0]\tvalidation_0-auc:0.83759\tvalidation_1-auc:0.81587                                                                  \n",
      "[1]\tvalidation_0-auc:0.84474\tvalidation_1-auc:0.81230                                                                  \n",
      "[2]\tvalidation_0-auc:0.85216\tvalidation_1-auc:0.82132                                                                  \n",
      "[3]\tvalidation_0-auc:0.85005\tvalidation_1-auc:0.81714                                                                  \n",
      "[4]\tvalidation_0-auc:0.85000\tvalidation_1-auc:0.81376                                                                  \n",
      "[5]\tvalidation_0-auc:0.85628\tvalidation_1-auc:0.82012                                                                  \n",
      "[6]\tvalidation_0-auc:0.86050\tvalidation_1-auc:0.82394                                                                  \n",
      "[7]\tvalidation_0-auc:0.86177\tvalidation_1-auc:0.82344                                                                  \n",
      "[8]\tvalidation_0-auc:0.86563\tvalidation_1-auc:0.82677                                                                  \n",
      "[9]\tvalidation_0-auc:0.86522\tvalidation_1-auc:0.82518                                                                  \n",
      "[10]\tvalidation_0-auc:0.86808\tvalidation_1-auc:0.82722                                                                 \n",
      "[11]\tvalidation_0-auc:0.87081\tvalidation_1-auc:0.82931                                                                 \n",
      "[12]\tvalidation_0-auc:0.87306\tvalidation_1-auc:0.83100                                                                 \n",
      "[13]\tvalidation_0-auc:0.87558\tvalidation_1-auc:0.83175                                                                 \n",
      "[14]\tvalidation_0-auc:0.87654\tvalidation_1-auc:0.83146                                                                 \n",
      "[15]\tvalidation_0-auc:0.87827\tvalidation_1-auc:0.83250                                                                 \n",
      "[16]\tvalidation_0-auc:0.87957\tvalidation_1-auc:0.83348                                                                 \n",
      "[17]\tvalidation_0-auc:0.88088\tvalidation_1-auc:0.83333                                                                 \n",
      "[18]\tvalidation_0-auc:0.88179\tvalidation_1-auc:0.83249                                                                 \n",
      "[19]\tvalidation_0-auc:0.88340\tvalidation_1-auc:0.83316                                                                 \n",
      "[20]\tvalidation_0-auc:0.88475\tvalidation_1-auc:0.83383                                                                 \n",
      "[21]\tvalidation_0-auc:0.88544\tvalidation_1-auc:0.83416                                                                 \n",
      "[22]\tvalidation_0-auc:0.88641\tvalidation_1-auc:0.83463                                                                 \n",
      "[23]\tvalidation_0-auc:0.88685\tvalidation_1-auc:0.83520                                                                 \n",
      "[24]\tvalidation_0-auc:0.88784\tvalidation_1-auc:0.83587                                                                 \n",
      "[25]\tvalidation_0-auc:0.88863\tvalidation_1-auc:0.83605                                                                 \n",
      "[26]\tvalidation_0-auc:0.88907\tvalidation_1-auc:0.83590                                                                 \n",
      "[27]\tvalidation_0-auc:0.88942\tvalidation_1-auc:0.83540                                                                 \n",
      "[28]\tvalidation_0-auc:0.88980\tvalidation_1-auc:0.83600                                                                 \n",
      "[29]\tvalidation_0-auc:0.89030\tvalidation_1-auc:0.83581                                                                 \n",
      "[30]\tvalidation_0-auc:0.89078\tvalidation_1-auc:0.83576                                                                 \n",
      "[31]\tvalidation_0-auc:0.89137\tvalidation_1-auc:0.83579                                                                 \n",
      "[32]\tvalidation_0-auc:0.89176\tvalidation_1-auc:0.83610                                                                 \n",
      "[33]\tvalidation_0-auc:0.89252\tvalidation_1-auc:0.83640                                                                 \n",
      "[34]\tvalidation_0-auc:0.89330\tvalidation_1-auc:0.83667                                                                 \n",
      "[35]\tvalidation_0-auc:0.89364\tvalidation_1-auc:0.83703                                                                 \n",
      "[36]\tvalidation_0-auc:0.89429\tvalidation_1-auc:0.83732                                                                 \n",
      "[37]\tvalidation_0-auc:0.89460\tvalidation_1-auc:0.83757                                                                 \n",
      "[38]\tvalidation_0-auc:0.89488\tvalidation_1-auc:0.83784                                                                 \n",
      "[39]\tvalidation_0-auc:0.89558\tvalidation_1-auc:0.83788                                                                 \n",
      "[40]\tvalidation_0-auc:0.89609\tvalidation_1-auc:0.83808                                                                 \n",
      "[41]\tvalidation_0-auc:0.89654\tvalidation_1-auc:0.83808                                                                 \n",
      "[42]\tvalidation_0-auc:0.89685\tvalidation_1-auc:0.83820                                                                 \n",
      "[43]\tvalidation_0-auc:0.89707\tvalidation_1-auc:0.83838                                                                 \n",
      "[44]\tvalidation_0-auc:0.89723\tvalidation_1-auc:0.83829                                                                 \n",
      "[45]\tvalidation_0-auc:0.89768\tvalidation_1-auc:0.83835                                                                 \n",
      "[46]\tvalidation_0-auc:0.89801\tvalidation_1-auc:0.83827                                                                 \n",
      "[47]\tvalidation_0-auc:0.89827\tvalidation_1-auc:0.83817                                                                 \n",
      "[48]\tvalidation_0-auc:0.89848\tvalidation_1-auc:0.83827                                                                 \n",
      "[49]\tvalidation_0-auc:0.89883\tvalidation_1-auc:0.83815                                                                 \n",
      "[50]\tvalidation_0-auc:0.89964\tvalidation_1-auc:0.83816                                                                 \n",
      "[51]\tvalidation_0-auc:0.90003\tvalidation_1-auc:0.83826                                                                 \n",
      "[52]\tvalidation_0-auc:0.90026\tvalidation_1-auc:0.83825                                                                 \n",
      "[53]\tvalidation_0-auc:0.90055\tvalidation_1-auc:0.83835                                                                 \n",
      "[54]\tvalidation_0-auc:0.90072\tvalidation_1-auc:0.83830                                                                 \n",
      "[55]\tvalidation_0-auc:0.90075\tvalidation_1-auc:0.83834                                                                 \n",
      "[56]\tvalidation_0-auc:0.90152\tvalidation_1-auc:0.83805                                                                 \n",
      "[57]\tvalidation_0-auc:0.90158\tvalidation_1-auc:0.83820                                                                 \n",
      "[58]\tvalidation_0-auc:0.90186\tvalidation_1-auc:0.83815                                                                 \n",
      "[59]\tvalidation_0-auc:0.90239\tvalidation_1-auc:0.83829                                                                 \n",
      "[60]\tvalidation_0-auc:0.90261\tvalidation_1-auc:0.83826                                                                 \n",
      "[61]\tvalidation_0-auc:0.90282\tvalidation_1-auc:0.83812                                                                 \n",
      "[62]\tvalidation_0-auc:0.90303\tvalidation_1-auc:0.83808                                                                 \n",
      "[63]\tvalidation_0-auc:0.90307\tvalidation_1-auc:0.83805                                                                 \n",
      "[64]\tvalidation_0-auc:0.90327\tvalidation_1-auc:0.83813                                                                 \n",
      "[65]\tvalidation_0-auc:0.90368\tvalidation_1-auc:0.83806                                                                 \n",
      "[66]\tvalidation_0-auc:0.90373\tvalidation_1-auc:0.83809                                                                 \n",
      "[67]\tvalidation_0-auc:0.90375\tvalidation_1-auc:0.83808                                                                 \n",
      "[68]\tvalidation_0-auc:0.90398\tvalidation_1-auc:0.83802                                                                 \n",
      "[69]\tvalidation_0-auc:0.90422\tvalidation_1-auc:0.83785                                                                 \n",
      "[70]\tvalidation_0-auc:0.90426\tvalidation_1-auc:0.83784                                                                 \n",
      "[71]\tvalidation_0-auc:0.90446\tvalidation_1-auc:0.83806                                                                 \n",
      "[72]\tvalidation_0-auc:0.90520\tvalidation_1-auc:0.83790                                                                 \n",
      "[73]\tvalidation_0-auc:0.90550\tvalidation_1-auc:0.83783                                                                 \n",
      "[0]\tvalidation_0-auc:0.83826\tvalidation_1-auc:0.81054                                                                  \n",
      "[1]\tvalidation_0-auc:0.84292\tvalidation_1-auc:0.81784                                                                  \n",
      "[2]\tvalidation_0-auc:0.84393\tvalidation_1-auc:0.81710                                                                  \n",
      "[3]\tvalidation_0-auc:0.84647\tvalidation_1-auc:0.81684                                                                  \n",
      "[4]\tvalidation_0-auc:0.84880\tvalidation_1-auc:0.81787                                                                  \n",
      "[5]\tvalidation_0-auc:0.84978\tvalidation_1-auc:0.81945                                                                  \n",
      "[6]\tvalidation_0-auc:0.84977\tvalidation_1-auc:0.81959                                                                  \n",
      "[7]\tvalidation_0-auc:0.85082\tvalidation_1-auc:0.82107                                                                  \n",
      "[8]\tvalidation_0-auc:0.85138\tvalidation_1-auc:0.82104                                                                  \n",
      "[9]\tvalidation_0-auc:0.85208\tvalidation_1-auc:0.81972                                                                  \n",
      "[10]\tvalidation_0-auc:0.85253\tvalidation_1-auc:0.82047                                                                 \n",
      "[11]\tvalidation_0-auc:0.85262\tvalidation_1-auc:0.81998                                                                 \n",
      "[12]\tvalidation_0-auc:0.85238\tvalidation_1-auc:0.81984                                                                 \n",
      "[13]\tvalidation_0-auc:0.85317\tvalidation_1-auc:0.82060                                                                 \n",
      "[14]\tvalidation_0-auc:0.85336\tvalidation_1-auc:0.82007                                                                 \n",
      "[15]\tvalidation_0-auc:0.85369\tvalidation_1-auc:0.82047                                                                 \n",
      "[16]\tvalidation_0-auc:0.85372\tvalidation_1-auc:0.82061                                                                 \n",
      "[17]\tvalidation_0-auc:0.85374\tvalidation_1-auc:0.82006                                                                 \n",
      "[18]\tvalidation_0-auc:0.85456\tvalidation_1-auc:0.81981                                                                 \n",
      "[19]\tvalidation_0-auc:0.85548\tvalidation_1-auc:0.82061                                                                 \n",
      "[20]\tvalidation_0-auc:0.85603\tvalidation_1-auc:0.82095                                                                 \n",
      "[21]\tvalidation_0-auc:0.85616\tvalidation_1-auc:0.82141                                                                 \n",
      "[22]\tvalidation_0-auc:0.85660\tvalidation_1-auc:0.82169                                                                 \n",
      "[23]\tvalidation_0-auc:0.85696\tvalidation_1-auc:0.82198                                                                 \n",
      "[24]\tvalidation_0-auc:0.85747\tvalidation_1-auc:0.82233                                                                 \n",
      "[25]\tvalidation_0-auc:0.85771\tvalidation_1-auc:0.82227                                                                 \n",
      "[26]\tvalidation_0-auc:0.85779\tvalidation_1-auc:0.82181                                                                 \n",
      "[27]\tvalidation_0-auc:0.85782\tvalidation_1-auc:0.82141                                                                 \n",
      "[28]\tvalidation_0-auc:0.85796\tvalidation_1-auc:0.82157                                                                 \n",
      "[29]\tvalidation_0-auc:0.85828\tvalidation_1-auc:0.82134                                                                 \n",
      "[30]\tvalidation_0-auc:0.85848\tvalidation_1-auc:0.82105                                                                 \n",
      "[31]\tvalidation_0-auc:0.85874\tvalidation_1-auc:0.82136                                                                 \n",
      "[32]\tvalidation_0-auc:0.85905\tvalidation_1-auc:0.82148                                                                 \n",
      "[33]\tvalidation_0-auc:0.85925\tvalidation_1-auc:0.82170                                                                 \n",
      "[34]\tvalidation_0-auc:0.85959\tvalidation_1-auc:0.82188                                                                 \n",
      "[35]\tvalidation_0-auc:0.86012\tvalidation_1-auc:0.82197                                                                 \n",
      "[36]\tvalidation_0-auc:0.86029\tvalidation_1-auc:0.82208                                                                 \n",
      "[37]\tvalidation_0-auc:0.86055\tvalidation_1-auc:0.82231                                                                 \n",
      "[38]\tvalidation_0-auc:0.86076\tvalidation_1-auc:0.82234                                                                 \n",
      "[39]\tvalidation_0-auc:0.86103\tvalidation_1-auc:0.82249                                                                 \n",
      "[40]\tvalidation_0-auc:0.86116\tvalidation_1-auc:0.82213                                                                 \n",
      "[41]\tvalidation_0-auc:0.86141\tvalidation_1-auc:0.82234                                                                 \n",
      "[42]\tvalidation_0-auc:0.86170\tvalidation_1-auc:0.82281                                                                 \n",
      "[43]\tvalidation_0-auc:0.86177\tvalidation_1-auc:0.82269                                                                 \n",
      "[44]\tvalidation_0-auc:0.86182\tvalidation_1-auc:0.82203                                                                 \n",
      "[45]\tvalidation_0-auc:0.86205\tvalidation_1-auc:0.82211                                                                 \n",
      "[46]\tvalidation_0-auc:0.86219\tvalidation_1-auc:0.82229                                                                 \n",
      "[47]\tvalidation_0-auc:0.86254\tvalidation_1-auc:0.82182                                                                 \n",
      "[48]\tvalidation_0-auc:0.86266\tvalidation_1-auc:0.82209                                                                 \n",
      "[49]\tvalidation_0-auc:0.86278\tvalidation_1-auc:0.82181                                                                 \n",
      "[50]\tvalidation_0-auc:0.86307\tvalidation_1-auc:0.82199                                                                 \n",
      "[51]\tvalidation_0-auc:0.86321\tvalidation_1-auc:0.82210                                                                 \n",
      "[52]\tvalidation_0-auc:0.86355\tvalidation_1-auc:0.82171                                                                 \n",
      "[53]\tvalidation_0-auc:0.86365\tvalidation_1-auc:0.82183                                                                 \n",
      "[54]\tvalidation_0-auc:0.86379\tvalidation_1-auc:0.82116                                                                 \n",
      "[55]\tvalidation_0-auc:0.86387\tvalidation_1-auc:0.82137                                                                 \n",
      "[56]\tvalidation_0-auc:0.86399\tvalidation_1-auc:0.82146                                                                 \n",
      "[57]\tvalidation_0-auc:0.86414\tvalidation_1-auc:0.82197                                                                 \n",
      "[58]\tvalidation_0-auc:0.86427\tvalidation_1-auc:0.82211                                                                 \n",
      "[59]\tvalidation_0-auc:0.86461\tvalidation_1-auc:0.82257                                                                 \n",
      "[60]\tvalidation_0-auc:0.86489\tvalidation_1-auc:0.82284                                                                 \n",
      "[61]\tvalidation_0-auc:0.86502\tvalidation_1-auc:0.82291                                                                 \n",
      "[62]\tvalidation_0-auc:0.86528\tvalidation_1-auc:0.82272                                                                 \n",
      "[63]\tvalidation_0-auc:0.86553\tvalidation_1-auc:0.82268                                                                 \n",
      "[64]\tvalidation_0-auc:0.86562\tvalidation_1-auc:0.82295                                                                 \n",
      "[65]\tvalidation_0-auc:0.86578\tvalidation_1-auc:0.82332                                                                 \n",
      "[66]\tvalidation_0-auc:0.86597\tvalidation_1-auc:0.82320                                                                 \n",
      "[67]\tvalidation_0-auc:0.86619\tvalidation_1-auc:0.82345                                                                 \n",
      "[68]\tvalidation_0-auc:0.86636\tvalidation_1-auc:0.82356                                                                 \n",
      "[69]\tvalidation_0-auc:0.86647\tvalidation_1-auc:0.82361                                                                 \n",
      "[70]\tvalidation_0-auc:0.86662\tvalidation_1-auc:0.82375                                                                 \n",
      "[71]\tvalidation_0-auc:0.86673\tvalidation_1-auc:0.82374                                                                 \n",
      "[72]\tvalidation_0-auc:0.86683\tvalidation_1-auc:0.82372                                                                 \n",
      "[73]\tvalidation_0-auc:0.86703\tvalidation_1-auc:0.82383                                                                 \n",
      "[74]\tvalidation_0-auc:0.86713\tvalidation_1-auc:0.82388                                                                 \n",
      "[75]\tvalidation_0-auc:0.86731\tvalidation_1-auc:0.82392                                                                 \n",
      "[76]\tvalidation_0-auc:0.86738\tvalidation_1-auc:0.82388                                                                 \n",
      "[77]\tvalidation_0-auc:0.86762\tvalidation_1-auc:0.82389                                                                 \n",
      "[78]\tvalidation_0-auc:0.86771\tvalidation_1-auc:0.82394                                                                 \n",
      "[79]\tvalidation_0-auc:0.86784\tvalidation_1-auc:0.82375                                                                 \n",
      "[80]\tvalidation_0-auc:0.86796\tvalidation_1-auc:0.82350                                                                 \n",
      "[81]\tvalidation_0-auc:0.86810\tvalidation_1-auc:0.82342                                                                 \n",
      "[82]\tvalidation_0-auc:0.86827\tvalidation_1-auc:0.82348                                                                 \n",
      "[83]\tvalidation_0-auc:0.86845\tvalidation_1-auc:0.82351                                                                 \n",
      "[84]\tvalidation_0-auc:0.86865\tvalidation_1-auc:0.82360                                                                 \n",
      "[85]\tvalidation_0-auc:0.86873\tvalidation_1-auc:0.82360                                                                 \n",
      "[86]\tvalidation_0-auc:0.86892\tvalidation_1-auc:0.82367                                                                 \n",
      "[87]\tvalidation_0-auc:0.86904\tvalidation_1-auc:0.82357                                                                 \n",
      "[88]\tvalidation_0-auc:0.86918\tvalidation_1-auc:0.82391                                                                 \n",
      "[89]\tvalidation_0-auc:0.86933\tvalidation_1-auc:0.82392                                                                 \n",
      "[90]\tvalidation_0-auc:0.86953\tvalidation_1-auc:0.82385                                                                 \n",
      "[91]\tvalidation_0-auc:0.86956\tvalidation_1-auc:0.82383                                                                 \n",
      "[92]\tvalidation_0-auc:0.86968\tvalidation_1-auc:0.82396                                                                 \n",
      "[93]\tvalidation_0-auc:0.86971\tvalidation_1-auc:0.82383                                                                 \n",
      "[94]\tvalidation_0-auc:0.86976\tvalidation_1-auc:0.82376                                                                 \n",
      "[95]\tvalidation_0-auc:0.86984\tvalidation_1-auc:0.82378                                                                 \n",
      "[96]\tvalidation_0-auc:0.86993\tvalidation_1-auc:0.82376                                                                 \n",
      "[97]\tvalidation_0-auc:0.87006\tvalidation_1-auc:0.82390                                                                 \n",
      "[98]\tvalidation_0-auc:0.87016\tvalidation_1-auc:0.82406                                                                 \n",
      "[99]\tvalidation_0-auc:0.87022\tvalidation_1-auc:0.82399                                                                 \n",
      "[0]\tvalidation_0-auc:0.83122\tvalidation_1-auc:0.81779                                                                  \n",
      "[1]\tvalidation_0-auc:0.83759\tvalidation_1-auc:0.82389                                                                  \n",
      "[2]\tvalidation_0-auc:0.83932\tvalidation_1-auc:0.82672                                                                  \n",
      "[3]\tvalidation_0-auc:0.84230\tvalidation_1-auc:0.83170                                                                  \n",
      "[4]\tvalidation_0-auc:0.84352\tvalidation_1-auc:0.83323                                                                  \n",
      "[5]\tvalidation_0-auc:0.84390\tvalidation_1-auc:0.83332                                                                  \n",
      "[6]\tvalidation_0-auc:0.84452\tvalidation_1-auc:0.83292                                                                  \n",
      "[7]\tvalidation_0-auc:0.84543\tvalidation_1-auc:0.83348                                                                  \n",
      "[8]\tvalidation_0-auc:0.84547\tvalidation_1-auc:0.83338                                                                  \n",
      "[9]\tvalidation_0-auc:0.84539\tvalidation_1-auc:0.83548                                                                  \n",
      "[10]\tvalidation_0-auc:0.84596\tvalidation_1-auc:0.83588                                                                 \n",
      "[11]\tvalidation_0-auc:0.84612\tvalidation_1-auc:0.83567                                                                 \n",
      "[12]\tvalidation_0-auc:0.84638\tvalidation_1-auc:0.83545                                                                 \n",
      "[13]\tvalidation_0-auc:0.84660\tvalidation_1-auc:0.83515                                                                 \n",
      "[14]\tvalidation_0-auc:0.84682\tvalidation_1-auc:0.83585                                                                 \n",
      "[15]\tvalidation_0-auc:0.84705\tvalidation_1-auc:0.83579                                                                 \n",
      "[16]\tvalidation_0-auc:0.84786\tvalidation_1-auc:0.83617                                                                 \n",
      "[17]\tvalidation_0-auc:0.84803\tvalidation_1-auc:0.83671                                                                 \n",
      "[18]\tvalidation_0-auc:0.84889\tvalidation_1-auc:0.83672                                                                 \n",
      "[19]\tvalidation_0-auc:0.84956\tvalidation_1-auc:0.83728                                                                 \n",
      "[20]\tvalidation_0-auc:0.84996\tvalidation_1-auc:0.83739                                                                 \n",
      "[21]\tvalidation_0-auc:0.85010\tvalidation_1-auc:0.83744                                                                 \n",
      "[22]\tvalidation_0-auc:0.85052\tvalidation_1-auc:0.83810                                                                 \n",
      "[23]\tvalidation_0-auc:0.85060\tvalidation_1-auc:0.83848                                                                 \n",
      "[24]\tvalidation_0-auc:0.85079\tvalidation_1-auc:0.83872                                                                 \n",
      "[25]\tvalidation_0-auc:0.85111\tvalidation_1-auc:0.83881                                                                 \n",
      "[26]\tvalidation_0-auc:0.85129\tvalidation_1-auc:0.83907                                                                 \n",
      "[27]\tvalidation_0-auc:0.85146\tvalidation_1-auc:0.83926                                                                 \n",
      "[28]\tvalidation_0-auc:0.85165\tvalidation_1-auc:0.83936                                                                 \n",
      "[29]\tvalidation_0-auc:0.85170\tvalidation_1-auc:0.83980                                                                 \n",
      "[30]\tvalidation_0-auc:0.85180\tvalidation_1-auc:0.83973                                                                 \n",
      "[31]\tvalidation_0-auc:0.85232\tvalidation_1-auc:0.83992                                                                 \n",
      "[32]\tvalidation_0-auc:0.85267\tvalidation_1-auc:0.83993                                                                 \n",
      "[33]\tvalidation_0-auc:0.85307\tvalidation_1-auc:0.84011                                                                 \n",
      "[34]\tvalidation_0-auc:0.85337\tvalidation_1-auc:0.84003                                                                 \n",
      "[35]\tvalidation_0-auc:0.85362\tvalidation_1-auc:0.84006                                                                 \n",
      "[36]\tvalidation_0-auc:0.85387\tvalidation_1-auc:0.84010                                                                 \n",
      "[37]\tvalidation_0-auc:0.85408\tvalidation_1-auc:0.84024                                                                 \n",
      "[38]\tvalidation_0-auc:0.85439\tvalidation_1-auc:0.84018                                                                 \n",
      "[39]\tvalidation_0-auc:0.85463\tvalidation_1-auc:0.84040                                                                 \n",
      "[40]\tvalidation_0-auc:0.85481\tvalidation_1-auc:0.84041                                                                 \n",
      "[41]\tvalidation_0-auc:0.85514\tvalidation_1-auc:0.84042                                                                 \n",
      "[42]\tvalidation_0-auc:0.85535\tvalidation_1-auc:0.84050                                                                 \n",
      "[43]\tvalidation_0-auc:0.85547\tvalidation_1-auc:0.84064                                                                 \n",
      "[44]\tvalidation_0-auc:0.85555\tvalidation_1-auc:0.84077                                                                 \n",
      "[45]\tvalidation_0-auc:0.85591\tvalidation_1-auc:0.84068                                                                 \n",
      "[46]\tvalidation_0-auc:0.85627\tvalidation_1-auc:0.84073                                                                 \n",
      "[47]\tvalidation_0-auc:0.85668\tvalidation_1-auc:0.84099                                                                 \n",
      "[48]\tvalidation_0-auc:0.85702\tvalidation_1-auc:0.84099                                                                 \n",
      "[49]\tvalidation_0-auc:0.85721\tvalidation_1-auc:0.84117                                                                 \n",
      "[50]\tvalidation_0-auc:0.85755\tvalidation_1-auc:0.84115                                                                 \n",
      "[51]\tvalidation_0-auc:0.85779\tvalidation_1-auc:0.84109                                                                 \n",
      "[52]\tvalidation_0-auc:0.85787\tvalidation_1-auc:0.84119                                                                 \n",
      "[53]\tvalidation_0-auc:0.85808\tvalidation_1-auc:0.84129                                                                 \n",
      "[54]\tvalidation_0-auc:0.85811\tvalidation_1-auc:0.84129                                                                 \n",
      "[55]\tvalidation_0-auc:0.85831\tvalidation_1-auc:0.84134                                                                 \n",
      "[56]\tvalidation_0-auc:0.85863\tvalidation_1-auc:0.84141                                                                 \n",
      "[57]\tvalidation_0-auc:0.85890\tvalidation_1-auc:0.84163                                                                 \n",
      "[58]\tvalidation_0-auc:0.85923\tvalidation_1-auc:0.84173                                                                 \n",
      "[59]\tvalidation_0-auc:0.85946\tvalidation_1-auc:0.84188                                                                 \n",
      "[60]\tvalidation_0-auc:0.85971\tvalidation_1-auc:0.84184                                                                 \n",
      "[61]\tvalidation_0-auc:0.85992\tvalidation_1-auc:0.84177                                                                 \n",
      "[62]\tvalidation_0-auc:0.85989\tvalidation_1-auc:0.84201                                                                 \n",
      "[63]\tvalidation_0-auc:0.86013\tvalidation_1-auc:0.84215                                                                 \n",
      "[64]\tvalidation_0-auc:0.86034\tvalidation_1-auc:0.84215                                                                 \n",
      "[65]\tvalidation_0-auc:0.86058\tvalidation_1-auc:0.84226                                                                 \n",
      "[66]\tvalidation_0-auc:0.86058\tvalidation_1-auc:0.84230                                                                 \n",
      "[67]\tvalidation_0-auc:0.86083\tvalidation_1-auc:0.84236                                                                 \n",
      "[68]\tvalidation_0-auc:0.86098\tvalidation_1-auc:0.84261                                                                 \n",
      "[69]\tvalidation_0-auc:0.86122\tvalidation_1-auc:0.84271                                                                 \n",
      "[70]\tvalidation_0-auc:0.86140\tvalidation_1-auc:0.84271                                                                 \n",
      "[71]\tvalidation_0-auc:0.86161\tvalidation_1-auc:0.84282                                                                 \n",
      "[72]\tvalidation_0-auc:0.86178\tvalidation_1-auc:0.84281                                                                 \n",
      "[73]\tvalidation_0-auc:0.86195\tvalidation_1-auc:0.84287                                                                 \n",
      "[74]\tvalidation_0-auc:0.86209\tvalidation_1-auc:0.84287                                                                 \n",
      "[75]\tvalidation_0-auc:0.86224\tvalidation_1-auc:0.84290                                                                 \n",
      "[76]\tvalidation_0-auc:0.86236\tvalidation_1-auc:0.84287                                                                 \n",
      "[77]\tvalidation_0-auc:0.86248\tvalidation_1-auc:0.84287                                                                 \n",
      "[78]\tvalidation_0-auc:0.86257\tvalidation_1-auc:0.84288                                                                 \n",
      "[79]\tvalidation_0-auc:0.86274\tvalidation_1-auc:0.84302                                                                 \n",
      "[80]\tvalidation_0-auc:0.86283\tvalidation_1-auc:0.84316                                                                 \n",
      "[81]\tvalidation_0-auc:0.86298\tvalidation_1-auc:0.84317                                                                 \n",
      "[82]\tvalidation_0-auc:0.86314\tvalidation_1-auc:0.84337                                                                 \n",
      "[83]\tvalidation_0-auc:0.86327\tvalidation_1-auc:0.84337                                                                 \n",
      "[84]\tvalidation_0-auc:0.86342\tvalidation_1-auc:0.84342                                                                 \n",
      "[85]\tvalidation_0-auc:0.86356\tvalidation_1-auc:0.84335                                                                 \n",
      "[86]\tvalidation_0-auc:0.86366\tvalidation_1-auc:0.84334                                                                 \n",
      "[87]\tvalidation_0-auc:0.86373\tvalidation_1-auc:0.84337                                                                 \n",
      "[88]\tvalidation_0-auc:0.86385\tvalidation_1-auc:0.84336                                                                 \n",
      "[89]\tvalidation_0-auc:0.86394\tvalidation_1-auc:0.84331                                                                 \n",
      "[90]\tvalidation_0-auc:0.86406\tvalidation_1-auc:0.84342                                                                 \n",
      "[91]\tvalidation_0-auc:0.86417\tvalidation_1-auc:0.84340                                                                 \n",
      "[92]\tvalidation_0-auc:0.86426\tvalidation_1-auc:0.84341                                                                 \n",
      "[93]\tvalidation_0-auc:0.86431\tvalidation_1-auc:0.84360                                                                 \n",
      "[94]\tvalidation_0-auc:0.86447\tvalidation_1-auc:0.84379                                                                 \n",
      "[95]\tvalidation_0-auc:0.86458\tvalidation_1-auc:0.84389                                                                 \n",
      "[96]\tvalidation_0-auc:0.86469\tvalidation_1-auc:0.84391                                                                 \n",
      "[97]\tvalidation_0-auc:0.86472\tvalidation_1-auc:0.84391                                                                 \n",
      "[98]\tvalidation_0-auc:0.86486\tvalidation_1-auc:0.84394                                                                 \n",
      "[99]\tvalidation_0-auc:0.86499\tvalidation_1-auc:0.84401                                                                 \n",
      "[0]\tvalidation_0-auc:0.82771\tvalidation_1-auc:0.82031                                                                  \n",
      "[1]\tvalidation_0-auc:0.82983\tvalidation_1-auc:0.82356                                                                  \n",
      "[2]\tvalidation_0-auc:0.83142\tvalidation_1-auc:0.82223                                                                  \n",
      "[3]\tvalidation_0-auc:0.83430\tvalidation_1-auc:0.82227                                                                  \n",
      "[4]\tvalidation_0-auc:0.83567\tvalidation_1-auc:0.82422                                                                  \n",
      "[5]\tvalidation_0-auc:0.83692\tvalidation_1-auc:0.82468                                                                  \n",
      "[6]\tvalidation_0-auc:0.83657\tvalidation_1-auc:0.82576                                                                  \n",
      "[7]\tvalidation_0-auc:0.83817\tvalidation_1-auc:0.82592                                                                  \n",
      "[8]\tvalidation_0-auc:0.83865\tvalidation_1-auc:0.82747                                                                  \n",
      "[9]\tvalidation_0-auc:0.83988\tvalidation_1-auc:0.82685                                                                  \n",
      "[10]\tvalidation_0-auc:0.84079\tvalidation_1-auc:0.82857                                                                 \n",
      "[11]\tvalidation_0-auc:0.84143\tvalidation_1-auc:0.82922                                                                 \n",
      "[12]\tvalidation_0-auc:0.84147\tvalidation_1-auc:0.83005                                                                 \n",
      "[13]\tvalidation_0-auc:0.84223\tvalidation_1-auc:0.83073                                                                 \n",
      "[14]\tvalidation_0-auc:0.84258\tvalidation_1-auc:0.82998                                                                 \n",
      "[15]\tvalidation_0-auc:0.84302\tvalidation_1-auc:0.83124                                                                 \n",
      "[16]\tvalidation_0-auc:0.84368\tvalidation_1-auc:0.83153                                                                 \n",
      "[17]\tvalidation_0-auc:0.84348\tvalidation_1-auc:0.83032                                                                 \n",
      "[18]\tvalidation_0-auc:0.84375\tvalidation_1-auc:0.82920                                                                 \n",
      "[19]\tvalidation_0-auc:0.84439\tvalidation_1-auc:0.83015                                                                 \n",
      "[20]\tvalidation_0-auc:0.84547\tvalidation_1-auc:0.83112                                                                 \n",
      "[21]\tvalidation_0-auc:0.84632\tvalidation_1-auc:0.83174                                                                 \n",
      "[22]\tvalidation_0-auc:0.84693\tvalidation_1-auc:0.83282                                                                 \n",
      "[23]\tvalidation_0-auc:0.84743\tvalidation_1-auc:0.83324                                                                 \n",
      "[24]\tvalidation_0-auc:0.84828\tvalidation_1-auc:0.83367                                                                 \n",
      "[25]\tvalidation_0-auc:0.84880\tvalidation_1-auc:0.83400                                                                 \n",
      "[26]\tvalidation_0-auc:0.84913\tvalidation_1-auc:0.83377                                                                 \n",
      "[27]\tvalidation_0-auc:0.84938\tvalidation_1-auc:0.83333                                                                 \n",
      "[28]\tvalidation_0-auc:0.84987\tvalidation_1-auc:0.83341                                                                 \n",
      "[29]\tvalidation_0-auc:0.84984\tvalidation_1-auc:0.83293                                                                 \n",
      "[30]\tvalidation_0-auc:0.84971\tvalidation_1-auc:0.83247                                                                 \n",
      "[31]\tvalidation_0-auc:0.85011\tvalidation_1-auc:0.83296                                                                 \n",
      "[32]\tvalidation_0-auc:0.85089\tvalidation_1-auc:0.83346                                                                 \n",
      "[33]\tvalidation_0-auc:0.85126\tvalidation_1-auc:0.83399                                                                 \n",
      "[34]\tvalidation_0-auc:0.85147\tvalidation_1-auc:0.83420                                                                 \n",
      "[35]\tvalidation_0-auc:0.85197\tvalidation_1-auc:0.83472                                                                 \n",
      "[36]\tvalidation_0-auc:0.85223\tvalidation_1-auc:0.83521                                                                 \n",
      "[37]\tvalidation_0-auc:0.85244\tvalidation_1-auc:0.83544                                                                 \n",
      "[38]\tvalidation_0-auc:0.85279\tvalidation_1-auc:0.83564                                                                 \n",
      "[39]\tvalidation_0-auc:0.85301\tvalidation_1-auc:0.83558                                                                 \n",
      "[40]\tvalidation_0-auc:0.85322\tvalidation_1-auc:0.83536                                                                 \n",
      "[41]\tvalidation_0-auc:0.85350\tvalidation_1-auc:0.83559                                                                 \n",
      "[42]\tvalidation_0-auc:0.85390\tvalidation_1-auc:0.83572                                                                 \n",
      "[43]\tvalidation_0-auc:0.85392\tvalidation_1-auc:0.83536                                                                 \n",
      "[44]\tvalidation_0-auc:0.85396\tvalidation_1-auc:0.83500                                                                 \n",
      "[45]\tvalidation_0-auc:0.85423\tvalidation_1-auc:0.83523                                                                 \n",
      "[46]\tvalidation_0-auc:0.85443\tvalidation_1-auc:0.83554                                                                 \n",
      "[47]\tvalidation_0-auc:0.85482\tvalidation_1-auc:0.83538                                                                 \n",
      "[48]\tvalidation_0-auc:0.85505\tvalidation_1-auc:0.83550                                                                 \n",
      "[49]\tvalidation_0-auc:0.85534\tvalidation_1-auc:0.83541                                                                 \n",
      "[50]\tvalidation_0-auc:0.85558\tvalidation_1-auc:0.83562                                                                 \n",
      "[51]\tvalidation_0-auc:0.85591\tvalidation_1-auc:0.83582                                                                 \n",
      "[52]\tvalidation_0-auc:0.85591\tvalidation_1-auc:0.83549                                                                 \n",
      "[53]\tvalidation_0-auc:0.85596\tvalidation_1-auc:0.83559                                                                 \n",
      "[54]\tvalidation_0-auc:0.85607\tvalidation_1-auc:0.83525                                                                 \n",
      "[55]\tvalidation_0-auc:0.85624\tvalidation_1-auc:0.83542                                                                 \n",
      "[56]\tvalidation_0-auc:0.85659\tvalidation_1-auc:0.83595                                                                 \n",
      "[57]\tvalidation_0-auc:0.85683\tvalidation_1-auc:0.83612                                                                 \n",
      "[58]\tvalidation_0-auc:0.85716\tvalidation_1-auc:0.83622                                                                 \n",
      "[59]\tvalidation_0-auc:0.85751\tvalidation_1-auc:0.83626                                                                 \n",
      "[60]\tvalidation_0-auc:0.85773\tvalidation_1-auc:0.83631                                                                 \n",
      "[61]\tvalidation_0-auc:0.85788\tvalidation_1-auc:0.83636                                                                 \n",
      "[62]\tvalidation_0-auc:0.85811\tvalidation_1-auc:0.83634                                                                 \n",
      "[63]\tvalidation_0-auc:0.85840\tvalidation_1-auc:0.83613                                                                 \n",
      "[64]\tvalidation_0-auc:0.85869\tvalidation_1-auc:0.83628                                                                 \n",
      "[65]\tvalidation_0-auc:0.85890\tvalidation_1-auc:0.83641                                                                 \n",
      "[66]\tvalidation_0-auc:0.85900\tvalidation_1-auc:0.83617                                                                 \n",
      "[67]\tvalidation_0-auc:0.85924\tvalidation_1-auc:0.83627                                                                 \n",
      "[68]\tvalidation_0-auc:0.85944\tvalidation_1-auc:0.83632                                                                 \n",
      "[69]\tvalidation_0-auc:0.85959\tvalidation_1-auc:0.83643                                                                 \n",
      "[70]\tvalidation_0-auc:0.85988\tvalidation_1-auc:0.83658                                                                 \n",
      "[71]\tvalidation_0-auc:0.86006\tvalidation_1-auc:0.83685                                                                 \n",
      "[72]\tvalidation_0-auc:0.86025\tvalidation_1-auc:0.83694                                                                 \n",
      "[73]\tvalidation_0-auc:0.86041\tvalidation_1-auc:0.83704                                                                 \n",
      "[74]\tvalidation_0-auc:0.86069\tvalidation_1-auc:0.83715                                                                 \n",
      "[75]\tvalidation_0-auc:0.86088\tvalidation_1-auc:0.83724                                                                 \n",
      "[76]\tvalidation_0-auc:0.86104\tvalidation_1-auc:0.83744                                                                 \n",
      "[77]\tvalidation_0-auc:0.86111\tvalidation_1-auc:0.83742                                                                 \n",
      "[78]\tvalidation_0-auc:0.86120\tvalidation_1-auc:0.83760                                                                 \n",
      "[79]\tvalidation_0-auc:0.86138\tvalidation_1-auc:0.83757                                                                 \n",
      "[80]\tvalidation_0-auc:0.86157\tvalidation_1-auc:0.83760                                                                 \n",
      "[81]\tvalidation_0-auc:0.86172\tvalidation_1-auc:0.83773                                                                 \n",
      "[82]\tvalidation_0-auc:0.86187\tvalidation_1-auc:0.83760                                                                 \n",
      "[83]\tvalidation_0-auc:0.86201\tvalidation_1-auc:0.83765                                                                 \n",
      "[84]\tvalidation_0-auc:0.86222\tvalidation_1-auc:0.83773                                                                 \n",
      "[85]\tvalidation_0-auc:0.86236\tvalidation_1-auc:0.83770                                                                 \n",
      "[86]\tvalidation_0-auc:0.86256\tvalidation_1-auc:0.83771                                                                 \n",
      "[87]\tvalidation_0-auc:0.86275\tvalidation_1-auc:0.83774                                                                 \n",
      "[88]\tvalidation_0-auc:0.86294\tvalidation_1-auc:0.83781                                                                 \n",
      "[89]\tvalidation_0-auc:0.86306\tvalidation_1-auc:0.83784                                                                 \n",
      "[90]\tvalidation_0-auc:0.86330\tvalidation_1-auc:0.83781                                                                 \n",
      "[91]\tvalidation_0-auc:0.86355\tvalidation_1-auc:0.83786                                                                 \n",
      "[92]\tvalidation_0-auc:0.86376\tvalidation_1-auc:0.83802                                                                 \n",
      "[93]\tvalidation_0-auc:0.86391\tvalidation_1-auc:0.83803                                                                 \n",
      "[94]\tvalidation_0-auc:0.86398\tvalidation_1-auc:0.83793                                                                 \n",
      "[95]\tvalidation_0-auc:0.86417\tvalidation_1-auc:0.83797                                                                 \n",
      "[96]\tvalidation_0-auc:0.86439\tvalidation_1-auc:0.83804                                                                 \n",
      "[97]\tvalidation_0-auc:0.86453\tvalidation_1-auc:0.83814                                                                 \n",
      "[98]\tvalidation_0-auc:0.86471\tvalidation_1-auc:0.83817                                                                 \n",
      "[99]\tvalidation_0-auc:0.86483\tvalidation_1-auc:0.83818                                                                 \n",
      "[0]\tvalidation_0-auc:0.83786\tvalidation_1-auc:0.81072                                                                  \n",
      "[1]\tvalidation_0-auc:0.83626\tvalidation_1-auc:0.80329                                                                  \n",
      "[2]\tvalidation_0-auc:0.84573\tvalidation_1-auc:0.81218                                                                  \n",
      "[3]\tvalidation_0-auc:0.84300\tvalidation_1-auc:0.80851                                                                  \n",
      "[4]\tvalidation_0-auc:0.84028\tvalidation_1-auc:0.80269                                                                  \n",
      "[5]\tvalidation_0-auc:0.84903\tvalidation_1-auc:0.81113                                                                  \n",
      "[6]\tvalidation_0-auc:0.85266\tvalidation_1-auc:0.81545                                                                  \n",
      "[7]\tvalidation_0-auc:0.85664\tvalidation_1-auc:0.81931                                                                  \n",
      "[8]\tvalidation_0-auc:0.85880\tvalidation_1-auc:0.82053                                                                  \n",
      "[9]\tvalidation_0-auc:0.85793\tvalidation_1-auc:0.81828                                                                  \n",
      "[10]\tvalidation_0-auc:0.85969\tvalidation_1-auc:0.82030                                                                 \n",
      "[11]\tvalidation_0-auc:0.86165\tvalidation_1-auc:0.82125                                                                 \n",
      "[12]\tvalidation_0-auc:0.86284\tvalidation_1-auc:0.82069                                                                 \n",
      "[13]\tvalidation_0-auc:0.86413\tvalidation_1-auc:0.82180                                                                 \n",
      "[14]\tvalidation_0-auc:0.86492\tvalidation_1-auc:0.82154                                                                 \n",
      "[15]\tvalidation_0-auc:0.86651\tvalidation_1-auc:0.82169                                                                 \n",
      "[16]\tvalidation_0-auc:0.86716\tvalidation_1-auc:0.82226                                                                 \n",
      "[17]\tvalidation_0-auc:0.86781\tvalidation_1-auc:0.82208                                                                 \n",
      "[18]\tvalidation_0-auc:0.86871\tvalidation_1-auc:0.82223                                                                 \n",
      "[19]\tvalidation_0-auc:0.86942\tvalidation_1-auc:0.82275                                                                 \n",
      "[20]\tvalidation_0-auc:0.86990\tvalidation_1-auc:0.82321                                                                 \n",
      "[21]\tvalidation_0-auc:0.87043\tvalidation_1-auc:0.82340                                                                 \n",
      "[22]\tvalidation_0-auc:0.87108\tvalidation_1-auc:0.82394                                                                 \n",
      "[23]\tvalidation_0-auc:0.87122\tvalidation_1-auc:0.82371                                                                 \n",
      "[24]\tvalidation_0-auc:0.87166\tvalidation_1-auc:0.82409                                                                 \n",
      "[25]\tvalidation_0-auc:0.87209\tvalidation_1-auc:0.82468                                                                 \n",
      "[26]\tvalidation_0-auc:0.87268\tvalidation_1-auc:0.82447                                                                 \n",
      "[27]\tvalidation_0-auc:0.87307\tvalidation_1-auc:0.82415                                                                 \n",
      "[28]\tvalidation_0-auc:0.87324\tvalidation_1-auc:0.82425                                                                 \n",
      "[29]\tvalidation_0-auc:0.87417\tvalidation_1-auc:0.82430                                                                 \n",
      "[30]\tvalidation_0-auc:0.87470\tvalidation_1-auc:0.82446                                                                 \n",
      "[31]\tvalidation_0-auc:0.87559\tvalidation_1-auc:0.82415                                                                 \n",
      "[32]\tvalidation_0-auc:0.87571\tvalidation_1-auc:0.82442                                                                 \n",
      "[33]\tvalidation_0-auc:0.87644\tvalidation_1-auc:0.82477                                                                 \n",
      "[34]\tvalidation_0-auc:0.87692\tvalidation_1-auc:0.82544                                                                 \n",
      "[35]\tvalidation_0-auc:0.87713\tvalidation_1-auc:0.82550                                                                 \n",
      "[36]\tvalidation_0-auc:0.87755\tvalidation_1-auc:0.82570                                                                 \n",
      "[37]\tvalidation_0-auc:0.87807\tvalidation_1-auc:0.82577                                                                 \n",
      "[38]\tvalidation_0-auc:0.87846\tvalidation_1-auc:0.82594                                                                 \n",
      "[39]\tvalidation_0-auc:0.87878\tvalidation_1-auc:0.82627                                                                 \n",
      "[40]\tvalidation_0-auc:0.87893\tvalidation_1-auc:0.82619                                                                 \n",
      "[41]\tvalidation_0-auc:0.87944\tvalidation_1-auc:0.82623                                                                 \n",
      "[42]\tvalidation_0-auc:0.88006\tvalidation_1-auc:0.82604                                                                 \n",
      "[43]\tvalidation_0-auc:0.88013\tvalidation_1-auc:0.82601                                                                 \n",
      "[44]\tvalidation_0-auc:0.88043\tvalidation_1-auc:0.82584                                                                 \n",
      "[45]\tvalidation_0-auc:0.88096\tvalidation_1-auc:0.82593                                                                 \n",
      "[46]\tvalidation_0-auc:0.88131\tvalidation_1-auc:0.82564                                                                 \n",
      "[47]\tvalidation_0-auc:0.88142\tvalidation_1-auc:0.82568                                                                 \n",
      "[48]\tvalidation_0-auc:0.88159\tvalidation_1-auc:0.82583                                                                 \n",
      "[49]\tvalidation_0-auc:0.88177\tvalidation_1-auc:0.82571                                                                 \n",
      "[50]\tvalidation_0-auc:0.88249\tvalidation_1-auc:0.82576                                                                 \n",
      "[51]\tvalidation_0-auc:0.88266\tvalidation_1-auc:0.82585                                                                 \n",
      "[52]\tvalidation_0-auc:0.88295\tvalidation_1-auc:0.82569                                                                 \n",
      "[53]\tvalidation_0-auc:0.88312\tvalidation_1-auc:0.82570                                                                 \n",
      "[54]\tvalidation_0-auc:0.88330\tvalidation_1-auc:0.82551                                                                 \n",
      "[55]\tvalidation_0-auc:0.88367\tvalidation_1-auc:0.82548                                                                 \n",
      "[56]\tvalidation_0-auc:0.88381\tvalidation_1-auc:0.82530                                                                 \n",
      "[57]\tvalidation_0-auc:0.88407\tvalidation_1-auc:0.82546                                                                 \n",
      "[58]\tvalidation_0-auc:0.88424\tvalidation_1-auc:0.82535                                                                 \n",
      "[59]\tvalidation_0-auc:0.88444\tvalidation_1-auc:0.82542                                                                 \n",
      "[60]\tvalidation_0-auc:0.88460\tvalidation_1-auc:0.82540                                                                 \n",
      "[61]\tvalidation_0-auc:0.88485\tvalidation_1-auc:0.82535                                                                 \n",
      "[62]\tvalidation_0-auc:0.88556\tvalidation_1-auc:0.82563                                                                 \n",
      "[63]\tvalidation_0-auc:0.88568\tvalidation_1-auc:0.82546                                                                 \n",
      "[64]\tvalidation_0-auc:0.88628\tvalidation_1-auc:0.82554                                                                 \n",
      "[65]\tvalidation_0-auc:0.88677\tvalidation_1-auc:0.82535                                                                 \n",
      "[66]\tvalidation_0-auc:0.88683\tvalidation_1-auc:0.82543                                                                 \n",
      "[67]\tvalidation_0-auc:0.88687\tvalidation_1-auc:0.82537                                                                 \n",
      "[68]\tvalidation_0-auc:0.88742\tvalidation_1-auc:0.82547                                                                 \n",
      "[69]\tvalidation_0-auc:0.88767\tvalidation_1-auc:0.82552                                                                 \n",
      "[0]\tvalidation_0-auc:0.83074\tvalidation_1-auc:0.81732                                                                  \n",
      "[1]\tvalidation_0-auc:0.83150\tvalidation_1-auc:0.82084                                                                  \n",
      "[2]\tvalidation_0-auc:0.84171\tvalidation_1-auc:0.83041                                                                  \n",
      "[3]\tvalidation_0-auc:0.83680\tvalidation_1-auc:0.82944                                                                  \n",
      "[4]\tvalidation_0-auc:0.83452\tvalidation_1-auc:0.82715                                                                  \n",
      "[5]\tvalidation_0-auc:0.84303\tvalidation_1-auc:0.83300                                                                  \n",
      "[6]\tvalidation_0-auc:0.84887\tvalidation_1-auc:0.83676                                                                  \n",
      "[7]\tvalidation_0-auc:0.85180\tvalidation_1-auc:0.83833                                                                  \n",
      "[8]\tvalidation_0-auc:0.85427\tvalidation_1-auc:0.83859                                                                  \n",
      "[9]\tvalidation_0-auc:0.85407\tvalidation_1-auc:0.83963                                                                  \n",
      "[10]\tvalidation_0-auc:0.85589\tvalidation_1-auc:0.84023                                                                 \n",
      "[11]\tvalidation_0-auc:0.85763\tvalidation_1-auc:0.83996                                                                 \n",
      "[12]\tvalidation_0-auc:0.85882\tvalidation_1-auc:0.84045                                                                 \n",
      "[13]\tvalidation_0-auc:0.86011\tvalidation_1-auc:0.84109                                                                 \n",
      "[14]\tvalidation_0-auc:0.86102\tvalidation_1-auc:0.84212                                                                 \n",
      "[15]\tvalidation_0-auc:0.86178\tvalidation_1-auc:0.84247                                                                 \n",
      "[16]\tvalidation_0-auc:0.86279\tvalidation_1-auc:0.84266                                                                 \n",
      "[17]\tvalidation_0-auc:0.86358\tvalidation_1-auc:0.84322                                                                 \n",
      "[18]\tvalidation_0-auc:0.86452\tvalidation_1-auc:0.84384                                                                 \n",
      "[19]\tvalidation_0-auc:0.86506\tvalidation_1-auc:0.84399                                                                 \n",
      "[20]\tvalidation_0-auc:0.86571\tvalidation_1-auc:0.84411                                                                 \n",
      "[21]\tvalidation_0-auc:0.86618\tvalidation_1-auc:0.84408                                                                 \n",
      "[22]\tvalidation_0-auc:0.86645\tvalidation_1-auc:0.84409                                                                 \n",
      "[23]\tvalidation_0-auc:0.86693\tvalidation_1-auc:0.84439                                                                 \n",
      "[24]\tvalidation_0-auc:0.86724\tvalidation_1-auc:0.84454                                                                 \n",
      "[25]\tvalidation_0-auc:0.86768\tvalidation_1-auc:0.84481                                                                 \n",
      "[26]\tvalidation_0-auc:0.86813\tvalidation_1-auc:0.84503                                                                 \n",
      "[27]\tvalidation_0-auc:0.86847\tvalidation_1-auc:0.84546                                                                 \n",
      "[28]\tvalidation_0-auc:0.86863\tvalidation_1-auc:0.84556                                                                 \n",
      "[29]\tvalidation_0-auc:0.86886\tvalidation_1-auc:0.84578                                                                 \n",
      "[30]\tvalidation_0-auc:0.86923\tvalidation_1-auc:0.84595                                                                 \n",
      "[31]\tvalidation_0-auc:0.86947\tvalidation_1-auc:0.84641                                                                 \n",
      "[32]\tvalidation_0-auc:0.86991\tvalidation_1-auc:0.84637                                                                 \n",
      "[33]\tvalidation_0-auc:0.87031\tvalidation_1-auc:0.84631                                                                 \n",
      "[34]\tvalidation_0-auc:0.87056\tvalidation_1-auc:0.84634                                                                 \n",
      "[35]\tvalidation_0-auc:0.87100\tvalidation_1-auc:0.84612                                                                 \n",
      "[36]\tvalidation_0-auc:0.87143\tvalidation_1-auc:0.84611                                                                 \n",
      "[37]\tvalidation_0-auc:0.87166\tvalidation_1-auc:0.84601                                                                 \n",
      "[38]\tvalidation_0-auc:0.87245\tvalidation_1-auc:0.84614                                                                 \n",
      "[39]\tvalidation_0-auc:0.87271\tvalidation_1-auc:0.84622                                                                 \n",
      "[40]\tvalidation_0-auc:0.87358\tvalidation_1-auc:0.84642                                                                 \n",
      "[41]\tvalidation_0-auc:0.87408\tvalidation_1-auc:0.84647                                                                 \n",
      "[42]\tvalidation_0-auc:0.87427\tvalidation_1-auc:0.84648                                                                 \n",
      "[43]\tvalidation_0-auc:0.87503\tvalidation_1-auc:0.84645                                                                 \n",
      "[44]\tvalidation_0-auc:0.87519\tvalidation_1-auc:0.84649                                                                 \n",
      "[45]\tvalidation_0-auc:0.87548\tvalidation_1-auc:0.84639                                                                 \n",
      "[46]\tvalidation_0-auc:0.87567\tvalidation_1-auc:0.84639                                                                 \n",
      "[47]\tvalidation_0-auc:0.87593\tvalidation_1-auc:0.84644                                                                 \n",
      "[48]\tvalidation_0-auc:0.87608\tvalidation_1-auc:0.84637                                                                 \n",
      "[49]\tvalidation_0-auc:0.87623\tvalidation_1-auc:0.84619                                                                 \n",
      "[50]\tvalidation_0-auc:0.87700\tvalidation_1-auc:0.84629                                                                 \n",
      "[51]\tvalidation_0-auc:0.87726\tvalidation_1-auc:0.84645                                                                 \n",
      "[52]\tvalidation_0-auc:0.87741\tvalidation_1-auc:0.84651                                                                 \n",
      "[53]\tvalidation_0-auc:0.87796\tvalidation_1-auc:0.84622                                                                 \n",
      "[54]\tvalidation_0-auc:0.87821\tvalidation_1-auc:0.84635                                                                 \n",
      "[55]\tvalidation_0-auc:0.87831\tvalidation_1-auc:0.84628                                                                 \n",
      "[56]\tvalidation_0-auc:0.87880\tvalidation_1-auc:0.84646                                                                 \n",
      "[57]\tvalidation_0-auc:0.87898\tvalidation_1-auc:0.84638                                                                 \n",
      "[58]\tvalidation_0-auc:0.87912\tvalidation_1-auc:0.84627                                                                 \n",
      "[59]\tvalidation_0-auc:0.87950\tvalidation_1-auc:0.84646                                                                 \n",
      "[60]\tvalidation_0-auc:0.87993\tvalidation_1-auc:0.84648                                                                 \n",
      "[61]\tvalidation_0-auc:0.88033\tvalidation_1-auc:0.84640                                                                 \n",
      "[62]\tvalidation_0-auc:0.88066\tvalidation_1-auc:0.84622                                                                 \n",
      "[63]\tvalidation_0-auc:0.88129\tvalidation_1-auc:0.84584                                                                 \n",
      "[64]\tvalidation_0-auc:0.88176\tvalidation_1-auc:0.84587                                                                 \n",
      "[65]\tvalidation_0-auc:0.88199\tvalidation_1-auc:0.84574                                                                 \n",
      "[66]\tvalidation_0-auc:0.88228\tvalidation_1-auc:0.84545                                                                 \n",
      "[67]\tvalidation_0-auc:0.88259\tvalidation_1-auc:0.84563                                                                 \n",
      "[68]\tvalidation_0-auc:0.88287\tvalidation_1-auc:0.84561                                                                 \n",
      "[69]\tvalidation_0-auc:0.88339\tvalidation_1-auc:0.84578                                                                 \n",
      "[70]\tvalidation_0-auc:0.88376\tvalidation_1-auc:0.84592                                                                 \n",
      "[71]\tvalidation_0-auc:0.88386\tvalidation_1-auc:0.84587                                                                 \n",
      "[72]\tvalidation_0-auc:0.88432\tvalidation_1-auc:0.84565                                                                 \n",
      "[73]\tvalidation_0-auc:0.88442\tvalidation_1-auc:0.84563                                                                 \n",
      "[74]\tvalidation_0-auc:0.88467\tvalidation_1-auc:0.84569                                                                 \n",
      "[75]\tvalidation_0-auc:0.88491\tvalidation_1-auc:0.84578                                                                 \n",
      "[76]\tvalidation_0-auc:0.88505\tvalidation_1-auc:0.84573                                                                 \n",
      "[77]\tvalidation_0-auc:0.88554\tvalidation_1-auc:0.84589                                                                 \n",
      "[78]\tvalidation_0-auc:0.88632\tvalidation_1-auc:0.84577                                                                 \n",
      "[79]\tvalidation_0-auc:0.88694\tvalidation_1-auc:0.84559                                                                 \n",
      "[80]\tvalidation_0-auc:0.88736\tvalidation_1-auc:0.84557                                                                 \n",
      "[81]\tvalidation_0-auc:0.88784\tvalidation_1-auc:0.84576                                                                 \n",
      "[82]\tvalidation_0-auc:0.88802\tvalidation_1-auc:0.84568                                                                 \n",
      "[0]\tvalidation_0-auc:0.82771\tvalidation_1-auc:0.82031                                                                  \n",
      "[1]\tvalidation_0-auc:0.82733\tvalidation_1-auc:0.80882                                                                  \n",
      "[2]\tvalidation_0-auc:0.83570\tvalidation_1-auc:0.81593                                                                  \n",
      "[3]\tvalidation_0-auc:0.83422\tvalidation_1-auc:0.81424                                                                  \n",
      "[4]\tvalidation_0-auc:0.83350\tvalidation_1-auc:0.81260                                                                  \n",
      "[5]\tvalidation_0-auc:0.84025\tvalidation_1-auc:0.81945                                                                  \n",
      "[6]\tvalidation_0-auc:0.84353\tvalidation_1-auc:0.82478                                                                  \n",
      "[7]\tvalidation_0-auc:0.84606\tvalidation_1-auc:0.82768                                                                  \n",
      "[8]\tvalidation_0-auc:0.84937\tvalidation_1-auc:0.83145                                                                  \n",
      "[9]\tvalidation_0-auc:0.84897\tvalidation_1-auc:0.82983                                                                  \n",
      "[10]\tvalidation_0-auc:0.85103\tvalidation_1-auc:0.83233                                                                 \n",
      "[11]\tvalidation_0-auc:0.85321\tvalidation_1-auc:0.83345                                                                 \n",
      "[12]\tvalidation_0-auc:0.85485\tvalidation_1-auc:0.83428                                                                 \n",
      "[13]\tvalidation_0-auc:0.85680\tvalidation_1-auc:0.83503                                                                 \n",
      "[14]\tvalidation_0-auc:0.85784\tvalidation_1-auc:0.83482                                                                 \n",
      "[15]\tvalidation_0-auc:0.85919\tvalidation_1-auc:0.83597                                                                 \n",
      "[16]\tvalidation_0-auc:0.86046\tvalidation_1-auc:0.83622                                                                 \n",
      "[17]\tvalidation_0-auc:0.86148\tvalidation_1-auc:0.83581                                                                 \n",
      "[18]\tvalidation_0-auc:0.86203\tvalidation_1-auc:0.83587                                                                 \n",
      "[19]\tvalidation_0-auc:0.86268\tvalidation_1-auc:0.83685                                                                 \n",
      "[20]\tvalidation_0-auc:0.86360\tvalidation_1-auc:0.83772                                                                 \n",
      "[21]\tvalidation_0-auc:0.86438\tvalidation_1-auc:0.83824                                                                 \n",
      "[22]\tvalidation_0-auc:0.86495\tvalidation_1-auc:0.83885                                                                 \n",
      "[23]\tvalidation_0-auc:0.86567\tvalidation_1-auc:0.83954                                                                 \n",
      "[24]\tvalidation_0-auc:0.86624\tvalidation_1-auc:0.83969                                                                 \n",
      "[25]\tvalidation_0-auc:0.86691\tvalidation_1-auc:0.83982                                                                 \n",
      "[26]\tvalidation_0-auc:0.86815\tvalidation_1-auc:0.83983                                                                 \n",
      "[27]\tvalidation_0-auc:0.86916\tvalidation_1-auc:0.83972                                                                 \n",
      "[28]\tvalidation_0-auc:0.86977\tvalidation_1-auc:0.83982                                                                 \n",
      "[29]\tvalidation_0-auc:0.87079\tvalidation_1-auc:0.84006                                                                 \n",
      "[30]\tvalidation_0-auc:0.87147\tvalidation_1-auc:0.83985                                                                 \n",
      "[31]\tvalidation_0-auc:0.87243\tvalidation_1-auc:0.84007                                                                 \n",
      "[32]\tvalidation_0-auc:0.87284\tvalidation_1-auc:0.84014                                                                 \n",
      "[33]\tvalidation_0-auc:0.87315\tvalidation_1-auc:0.84018                                                                 \n",
      "[34]\tvalidation_0-auc:0.87361\tvalidation_1-auc:0.84027                                                                 \n",
      "[35]\tvalidation_0-auc:0.87397\tvalidation_1-auc:0.84016                                                                 \n",
      "[36]\tvalidation_0-auc:0.87458\tvalidation_1-auc:0.83978                                                                 \n",
      "[37]\tvalidation_0-auc:0.87505\tvalidation_1-auc:0.83987                                                                 \n",
      "[38]\tvalidation_0-auc:0.87513\tvalidation_1-auc:0.83991                                                                 \n",
      "[39]\tvalidation_0-auc:0.87607\tvalidation_1-auc:0.84030                                                                 \n",
      "[40]\tvalidation_0-auc:0.87645\tvalidation_1-auc:0.84006                                                                 \n",
      "[41]\tvalidation_0-auc:0.87679\tvalidation_1-auc:0.84016                                                                 \n",
      "[42]\tvalidation_0-auc:0.87701\tvalidation_1-auc:0.84041                                                                 \n",
      "[43]\tvalidation_0-auc:0.87735\tvalidation_1-auc:0.84041                                                                 \n",
      "[44]\tvalidation_0-auc:0.87743\tvalidation_1-auc:0.84048                                                                 \n",
      "[45]\tvalidation_0-auc:0.87840\tvalidation_1-auc:0.84028                                                                 \n",
      "[46]\tvalidation_0-auc:0.87850\tvalidation_1-auc:0.84029                                                                 \n",
      "[47]\tvalidation_0-auc:0.87881\tvalidation_1-auc:0.84022                                                                 \n",
      "[48]\tvalidation_0-auc:0.87898\tvalidation_1-auc:0.84005                                                                 \n",
      "[49]\tvalidation_0-auc:0.87911\tvalidation_1-auc:0.84008                                                                 \n",
      "[50]\tvalidation_0-auc:0.88007\tvalidation_1-auc:0.83977                                                                 \n",
      "[51]\tvalidation_0-auc:0.88040\tvalidation_1-auc:0.83989                                                                 \n",
      "[52]\tvalidation_0-auc:0.88054\tvalidation_1-auc:0.83994                                                                 \n",
      "[53]\tvalidation_0-auc:0.88103\tvalidation_1-auc:0.83983                                                                 \n",
      "[54]\tvalidation_0-auc:0.88121\tvalidation_1-auc:0.83975                                                                 \n",
      "[55]\tvalidation_0-auc:0.88154\tvalidation_1-auc:0.83965                                                                 \n",
      "[56]\tvalidation_0-auc:0.88167\tvalidation_1-auc:0.83976                                                                 \n",
      "[57]\tvalidation_0-auc:0.88206\tvalidation_1-auc:0.83956                                                                 \n",
      "[58]\tvalidation_0-auc:0.88226\tvalidation_1-auc:0.83954                                                                 \n",
      "[59]\tvalidation_0-auc:0.88246\tvalidation_1-auc:0.83958                                                                 \n",
      "[60]\tvalidation_0-auc:0.88279\tvalidation_1-auc:0.83962                                                                 \n",
      "[61]\tvalidation_0-auc:0.88315\tvalidation_1-auc:0.83977                                                                 \n",
      "[62]\tvalidation_0-auc:0.88334\tvalidation_1-auc:0.83972                                                                 \n",
      "[63]\tvalidation_0-auc:0.88383\tvalidation_1-auc:0.83974                                                                 \n",
      "[64]\tvalidation_0-auc:0.88454\tvalidation_1-auc:0.83938                                                                 \n",
      "[65]\tvalidation_0-auc:0.88494\tvalidation_1-auc:0.83932                                                                 \n",
      "[66]\tvalidation_0-auc:0.88501\tvalidation_1-auc:0.83926                                                                 \n",
      "[67]\tvalidation_0-auc:0.88559\tvalidation_1-auc:0.83936                                                                 \n",
      "[68]\tvalidation_0-auc:0.88577\tvalidation_1-auc:0.83920                                                                 \n",
      "[69]\tvalidation_0-auc:0.88616\tvalidation_1-auc:0.83897                                                                 \n",
      "[70]\tvalidation_0-auc:0.88640\tvalidation_1-auc:0.83890                                                                 \n",
      "[71]\tvalidation_0-auc:0.88649\tvalidation_1-auc:0.83898                                                                 \n",
      "[72]\tvalidation_0-auc:0.88660\tvalidation_1-auc:0.83900                                                                 \n",
      "[73]\tvalidation_0-auc:0.88704\tvalidation_1-auc:0.83891                                                                 \n",
      "[74]\tvalidation_0-auc:0.88759\tvalidation_1-auc:0.83900                                                                 \n",
      "[0]\tvalidation_0-auc:0.84898\tvalidation_1-auc:0.81125                                                                  \n",
      "[1]\tvalidation_0-auc:0.85647\tvalidation_1-auc:0.80901                                                                  \n",
      "[2]\tvalidation_0-auc:0.86453\tvalidation_1-auc:0.81562                                                                  \n",
      "[3]\tvalidation_0-auc:0.86505\tvalidation_1-auc:0.81131                                                                  \n",
      "[4]\tvalidation_0-auc:0.86488\tvalidation_1-auc:0.80822                                                                  \n",
      "[5]\tvalidation_0-auc:0.86814\tvalidation_1-auc:0.80938                                                                  \n",
      "[6]\tvalidation_0-auc:0.87534\tvalidation_1-auc:0.81440                                                                  \n",
      "[7]\tvalidation_0-auc:0.87721\tvalidation_1-auc:0.81345                                                                  \n",
      "[8]\tvalidation_0-auc:0.88291\tvalidation_1-auc:0.81611                                                                  \n",
      "[9]\tvalidation_0-auc:0.88316\tvalidation_1-auc:0.81465                                                                  \n",
      "[10]\tvalidation_0-auc:0.88591\tvalidation_1-auc:0.81620                                                                 \n",
      "[11]\tvalidation_0-auc:0.88856\tvalidation_1-auc:0.81637                                                                 \n",
      "[12]\tvalidation_0-auc:0.89015\tvalidation_1-auc:0.81683                                                                 \n",
      "[13]\tvalidation_0-auc:0.89292\tvalidation_1-auc:0.81797                                                                 \n",
      "[14]\tvalidation_0-auc:0.89498\tvalidation_1-auc:0.81802                                                                 \n",
      "[15]\tvalidation_0-auc:0.89630\tvalidation_1-auc:0.81902                                                                 \n",
      "[16]\tvalidation_0-auc:0.89739\tvalidation_1-auc:0.81955                                                                 \n",
      "[17]\tvalidation_0-auc:0.89799\tvalidation_1-auc:0.81917                                                                 \n",
      "[18]\tvalidation_0-auc:0.89874\tvalidation_1-auc:0.81911                                                                 \n",
      "[19]\tvalidation_0-auc:0.89985\tvalidation_1-auc:0.82049                                                                 \n",
      "[20]\tvalidation_0-auc:0.90216\tvalidation_1-auc:0.82124                                                                 \n",
      "[21]\tvalidation_0-auc:0.90308\tvalidation_1-auc:0.82157                                                                 \n",
      "[22]\tvalidation_0-auc:0.90366\tvalidation_1-auc:0.82202                                                                 \n",
      "[23]\tvalidation_0-auc:0.90407\tvalidation_1-auc:0.82262                                                                 \n",
      "[24]\tvalidation_0-auc:0.90472\tvalidation_1-auc:0.82320                                                                 \n",
      "[25]\tvalidation_0-auc:0.90563\tvalidation_1-auc:0.82338                                                                 \n",
      "[26]\tvalidation_0-auc:0.90618\tvalidation_1-auc:0.82310                                                                 \n",
      "[27]\tvalidation_0-auc:0.90642\tvalidation_1-auc:0.82320                                                                 \n",
      "[28]\tvalidation_0-auc:0.90761\tvalidation_1-auc:0.82341                                                                 \n",
      "[29]\tvalidation_0-auc:0.90813\tvalidation_1-auc:0.82330                                                                 \n",
      "[30]\tvalidation_0-auc:0.90837\tvalidation_1-auc:0.82294                                                                 \n",
      "[31]\tvalidation_0-auc:0.90943\tvalidation_1-auc:0.82251                                                                 \n",
      "[32]\tvalidation_0-auc:0.91069\tvalidation_1-auc:0.82227                                                                 \n",
      "[33]\tvalidation_0-auc:0.91202\tvalidation_1-auc:0.82263                                                                 \n",
      "[34]\tvalidation_0-auc:0.91270\tvalidation_1-auc:0.82218                                                                 \n",
      "[35]\tvalidation_0-auc:0.91401\tvalidation_1-auc:0.82160                                                                 \n",
      "[36]\tvalidation_0-auc:0.91420\tvalidation_1-auc:0.82157                                                                 \n",
      "[37]\tvalidation_0-auc:0.91463\tvalidation_1-auc:0.82159                                                                 \n",
      "[38]\tvalidation_0-auc:0.91544\tvalidation_1-auc:0.82156                                                                 \n",
      "[39]\tvalidation_0-auc:0.91670\tvalidation_1-auc:0.82138                                                                 \n",
      "[40]\tvalidation_0-auc:0.91696\tvalidation_1-auc:0.82116                                                                 \n",
      "[41]\tvalidation_0-auc:0.91780\tvalidation_1-auc:0.82105                                                                 \n",
      "[42]\tvalidation_0-auc:0.91837\tvalidation_1-auc:0.82071                                                                 \n",
      "[43]\tvalidation_0-auc:0.91924\tvalidation_1-auc:0.82035                                                                 \n",
      "[44]\tvalidation_0-auc:0.91974\tvalidation_1-auc:0.82036                                                                 \n",
      "[45]\tvalidation_0-auc:0.92034\tvalidation_1-auc:0.82074                                                                 \n",
      "[46]\tvalidation_0-auc:0.92082\tvalidation_1-auc:0.82066                                                                 \n",
      "[47]\tvalidation_0-auc:0.92130\tvalidation_1-auc:0.82051                                                                 \n",
      "[48]\tvalidation_0-auc:0.92193\tvalidation_1-auc:0.82037                                                                 \n",
      "[49]\tvalidation_0-auc:0.92205\tvalidation_1-auc:0.82018                                                                 \n",
      "[50]\tvalidation_0-auc:0.92298\tvalidation_1-auc:0.81998                                                                 \n",
      "[51]\tvalidation_0-auc:0.92312\tvalidation_1-auc:0.81963                                                                 \n",
      "[52]\tvalidation_0-auc:0.92335\tvalidation_1-auc:0.81948                                                                 \n",
      "[53]\tvalidation_0-auc:0.92370\tvalidation_1-auc:0.81924                                                                 \n",
      "[54]\tvalidation_0-auc:0.92389\tvalidation_1-auc:0.81898                                                                 \n",
      "[55]\tvalidation_0-auc:0.92407\tvalidation_1-auc:0.81923                                                                 \n",
      "[56]\tvalidation_0-auc:0.92431\tvalidation_1-auc:0.81919                                                                 \n",
      "[57]\tvalidation_0-auc:0.92441\tvalidation_1-auc:0.81907                                                                 \n",
      "[58]\tvalidation_0-auc:0.92537\tvalidation_1-auc:0.81884                                                                 \n",
      "[0]\tvalidation_0-auc:0.84293\tvalidation_1-auc:0.81769                                                                  \n",
      "[1]\tvalidation_0-auc:0.85242\tvalidation_1-auc:0.82410                                                                  \n",
      "[2]\tvalidation_0-auc:0.86305\tvalidation_1-auc:0.82987                                                                  \n",
      "[3]\tvalidation_0-auc:0.86481\tvalidation_1-auc:0.83186                                                                  \n",
      "[4]\tvalidation_0-auc:0.86365\tvalidation_1-auc:0.83288                                                                  \n",
      "[5]\tvalidation_0-auc:0.86733\tvalidation_1-auc:0.83259                                                                  \n",
      "[6]\tvalidation_0-auc:0.87613\tvalidation_1-auc:0.83668                                                                  \n",
      "[7]\tvalidation_0-auc:0.87844\tvalidation_1-auc:0.83697                                                                  \n",
      "[8]\tvalidation_0-auc:0.88415\tvalidation_1-auc:0.83939                                                                  \n",
      "[9]\tvalidation_0-auc:0.88495\tvalidation_1-auc:0.83921                                                                  \n",
      "[10]\tvalidation_0-auc:0.88745\tvalidation_1-auc:0.84006                                                                 \n",
      "[11]\tvalidation_0-auc:0.88929\tvalidation_1-auc:0.83953                                                                 \n",
      "[12]\tvalidation_0-auc:0.89065\tvalidation_1-auc:0.83948                                                                 \n",
      "[13]\tvalidation_0-auc:0.89257\tvalidation_1-auc:0.84113                                                                 \n",
      "[14]\tvalidation_0-auc:0.89357\tvalidation_1-auc:0.84033                                                                 \n",
      "[15]\tvalidation_0-auc:0.89545\tvalidation_1-auc:0.84132                                                                 \n",
      "[16]\tvalidation_0-auc:0.89626\tvalidation_1-auc:0.84182                                                                 \n",
      "[17]\tvalidation_0-auc:0.89805\tvalidation_1-auc:0.84126                                                                 \n",
      "[18]\tvalidation_0-auc:0.89817\tvalidation_1-auc:0.84128                                                                 \n",
      "[19]\tvalidation_0-auc:0.89952\tvalidation_1-auc:0.84091                                                                 \n",
      "[20]\tvalidation_0-auc:0.90118\tvalidation_1-auc:0.84152                                                                 \n",
      "[21]\tvalidation_0-auc:0.90204\tvalidation_1-auc:0.84084                                                                 \n",
      "[22]\tvalidation_0-auc:0.90270\tvalidation_1-auc:0.84108                                                                 \n",
      "[23]\tvalidation_0-auc:0.90343\tvalidation_1-auc:0.84082                                                                 \n",
      "[24]\tvalidation_0-auc:0.90400\tvalidation_1-auc:0.84084                                                                 \n",
      "[25]\tvalidation_0-auc:0.90458\tvalidation_1-auc:0.84106                                                                 \n",
      "[26]\tvalidation_0-auc:0.90500\tvalidation_1-auc:0.84052                                                                 \n",
      "[27]\tvalidation_0-auc:0.90575\tvalidation_1-auc:0.84025                                                                 \n",
      "[28]\tvalidation_0-auc:0.90668\tvalidation_1-auc:0.84022                                                                 \n",
      "[29]\tvalidation_0-auc:0.90683\tvalidation_1-auc:0.84009                                                                 \n",
      "[30]\tvalidation_0-auc:0.90736\tvalidation_1-auc:0.84001                                                                 \n",
      "[31]\tvalidation_0-auc:0.90795\tvalidation_1-auc:0.83978                                                                 \n",
      "[32]\tvalidation_0-auc:0.90936\tvalidation_1-auc:0.83930                                                                 \n",
      "[33]\tvalidation_0-auc:0.90971\tvalidation_1-auc:0.83861                                                                 \n",
      "[34]\tvalidation_0-auc:0.91047\tvalidation_1-auc:0.83855                                                                 \n",
      "[35]\tvalidation_0-auc:0.91090\tvalidation_1-auc:0.83832                                                                 \n",
      "[36]\tvalidation_0-auc:0.91236\tvalidation_1-auc:0.83828                                                                 \n",
      "[37]\tvalidation_0-auc:0.91259\tvalidation_1-auc:0.83822                                                                 \n",
      "[38]\tvalidation_0-auc:0.91288\tvalidation_1-auc:0.83806                                                                 \n",
      "[39]\tvalidation_0-auc:0.91307\tvalidation_1-auc:0.83830                                                                 \n",
      "[40]\tvalidation_0-auc:0.91339\tvalidation_1-auc:0.83791                                                                 \n",
      "[41]\tvalidation_0-auc:0.91351\tvalidation_1-auc:0.83809                                                                 \n",
      "[42]\tvalidation_0-auc:0.91425\tvalidation_1-auc:0.83789                                                                 \n",
      "[43]\tvalidation_0-auc:0.91479\tvalidation_1-auc:0.83753                                                                 \n",
      "[44]\tvalidation_0-auc:0.91606\tvalidation_1-auc:0.83781                                                                 \n",
      "[45]\tvalidation_0-auc:0.91639\tvalidation_1-auc:0.83742                                                                 \n",
      "[46]\tvalidation_0-auc:0.91670\tvalidation_1-auc:0.83721                                                                 \n",
      "[0]\tvalidation_0-auc:0.84199\tvalidation_1-auc:0.81551                                                                  \n",
      "[1]\tvalidation_0-auc:0.85206\tvalidation_1-auc:0.81235                                                                  \n",
      "[2]\tvalidation_0-auc:0.86035\tvalidation_1-auc:0.82144                                                                  \n",
      "[3]\tvalidation_0-auc:0.86011\tvalidation_1-auc:0.81808                                                                  \n",
      "[4]\tvalidation_0-auc:0.86077\tvalidation_1-auc:0.81622                                                                  \n",
      "[5]\tvalidation_0-auc:0.86252\tvalidation_1-auc:0.81535                                                                  \n",
      "[6]\tvalidation_0-auc:0.86996\tvalidation_1-auc:0.82405                                                                  \n",
      "[7]\tvalidation_0-auc:0.87356\tvalidation_1-auc:0.82238                                                                  \n",
      "[8]\tvalidation_0-auc:0.87984\tvalidation_1-auc:0.82759                                                                  \n",
      "[9]\tvalidation_0-auc:0.88078\tvalidation_1-auc:0.82646                                                                  \n",
      "[10]\tvalidation_0-auc:0.88434\tvalidation_1-auc:0.82958                                                                 \n",
      "[11]\tvalidation_0-auc:0.88676\tvalidation_1-auc:0.82937                                                                 \n",
      "[12]\tvalidation_0-auc:0.88877\tvalidation_1-auc:0.82806                                                                 \n",
      "[13]\tvalidation_0-auc:0.89238\tvalidation_1-auc:0.83001                                                                 \n",
      "[14]\tvalidation_0-auc:0.89446\tvalidation_1-auc:0.82940                                                                 \n",
      "[15]\tvalidation_0-auc:0.89578\tvalidation_1-auc:0.83135                                                                 \n",
      "[16]\tvalidation_0-auc:0.89710\tvalidation_1-auc:0.83215                                                                 \n",
      "[17]\tvalidation_0-auc:0.89910\tvalidation_1-auc:0.83160                                                                 \n",
      "[18]\tvalidation_0-auc:0.89974\tvalidation_1-auc:0.83150                                                                 \n",
      "[19]\tvalidation_0-auc:0.90084\tvalidation_1-auc:0.83238                                                                 \n",
      "[20]\tvalidation_0-auc:0.90177\tvalidation_1-auc:0.83298                                                                 \n",
      "[21]\tvalidation_0-auc:0.90388\tvalidation_1-auc:0.83314                                                                 \n",
      "[22]\tvalidation_0-auc:0.90571\tvalidation_1-auc:0.83250                                                                 \n",
      "[23]\tvalidation_0-auc:0.90600\tvalidation_1-auc:0.83306                                                                 \n",
      "[24]\tvalidation_0-auc:0.90678\tvalidation_1-auc:0.83312                                                                 \n",
      "[25]\tvalidation_0-auc:0.90740\tvalidation_1-auc:0.83289                                                                 \n",
      "[26]\tvalidation_0-auc:0.90768\tvalidation_1-auc:0.83322                                                                 \n",
      "[27]\tvalidation_0-auc:0.90799\tvalidation_1-auc:0.83330                                                                 \n",
      "[28]\tvalidation_0-auc:0.90831\tvalidation_1-auc:0.83365                                                                 \n",
      "[29]\tvalidation_0-auc:0.90900\tvalidation_1-auc:0.83378                                                                 \n",
      "[30]\tvalidation_0-auc:0.90981\tvalidation_1-auc:0.83340                                                                 \n",
      "[31]\tvalidation_0-auc:0.91062\tvalidation_1-auc:0.83359                                                                 \n",
      "[32]\tvalidation_0-auc:0.91141\tvalidation_1-auc:0.83328                                                                 \n",
      "[33]\tvalidation_0-auc:0.91238\tvalidation_1-auc:0.83306                                                                 \n",
      "[34]\tvalidation_0-auc:0.91386\tvalidation_1-auc:0.83319                                                                 \n",
      "[35]\tvalidation_0-auc:0.91414\tvalidation_1-auc:0.83314                                                                 \n",
      "[36]\tvalidation_0-auc:0.91453\tvalidation_1-auc:0.83315                                                                 \n",
      "[37]\tvalidation_0-auc:0.91521\tvalidation_1-auc:0.83294                                                                 \n",
      "[38]\tvalidation_0-auc:0.91701\tvalidation_1-auc:0.83250                                                                 \n",
      "[39]\tvalidation_0-auc:0.91819\tvalidation_1-auc:0.83266                                                                 \n",
      "[40]\tvalidation_0-auc:0.91867\tvalidation_1-auc:0.83245                                                                 \n",
      "[41]\tvalidation_0-auc:0.91928\tvalidation_1-auc:0.83261                                                                 \n",
      "[42]\tvalidation_0-auc:0.91966\tvalidation_1-auc:0.83294                                                                 \n",
      "[43]\tvalidation_0-auc:0.91988\tvalidation_1-auc:0.83298                                                                 \n",
      "[44]\tvalidation_0-auc:0.92025\tvalidation_1-auc:0.83284                                                                 \n",
      "[45]\tvalidation_0-auc:0.92047\tvalidation_1-auc:0.83245                                                                 \n",
      "[46]\tvalidation_0-auc:0.92069\tvalidation_1-auc:0.83233                                                                 \n",
      "[47]\tvalidation_0-auc:0.92089\tvalidation_1-auc:0.83229                                                                 \n",
      "[48]\tvalidation_0-auc:0.92185\tvalidation_1-auc:0.83223                                                                 \n",
      "[49]\tvalidation_0-auc:0.92241\tvalidation_1-auc:0.83228                                                                 \n",
      "[50]\tvalidation_0-auc:0.92340\tvalidation_1-auc:0.83217                                                                 \n",
      "[51]\tvalidation_0-auc:0.92389\tvalidation_1-auc:0.83213                                                                 \n",
      "[52]\tvalidation_0-auc:0.92418\tvalidation_1-auc:0.83192                                                                 \n",
      "[53]\tvalidation_0-auc:0.92442\tvalidation_1-auc:0.83200                                                                 \n",
      "[54]\tvalidation_0-auc:0.92466\tvalidation_1-auc:0.83206                                                                 \n",
      "[55]\tvalidation_0-auc:0.92475\tvalidation_1-auc:0.83199                                                                 \n",
      "[56]\tvalidation_0-auc:0.92487\tvalidation_1-auc:0.83195                                                                 \n",
      "[57]\tvalidation_0-auc:0.92525\tvalidation_1-auc:0.83197                                                                 \n",
      "[58]\tvalidation_0-auc:0.92586\tvalidation_1-auc:0.83144                                                                 \n",
      "[59]\tvalidation_0-auc:0.92668\tvalidation_1-auc:0.83127                                                                 \n",
      "[0]\tvalidation_0-auc:0.83826\tvalidation_1-auc:0.81054                                                                  \n",
      "[1]\tvalidation_0-auc:0.84330\tvalidation_1-auc:0.81338                                                                  \n",
      "[2]\tvalidation_0-auc:0.84729\tvalidation_1-auc:0.81800                                                                  \n",
      "[3]\tvalidation_0-auc:0.85123\tvalidation_1-auc:0.81876                                                                  \n",
      "[4]\tvalidation_0-auc:0.85522\tvalidation_1-auc:0.81958                                                                  \n",
      "[5]\tvalidation_0-auc:0.85735\tvalidation_1-auc:0.82021                                                                  \n",
      "[6]\tvalidation_0-auc:0.85853\tvalidation_1-auc:0.82128                                                                  \n",
      "[7]\tvalidation_0-auc:0.86008\tvalidation_1-auc:0.82244                                                                  \n",
      "[8]\tvalidation_0-auc:0.86097\tvalidation_1-auc:0.82265                                                                  \n",
      "[9]\tvalidation_0-auc:0.86200\tvalidation_1-auc:0.82173                                                                  \n",
      "[10]\tvalidation_0-auc:0.86264\tvalidation_1-auc:0.82235                                                                 \n",
      "[11]\tvalidation_0-auc:0.86316\tvalidation_1-auc:0.82309                                                                 \n",
      "[12]\tvalidation_0-auc:0.86371\tvalidation_1-auc:0.82333                                                                 \n",
      "[13]\tvalidation_0-auc:0.86461\tvalidation_1-auc:0.82360                                                                 \n",
      "[14]\tvalidation_0-auc:0.86595\tvalidation_1-auc:0.82347                                                                 \n",
      "[15]\tvalidation_0-auc:0.86700\tvalidation_1-auc:0.82359                                                                 \n",
      "[16]\tvalidation_0-auc:0.86764\tvalidation_1-auc:0.82308                                                                 \n",
      "[17]\tvalidation_0-auc:0.86859\tvalidation_1-auc:0.82346                                                                 \n",
      "[18]\tvalidation_0-auc:0.86953\tvalidation_1-auc:0.82367                                                                 \n",
      "[19]\tvalidation_0-auc:0.87007\tvalidation_1-auc:0.82339                                                                 \n",
      "[20]\tvalidation_0-auc:0.87080\tvalidation_1-auc:0.82322                                                                 \n",
      "[21]\tvalidation_0-auc:0.87129\tvalidation_1-auc:0.82386                                                                 \n",
      "[22]\tvalidation_0-auc:0.87187\tvalidation_1-auc:0.82425                                                                 \n",
      "[23]\tvalidation_0-auc:0.87222\tvalidation_1-auc:0.82489                                                                 \n",
      "[24]\tvalidation_0-auc:0.87263\tvalidation_1-auc:0.82514                                                                 \n",
      "[25]\tvalidation_0-auc:0.87286\tvalidation_1-auc:0.82498                                                                 \n",
      "[26]\tvalidation_0-auc:0.87304\tvalidation_1-auc:0.82548                                                                 \n",
      "[27]\tvalidation_0-auc:0.87346\tvalidation_1-auc:0.82500                                                                 \n",
      "[28]\tvalidation_0-auc:0.87382\tvalidation_1-auc:0.82508                                                                 \n",
      "[29]\tvalidation_0-auc:0.87450\tvalidation_1-auc:0.82491                                                                 \n",
      "[30]\tvalidation_0-auc:0.87509\tvalidation_1-auc:0.82488                                                                 \n",
      "[31]\tvalidation_0-auc:0.87580\tvalidation_1-auc:0.82564                                                                 \n",
      "[32]\tvalidation_0-auc:0.87630\tvalidation_1-auc:0.82579                                                                 \n",
      "[33]\tvalidation_0-auc:0.87670\tvalidation_1-auc:0.82577                                                                 \n",
      "[34]\tvalidation_0-auc:0.87690\tvalidation_1-auc:0.82611                                                                 \n",
      "[35]\tvalidation_0-auc:0.87721\tvalidation_1-auc:0.82620                                                                 \n",
      "[36]\tvalidation_0-auc:0.87748\tvalidation_1-auc:0.82648                                                                 \n",
      "[37]\tvalidation_0-auc:0.87802\tvalidation_1-auc:0.82660                                                                 \n",
      "[38]\tvalidation_0-auc:0.87825\tvalidation_1-auc:0.82704                                                                 \n",
      "[39]\tvalidation_0-auc:0.87852\tvalidation_1-auc:0.82681                                                                 \n",
      "[40]\tvalidation_0-auc:0.87861\tvalidation_1-auc:0.82673                                                                 \n",
      "[41]\tvalidation_0-auc:0.87870\tvalidation_1-auc:0.82671                                                                 \n",
      "[42]\tvalidation_0-auc:0.87919\tvalidation_1-auc:0.82681                                                                 \n",
      "[43]\tvalidation_0-auc:0.87959\tvalidation_1-auc:0.82667                                                                 \n",
      "[44]\tvalidation_0-auc:0.87970\tvalidation_1-auc:0.82675                                                                 \n",
      "[45]\tvalidation_0-auc:0.87994\tvalidation_1-auc:0.82678                                                                 \n",
      "[46]\tvalidation_0-auc:0.88046\tvalidation_1-auc:0.82691                                                                 \n",
      "[47]\tvalidation_0-auc:0.88080\tvalidation_1-auc:0.82688                                                                 \n",
      "[48]\tvalidation_0-auc:0.88088\tvalidation_1-auc:0.82702                                                                 \n",
      "[49]\tvalidation_0-auc:0.88093\tvalidation_1-auc:0.82692                                                                 \n",
      "[50]\tvalidation_0-auc:0.88134\tvalidation_1-auc:0.82680                                                                 \n",
      "[51]\tvalidation_0-auc:0.88166\tvalidation_1-auc:0.82678                                                                 \n",
      "[52]\tvalidation_0-auc:0.88187\tvalidation_1-auc:0.82667                                                                 \n",
      "[53]\tvalidation_0-auc:0.88224\tvalidation_1-auc:0.82647                                                                 \n",
      "[54]\tvalidation_0-auc:0.88242\tvalidation_1-auc:0.82652                                                                 \n",
      "[55]\tvalidation_0-auc:0.88309\tvalidation_1-auc:0.82664                                                                 \n",
      "[56]\tvalidation_0-auc:0.88351\tvalidation_1-auc:0.82684                                                                 \n",
      "[57]\tvalidation_0-auc:0.88371\tvalidation_1-auc:0.82674                                                                 \n",
      "[58]\tvalidation_0-auc:0.88394\tvalidation_1-auc:0.82667                                                                 \n",
      "[59]\tvalidation_0-auc:0.88424\tvalidation_1-auc:0.82688                                                                 \n",
      "[60]\tvalidation_0-auc:0.88480\tvalidation_1-auc:0.82685                                                                 \n",
      "[61]\tvalidation_0-auc:0.88505\tvalidation_1-auc:0.82700                                                                 \n",
      "[62]\tvalidation_0-auc:0.88556\tvalidation_1-auc:0.82713                                                                 \n",
      "[63]\tvalidation_0-auc:0.88586\tvalidation_1-auc:0.82675                                                                 \n",
      "[64]\tvalidation_0-auc:0.88637\tvalidation_1-auc:0.82684                                                                 \n",
      "[65]\tvalidation_0-auc:0.88645\tvalidation_1-auc:0.82677                                                                 \n",
      "[66]\tvalidation_0-auc:0.88693\tvalidation_1-auc:0.82682                                                                 \n",
      "[67]\tvalidation_0-auc:0.88705\tvalidation_1-auc:0.82665                                                                 \n",
      "[68]\tvalidation_0-auc:0.88714\tvalidation_1-auc:0.82671                                                                 \n",
      "[69]\tvalidation_0-auc:0.88745\tvalidation_1-auc:0.82667                                                                 \n",
      "[70]\tvalidation_0-auc:0.88782\tvalidation_1-auc:0.82651                                                                 \n",
      "[71]\tvalidation_0-auc:0.88821\tvalidation_1-auc:0.82665                                                                 \n",
      "[72]\tvalidation_0-auc:0.88868\tvalidation_1-auc:0.82650                                                                 \n",
      "[73]\tvalidation_0-auc:0.88883\tvalidation_1-auc:0.82659                                                                 \n",
      "[74]\tvalidation_0-auc:0.88900\tvalidation_1-auc:0.82668                                                                 \n",
      "[75]\tvalidation_0-auc:0.88940\tvalidation_1-auc:0.82667                                                                 \n",
      "[76]\tvalidation_0-auc:0.88953\tvalidation_1-auc:0.82668                                                                 \n",
      "[77]\tvalidation_0-auc:0.88960\tvalidation_1-auc:0.82660                                                                 \n",
      "[78]\tvalidation_0-auc:0.88967\tvalidation_1-auc:0.82655                                                                 \n",
      "[79]\tvalidation_0-auc:0.88987\tvalidation_1-auc:0.82652                                                                 \n",
      "[80]\tvalidation_0-auc:0.89015\tvalidation_1-auc:0.82654                                                                 \n",
      "[81]\tvalidation_0-auc:0.89025\tvalidation_1-auc:0.82639                                                                 \n",
      "[82]\tvalidation_0-auc:0.89061\tvalidation_1-auc:0.82641                                                                 \n",
      "[83]\tvalidation_0-auc:0.89107\tvalidation_1-auc:0.82628                                                                 \n",
      "[84]\tvalidation_0-auc:0.89157\tvalidation_1-auc:0.82650                                                                 \n",
      "[85]\tvalidation_0-auc:0.89194\tvalidation_1-auc:0.82640                                                                 \n",
      "[86]\tvalidation_0-auc:0.89244\tvalidation_1-auc:0.82657                                                                 \n",
      "[87]\tvalidation_0-auc:0.89265\tvalidation_1-auc:0.82655                                                                 \n",
      "[88]\tvalidation_0-auc:0.89279\tvalidation_1-auc:0.82652                                                                 \n",
      "[89]\tvalidation_0-auc:0.89309\tvalidation_1-auc:0.82672                                                                 \n",
      "[90]\tvalidation_0-auc:0.89362\tvalidation_1-auc:0.82664                                                                 \n",
      "[91]\tvalidation_0-auc:0.89406\tvalidation_1-auc:0.82656                                                                 \n",
      "[92]\tvalidation_0-auc:0.89411\tvalidation_1-auc:0.82660                                                                 \n",
      "[0]\tvalidation_0-auc:0.83122\tvalidation_1-auc:0.81779                                                                  \n",
      "[1]\tvalidation_0-auc:0.83540\tvalidation_1-auc:0.82018                                                                  \n",
      "[2]\tvalidation_0-auc:0.84151\tvalidation_1-auc:0.82714                                                                  \n",
      "[3]\tvalidation_0-auc:0.84513\tvalidation_1-auc:0.83338                                                                  \n",
      "[4]\tvalidation_0-auc:0.84920\tvalidation_1-auc:0.83717                                                                  \n",
      "[5]\tvalidation_0-auc:0.85038\tvalidation_1-auc:0.83703                                                                  \n",
      "[6]\tvalidation_0-auc:0.85163\tvalidation_1-auc:0.83770                                                                  \n",
      "[7]\tvalidation_0-auc:0.85261\tvalidation_1-auc:0.83940                                                                  \n",
      "[8]\tvalidation_0-auc:0.85348\tvalidation_1-auc:0.83950                                                                  \n",
      "[9]\tvalidation_0-auc:0.85460\tvalidation_1-auc:0.84055                                                                  \n",
      "[10]\tvalidation_0-auc:0.85628\tvalidation_1-auc:0.84083                                                                 \n",
      "[11]\tvalidation_0-auc:0.85756\tvalidation_1-auc:0.84090                                                                 \n",
      "[12]\tvalidation_0-auc:0.85850\tvalidation_1-auc:0.84097                                                                 \n",
      "[13]\tvalidation_0-auc:0.85921\tvalidation_1-auc:0.84141                                                                 \n",
      "[14]\tvalidation_0-auc:0.86054\tvalidation_1-auc:0.84262                                                                 \n",
      "[15]\tvalidation_0-auc:0.86127\tvalidation_1-auc:0.84285                                                                 \n",
      "[16]\tvalidation_0-auc:0.86234\tvalidation_1-auc:0.84261                                                                 \n",
      "[17]\tvalidation_0-auc:0.86340\tvalidation_1-auc:0.84320                                                                 \n",
      "[18]\tvalidation_0-auc:0.86413\tvalidation_1-auc:0.84311                                                                 \n",
      "[19]\tvalidation_0-auc:0.86458\tvalidation_1-auc:0.84297                                                                 \n",
      "[20]\tvalidation_0-auc:0.86494\tvalidation_1-auc:0.84331                                                                 \n",
      "[21]\tvalidation_0-auc:0.86505\tvalidation_1-auc:0.84345                                                                 \n",
      "[22]\tvalidation_0-auc:0.86540\tvalidation_1-auc:0.84337                                                                 \n",
      "[23]\tvalidation_0-auc:0.86553\tvalidation_1-auc:0.84343                                                                 \n",
      "[24]\tvalidation_0-auc:0.86559\tvalidation_1-auc:0.84389                                                                 \n",
      "[25]\tvalidation_0-auc:0.86637\tvalidation_1-auc:0.84398                                                                 \n",
      "[26]\tvalidation_0-auc:0.86642\tvalidation_1-auc:0.84386                                                                 \n",
      "[27]\tvalidation_0-auc:0.86684\tvalidation_1-auc:0.84449                                                                 \n",
      "[28]\tvalidation_0-auc:0.86703\tvalidation_1-auc:0.84436                                                                 \n",
      "[29]\tvalidation_0-auc:0.86812\tvalidation_1-auc:0.84471                                                                 \n",
      "[30]\tvalidation_0-auc:0.86832\tvalidation_1-auc:0.84497                                                                 \n",
      "[31]\tvalidation_0-auc:0.86869\tvalidation_1-auc:0.84491                                                                 \n",
      "[32]\tvalidation_0-auc:0.86899\tvalidation_1-auc:0.84470                                                                 \n",
      "[33]\tvalidation_0-auc:0.86924\tvalidation_1-auc:0.84464                                                                 \n",
      "[34]\tvalidation_0-auc:0.86939\tvalidation_1-auc:0.84482                                                                 \n",
      "[35]\tvalidation_0-auc:0.86976\tvalidation_1-auc:0.84489                                                                 \n",
      "[36]\tvalidation_0-auc:0.87011\tvalidation_1-auc:0.84502                                                                 \n",
      "[37]\tvalidation_0-auc:0.87028\tvalidation_1-auc:0.84509                                                                 \n",
      "[38]\tvalidation_0-auc:0.87042\tvalidation_1-auc:0.84498                                                                 \n",
      "[39]\tvalidation_0-auc:0.87096\tvalidation_1-auc:0.84489                                                                 \n",
      "[40]\tvalidation_0-auc:0.87131\tvalidation_1-auc:0.84499                                                                 \n",
      "[41]\tvalidation_0-auc:0.87194\tvalidation_1-auc:0.84512                                                                 \n",
      "[42]\tvalidation_0-auc:0.87218\tvalidation_1-auc:0.84502                                                                 \n",
      "[43]\tvalidation_0-auc:0.87246\tvalidation_1-auc:0.84482                                                                 \n",
      "[44]\tvalidation_0-auc:0.87255\tvalidation_1-auc:0.84483                                                                 \n",
      "[45]\tvalidation_0-auc:0.87273\tvalidation_1-auc:0.84474                                                                 \n",
      "[46]\tvalidation_0-auc:0.87293\tvalidation_1-auc:0.84496                                                                 \n",
      "[47]\tvalidation_0-auc:0.87336\tvalidation_1-auc:0.84500                                                                 \n",
      "[48]\tvalidation_0-auc:0.87371\tvalidation_1-auc:0.84492                                                                 \n",
      "[49]\tvalidation_0-auc:0.87398\tvalidation_1-auc:0.84491                                                                 \n",
      "[50]\tvalidation_0-auc:0.87421\tvalidation_1-auc:0.84496                                                                 \n",
      "[51]\tvalidation_0-auc:0.87446\tvalidation_1-auc:0.84490                                                                 \n",
      "[52]\tvalidation_0-auc:0.87465\tvalidation_1-auc:0.84478                                                                 \n",
      "[53]\tvalidation_0-auc:0.87476\tvalidation_1-auc:0.84473                                                                 \n",
      "[54]\tvalidation_0-auc:0.87534\tvalidation_1-auc:0.84491                                                                 \n",
      "[55]\tvalidation_0-auc:0.87563\tvalidation_1-auc:0.84501                                                                 \n",
      "[56]\tvalidation_0-auc:0.87573\tvalidation_1-auc:0.84511                                                                 \n",
      "[57]\tvalidation_0-auc:0.87583\tvalidation_1-auc:0.84533                                                                 \n",
      "[58]\tvalidation_0-auc:0.87600\tvalidation_1-auc:0.84543                                                                 \n",
      "[59]\tvalidation_0-auc:0.87651\tvalidation_1-auc:0.84509                                                                 \n",
      "[60]\tvalidation_0-auc:0.87699\tvalidation_1-auc:0.84490                                                                 \n",
      "[61]\tvalidation_0-auc:0.87725\tvalidation_1-auc:0.84485                                                                 \n",
      "[62]\tvalidation_0-auc:0.87750\tvalidation_1-auc:0.84459                                                                 \n",
      "[63]\tvalidation_0-auc:0.87798\tvalidation_1-auc:0.84481                                                                 \n",
      "[64]\tvalidation_0-auc:0.87849\tvalidation_1-auc:0.84465                                                                 \n",
      "[65]\tvalidation_0-auc:0.87894\tvalidation_1-auc:0.84468                                                                 \n",
      "[66]\tvalidation_0-auc:0.87903\tvalidation_1-auc:0.84459                                                                 \n",
      "[67]\tvalidation_0-auc:0.87940\tvalidation_1-auc:0.84430                                                                 \n",
      "[68]\tvalidation_0-auc:0.88022\tvalidation_1-auc:0.84449                                                                 \n",
      "[69]\tvalidation_0-auc:0.88076\tvalidation_1-auc:0.84403                                                                 \n",
      "[70]\tvalidation_0-auc:0.88101\tvalidation_1-auc:0.84402                                                                 \n",
      "[71]\tvalidation_0-auc:0.88114\tvalidation_1-auc:0.84406                                                                 \n",
      "[72]\tvalidation_0-auc:0.88141\tvalidation_1-auc:0.84396                                                                 \n",
      "[73]\tvalidation_0-auc:0.88177\tvalidation_1-auc:0.84394                                                                 \n",
      "[74]\tvalidation_0-auc:0.88198\tvalidation_1-auc:0.84395                                                                 \n",
      "[75]\tvalidation_0-auc:0.88244\tvalidation_1-auc:0.84402                                                                 \n",
      "[76]\tvalidation_0-auc:0.88307\tvalidation_1-auc:0.84411                                                                 \n",
      "[77]\tvalidation_0-auc:0.88328\tvalidation_1-auc:0.84406                                                                 \n",
      "[78]\tvalidation_0-auc:0.88363\tvalidation_1-auc:0.84403                                                                 \n",
      "[79]\tvalidation_0-auc:0.88374\tvalidation_1-auc:0.84395                                                                 \n",
      "[80]\tvalidation_0-auc:0.88401\tvalidation_1-auc:0.84389                                                                 \n",
      "[81]\tvalidation_0-auc:0.88413\tvalidation_1-auc:0.84368                                                                 \n",
      "[82]\tvalidation_0-auc:0.88464\tvalidation_1-auc:0.84388                                                                 \n",
      "[83]\tvalidation_0-auc:0.88512\tvalidation_1-auc:0.84377                                                                 \n",
      "[84]\tvalidation_0-auc:0.88555\tvalidation_1-auc:0.84374                                                                 \n",
      "[85]\tvalidation_0-auc:0.88568\tvalidation_1-auc:0.84374                                                                 \n",
      "[86]\tvalidation_0-auc:0.88575\tvalidation_1-auc:0.84359                                                                 \n",
      "[87]\tvalidation_0-auc:0.88582\tvalidation_1-auc:0.84358                                                                 \n",
      "[88]\tvalidation_0-auc:0.88600\tvalidation_1-auc:0.84366                                                                 \n",
      "[0]\tvalidation_0-auc:0.82771\tvalidation_1-auc:0.82031                                                                  \n",
      "[1]\tvalidation_0-auc:0.83547\tvalidation_1-auc:0.82884                                                                  \n",
      "[2]\tvalidation_0-auc:0.83743\tvalidation_1-auc:0.82910                                                                  \n",
      "[3]\tvalidation_0-auc:0.84066\tvalidation_1-auc:0.82723                                                                  \n",
      "[4]\tvalidation_0-auc:0.84641\tvalidation_1-auc:0.83130                                                                  \n",
      "[5]\tvalidation_0-auc:0.84827\tvalidation_1-auc:0.83417                                                                  \n",
      "[6]\tvalidation_0-auc:0.85072\tvalidation_1-auc:0.83419                                                                  \n",
      "[7]\tvalidation_0-auc:0.85217\tvalidation_1-auc:0.83448                                                                  \n",
      "[8]\tvalidation_0-auc:0.85439\tvalidation_1-auc:0.83448                                                                  \n",
      "[9]\tvalidation_0-auc:0.85554\tvalidation_1-auc:0.83563                                                                  \n",
      "[10]\tvalidation_0-auc:0.85638\tvalidation_1-auc:0.83572                                                                 \n",
      "[11]\tvalidation_0-auc:0.85759\tvalidation_1-auc:0.83631                                                                 \n",
      "[12]\tvalidation_0-auc:0.85880\tvalidation_1-auc:0.83685                                                                 \n",
      "[13]\tvalidation_0-auc:0.85931\tvalidation_1-auc:0.83736                                                                 \n",
      "[14]\tvalidation_0-auc:0.86057\tvalidation_1-auc:0.83698                                                                 \n",
      "[15]\tvalidation_0-auc:0.86121\tvalidation_1-auc:0.83711                                                                 \n",
      "[16]\tvalidation_0-auc:0.86233\tvalidation_1-auc:0.83713                                                                 \n",
      "[17]\tvalidation_0-auc:0.86353\tvalidation_1-auc:0.83695                                                                 \n",
      "[18]\tvalidation_0-auc:0.86399\tvalidation_1-auc:0.83690                                                                 \n",
      "[19]\tvalidation_0-auc:0.86482\tvalidation_1-auc:0.83720                                                                 \n",
      "[20]\tvalidation_0-auc:0.86556\tvalidation_1-auc:0.83720                                                                 \n",
      "[21]\tvalidation_0-auc:0.86641\tvalidation_1-auc:0.83730                                                                 \n",
      "[22]\tvalidation_0-auc:0.86718\tvalidation_1-auc:0.83773                                                                 \n",
      "[23]\tvalidation_0-auc:0.86741\tvalidation_1-auc:0.83821                                                                 \n",
      "[24]\tvalidation_0-auc:0.86821\tvalidation_1-auc:0.83856                                                                 \n",
      "[25]\tvalidation_0-auc:0.86886\tvalidation_1-auc:0.83869                                                                 \n",
      "[26]\tvalidation_0-auc:0.86931\tvalidation_1-auc:0.83875                                                                 \n",
      "[27]\tvalidation_0-auc:0.87001\tvalidation_1-auc:0.83872                                                                 \n",
      "[28]\tvalidation_0-auc:0.87024\tvalidation_1-auc:0.83890                                                                 \n",
      "[29]\tvalidation_0-auc:0.87132\tvalidation_1-auc:0.83903                                                                 \n",
      "[30]\tvalidation_0-auc:0.87196\tvalidation_1-auc:0.83904                                                                 \n",
      "[31]\tvalidation_0-auc:0.87237\tvalidation_1-auc:0.83950                                                                 \n",
      "[32]\tvalidation_0-auc:0.87288\tvalidation_1-auc:0.83959                                                                 \n",
      "[33]\tvalidation_0-auc:0.87340\tvalidation_1-auc:0.83967                                                                 \n",
      "[34]\tvalidation_0-auc:0.87379\tvalidation_1-auc:0.83945                                                                 \n",
      "[35]\tvalidation_0-auc:0.87448\tvalidation_1-auc:0.83939                                                                 \n",
      "[36]\tvalidation_0-auc:0.87466\tvalidation_1-auc:0.83947                                                                 \n",
      "[37]\tvalidation_0-auc:0.87552\tvalidation_1-auc:0.83928                                                                 \n",
      "[38]\tvalidation_0-auc:0.87617\tvalidation_1-auc:0.83958                                                                 \n",
      "[39]\tvalidation_0-auc:0.87630\tvalidation_1-auc:0.83960                                                                 \n",
      "[40]\tvalidation_0-auc:0.87682\tvalidation_1-auc:0.83949                                                                 \n",
      "[41]\tvalidation_0-auc:0.87703\tvalidation_1-auc:0.83944                                                                 \n",
      "[42]\tvalidation_0-auc:0.87727\tvalidation_1-auc:0.83953                                                                 \n",
      "[43]\tvalidation_0-auc:0.87786\tvalidation_1-auc:0.83944                                                                 \n",
      "[44]\tvalidation_0-auc:0.87812\tvalidation_1-auc:0.83942                                                                 \n",
      "[45]\tvalidation_0-auc:0.87872\tvalidation_1-auc:0.83930                                                                 \n",
      "[46]\tvalidation_0-auc:0.87897\tvalidation_1-auc:0.83927                                                                 \n",
      "[47]\tvalidation_0-auc:0.87946\tvalidation_1-auc:0.83929                                                                 \n",
      "[48]\tvalidation_0-auc:0.87968\tvalidation_1-auc:0.83943                                                                 \n",
      "[49]\tvalidation_0-auc:0.88052\tvalidation_1-auc:0.83948                                                                 \n",
      "[50]\tvalidation_0-auc:0.88061\tvalidation_1-auc:0.83950                                                                 \n",
      "[51]\tvalidation_0-auc:0.88073\tvalidation_1-auc:0.83952                                                                 \n",
      "[52]\tvalidation_0-auc:0.88087\tvalidation_1-auc:0.83958                                                                 \n",
      "[53]\tvalidation_0-auc:0.88099\tvalidation_1-auc:0.83970                                                                 \n",
      "[54]\tvalidation_0-auc:0.88137\tvalidation_1-auc:0.83978                                                                 \n",
      "[55]\tvalidation_0-auc:0.88193\tvalidation_1-auc:0.83992                                                                 \n",
      "[56]\tvalidation_0-auc:0.88222\tvalidation_1-auc:0.83980                                                                 \n",
      "[57]\tvalidation_0-auc:0.88236\tvalidation_1-auc:0.83981                                                                 \n",
      "[58]\tvalidation_0-auc:0.88272\tvalidation_1-auc:0.83992                                                                 \n",
      "[59]\tvalidation_0-auc:0.88290\tvalidation_1-auc:0.83996                                                                 \n",
      "[60]\tvalidation_0-auc:0.88297\tvalidation_1-auc:0.83993                                                                 \n",
      "[61]\tvalidation_0-auc:0.88346\tvalidation_1-auc:0.83992                                                                 \n",
      "[62]\tvalidation_0-auc:0.88398\tvalidation_1-auc:0.83998                                                                 \n",
      "[63]\tvalidation_0-auc:0.88412\tvalidation_1-auc:0.83997                                                                 \n",
      "[64]\tvalidation_0-auc:0.88460\tvalidation_1-auc:0.83984                                                                 \n",
      "[65]\tvalidation_0-auc:0.88484\tvalidation_1-auc:0.83995                                                                 \n",
      "[66]\tvalidation_0-auc:0.88511\tvalidation_1-auc:0.83989                                                                 \n",
      "[67]\tvalidation_0-auc:0.88539\tvalidation_1-auc:0.83979                                                                 \n",
      "[68]\tvalidation_0-auc:0.88617\tvalidation_1-auc:0.83950                                                                 \n",
      "[69]\tvalidation_0-auc:0.88664\tvalidation_1-auc:0.83928                                                                 \n",
      "[70]\tvalidation_0-auc:0.88674\tvalidation_1-auc:0.83930                                                                 \n",
      "[71]\tvalidation_0-auc:0.88752\tvalidation_1-auc:0.83918                                                                 \n",
      "[72]\tvalidation_0-auc:0.88803\tvalidation_1-auc:0.83916                                                                 \n",
      "[73]\tvalidation_0-auc:0.88820\tvalidation_1-auc:0.83914                                                                 \n",
      "[74]\tvalidation_0-auc:0.88865\tvalidation_1-auc:0.83919                                                                 \n",
      "[75]\tvalidation_0-auc:0.88889\tvalidation_1-auc:0.83913                                                                 \n",
      "[76]\tvalidation_0-auc:0.88897\tvalidation_1-auc:0.83907                                                                 \n",
      "[77]\tvalidation_0-auc:0.88920\tvalidation_1-auc:0.83888                                                                 \n",
      "[78]\tvalidation_0-auc:0.88933\tvalidation_1-auc:0.83886                                                                 \n",
      "[79]\tvalidation_0-auc:0.88939\tvalidation_1-auc:0.83880                                                                 \n",
      "[80]\tvalidation_0-auc:0.88975\tvalidation_1-auc:0.83866                                                                 \n",
      "[81]\tvalidation_0-auc:0.88991\tvalidation_1-auc:0.83870                                                                 \n",
      "[82]\tvalidation_0-auc:0.88997\tvalidation_1-auc:0.83853                                                                 \n",
      "[83]\tvalidation_0-auc:0.89027\tvalidation_1-auc:0.83850                                                                 \n",
      "[84]\tvalidation_0-auc:0.89053\tvalidation_1-auc:0.83866                                                                 \n",
      "[85]\tvalidation_0-auc:0.89078\tvalidation_1-auc:0.83859                                                                 \n",
      "[86]\tvalidation_0-auc:0.89090\tvalidation_1-auc:0.83849                                                                 \n",
      "[87]\tvalidation_0-auc:0.89182\tvalidation_1-auc:0.83833                                                                 \n",
      "[88]\tvalidation_0-auc:0.89190\tvalidation_1-auc:0.83826                                                                 \n",
      "[89]\tvalidation_0-auc:0.89200\tvalidation_1-auc:0.83825                                                                 \n",
      "[90]\tvalidation_0-auc:0.89232\tvalidation_1-auc:0.83830                                                                 \n",
      "[91]\tvalidation_0-auc:0.89238\tvalidation_1-auc:0.83826                                                                 \n",
      "[92]\tvalidation_0-auc:0.89271\tvalidation_1-auc:0.83817                                                                 \n",
      "[0]\tvalidation_0-auc:0.83826\tvalidation_1-auc:0.81054                                                                  \n",
      "[1]\tvalidation_0-auc:0.84486\tvalidation_1-auc:0.81393                                                                  \n",
      "[2]\tvalidation_0-auc:0.84877\tvalidation_1-auc:0.81789                                                                  \n",
      "[3]\tvalidation_0-auc:0.85301\tvalidation_1-auc:0.81662                                                                  \n",
      "[4]\tvalidation_0-auc:0.85646\tvalidation_1-auc:0.81667                                                                  \n",
      "[5]\tvalidation_0-auc:0.85774\tvalidation_1-auc:0.81749                                                                  \n",
      "[6]\tvalidation_0-auc:0.85998\tvalidation_1-auc:0.81829                                                                  \n",
      "[7]\tvalidation_0-auc:0.86170\tvalidation_1-auc:0.81891                                                                  \n",
      "[8]\tvalidation_0-auc:0.86270\tvalidation_1-auc:0.82028                                                                  \n",
      "[9]\tvalidation_0-auc:0.86421\tvalidation_1-auc:0.81947                                                                  \n",
      "[10]\tvalidation_0-auc:0.86545\tvalidation_1-auc:0.82034                                                                 \n",
      "[11]\tvalidation_0-auc:0.86617\tvalidation_1-auc:0.82046                                                                 \n",
      "[12]\tvalidation_0-auc:0.86671\tvalidation_1-auc:0.82102                                                                 \n",
      "[13]\tvalidation_0-auc:0.86740\tvalidation_1-auc:0.82125                                                                 \n",
      "[14]\tvalidation_0-auc:0.86921\tvalidation_1-auc:0.82165                                                                 \n",
      "[15]\tvalidation_0-auc:0.86967\tvalidation_1-auc:0.82229                                                                 \n",
      "[16]\tvalidation_0-auc:0.87041\tvalidation_1-auc:0.82268                                                                 \n",
      "[17]\tvalidation_0-auc:0.87127\tvalidation_1-auc:0.82288                                                                 \n",
      "[18]\tvalidation_0-auc:0.87200\tvalidation_1-auc:0.82326                                                                 \n",
      "[19]\tvalidation_0-auc:0.87316\tvalidation_1-auc:0.82338                                                                 \n",
      "[20]\tvalidation_0-auc:0.87381\tvalidation_1-auc:0.82376                                                                 \n",
      "[21]\tvalidation_0-auc:0.87419\tvalidation_1-auc:0.82378                                                                 \n",
      "[22]\tvalidation_0-auc:0.87528\tvalidation_1-auc:0.82354                                                                 \n",
      "[23]\tvalidation_0-auc:0.87599\tvalidation_1-auc:0.82380                                                                 \n",
      "[24]\tvalidation_0-auc:0.87631\tvalidation_1-auc:0.82410                                                                 \n",
      "[25]\tvalidation_0-auc:0.87750\tvalidation_1-auc:0.82383                                                                 \n",
      "[26]\tvalidation_0-auc:0.87812\tvalidation_1-auc:0.82359                                                                 \n",
      "[27]\tvalidation_0-auc:0.87851\tvalidation_1-auc:0.82348                                                                 \n",
      "[28]\tvalidation_0-auc:0.87870\tvalidation_1-auc:0.82320                                                                 \n",
      "[29]\tvalidation_0-auc:0.87893\tvalidation_1-auc:0.82324                                                                 \n",
      "[30]\tvalidation_0-auc:0.87929\tvalidation_1-auc:0.82334                                                                 \n",
      "[31]\tvalidation_0-auc:0.87979\tvalidation_1-auc:0.82368                                                                 \n",
      "[32]\tvalidation_0-auc:0.88025\tvalidation_1-auc:0.82379                                                                 \n",
      "[33]\tvalidation_0-auc:0.88058\tvalidation_1-auc:0.82362                                                                 \n",
      "[34]\tvalidation_0-auc:0.88075\tvalidation_1-auc:0.82353                                                                 \n",
      "[35]\tvalidation_0-auc:0.88098\tvalidation_1-auc:0.82365                                                                 \n",
      "[36]\tvalidation_0-auc:0.88114\tvalidation_1-auc:0.82344                                                                 \n",
      "[37]\tvalidation_0-auc:0.88200\tvalidation_1-auc:0.82374                                                                 \n",
      "[38]\tvalidation_0-auc:0.88218\tvalidation_1-auc:0.82356                                                                 \n",
      "[39]\tvalidation_0-auc:0.88324\tvalidation_1-auc:0.82365                                                                 \n",
      "[40]\tvalidation_0-auc:0.88369\tvalidation_1-auc:0.82397                                                                 \n",
      "[41]\tvalidation_0-auc:0.88388\tvalidation_1-auc:0.82393                                                                 \n",
      "[42]\tvalidation_0-auc:0.88456\tvalidation_1-auc:0.82388                                                                 \n",
      "[43]\tvalidation_0-auc:0.88540\tvalidation_1-auc:0.82366                                                                 \n",
      "[44]\tvalidation_0-auc:0.88576\tvalidation_1-auc:0.82345                                                                 \n",
      "[45]\tvalidation_0-auc:0.88630\tvalidation_1-auc:0.82365                                                                 \n",
      "[46]\tvalidation_0-auc:0.88663\tvalidation_1-auc:0.82437                                                                 \n",
      "[47]\tvalidation_0-auc:0.88742\tvalidation_1-auc:0.82431                                                                 \n",
      "[48]\tvalidation_0-auc:0.88761\tvalidation_1-auc:0.82414                                                                 \n",
      "[49]\tvalidation_0-auc:0.88854\tvalidation_1-auc:0.82431                                                                 \n",
      "[50]\tvalidation_0-auc:0.88862\tvalidation_1-auc:0.82415                                                                 \n",
      "[51]\tvalidation_0-auc:0.88926\tvalidation_1-auc:0.82379                                                                 \n",
      "[52]\tvalidation_0-auc:0.88992\tvalidation_1-auc:0.82333                                                                 \n",
      "[53]\tvalidation_0-auc:0.89063\tvalidation_1-auc:0.82333                                                                 \n",
      "[54]\tvalidation_0-auc:0.89116\tvalidation_1-auc:0.82312                                                                 \n",
      "[55]\tvalidation_0-auc:0.89168\tvalidation_1-auc:0.82334                                                                 \n",
      "[56]\tvalidation_0-auc:0.89178\tvalidation_1-auc:0.82315                                                                 \n",
      "[57]\tvalidation_0-auc:0.89189\tvalidation_1-auc:0.82341                                                                 \n",
      "[58]\tvalidation_0-auc:0.89201\tvalidation_1-auc:0.82343                                                                 \n",
      "[59]\tvalidation_0-auc:0.89220\tvalidation_1-auc:0.82337                                                                 \n",
      "[60]\tvalidation_0-auc:0.89258\tvalidation_1-auc:0.82316                                                                 \n",
      "[61]\tvalidation_0-auc:0.89265\tvalidation_1-auc:0.82295                                                                 \n",
      "[62]\tvalidation_0-auc:0.89354\tvalidation_1-auc:0.82277                                                                 \n",
      "[63]\tvalidation_0-auc:0.89381\tvalidation_1-auc:0.82274                                                                 \n",
      "[64]\tvalidation_0-auc:0.89413\tvalidation_1-auc:0.82263                                                                 \n",
      "[65]\tvalidation_0-auc:0.89458\tvalidation_1-auc:0.82257                                                                 \n",
      "[66]\tvalidation_0-auc:0.89516\tvalidation_1-auc:0.82270                                                                 \n",
      "[67]\tvalidation_0-auc:0.89559\tvalidation_1-auc:0.82266                                                                 \n",
      "[68]\tvalidation_0-auc:0.89604\tvalidation_1-auc:0.82252                                                                 \n",
      "[69]\tvalidation_0-auc:0.89639\tvalidation_1-auc:0.82254                                                                 \n",
      "[70]\tvalidation_0-auc:0.89653\tvalidation_1-auc:0.82262                                                                 \n",
      "[71]\tvalidation_0-auc:0.89676\tvalidation_1-auc:0.82240                                                                 \n",
      "[72]\tvalidation_0-auc:0.89681\tvalidation_1-auc:0.82236                                                                 \n",
      "[73]\tvalidation_0-auc:0.89751\tvalidation_1-auc:0.82249                                                                 \n",
      "[74]\tvalidation_0-auc:0.89767\tvalidation_1-auc:0.82235                                                                 \n",
      "[75]\tvalidation_0-auc:0.89779\tvalidation_1-auc:0.82246                                                                 \n",
      "[76]\tvalidation_0-auc:0.89790\tvalidation_1-auc:0.82249                                                                 \n",
      "[0]\tvalidation_0-auc:0.83122\tvalidation_1-auc:0.81779                                                                  \n",
      "[1]\tvalidation_0-auc:0.83776\tvalidation_1-auc:0.82356                                                                  \n",
      "[2]\tvalidation_0-auc:0.84328\tvalidation_1-auc:0.82907                                                                  \n",
      "[3]\tvalidation_0-auc:0.84745\tvalidation_1-auc:0.83711                                                                  \n",
      "[4]\tvalidation_0-auc:0.85082\tvalidation_1-auc:0.83818                                                                  \n",
      "[5]\tvalidation_0-auc:0.85290\tvalidation_1-auc:0.83916                                                                  \n",
      "[6]\tvalidation_0-auc:0.85371\tvalidation_1-auc:0.84042                                                                  \n",
      "[7]\tvalidation_0-auc:0.85495\tvalidation_1-auc:0.84064                                                                  \n",
      "[8]\tvalidation_0-auc:0.85691\tvalidation_1-auc:0.84110                                                                  \n",
      "[9]\tvalidation_0-auc:0.85806\tvalidation_1-auc:0.84252                                                                  \n",
      "[10]\tvalidation_0-auc:0.85925\tvalidation_1-auc:0.84281                                                                 \n",
      "[11]\tvalidation_0-auc:0.86046\tvalidation_1-auc:0.84268                                                                 \n",
      "[12]\tvalidation_0-auc:0.86176\tvalidation_1-auc:0.84244                                                                 \n",
      "[13]\tvalidation_0-auc:0.86295\tvalidation_1-auc:0.84225                                                                 \n",
      "[14]\tvalidation_0-auc:0.86462\tvalidation_1-auc:0.84340                                                                 \n",
      "[15]\tvalidation_0-auc:0.86537\tvalidation_1-auc:0.84327                                                                 \n",
      "[16]\tvalidation_0-auc:0.86578\tvalidation_1-auc:0.84346                                                                 \n",
      "[17]\tvalidation_0-auc:0.86684\tvalidation_1-auc:0.84366                                                                 \n",
      "[18]\tvalidation_0-auc:0.86723\tvalidation_1-auc:0.84338                                                                 \n",
      "[19]\tvalidation_0-auc:0.86772\tvalidation_1-auc:0.84334                                                                 \n",
      "[20]\tvalidation_0-auc:0.86809\tvalidation_1-auc:0.84333                                                                 \n",
      "[21]\tvalidation_0-auc:0.86863\tvalidation_1-auc:0.84326                                                                 \n",
      "[22]\tvalidation_0-auc:0.86890\tvalidation_1-auc:0.84315                                                                 \n",
      "[23]\tvalidation_0-auc:0.86960\tvalidation_1-auc:0.84325                                                                 \n",
      "[24]\tvalidation_0-auc:0.87036\tvalidation_1-auc:0.84351                                                                 \n",
      "[25]\tvalidation_0-auc:0.87125\tvalidation_1-auc:0.84399                                                                 \n",
      "[26]\tvalidation_0-auc:0.87130\tvalidation_1-auc:0.84379                                                                 \n",
      "[27]\tvalidation_0-auc:0.87186\tvalidation_1-auc:0.84403                                                                 \n",
      "[28]\tvalidation_0-auc:0.87258\tvalidation_1-auc:0.84384                                                                 \n",
      "[29]\tvalidation_0-auc:0.87323\tvalidation_1-auc:0.84405                                                                 \n",
      "[30]\tvalidation_0-auc:0.87347\tvalidation_1-auc:0.84426                                                                 \n",
      "[31]\tvalidation_0-auc:0.87385\tvalidation_1-auc:0.84420                                                                 \n",
      "[32]\tvalidation_0-auc:0.87400\tvalidation_1-auc:0.84412                                                                 \n",
      "[33]\tvalidation_0-auc:0.87497\tvalidation_1-auc:0.84397                                                                 \n",
      "[34]\tvalidation_0-auc:0.87557\tvalidation_1-auc:0.84394                                                                 \n",
      "[35]\tvalidation_0-auc:0.87629\tvalidation_1-auc:0.84422                                                                 \n",
      "[36]\tvalidation_0-auc:0.87664\tvalidation_1-auc:0.84434                                                                 \n",
      "[37]\tvalidation_0-auc:0.87684\tvalidation_1-auc:0.84427                                                                 \n",
      "[38]\tvalidation_0-auc:0.87741\tvalidation_1-auc:0.84439                                                                 \n",
      "[39]\tvalidation_0-auc:0.87772\tvalidation_1-auc:0.84445                                                                 \n",
      "[40]\tvalidation_0-auc:0.87882\tvalidation_1-auc:0.84434                                                                 \n",
      "[41]\tvalidation_0-auc:0.87945\tvalidation_1-auc:0.84470                                                                 \n",
      "[42]\tvalidation_0-auc:0.87974\tvalidation_1-auc:0.84449                                                                 \n",
      "[43]\tvalidation_0-auc:0.88029\tvalidation_1-auc:0.84379                                                                 \n",
      "[44]\tvalidation_0-auc:0.88085\tvalidation_1-auc:0.84374                                                                 \n",
      "[45]\tvalidation_0-auc:0.88126\tvalidation_1-auc:0.84368                                                                 \n",
      "[46]\tvalidation_0-auc:0.88209\tvalidation_1-auc:0.84369                                                                 \n",
      "[47]\tvalidation_0-auc:0.88252\tvalidation_1-auc:0.84378                                                                 \n",
      "[48]\tvalidation_0-auc:0.88291\tvalidation_1-auc:0.84383                                                                 \n",
      "[49]\tvalidation_0-auc:0.88313\tvalidation_1-auc:0.84382                                                                 \n",
      "[50]\tvalidation_0-auc:0.88344\tvalidation_1-auc:0.84394                                                                 \n",
      "[51]\tvalidation_0-auc:0.88350\tvalidation_1-auc:0.84381                                                                 \n",
      "[52]\tvalidation_0-auc:0.88386\tvalidation_1-auc:0.84336                                                                 \n",
      "[53]\tvalidation_0-auc:0.88439\tvalidation_1-auc:0.84315                                                                 \n",
      "[54]\tvalidation_0-auc:0.88505\tvalidation_1-auc:0.84312                                                                 \n",
      "[55]\tvalidation_0-auc:0.88529\tvalidation_1-auc:0.84315                                                                 \n",
      "[56]\tvalidation_0-auc:0.88608\tvalidation_1-auc:0.84336                                                                 \n",
      "[57]\tvalidation_0-auc:0.88643\tvalidation_1-auc:0.84348                                                                 \n",
      "[58]\tvalidation_0-auc:0.88680\tvalidation_1-auc:0.84341                                                                 \n",
      "[59]\tvalidation_0-auc:0.88714\tvalidation_1-auc:0.84314                                                                 \n",
      "[60]\tvalidation_0-auc:0.88732\tvalidation_1-auc:0.84303                                                                 \n",
      "[61]\tvalidation_0-auc:0.88785\tvalidation_1-auc:0.84315                                                                 \n",
      "[62]\tvalidation_0-auc:0.88838\tvalidation_1-auc:0.84324                                                                 \n",
      "[63]\tvalidation_0-auc:0.88845\tvalidation_1-auc:0.84321                                                                 \n",
      "[64]\tvalidation_0-auc:0.88853\tvalidation_1-auc:0.84317                                                                 \n",
      "[65]\tvalidation_0-auc:0.88904\tvalidation_1-auc:0.84297                                                                 \n",
      "[66]\tvalidation_0-auc:0.88930\tvalidation_1-auc:0.84302                                                                 \n",
      "[67]\tvalidation_0-auc:0.88955\tvalidation_1-auc:0.84278                                                                 \n",
      "[68]\tvalidation_0-auc:0.88971\tvalidation_1-auc:0.84264                                                                 \n",
      "[69]\tvalidation_0-auc:0.88993\tvalidation_1-auc:0.84241                                                                 \n",
      "[70]\tvalidation_0-auc:0.89044\tvalidation_1-auc:0.84224                                                                 \n",
      "[71]\tvalidation_0-auc:0.89103\tvalidation_1-auc:0.84181                                                                 \n",
      "[0]\tvalidation_0-auc:0.82771\tvalidation_1-auc:0.82031                                                                  \n",
      "[1]\tvalidation_0-auc:0.83647\tvalidation_1-auc:0.83027                                                                  \n",
      "[2]\tvalidation_0-auc:0.84124\tvalidation_1-auc:0.83217                                                                  \n",
      "[3]\tvalidation_0-auc:0.84591\tvalidation_1-auc:0.83291                                                                  \n",
      "[4]\tvalidation_0-auc:0.85025\tvalidation_1-auc:0.83580                                                                  \n",
      "[5]\tvalidation_0-auc:0.85276\tvalidation_1-auc:0.83707                                                                  \n",
      "[6]\tvalidation_0-auc:0.85508\tvalidation_1-auc:0.83723                                                                  \n",
      "[7]\tvalidation_0-auc:0.85660\tvalidation_1-auc:0.83646                                                                  \n",
      "[8]\tvalidation_0-auc:0.85757\tvalidation_1-auc:0.83658                                                                  \n",
      "[9]\tvalidation_0-auc:0.85926\tvalidation_1-auc:0.83741                                                                  \n",
      "[10]\tvalidation_0-auc:0.86033\tvalidation_1-auc:0.83775                                                                 \n",
      "[11]\tvalidation_0-auc:0.86159\tvalidation_1-auc:0.83816                                                                 \n",
      "[12]\tvalidation_0-auc:0.86275\tvalidation_1-auc:0.83895                                                                 \n",
      "[13]\tvalidation_0-auc:0.86402\tvalidation_1-auc:0.83943                                                                 \n",
      "[14]\tvalidation_0-auc:0.86574\tvalidation_1-auc:0.83963                                                                 \n",
      "[15]\tvalidation_0-auc:0.86667\tvalidation_1-auc:0.84040                                                                 \n",
      "[16]\tvalidation_0-auc:0.86778\tvalidation_1-auc:0.84061                                                                 \n",
      "[17]\tvalidation_0-auc:0.86886\tvalidation_1-auc:0.84027                                                                 \n",
      "[18]\tvalidation_0-auc:0.86934\tvalidation_1-auc:0.84035                                                                 \n",
      "[19]\tvalidation_0-auc:0.87044\tvalidation_1-auc:0.84104                                                                 \n",
      "[20]\tvalidation_0-auc:0.87140\tvalidation_1-auc:0.84106                                                                 \n",
      "[21]\tvalidation_0-auc:0.87222\tvalidation_1-auc:0.84145                                                                 \n",
      "[22]\tvalidation_0-auc:0.87280\tvalidation_1-auc:0.84135                                                                 \n",
      "[23]\tvalidation_0-auc:0.87302\tvalidation_1-auc:0.84144                                                                 \n",
      "[24]\tvalidation_0-auc:0.87348\tvalidation_1-auc:0.84182                                                                 \n",
      "[25]\tvalidation_0-auc:0.87397\tvalidation_1-auc:0.84221                                                                 \n",
      "[26]\tvalidation_0-auc:0.87423\tvalidation_1-auc:0.84228                                                                 \n",
      "[27]\tvalidation_0-auc:0.87431\tvalidation_1-auc:0.84245                                                                 \n",
      "[28]\tvalidation_0-auc:0.87453\tvalidation_1-auc:0.84223                                                                 \n",
      "[29]\tvalidation_0-auc:0.87513\tvalidation_1-auc:0.84232                                                                 \n",
      "[30]\tvalidation_0-auc:0.87577\tvalidation_1-auc:0.84259                                                                 \n",
      "[31]\tvalidation_0-auc:0.87629\tvalidation_1-auc:0.84229                                                                 \n",
      "[32]\tvalidation_0-auc:0.87776\tvalidation_1-auc:0.84216                                                                 \n",
      "[33]\tvalidation_0-auc:0.87799\tvalidation_1-auc:0.84221                                                                 \n",
      "[34]\tvalidation_0-auc:0.87887\tvalidation_1-auc:0.84195                                                                 \n",
      "[35]\tvalidation_0-auc:0.87904\tvalidation_1-auc:0.84201                                                                 \n",
      "[36]\tvalidation_0-auc:0.87946\tvalidation_1-auc:0.84179                                                                 \n",
      "[37]\tvalidation_0-auc:0.88039\tvalidation_1-auc:0.84162                                                                 \n",
      "[38]\tvalidation_0-auc:0.88100\tvalidation_1-auc:0.84172                                                                 \n",
      "[39]\tvalidation_0-auc:0.88123\tvalidation_1-auc:0.84164                                                                 \n",
      "[40]\tvalidation_0-auc:0.88173\tvalidation_1-auc:0.84158                                                                 \n",
      "[41]\tvalidation_0-auc:0.88220\tvalidation_1-auc:0.84126                                                                 \n",
      "[42]\tvalidation_0-auc:0.88263\tvalidation_1-auc:0.84129                                                                 \n",
      "[43]\tvalidation_0-auc:0.88358\tvalidation_1-auc:0.84132                                                                 \n",
      "[44]\tvalidation_0-auc:0.88376\tvalidation_1-auc:0.84142                                                                 \n",
      "[45]\tvalidation_0-auc:0.88471\tvalidation_1-auc:0.84126                                                                 \n",
      "[46]\tvalidation_0-auc:0.88553\tvalidation_1-auc:0.84181                                                                 \n",
      "[47]\tvalidation_0-auc:0.88582\tvalidation_1-auc:0.84187                                                                 \n",
      "[48]\tvalidation_0-auc:0.88634\tvalidation_1-auc:0.84158                                                                 \n",
      "[49]\tvalidation_0-auc:0.88690\tvalidation_1-auc:0.84134                                                                 \n",
      "[50]\tvalidation_0-auc:0.88722\tvalidation_1-auc:0.84154                                                                 \n",
      "[51]\tvalidation_0-auc:0.88730\tvalidation_1-auc:0.84148                                                                 \n",
      "[52]\tvalidation_0-auc:0.88752\tvalidation_1-auc:0.84145                                                                 \n",
      "[53]\tvalidation_0-auc:0.88840\tvalidation_1-auc:0.84142                                                                 \n",
      "[54]\tvalidation_0-auc:0.88846\tvalidation_1-auc:0.84140                                                                 \n",
      "[55]\tvalidation_0-auc:0.88904\tvalidation_1-auc:0.84111                                                                 \n",
      "[56]\tvalidation_0-auc:0.88960\tvalidation_1-auc:0.84107                                                                 \n",
      "[57]\tvalidation_0-auc:0.88985\tvalidation_1-auc:0.84097                                                                 \n",
      "[58]\tvalidation_0-auc:0.89006\tvalidation_1-auc:0.84106                                                                 \n",
      "[59]\tvalidation_0-auc:0.89019\tvalidation_1-auc:0.84105                                                                 \n",
      "[60]\tvalidation_0-auc:0.89114\tvalidation_1-auc:0.84090                                                                 \n",
      "[0]\tvalidation_0-auc:0.85590\tvalidation_1-auc:0.81267                                                                  \n",
      "[1]\tvalidation_0-auc:0.86249\tvalidation_1-auc:0.81662                                                                  \n",
      "[2]\tvalidation_0-auc:0.86584\tvalidation_1-auc:0.81951                                                                  \n",
      "[3]\tvalidation_0-auc:0.86779\tvalidation_1-auc:0.82083                                                                  \n",
      "[4]\tvalidation_0-auc:0.87039\tvalidation_1-auc:0.82173                                                                  \n",
      "[5]\tvalidation_0-auc:0.87434\tvalidation_1-auc:0.82175                                                                  \n",
      "[6]\tvalidation_0-auc:0.87718\tvalidation_1-auc:0.82221                                                                  \n",
      "[7]\tvalidation_0-auc:0.87899\tvalidation_1-auc:0.82290                                                                  \n",
      "[8]\tvalidation_0-auc:0.88049\tvalidation_1-auc:0.82354                                                                  \n",
      "[9]\tvalidation_0-auc:0.88165\tvalidation_1-auc:0.82367                                                                  \n",
      "[10]\tvalidation_0-auc:0.88350\tvalidation_1-auc:0.82346                                                                 \n",
      "[11]\tvalidation_0-auc:0.88421\tvalidation_1-auc:0.82306                                                                 \n",
      "[12]\tvalidation_0-auc:0.88562\tvalidation_1-auc:0.82409                                                                 \n",
      "[13]\tvalidation_0-auc:0.88682\tvalidation_1-auc:0.82309                                                                 \n",
      "[14]\tvalidation_0-auc:0.88830\tvalidation_1-auc:0.82293                                                                 \n",
      "[15]\tvalidation_0-auc:0.88968\tvalidation_1-auc:0.82247                                                                 \n",
      "[16]\tvalidation_0-auc:0.89056\tvalidation_1-auc:0.82214                                                                 \n",
      "[17]\tvalidation_0-auc:0.89165\tvalidation_1-auc:0.82184                                                                 \n",
      "[18]\tvalidation_0-auc:0.89272\tvalidation_1-auc:0.82169                                                                 \n",
      "[19]\tvalidation_0-auc:0.89355\tvalidation_1-auc:0.82146                                                                 \n",
      "[20]\tvalidation_0-auc:0.89409\tvalidation_1-auc:0.82164                                                                 \n",
      "[21]\tvalidation_0-auc:0.89451\tvalidation_1-auc:0.82175                                                                 \n",
      "[22]\tvalidation_0-auc:0.89517\tvalidation_1-auc:0.82200                                                                 \n",
      "[23]\tvalidation_0-auc:0.89566\tvalidation_1-auc:0.82240                                                                 \n",
      "[24]\tvalidation_0-auc:0.89601\tvalidation_1-auc:0.82261                                                                 \n",
      "[25]\tvalidation_0-auc:0.89660\tvalidation_1-auc:0.82236                                                                 \n",
      "[26]\tvalidation_0-auc:0.89751\tvalidation_1-auc:0.82267                                                                 \n",
      "[27]\tvalidation_0-auc:0.89790\tvalidation_1-auc:0.82302                                                                 \n",
      "[28]\tvalidation_0-auc:0.89841\tvalidation_1-auc:0.82262                                                                 \n",
      "[29]\tvalidation_0-auc:0.89860\tvalidation_1-auc:0.82263                                                                 \n",
      "[30]\tvalidation_0-auc:0.89959\tvalidation_1-auc:0.82282                                                                 \n",
      "[31]\tvalidation_0-auc:0.89998\tvalidation_1-auc:0.82283                                                                 \n",
      "[32]\tvalidation_0-auc:0.90089\tvalidation_1-auc:0.82274                                                                 \n",
      "[33]\tvalidation_0-auc:0.90120\tvalidation_1-auc:0.82280                                                                 \n",
      "[34]\tvalidation_0-auc:0.90166\tvalidation_1-auc:0.82264                                                                 \n",
      "[35]\tvalidation_0-auc:0.90256\tvalidation_1-auc:0.82258                                                                 \n",
      "[36]\tvalidation_0-auc:0.90278\tvalidation_1-auc:0.82260                                                                 \n",
      "[37]\tvalidation_0-auc:0.90311\tvalidation_1-auc:0.82246                                                                 \n",
      "[38]\tvalidation_0-auc:0.90327\tvalidation_1-auc:0.82224                                                                 \n",
      "[39]\tvalidation_0-auc:0.90390\tvalidation_1-auc:0.82224                                                                 \n",
      "[40]\tvalidation_0-auc:0.90456\tvalidation_1-auc:0.82211                                                                 \n",
      "[41]\tvalidation_0-auc:0.90469\tvalidation_1-auc:0.82205                                                                 \n",
      "[42]\tvalidation_0-auc:0.90502\tvalidation_1-auc:0.82212                                                                 \n",
      "[0]\tvalidation_0-auc:0.85139\tvalidation_1-auc:0.82164                                                                  \n",
      "[1]\tvalidation_0-auc:0.85672\tvalidation_1-auc:0.82631                                                                  \n",
      "[2]\tvalidation_0-auc:0.86100\tvalidation_1-auc:0.83007                                                                  \n",
      "[3]\tvalidation_0-auc:0.86641\tvalidation_1-auc:0.83246                                                                  \n",
      "[4]\tvalidation_0-auc:0.86888\tvalidation_1-auc:0.83273                                                                  \n",
      "[5]\tvalidation_0-auc:0.87133\tvalidation_1-auc:0.83298                                                                  \n",
      "[6]\tvalidation_0-auc:0.87418\tvalidation_1-auc:0.83331                                                                  \n",
      "[7]\tvalidation_0-auc:0.87702\tvalidation_1-auc:0.83398                                                                  \n",
      "[8]\tvalidation_0-auc:0.87859\tvalidation_1-auc:0.83488                                                                  \n",
      "[9]\tvalidation_0-auc:0.88071\tvalidation_1-auc:0.83511                                                                  \n",
      "[10]\tvalidation_0-auc:0.88219\tvalidation_1-auc:0.83513                                                                 \n",
      "[11]\tvalidation_0-auc:0.88374\tvalidation_1-auc:0.83591                                                                 \n",
      "[12]\tvalidation_0-auc:0.88539\tvalidation_1-auc:0.83580                                                                 \n",
      "[13]\tvalidation_0-auc:0.88619\tvalidation_1-auc:0.83593                                                                 \n",
      "[14]\tvalidation_0-auc:0.88667\tvalidation_1-auc:0.83661                                                                 \n",
      "[15]\tvalidation_0-auc:0.88776\tvalidation_1-auc:0.83727                                                                 \n",
      "[16]\tvalidation_0-auc:0.88915\tvalidation_1-auc:0.83717                                                                 \n",
      "[17]\tvalidation_0-auc:0.88995\tvalidation_1-auc:0.83749                                                                 \n",
      "[18]\tvalidation_0-auc:0.89046\tvalidation_1-auc:0.83781                                                                 \n",
      "[19]\tvalidation_0-auc:0.89091\tvalidation_1-auc:0.83796                                                                 \n",
      "[20]\tvalidation_0-auc:0.89159\tvalidation_1-auc:0.83821                                                                 \n",
      "[21]\tvalidation_0-auc:0.89191\tvalidation_1-auc:0.83852                                                                 \n",
      "[22]\tvalidation_0-auc:0.89250\tvalidation_1-auc:0.83868                                                                 \n",
      "[23]\tvalidation_0-auc:0.89284\tvalidation_1-auc:0.83837                                                                 \n",
      "[24]\tvalidation_0-auc:0.89329\tvalidation_1-auc:0.83817                                                                 \n",
      "[25]\tvalidation_0-auc:0.89354\tvalidation_1-auc:0.83847                                                                 \n",
      "[26]\tvalidation_0-auc:0.89418\tvalidation_1-auc:0.83833                                                                 \n",
      "[27]\tvalidation_0-auc:0.89483\tvalidation_1-auc:0.83834                                                                 \n",
      "[28]\tvalidation_0-auc:0.89526\tvalidation_1-auc:0.83852                                                                 \n",
      "[29]\tvalidation_0-auc:0.89558\tvalidation_1-auc:0.83870                                                                 \n",
      "[30]\tvalidation_0-auc:0.89644\tvalidation_1-auc:0.83934                                                                 \n",
      "[31]\tvalidation_0-auc:0.89688\tvalidation_1-auc:0.83923                                                                 \n",
      "[32]\tvalidation_0-auc:0.89726\tvalidation_1-auc:0.83930                                                                 \n",
      "[33]\tvalidation_0-auc:0.89816\tvalidation_1-auc:0.83917                                                                 \n",
      "[34]\tvalidation_0-auc:0.89838\tvalidation_1-auc:0.83907                                                                 \n",
      "[35]\tvalidation_0-auc:0.89882\tvalidation_1-auc:0.83902                                                                 \n",
      "[36]\tvalidation_0-auc:0.89909\tvalidation_1-auc:0.83903                                                                 \n",
      "[37]\tvalidation_0-auc:0.89969\tvalidation_1-auc:0.83915                                                                 \n",
      "[38]\tvalidation_0-auc:0.89984\tvalidation_1-auc:0.83923                                                                 \n",
      "[39]\tvalidation_0-auc:0.90004\tvalidation_1-auc:0.83904                                                                 \n",
      "[40]\tvalidation_0-auc:0.90086\tvalidation_1-auc:0.83881                                                                 \n",
      "[41]\tvalidation_0-auc:0.90102\tvalidation_1-auc:0.83874                                                                 \n",
      "[42]\tvalidation_0-auc:0.90168\tvalidation_1-auc:0.83861                                                                 \n",
      "[43]\tvalidation_0-auc:0.90301\tvalidation_1-auc:0.83853                                                                 \n",
      "[44]\tvalidation_0-auc:0.90360\tvalidation_1-auc:0.83871                                                                 \n",
      "[45]\tvalidation_0-auc:0.90402\tvalidation_1-auc:0.83870                                                                 \n",
      "[46]\tvalidation_0-auc:0.90448\tvalidation_1-auc:0.83845                                                                 \n",
      "[47]\tvalidation_0-auc:0.90474\tvalidation_1-auc:0.83832                                                                 \n",
      "[48]\tvalidation_0-auc:0.90504\tvalidation_1-auc:0.83833                                                                 \n",
      "[49]\tvalidation_0-auc:0.90518\tvalidation_1-auc:0.83823                                                                 \n",
      "[50]\tvalidation_0-auc:0.90579\tvalidation_1-auc:0.83820                                                                 \n",
      "[51]\tvalidation_0-auc:0.90619\tvalidation_1-auc:0.83837                                                                 \n",
      "[52]\tvalidation_0-auc:0.90695\tvalidation_1-auc:0.83835                                                                 \n",
      "[53]\tvalidation_0-auc:0.90714\tvalidation_1-auc:0.83815                                                                 \n",
      "[54]\tvalidation_0-auc:0.90790\tvalidation_1-auc:0.83800                                                                 \n",
      "[55]\tvalidation_0-auc:0.90805\tvalidation_1-auc:0.83795                                                                 \n",
      "[56]\tvalidation_0-auc:0.90814\tvalidation_1-auc:0.83770                                                                 \n",
      "[57]\tvalidation_0-auc:0.90835\tvalidation_1-auc:0.83754                                                                 \n",
      "[58]\tvalidation_0-auc:0.90924\tvalidation_1-auc:0.83756                                                                 \n",
      "[59]\tvalidation_0-auc:0.90943\tvalidation_1-auc:0.83745                                                                 \n",
      "[60]\tvalidation_0-auc:0.91005\tvalidation_1-auc:0.83725                                                                 \n",
      "[0]\tvalidation_0-auc:0.84962\tvalidation_1-auc:0.81487                                                                  \n",
      "[1]\tvalidation_0-auc:0.85604\tvalidation_1-auc:0.82450                                                                  \n",
      "[2]\tvalidation_0-auc:0.86001\tvalidation_1-auc:0.83162                                                                  \n",
      "[3]\tvalidation_0-auc:0.86496\tvalidation_1-auc:0.83124                                                                  \n",
      "[4]\tvalidation_0-auc:0.86669\tvalidation_1-auc:0.83191                                                                  \n",
      "[5]\tvalidation_0-auc:0.87133\tvalidation_1-auc:0.83398                                                                  \n",
      "[6]\tvalidation_0-auc:0.87312\tvalidation_1-auc:0.83443                                                                  \n",
      "[7]\tvalidation_0-auc:0.87441\tvalidation_1-auc:0.83560                                                                  \n",
      "[8]\tvalidation_0-auc:0.87658\tvalidation_1-auc:0.83466                                                                  \n",
      "[9]\tvalidation_0-auc:0.87775\tvalidation_1-auc:0.83483                                                                  \n",
      "[10]\tvalidation_0-auc:0.88025\tvalidation_1-auc:0.83448                                                                 \n",
      "[11]\tvalidation_0-auc:0.88166\tvalidation_1-auc:0.83443                                                                 \n",
      "[12]\tvalidation_0-auc:0.88271\tvalidation_1-auc:0.83379                                                                 \n",
      "[13]\tvalidation_0-auc:0.88345\tvalidation_1-auc:0.83379                                                                 \n",
      "[14]\tvalidation_0-auc:0.88504\tvalidation_1-auc:0.83411                                                                 \n",
      "[15]\tvalidation_0-auc:0.88665\tvalidation_1-auc:0.83415                                                                 \n",
      "[16]\tvalidation_0-auc:0.88821\tvalidation_1-auc:0.83427                                                                 \n",
      "[17]\tvalidation_0-auc:0.88944\tvalidation_1-auc:0.83400                                                                 \n",
      "[18]\tvalidation_0-auc:0.89030\tvalidation_1-auc:0.83431                                                                 \n",
      "[19]\tvalidation_0-auc:0.89156\tvalidation_1-auc:0.83473                                                                 \n",
      "[20]\tvalidation_0-auc:0.89240\tvalidation_1-auc:0.83533                                                                 \n",
      "[21]\tvalidation_0-auc:0.89360\tvalidation_1-auc:0.83545                                                                 \n",
      "[22]\tvalidation_0-auc:0.89495\tvalidation_1-auc:0.83570                                                                 \n",
      "[23]\tvalidation_0-auc:0.89567\tvalidation_1-auc:0.83578                                                                 \n",
      "[24]\tvalidation_0-auc:0.89678\tvalidation_1-auc:0.83585                                                                 \n",
      "[25]\tvalidation_0-auc:0.89716\tvalidation_1-auc:0.83602                                                                 \n",
      "[26]\tvalidation_0-auc:0.89834\tvalidation_1-auc:0.83607                                                                 \n",
      "[27]\tvalidation_0-auc:0.89890\tvalidation_1-auc:0.83648                                                                 \n",
      "[28]\tvalidation_0-auc:0.90011\tvalidation_1-auc:0.83634                                                                 \n",
      "[29]\tvalidation_0-auc:0.90047\tvalidation_1-auc:0.83627                                                                 \n",
      "[30]\tvalidation_0-auc:0.90110\tvalidation_1-auc:0.83645                                                                 \n",
      "[31]\tvalidation_0-auc:0.90127\tvalidation_1-auc:0.83649                                                                 \n",
      "[32]\tvalidation_0-auc:0.90270\tvalidation_1-auc:0.83634                                                                 \n",
      "[33]\tvalidation_0-auc:0.90353\tvalidation_1-auc:0.83632                                                                 \n",
      "[34]\tvalidation_0-auc:0.90371\tvalidation_1-auc:0.83648                                                                 \n",
      "[35]\tvalidation_0-auc:0.90393\tvalidation_1-auc:0.83663                                                                 \n",
      "[36]\tvalidation_0-auc:0.90407\tvalidation_1-auc:0.83676                                                                 \n",
      "[37]\tvalidation_0-auc:0.90448\tvalidation_1-auc:0.83683                                                                 \n",
      "[38]\tvalidation_0-auc:0.90488\tvalidation_1-auc:0.83693                                                                 \n",
      "[39]\tvalidation_0-auc:0.90599\tvalidation_1-auc:0.83658                                                                 \n",
      "[40]\tvalidation_0-auc:0.90661\tvalidation_1-auc:0.83661                                                                 \n",
      "[41]\tvalidation_0-auc:0.90673\tvalidation_1-auc:0.83662                                                                 \n",
      "[42]\tvalidation_0-auc:0.90716\tvalidation_1-auc:0.83664                                                                 \n",
      "[43]\tvalidation_0-auc:0.90752\tvalidation_1-auc:0.83671                                                                 \n",
      "[44]\tvalidation_0-auc:0.90785\tvalidation_1-auc:0.83669                                                                 \n",
      "[45]\tvalidation_0-auc:0.90838\tvalidation_1-auc:0.83628                                                                 \n",
      "[46]\tvalidation_0-auc:0.90849\tvalidation_1-auc:0.83634                                                                 \n",
      "[47]\tvalidation_0-auc:0.90911\tvalidation_1-auc:0.83642                                                                 \n",
      "[48]\tvalidation_0-auc:0.90984\tvalidation_1-auc:0.83613                                                                 \n",
      "[49]\tvalidation_0-auc:0.91009\tvalidation_1-auc:0.83608                                                                 \n",
      "[50]\tvalidation_0-auc:0.91052\tvalidation_1-auc:0.83617                                                                 \n",
      "[51]\tvalidation_0-auc:0.91065\tvalidation_1-auc:0.83619                                                                 \n",
      "[52]\tvalidation_0-auc:0.91137\tvalidation_1-auc:0.83606                                                                 \n",
      "[53]\tvalidation_0-auc:0.91152\tvalidation_1-auc:0.83592                                                                 \n",
      "[54]\tvalidation_0-auc:0.91160\tvalidation_1-auc:0.83587                                                                 \n",
      "[55]\tvalidation_0-auc:0.91179\tvalidation_1-auc:0.83597                                                                 \n",
      "[56]\tvalidation_0-auc:0.91202\tvalidation_1-auc:0.83587                                                                 \n",
      "[57]\tvalidation_0-auc:0.91213\tvalidation_1-auc:0.83601                                                                 \n",
      "[58]\tvalidation_0-auc:0.91238\tvalidation_1-auc:0.83606                                                                 \n",
      "[59]\tvalidation_0-auc:0.91319\tvalidation_1-auc:0.83574                                                                 \n",
      "[60]\tvalidation_0-auc:0.91376\tvalidation_1-auc:0.83543                                                                 \n",
      "[61]\tvalidation_0-auc:0.91391\tvalidation_1-auc:0.83537                                                                 \n",
      "[62]\tvalidation_0-auc:0.91420\tvalidation_1-auc:0.83516                                                                 \n",
      "[63]\tvalidation_0-auc:0.91434\tvalidation_1-auc:0.83525                                                                 \n",
      "[64]\tvalidation_0-auc:0.91440\tvalidation_1-auc:0.83526                                                                 \n",
      "[65]\tvalidation_0-auc:0.91487\tvalidation_1-auc:0.83525                                                                 \n",
      "[66]\tvalidation_0-auc:0.91517\tvalidation_1-auc:0.83487                                                                 \n",
      "[67]\tvalidation_0-auc:0.91536\tvalidation_1-auc:0.83483                                                                 \n",
      "[68]\tvalidation_0-auc:0.91552\tvalidation_1-auc:0.83501                                                                 \n",
      "[0]\tvalidation_0-auc:0.83826\tvalidation_1-auc:0.81054                                                                  \n",
      "[1]\tvalidation_0-auc:0.84462\tvalidation_1-auc:0.81396                                                                  \n",
      "[2]\tvalidation_0-auc:0.84861\tvalidation_1-auc:0.81758                                                                  \n",
      "[3]\tvalidation_0-auc:0.85261\tvalidation_1-auc:0.81627                                                                  \n",
      "[4]\tvalidation_0-auc:0.85550\tvalidation_1-auc:0.81703                                                                  \n",
      "[5]\tvalidation_0-auc:0.85743\tvalidation_1-auc:0.81781                                                                  \n",
      "[6]\tvalidation_0-auc:0.85941\tvalidation_1-auc:0.81849                                                                  \n",
      "[7]\tvalidation_0-auc:0.86107\tvalidation_1-auc:0.82022                                                                  \n",
      "[94]\tvalidation_0-auc:0.95903\tvalidation_1-auc:0.83058                                                                 \n",
      "[95]\tvalidation_0-auc:0.95924\tvalidation_1-auc:0.83075                                                                 \n",
      "[96]\tvalidation_0-auc:0.95944\tvalidation_1-auc:0.83087                                                                 \n",
      "[97]\tvalidation_0-auc:0.95948\tvalidation_1-auc:0.83086                                                                 \n",
      "[98]\tvalidation_0-auc:0.95956\tvalidation_1-auc:0.83092                                                                 \n",
      "[99]\tvalidation_0-auc:0.95985\tvalidation_1-auc:0.83103                                                                 \n",
      "100%|███████████████████████████████████████████████| 50/50 [05:12<00:00,  6.24s/trial, best loss: -0.8379624777063143]\n",
      "best: {'colsample_bytree': np.float64(0.7934236500158641), 'learning_rate': np.float64(0.10088262075750994), 'max_depth': np.float64(5.0), 'min_child_weight': np.float64(6.0)}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn=objective_func, \n",
    "            space=xgb_search_space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=50, \n",
    "            trials=trials, \n",
    "            rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print(f'best: {best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e9d2b0bf-3aac-494b-9109-de3aba6f0363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "6.0\n",
      "0.7934236500158641\n",
      "0.10088262075750994\n"
     ]
    }
   ],
   "source": [
    "print(best['max_depth'], \n",
    "      best['min_child_weight'], \n",
    "      best['colsample_bytree'], \n",
    "      best['learning_rate'], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "519bebf9-a419-41da-8f12-c3c8a1362fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.82962\tvalidation_1-auc:0.81129\n",
      "[1]\tvalidation_0-auc:0.83543\tvalidation_1-auc:0.81222\n",
      "[2]\tvalidation_0-auc:0.84230\tvalidation_1-auc:0.82100\n",
      "[3]\tvalidation_0-auc:0.84377\tvalidation_1-auc:0.82461\n",
      "[4]\tvalidation_0-auc:0.84855\tvalidation_1-auc:0.82712\n",
      "[5]\tvalidation_0-auc:0.84932\tvalidation_1-auc:0.82756\n",
      "[6]\tvalidation_0-auc:0.85087\tvalidation_1-auc:0.82889\n",
      "[7]\tvalidation_0-auc:0.85225\tvalidation_1-auc:0.82981\n",
      "[8]\tvalidation_0-auc:0.85319\tvalidation_1-auc:0.82990\n",
      "[9]\tvalidation_0-auc:0.85445\tvalidation_1-auc:0.83123\n",
      "[10]\tvalidation_0-auc:0.85503\tvalidation_1-auc:0.83208\n",
      "[11]\tvalidation_0-auc:0.85636\tvalidation_1-auc:0.83257\n",
      "[12]\tvalidation_0-auc:0.85717\tvalidation_1-auc:0.83316\n",
      "[13]\tvalidation_0-auc:0.85822\tvalidation_1-auc:0.83303\n",
      "[14]\tvalidation_0-auc:0.85952\tvalidation_1-auc:0.83356\n",
      "[15]\tvalidation_0-auc:0.86012\tvalidation_1-auc:0.83362\n",
      "[16]\tvalidation_0-auc:0.86097\tvalidation_1-auc:0.83419\n",
      "[17]\tvalidation_0-auc:0.86219\tvalidation_1-auc:0.83474\n",
      "[18]\tvalidation_0-auc:0.86280\tvalidation_1-auc:0.83503\n",
      "[19]\tvalidation_0-auc:0.86355\tvalidation_1-auc:0.83530\n",
      "[20]\tvalidation_0-auc:0.86399\tvalidation_1-auc:0.83545\n",
      "[21]\tvalidation_0-auc:0.86472\tvalidation_1-auc:0.83574\n",
      "[22]\tvalidation_0-auc:0.86510\tvalidation_1-auc:0.83591\n",
      "[23]\tvalidation_0-auc:0.86561\tvalidation_1-auc:0.83600\n",
      "[24]\tvalidation_0-auc:0.86606\tvalidation_1-auc:0.83614\n",
      "[25]\tvalidation_0-auc:0.86639\tvalidation_1-auc:0.83613\n",
      "[26]\tvalidation_0-auc:0.86705\tvalidation_1-auc:0.83647\n",
      "[27]\tvalidation_0-auc:0.86763\tvalidation_1-auc:0.83657\n",
      "[28]\tvalidation_0-auc:0.86792\tvalidation_1-auc:0.83644\n",
      "[29]\tvalidation_0-auc:0.86852\tvalidation_1-auc:0.83659\n",
      "[30]\tvalidation_0-auc:0.86924\tvalidation_1-auc:0.83668\n",
      "[31]\tvalidation_0-auc:0.86994\tvalidation_1-auc:0.83660\n",
      "[32]\tvalidation_0-auc:0.87019\tvalidation_1-auc:0.83679\n",
      "[33]\tvalidation_0-auc:0.87079\tvalidation_1-auc:0.83661\n",
      "[34]\tvalidation_0-auc:0.87132\tvalidation_1-auc:0.83675\n",
      "[35]\tvalidation_0-auc:0.87159\tvalidation_1-auc:0.83656\n",
      "[36]\tvalidation_0-auc:0.87188\tvalidation_1-auc:0.83665\n",
      "[37]\tvalidation_0-auc:0.87213\tvalidation_1-auc:0.83644\n",
      "[38]\tvalidation_0-auc:0.87239\tvalidation_1-auc:0.83654\n",
      "[39]\tvalidation_0-auc:0.87295\tvalidation_1-auc:0.83658\n",
      "[40]\tvalidation_0-auc:0.87363\tvalidation_1-auc:0.83637\n",
      "[41]\tvalidation_0-auc:0.87402\tvalidation_1-auc:0.83641\n",
      "[42]\tvalidation_0-auc:0.87473\tvalidation_1-auc:0.83663\n",
      "[43]\tvalidation_0-auc:0.87482\tvalidation_1-auc:0.83643\n",
      "[44]\tvalidation_0-auc:0.87499\tvalidation_1-auc:0.83612\n",
      "[45]\tvalidation_0-auc:0.87548\tvalidation_1-auc:0.83635\n",
      "[46]\tvalidation_0-auc:0.87576\tvalidation_1-auc:0.83653\n",
      "[47]\tvalidation_0-auc:0.87598\tvalidation_1-auc:0.83681\n",
      "[48]\tvalidation_0-auc:0.87614\tvalidation_1-auc:0.83681\n",
      "[49]\tvalidation_0-auc:0.87624\tvalidation_1-auc:0.83664\n",
      "[50]\tvalidation_0-auc:0.87643\tvalidation_1-auc:0.83671\n",
      "[51]\tvalidation_0-auc:0.87680\tvalidation_1-auc:0.83668\n",
      "[52]\tvalidation_0-auc:0.87689\tvalidation_1-auc:0.83649\n",
      "[53]\tvalidation_0-auc:0.87712\tvalidation_1-auc:0.83655\n",
      "[54]\tvalidation_0-auc:0.87757\tvalidation_1-auc:0.83659\n",
      "[55]\tvalidation_0-auc:0.87792\tvalidation_1-auc:0.83674\n",
      "[56]\tvalidation_0-auc:0.87803\tvalidation_1-auc:0.83657\n",
      "[57]\tvalidation_0-auc:0.87846\tvalidation_1-auc:0.83646\n",
      "[58]\tvalidation_0-auc:0.87866\tvalidation_1-auc:0.83660\n",
      "[59]\tvalidation_0-auc:0.87930\tvalidation_1-auc:0.83647\n",
      "[60]\tvalidation_0-auc:0.87940\tvalidation_1-auc:0.83637\n",
      "[61]\tvalidation_0-auc:0.88017\tvalidation_1-auc:0.83644\n",
      "[62]\tvalidation_0-auc:0.88052\tvalidation_1-auc:0.83632\n",
      "[63]\tvalidation_0-auc:0.88097\tvalidation_1-auc:0.83594\n",
      "[64]\tvalidation_0-auc:0.88120\tvalidation_1-auc:0.83587\n",
      "[65]\tvalidation_0-auc:0.88159\tvalidation_1-auc:0.83576\n",
      "[66]\tvalidation_0-auc:0.88186\tvalidation_1-auc:0.83550\n",
      "[67]\tvalidation_0-auc:0.88201\tvalidation_1-auc:0.83546\n",
      "[68]\tvalidation_0-auc:0.88233\tvalidation_1-auc:0.83524\n",
      "[69]\tvalidation_0-auc:0.88262\tvalidation_1-auc:0.83522\n",
      "[70]\tvalidation_0-auc:0.88271\tvalidation_1-auc:0.83527\n",
      "[71]\tvalidation_0-auc:0.88300\tvalidation_1-auc:0.83521\n",
      "[72]\tvalidation_0-auc:0.88359\tvalidation_1-auc:0.83533\n",
      "[73]\tvalidation_0-auc:0.88373\tvalidation_1-auc:0.83534\n",
      "[74]\tvalidation_0-auc:0.88382\tvalidation_1-auc:0.83540\n",
      "[75]\tvalidation_0-auc:0.88405\tvalidation_1-auc:0.83541\n",
      "[76]\tvalidation_0-auc:0.88434\tvalidation_1-auc:0.83526\n",
      "[77]\tvalidation_0-auc:0.88441\tvalidation_1-auc:0.83521\n",
      "[78]\tvalidation_0-auc:0.88480\tvalidation_1-auc:0.83514\n",
      "[79]\tvalidation_0-auc:0.88495\tvalidation_1-auc:0.83499\n",
      "[80]\tvalidation_0-auc:0.88501\tvalidation_1-auc:0.83496\n",
      "[81]\tvalidation_0-auc:0.88516\tvalidation_1-auc:0.83490\n",
      "[82]\tvalidation_0-auc:0.88533\tvalidation_1-auc:0.83475\n",
      "[83]\tvalidation_0-auc:0.88567\tvalidation_1-auc:0.83464\n",
      "[84]\tvalidation_0-auc:0.88587\tvalidation_1-auc:0.83475\n",
      "[85]\tvalidation_0-auc:0.88629\tvalidation_1-auc:0.83463\n",
      "[86]\tvalidation_0-auc:0.88648\tvalidation_1-auc:0.83462\n",
      "[87]\tvalidation_0-auc:0.88654\tvalidation_1-auc:0.83467\n",
      "[88]\tvalidation_0-auc:0.88701\tvalidation_1-auc:0.83438\n",
      "[89]\tvalidation_0-auc:0.88742\tvalidation_1-auc:0.83443\n",
      "[90]\tvalidation_0-auc:0.88756\tvalidation_1-auc:0.83429\n",
      "[91]\tvalidation_0-auc:0.88784\tvalidation_1-auc:0.83421\n",
      "[92]\tvalidation_0-auc:0.88809\tvalidation_1-auc:0.83415\n",
      "[93]\tvalidation_0-auc:0.88840\tvalidation_1-auc:0.83413\n",
      "[94]\tvalidation_0-auc:0.88854\tvalidation_1-auc:0.83413\n",
      "[95]\tvalidation_0-auc:0.88872\tvalidation_1-auc:0.83421\n",
      "[96]\tvalidation_0-auc:0.88876\tvalidation_1-auc:0.83424\n",
      "[97]\tvalidation_0-auc:0.88881\tvalidation_1-auc:0.83429\n",
      "[98]\tvalidation_0-auc:0.88884\tvalidation_1-auc:0.83421\n",
      "[99]\tvalidation_0-auc:0.88892\tvalidation_1-auc:0.83436\n",
      "ROC AUC: 0.8393\n"
     ]
    }
   ],
   "source": [
    "# 최적 하이퍼파라미터 적용 모델 재 학습\n",
    "xgb_clf=XGBClassifier(n_estimators=100,\n",
    "                      early_stopping_rounds=100,\n",
    "                      eval_metric='auc',\n",
    "                      max_depth=int(best['max_depth']), \n",
    "                      min_child_weight=best['min_child_weight'], \n",
    "                      colsample_bytree=round(best['colsample_bytree'], 5), \n",
    "                      learning_rate=round(best['learning_rate'], 5))\n",
    "\n",
    "xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "model = 'xgboost_ft'\n",
    "\n",
    "print(f'ROC AUC: {xgb_roc_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45a8ff7e-0ec2-4a06-bbbc-867f28023e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': model, 'auc_score': f'{xgb_roc_score:.4f}'}\n",
    "scores_df.loc[len(scores_df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a764bc28-f0b0-4535-9090-c4f04433c910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_ft</td>\n",
       "      <td>0.8393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.8386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model auc_score\n",
       "0  xgboost_ft    0.8393\n",
       "1     xgboost    0.8386"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "da2571e1-eb8a-45f4-ad01-4e0b46e5b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18c723f8-589a-4fa0-b07a-16cd2d637fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "plot_importance(xgb_clf, ax=ax, max_num_features=20, height=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "20cbd597-29a5-4df2-b77b-9d644afde2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1691, number of negative: 40880\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13637\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 249\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039722 -> initscore=-3.185321\n",
      "[LightGBM] [Info] Start training from score -3.185321\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's auc: 0.906095\ttraining's binary_logloss: 0.11576\tvalid_1's auc: 0.830248\tvalid_1's binary_logloss: 0.134543\n",
      "ROC AUC: 0.8377\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=500, early_stopping_round=100)\n",
    "\n",
    "eval_set = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_metric='auc', eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\n",
    "print(f'ROC AUC: {lgbm_roc_score:.4f}')\n",
    "\n",
    "model = 'lgbm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc02dd1a-8f03-4652-995a-0085382dfbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': model, 'auc_score': f'{lgbm_roc_score:.4f}'}\n",
    "scores_df.loc[len(scores_df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2ec79574-0960-4a00-a2da-ed118eae8afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_ft</td>\n",
       "      <td>0.8393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.8386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.8377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgbm_ft</td>\n",
       "      <td>0.8401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbm_scaled</td>\n",
       "      <td>0.8391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgbm_scaled_ft</td>\n",
       "      <td>0.8387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model auc_score\n",
       "0      xgboost_ft    0.8393\n",
       "1         xgboost    0.8386\n",
       "2            lgbm    0.8377\n",
       "3         lgbm_ft    0.8401\n",
       "4     lgbm_scaled    0.8391\n",
       "5  lgbm_scaled_ft    0.8387"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e6036721-775b-4706-ba4e-0f4f79bcdbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_search_space = {'num_leaves': hp.quniform('num_leaves', 32, 64, 1), \n",
    "                     'max_depth': hp.quniform('max_depth', 100, 160, 1), \n",
    "                     'min_child_samples': hp.quniform('min_child_samples', 60, 100, 1),\n",
    "                     'subsample': hp.uniform('subsample', 0.7, 1), \n",
    "                     'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9f4da62b-087b-4f90-ad66-93c286bbbcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(search_space):\n",
    "    lgbm_clf = LGBMClassifier(n_estimators=100,\n",
    "                              early_stopping_rounds=30,\n",
    "                              num_leaves = int(search_space['num_leaves']),\n",
    "                              max_depth=int(search_space['max_depth']), \n",
    "                              min_child_samples=int(search_space['min_child_samples']), \n",
    "                              subsample=search_space['subsample'],\n",
    "                              learning_rate=search_space['learning_rate'])\n",
    "    # 3-fold\n",
    "    kf=KFold(n_splits=3)\n",
    "\n",
    "    # 3-fold cv 스코어를 담을 리스트 생성\n",
    "    roc_auc_list = []\n",
    "    \n",
    "    # X_train을 학습용, 검증용 으로 분리하기\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        eval_set = [(X_tr, y_tr), (X_val, y_val)]\n",
    "\n",
    "        lgbm_clf.fit(X_tr, y_tr, eval_metric='auc', eval_set=eval_set)\n",
    "\n",
    "        # 1로 예측한 확률값 추출 -> roc_auc 계산, 평균 계산을 위해 리스트에 담음.\n",
    "        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1])\n",
    "        roc_auc_list.append(score)\n",
    "\n",
    "    return -1*np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0dde59b9-375a-45d2-8fe1-2eff03ae1e3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006654 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13059                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[95]\ttraining's auc: 0.887218\ttraining's binary_logloss: 0.122791\tvalid_1's auc: 0.820975\tvalid_1's binary_logloss: 0.135528\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008153 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[57]\ttraining's auc: 0.870816\ttraining's binary_logloss: 0.129179\tvalid_1's auc: 0.840644\tvalid_1's binary_logloss: 0.138325\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006592 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13087                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.889241\ttraining's binary_logloss: 0.121904\tvalid_1's auc: 0.837247\tvalid_1's binary_logloss: 0.135266\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006265 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\ttraining's auc: 0.888641\ttraining's binary_logloss: 0.123657\tvalid_1's auc: 0.817381\tvalid_1's binary_logloss: 0.13724\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005966 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.880932\ttraining's binary_logloss: 0.125862\tvalid_1's auc: 0.837625\tvalid_1's binary_logloss: 0.139014\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006098 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13139                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 198                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[29]\ttraining's auc: 0.923185\ttraining's binary_logloss: 0.108987\tvalid_1's auc: 0.832112\tvalid_1's binary_logloss: 0.136247\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006334 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[39]\ttraining's auc: 0.901025\ttraining's binary_logloss: 0.118439\tvalid_1's auc: 0.82032\tvalid_1's binary_logloss: 0.13565\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006321 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's auc: 0.888111\ttraining's binary_logloss: 0.123498\tvalid_1's auc: 0.840162\tvalid_1's binary_logloss: 0.137379\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006134 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[60]\ttraining's auc: 0.919254\ttraining's binary_logloss: 0.111019\tvalid_1's auc: 0.837375\tvalid_1's binary_logloss: 0.135007\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006346 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.894105\ttraining's binary_logloss: 0.122462\tvalid_1's auc: 0.81842\tvalid_1's binary_logloss: 0.137055\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005837 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13129                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.892839\ttraining's binary_logloss: 0.122197\tvalid_1's auc: 0.834657\tvalid_1's binary_logloss: 0.139034\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006244 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13148                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\ttraining's auc: 0.931912\ttraining's binary_logloss: 0.105624\tvalid_1's auc: 0.837072\tvalid_1's binary_logloss: 0.135072\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006183 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's auc: 0.890635\ttraining's binary_logloss: 0.124168\tvalid_1's auc: 0.820787\tvalid_1's binary_logloss: 0.136129\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006833 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[28]\ttraining's auc: 0.8891\ttraining's binary_logloss: 0.123745\tvalid_1's auc: 0.840142\tvalid_1's binary_logloss: 0.137814\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005403 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[68]\ttraining's auc: 0.924801\ttraining's binary_logloss: 0.109185\tvalid_1's auc: 0.834344\tvalid_1's binary_logloss: 0.135541\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006027 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13059                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.878423\ttraining's binary_logloss: 0.128205\tvalid_1's auc: 0.820917\tvalid_1's binary_logloss: 0.136811\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006020 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[98]\ttraining's auc: 0.873983\ttraining's binary_logloss: 0.128562\tvalid_1's auc: 0.84087\tvalid_1's binary_logloss: 0.138455\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005486 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[82]\ttraining's auc: 0.871479\ttraining's binary_logloss: 0.131005\tvalid_1's auc: 0.834549\tvalid_1's binary_logloss: 0.139183\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006453 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\ttraining's auc: 0.902922\ttraining's binary_logloss: 0.116875\tvalid_1's auc: 0.819787\tvalid_1's binary_logloss: 0.135791\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006415 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\ttraining's auc: 0.876363\ttraining's binary_logloss: 0.126402\tvalid_1's auc: 0.838283\tvalid_1's binary_logloss: 0.137883\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005803 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\ttraining's auc: 0.903598\ttraining's binary_logloss: 0.115985\tvalid_1's auc: 0.836971\tvalid_1's binary_logloss: 0.135432\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006106 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13059                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's auc: 0.905313\ttraining's binary_logloss: 0.116476\tvalid_1's auc: 0.81594\tvalid_1's binary_logloss: 0.137027\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006676 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\ttraining's auc: 0.879285\ttraining's binary_logloss: 0.126958\tvalid_1's auc: 0.835128\tvalid_1's binary_logloss: 0.140681\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005834 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13139                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 198                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\ttraining's auc: 0.919182\ttraining's binary_logloss: 0.111008\tvalid_1's auc: 0.832139\tvalid_1's binary_logloss: 0.136469\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006067 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.897585\ttraining's binary_logloss: 0.118997\tvalid_1's auc: 0.820954\tvalid_1's binary_logloss: 0.135748\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006758 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.900628\ttraining's binary_logloss: 0.117597\tvalid_1's auc: 0.837166\tvalid_1's binary_logloss: 0.136091\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006162 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\ttraining's auc: 0.89118\ttraining's binary_logloss: 0.120425\tvalid_1's auc: 0.836445\tvalid_1's binary_logloss: 0.135827\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006184 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\ttraining's auc: 0.885986\ttraining's binary_logloss: 0.12619\tvalid_1's auc: 0.821408\tvalid_1's binary_logloss: 0.136819\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006259 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.889702\ttraining's binary_logloss: 0.12315\tvalid_1's auc: 0.840342\tvalid_1's binary_logloss: 0.137371\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006265 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[63]\ttraining's auc: 0.92778\ttraining's binary_logloss: 0.107619\tvalid_1's auc: 0.83811\tvalid_1's binary_logloss: 0.135005\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006369 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13162                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8]\ttraining's auc: 0.894294\ttraining's binary_logloss: 0.121506\tvalid_1's auc: 0.81753\tvalid_1's binary_logloss: 0.137818\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006440 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13133                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 201                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.896635\ttraining's binary_logloss: 0.119287\tvalid_1's auc: 0.832276\tvalid_1's binary_logloss: 0.139075\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006585 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13179                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 204                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's auc: 0.915834\ttraining's binary_logloss: 0.1115\tvalid_1's auc: 0.829739\tvalid_1's binary_logloss: 0.137648\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005332 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\ttraining's auc: 0.892781\ttraining's binary_logloss: 0.124712\tvalid_1's auc: 0.819689\tvalid_1's binary_logloss: 0.136746\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006474 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.893218\ttraining's binary_logloss: 0.122804\tvalid_1's auc: 0.839032\tvalid_1's binary_logloss: 0.138023\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006296 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's auc: 0.912556\ttraining's binary_logloss: 0.114868\tvalid_1's auc: 0.833768\tvalid_1's binary_logloss: 0.136086\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006292 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13109                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 198                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16]\ttraining's auc: 0.90488\ttraining's binary_logloss: 0.116167\tvalid_1's auc: 0.820013\tvalid_1's binary_logloss: 0.136713\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007597 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13129                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8]\ttraining's auc: 0.877763\ttraining's binary_logloss: 0.12536\tvalid_1's auc: 0.836601\tvalid_1's binary_logloss: 0.138593\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006617 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13175                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16]\ttraining's auc: 0.905224\ttraining's binary_logloss: 0.115507\tvalid_1's auc: 0.833487\tvalid_1's binary_logloss: 0.136489\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006433 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\ttraining's auc: 0.892664\ttraining's binary_logloss: 0.121992\tvalid_1's auc: 0.820322\tvalid_1's binary_logloss: 0.136138\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007609 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13129                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\ttraining's auc: 0.885156\ttraining's binary_logloss: 0.124915\tvalid_1's auc: 0.839273\tvalid_1's binary_logloss: 0.138251\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006435 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13148                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[89]\ttraining's auc: 0.927621\ttraining's binary_logloss: 0.107589\tvalid_1's auc: 0.83838\tvalid_1's binary_logloss: 0.13474\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006100 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13059                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's auc: 0.891557\ttraining's binary_logloss: 0.121159\tvalid_1's auc: 0.821747\tvalid_1's binary_logloss: 0.135595\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006219 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\ttraining's auc: 0.871199\ttraining's binary_logloss: 0.128126\tvalid_1's auc: 0.839194\tvalid_1's binary_logloss: 0.138111\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005472 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13139                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 198                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[29]\ttraining's auc: 0.903819\ttraining's binary_logloss: 0.116259\tvalid_1's auc: 0.837664\tvalid_1's binary_logloss: 0.135025\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006133 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[28]\ttraining's auc: 0.897326\ttraining's binary_logloss: 0.122473\tvalid_1's auc: 0.822267\tvalid_1's binary_logloss: 0.136184\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005842 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[32]\ttraining's auc: 0.900165\ttraining's binary_logloss: 0.120322\tvalid_1's auc: 0.83962\tvalid_1's binary_logloss: 0.137496\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006721 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[56]\ttraining's auc: 0.92318\ttraining's binary_logloss: 0.110256\tvalid_1's auc: 0.834058\tvalid_1's binary_logloss: 0.135857\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005929 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13059                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.894611\ttraining's binary_logloss: 0.120337\tvalid_1's auc: 0.821826\tvalid_1's binary_logloss: 0.135289\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005955 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[54]\ttraining's auc: 0.874228\ttraining's binary_logloss: 0.128521\tvalid_1's auc: 0.840743\tvalid_1's binary_logloss: 0.138559\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008098 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13087                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[98]\ttraining's auc: 0.893718\ttraining's binary_logloss: 0.120455\tvalid_1's auc: 0.83665\tvalid_1's binary_logloss: 0.135392\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005448 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13059                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.892587\ttraining's binary_logloss: 0.123202\tvalid_1's auc: 0.821127\tvalid_1's binary_logloss: 0.136619\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006195 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's auc: 0.884146\ttraining's binary_logloss: 0.125666\tvalid_1's auc: 0.838279\tvalid_1's binary_logloss: 0.139132\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006113 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[32]\ttraining's auc: 0.920178\ttraining's binary_logloss: 0.110747\tvalid_1's auc: 0.832511\tvalid_1's binary_logloss: 0.136077\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006536 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13059                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.88781\ttraining's binary_logloss: 0.123026\tvalid_1's auc: 0.815773\tvalid_1's binary_logloss: 0.137508\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006951 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.886936\ttraining's binary_logloss: 0.122858\tvalid_1's auc: 0.836706\tvalid_1's binary_logloss: 0.138147\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006188 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13139                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 198                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\ttraining's auc: 0.914369\ttraining's binary_logloss: 0.111782\tvalid_1's auc: 0.83266\tvalid_1's binary_logloss: 0.136616\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007389 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13059                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[58]\ttraining's auc: 0.880336\ttraining's binary_logloss: 0.127372\tvalid_1's auc: 0.819832\tvalid_1's binary_logloss: 0.136846\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005734 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[97]\ttraining's auc: 0.893349\ttraining's binary_logloss: 0.120798\tvalid_1's auc: 0.841497\tvalid_1's binary_logloss: 0.13585\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005781 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13087                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.895614\ttraining's binary_logloss: 0.119825\tvalid_1's auc: 0.83667\tvalid_1's binary_logloss: 0.135333\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006091 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.881417\ttraining's binary_logloss: 0.127591\tvalid_1's auc: 0.821403\tvalid_1's binary_logloss: 0.136906\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006341 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.883774\ttraining's binary_logloss: 0.124745\tvalid_1's auc: 0.838433\tvalid_1's binary_logloss: 0.137721\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006266 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[57]\ttraining's auc: 0.919978\ttraining's binary_logloss: 0.110443\tvalid_1's auc: 0.837923\tvalid_1's binary_logloss: 0.135154\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005960 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[29]\ttraining's auc: 0.895702\ttraining's binary_logloss: 0.120088\tvalid_1's auc: 0.820768\tvalid_1's binary_logloss: 0.135621\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006322 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\ttraining's auc: 0.882892\ttraining's binary_logloss: 0.124946\tvalid_1's auc: 0.840649\tvalid_1's binary_logloss: 0.137413\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006108 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\ttraining's auc: 0.908775\ttraining's binary_logloss: 0.114937\tvalid_1's auc: 0.836008\tvalid_1's binary_logloss: 0.135141\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006252 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[73]\ttraining's auc: 0.899581\ttraining's binary_logloss: 0.119077\tvalid_1's auc: 0.821216\tvalid_1's binary_logloss: 0.135435\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006069 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[72]\ttraining's auc: 0.897329\ttraining's binary_logloss: 0.119478\tvalid_1's auc: 0.840057\tvalid_1's binary_logloss: 0.136186\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007725 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.913502\ttraining's binary_logloss: 0.113689\tvalid_1's auc: 0.83824\tvalid_1's binary_logloss: 0.134859\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005831 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\ttraining's auc: 0.88419\ttraining's binary_logloss: 0.126317\tvalid_1's auc: 0.821937\tvalid_1's binary_logloss: 0.136453\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007101 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\ttraining's auc: 0.882944\ttraining's binary_logloss: 0.125313\tvalid_1's auc: 0.839967\tvalid_1's binary_logloss: 0.13766\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005380 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[84]\ttraining's auc: 0.909733\ttraining's binary_logloss: 0.114706\tvalid_1's auc: 0.836949\tvalid_1's binary_logloss: 0.134883\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006159 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\ttraining's auc: 0.892274\ttraining's binary_logloss: 0.123035\tvalid_1's auc: 0.821444\tvalid_1's binary_logloss: 0.136181\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007855 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.888113\ttraining's binary_logloss: 0.124049\tvalid_1's auc: 0.839317\tvalid_1's binary_logloss: 0.138031\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006009 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[43]\ttraining's auc: 0.923102\ttraining's binary_logloss: 0.109607\tvalid_1's auc: 0.834705\tvalid_1's binary_logloss: 0.135461\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006133 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[93]\ttraining's auc: 0.879044\ttraining's binary_logloss: 0.131838\tvalid_1's auc: 0.820067\tvalid_1's binary_logloss: 0.138877\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006159 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.875588\ttraining's binary_logloss: 0.130597\tvalid_1's auc: 0.837997\tvalid_1's binary_logloss: 0.140714\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007131 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[94]\ttraining's auc: 0.876042\ttraining's binary_logloss: 0.131768\tvalid_1's auc: 0.833068\tvalid_1's binary_logloss: 0.140265\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005327 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[49]\ttraining's auc: 0.890744\ttraining's binary_logloss: 0.122906\tvalid_1's auc: 0.821064\tvalid_1's binary_logloss: 0.135893\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006068 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's auc: 0.884032\ttraining's binary_logloss: 0.125172\tvalid_1's auc: 0.841186\tvalid_1's binary_logloss: 0.137447\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006795 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[97]\ttraining's auc: 0.916886\ttraining's binary_logloss: 0.112228\tvalid_1's auc: 0.838591\tvalid_1's binary_logloss: 0.134791\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005360 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\ttraining's auc: 0.890919\ttraining's binary_logloss: 0.124132\tvalid_1's auc: 0.82007\tvalid_1's binary_logloss: 0.136593\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006261 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\ttraining's auc: 0.895241\ttraining's binary_logloss: 0.121318\tvalid_1's auc: 0.837597\tvalid_1's binary_logloss: 0.137576\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006314 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33]\ttraining's auc: 0.908559\ttraining's binary_logloss: 0.116144\tvalid_1's auc: 0.834573\tvalid_1's binary_logloss: 0.135805\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005978 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\ttraining's auc: 0.886273\ttraining's binary_logloss: 0.125774\tvalid_1's auc: 0.822175\tvalid_1's binary_logloss: 0.136315\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007565 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\ttraining's auc: 0.882814\ttraining's binary_logloss: 0.125814\tvalid_1's auc: 0.839586\tvalid_1's binary_logloss: 0.138098\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006072 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[93]\ttraining's auc: 0.91786\ttraining's binary_logloss: 0.112193\tvalid_1's auc: 0.836327\tvalid_1's binary_logloss: 0.135088\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007729 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.893677\ttraining's binary_logloss: 0.120981\tvalid_1's auc: 0.820523\tvalid_1's binary_logloss: 0.135848\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006104 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's auc: 0.894934\ttraining's binary_logloss: 0.119971\tvalid_1's auc: 0.839487\tvalid_1's binary_logloss: 0.13636\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007240 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33]\ttraining's auc: 0.904549\ttraining's binary_logloss: 0.116697\tvalid_1's auc: 0.836703\tvalid_1's binary_logloss: 0.135107\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006099 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.885781\ttraining's binary_logloss: 0.123583\tvalid_1's auc: 0.82265\tvalid_1's binary_logloss: 0.135531\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006321 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.87657\ttraining's binary_logloss: 0.126057\tvalid_1's auc: 0.839517\tvalid_1's binary_logloss: 0.137249\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006062 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[36]\ttraining's auc: 0.902919\ttraining's binary_logloss: 0.116707\tvalid_1's auc: 0.836971\tvalid_1's binary_logloss: 0.135067\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006234 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.890477\ttraining's binary_logloss: 0.123116\tvalid_1's auc: 0.821016\tvalid_1's binary_logloss: 0.136087\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007909 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's auc: 0.877673\ttraining's binary_logloss: 0.128535\tvalid_1's auc: 0.838761\tvalid_1's binary_logloss: 0.139769\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006112 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[47]\ttraining's auc: 0.914967\ttraining's binary_logloss: 0.113113\tvalid_1's auc: 0.835474\tvalid_1's binary_logloss: 0.135458\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005309 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's auc: 0.886998\ttraining's binary_logloss: 0.125795\tvalid_1's auc: 0.819982\tvalid_1's binary_logloss: 0.137093\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006364 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.887235\ttraining's binary_logloss: 0.123663\tvalid_1's auc: 0.837839\tvalid_1's binary_logloss: 0.138134\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006921 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\ttraining's auc: 0.916322\ttraining's binary_logloss: 0.112173\tvalid_1's auc: 0.833378\tvalid_1's binary_logloss: 0.135798\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007362 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's auc: 0.890345\ttraining's binary_logloss: 0.124364\tvalid_1's auc: 0.8199\tvalid_1's binary_logloss: 0.136608\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007620 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.898303\ttraining's binary_logloss: 0.119579\tvalid_1's auc: 0.837413\tvalid_1's binary_logloss: 0.137389\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007993 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.894611\ttraining's binary_logloss: 0.122381\tvalid_1's auc: 0.834524\tvalid_1's binary_logloss: 0.136702\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007319 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13059                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[89]\ttraining's auc: 0.877152\ttraining's binary_logloss: 0.132202\tvalid_1's auc: 0.819536\tvalid_1's binary_logloss: 0.13897\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006347 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.875673\ttraining's binary_logloss: 0.130362\tvalid_1's auc: 0.838846\tvalid_1's binary_logloss: 0.140486\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007188 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[77]\ttraining's auc: 0.870911\ttraining's binary_logloss: 0.134265\tvalid_1's auc: 0.832541\tvalid_1's binary_logloss: 0.141874\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006293 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[77]\ttraining's auc: 0.903269\ttraining's binary_logloss: 0.117395\tvalid_1's auc: 0.82271\tvalid_1's binary_logloss: 0.135072\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006492 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[53]\ttraining's auc: 0.886296\ttraining's binary_logloss: 0.122446\tvalid_1's auc: 0.841411\tvalid_1's binary_logloss: 0.135476\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007919 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[83]\ttraining's auc: 0.905918\ttraining's binary_logloss: 0.115896\tvalid_1's auc: 0.839972\tvalid_1's binary_logloss: 0.134365\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006065 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[50]\ttraining's auc: 0.885436\ttraining's binary_logloss: 0.123246\tvalid_1's auc: 0.822944\tvalid_1's binary_logloss: 0.135173\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005833 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[60]\ttraining's auc: 0.889723\ttraining's binary_logloss: 0.121255\tvalid_1's auc: 0.841813\tvalid_1's binary_logloss: 0.135384\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006178 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[80]\ttraining's auc: 0.902451\ttraining's binary_logloss: 0.116894\tvalid_1's auc: 0.839035\tvalid_1's binary_logloss: 0.134552\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006172 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[65]\ttraining's auc: 0.898624\ttraining's binary_logloss: 0.119097\tvalid_1's auc: 0.822229\tvalid_1's binary_logloss: 0.135166\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007829 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[73]\ttraining's auc: 0.898677\ttraining's binary_logloss: 0.118011\tvalid_1's auc: 0.840874\tvalid_1's binary_logloss: 0.135119\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006093 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[74]\ttraining's auc: 0.901706\ttraining's binary_logloss: 0.117173\tvalid_1's auc: 0.838899\tvalid_1's binary_logloss: 0.134516\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006015 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.895584\ttraining's binary_logloss: 0.119388\tvalid_1's auc: 0.820054\tvalid_1's binary_logloss: 0.13585\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005481 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.880797\ttraining's binary_logloss: 0.123834\tvalid_1's auc: 0.839348\tvalid_1's binary_logloss: 0.136373\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006476 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[30]\ttraining's auc: 0.901142\ttraining's binary_logloss: 0.11701\tvalid_1's auc: 0.838804\tvalid_1's binary_logloss: 0.134633\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005415 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[88]\ttraining's auc: 0.880132\ttraining's binary_logloss: 0.126783\tvalid_1's auc: 0.822226\tvalid_1's binary_logloss: 0.136098\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006257 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[97]\ttraining's auc: 0.879028\ttraining's binary_logloss: 0.125732\tvalid_1's auc: 0.840643\tvalid_1's binary_logloss: 0.136894\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006071 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.882189\ttraining's binary_logloss: 0.125161\tvalid_1's auc: 0.835919\tvalid_1's binary_logloss: 0.136198\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006309 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.880177\ttraining's binary_logloss: 0.126421\tvalid_1's auc: 0.821339\tvalid_1's binary_logloss: 0.13617\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006251 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's auc: 0.890323\ttraining's binary_logloss: 0.120955\tvalid_1's auc: 0.840442\tvalid_1's binary_logloss: 0.135776\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006233 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[57]\ttraining's auc: 0.903638\ttraining's binary_logloss: 0.116327\tvalid_1's auc: 0.839109\tvalid_1's binary_logloss: 0.134495\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005585 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.885764\ttraining's binary_logloss: 0.123293\tvalid_1's auc: 0.82057\tvalid_1's binary_logloss: 0.136189\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006304 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's auc: 0.890434\ttraining's binary_logloss: 0.121416\tvalid_1's auc: 0.838337\tvalid_1's binary_logloss: 0.136714\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006415 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.905282\ttraining's binary_logloss: 0.115116\tvalid_1's auc: 0.836431\tvalid_1's binary_logloss: 0.135184\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006451 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[99]\ttraining's auc: 0.8975\ttraining's binary_logloss: 0.119476\tvalid_1's auc: 0.822457\tvalid_1's binary_logloss: 0.135094\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006116 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\ttraining's auc: 0.867452\ttraining's binary_logloss: 0.13036\tvalid_1's auc: 0.839847\tvalid_1's binary_logloss: 0.13888\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006492 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.89713\ttraining's binary_logloss: 0.118966\tvalid_1's auc: 0.838747\tvalid_1's binary_logloss: 0.134727\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006148 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.878754\ttraining's binary_logloss: 0.126675\tvalid_1's auc: 0.819261\tvalid_1's binary_logloss: 0.136989\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007516 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\ttraining's auc: 0.883458\ttraining's binary_logloss: 0.123344\tvalid_1's auc: 0.836676\tvalid_1's binary_logloss: 0.137422\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006422 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's auc: 0.90828\ttraining's binary_logloss: 0.11514\tvalid_1's auc: 0.833535\tvalid_1's binary_logloss: 0.13612\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006357 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13193                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 206                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[75]\ttraining's auc: 0.90932\ttraining's binary_logloss: 0.115234\tvalid_1's auc: 0.821203\tvalid_1's binary_logloss: 0.135373\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006692 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13133                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 201                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[30]\ttraining's auc: 0.874982\ttraining's binary_logloss: 0.127888\tvalid_1's auc: 0.839375\tvalid_1's binary_logloss: 0.138401\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006453 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13223                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 206                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[93]\ttraining's auc: 0.917717\ttraining's binary_logloss: 0.111361\tvalid_1's auc: 0.838117\tvalid_1's binary_logloss: 0.13459\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005853 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33]\ttraining's auc: 0.887034\ttraining's binary_logloss: 0.12271\tvalid_1's auc: 0.82125\tvalid_1's binary_logloss: 0.135485\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006684 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[34]\ttraining's auc: 0.884636\ttraining's binary_logloss: 0.122891\tvalid_1's auc: 0.840021\tvalid_1's binary_logloss: 0.135901\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006166 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[54]\ttraining's auc: 0.904289\ttraining's binary_logloss: 0.116083\tvalid_1's auc: 0.839441\tvalid_1's binary_logloss: 0.134453\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006102 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.896471\ttraining's binary_logloss: 0.119075\tvalid_1's auc: 0.819796\tvalid_1's binary_logloss: 0.135816\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006107 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.876041\ttraining's binary_logloss: 0.12596\tvalid_1's auc: 0.838193\tvalid_1's binary_logloss: 0.137388\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006190 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's auc: 0.898217\ttraining's binary_logloss: 0.118205\tvalid_1's auc: 0.837929\tvalid_1's binary_logloss: 0.134876\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006326 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[82]\ttraining's auc: 0.896502\ttraining's binary_logloss: 0.122973\tvalid_1's auc: 0.821076\tvalid_1's binary_logloss: 0.136272\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006051 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[91]\ttraining's auc: 0.897758\ttraining's binary_logloss: 0.12134\tvalid_1's auc: 0.840082\tvalid_1's binary_logloss: 0.137585\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006072 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[48]\ttraining's auc: 0.880891\ttraining's binary_logloss: 0.13144\tvalid_1's auc: 0.83399\tvalid_1's binary_logloss: 0.140979\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006098 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[50]\ttraining's auc: 0.903398\ttraining's binary_logloss: 0.117274\tvalid_1's auc: 0.821878\tvalid_1's binary_logloss: 0.135166\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007451 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13081                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 198                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's auc: 0.894281\ttraining's binary_logloss: 0.120114\tvalid_1's auc: 0.838661\tvalid_1's binary_logloss: 0.136352\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006754 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13148                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[88]\ttraining's auc: 0.926072\ttraining's binary_logloss: 0.107747\tvalid_1's auc: 0.838643\tvalid_1's binary_logloss: 0.134564\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006379 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13049                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.888935\ttraining's binary_logloss: 0.126621\tvalid_1's auc: 0.816997\tvalid_1's binary_logloss: 0.137608\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006237 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13063                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\ttraining's auc: 0.908204\ttraining's binary_logloss: 0.115542\tvalid_1's auc: 0.836458\tvalid_1's binary_logloss: 0.136769\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006375 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13079                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.917102\ttraining's binary_logloss: 0.112404\tvalid_1's auc: 0.832974\tvalid_1's binary_logloss: 0.136104\n",
      "100%|███████████████████████████████████████████████| 50/50 [01:17<00:00,  1.55s/trial, best loss: -0.8346977098163455]\n",
      "best: {'learning_rate': np.float64(0.048074925843529494), 'max_depth': np.float64(101.0), 'min_child_samples': np.float64(94.0), 'num_leaves': np.float64(32.0), 'subsample': np.float64(0.7694719136506488)}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn=objective_func, \n",
    "            space=lgbm_search_space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=50, \n",
    "            trials=trials, \n",
    "            rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print(f'best: {best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "72cc2228-0819-46a9-86b9-3a5c5d3c7e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.0\n",
      "101.0\n",
      "94.0\n",
      "0.7694719136506488\n",
      "0.048074925843529494\n"
     ]
    }
   ],
   "source": [
    "print(best['num_leaves'], \n",
    "      best['max_depth'], \n",
    "      best['min_child_samples'], \n",
    "      best['subsample'], \n",
    "      best['learning_rate'], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e718fd10-1d54-4ef0-ac48-17fa56f4239f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] Number of positive: 1691, number of negative: 40880\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13209\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 193\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039722 -> initscore=-3.185321\n",
      "[LightGBM] [Info] Start training from score -3.185321\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[49]\ttraining's auc: 0.88482\ttraining's binary_logloss: 0.124339\tvalid_1's auc: 0.835459\tvalid_1's binary_logloss: 0.133885\n",
      "ROC AUC: 0.8414\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=100,\n",
    "                          early_stopping_rounds=100,\n",
    "                          num_leaves = int(best['num_leaves']),\n",
    "                          max_depth=int(best['max_depth']), \n",
    "                          min_child_samples=int(best['min_child_samples']), \n",
    "                          subsample=round(best['subsample'], 5),\n",
    "                          learning_rate=round(best['learning_rate'], 5))\n",
    "\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_metric='auc', eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\n",
    "print(f'ROC AUC: {lgbm_roc_score:.4f}')\n",
    "\n",
    "model = 'lgbm_ft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a3a73e49-df68-4dc9-9482-ad0fdf8413b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': model, 'auc_score': f'{lgbm_roc_score:.4f}'}\n",
    "scores_df.loc[len(scores_df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "868eb328-9c8a-4745-869d-6f5b15b47a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_ft</td>\n",
       "      <td>0.8393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.8386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.8377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgbm_ft</td>\n",
       "      <td>0.8414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbm_scaled</td>\n",
       "      <td>0.8391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgbm_scaled_ft</td>\n",
       "      <td>0.8387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model auc_score\n",
       "0      xgboost_ft    0.8393\n",
       "1         xgboost    0.8386\n",
       "2            lgbm    0.8377\n",
       "3         lgbm_ft    0.8414\n",
       "4     lgbm_scaled    0.8391\n",
       "5  lgbm_scaled_ft    0.8387"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fb1b9e95-6869-4ea0-be05-33398482d168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "3   8     2     37                 0.0                    195.0   \n",
       "4  10     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "3                      0.0                      0.0  ...   \n",
       "4                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "3                      0.0                      0.0                     0.0   \n",
       "4                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3          var38  TARGET  \n",
       "0                     0.0                     0.0   39205.170000       0  \n",
       "1                     0.0                     0.0   49278.030000       0  \n",
       "2                     0.0                     0.0   67333.770000       0  \n",
       "3                     0.0                     0.0   64007.970000       0  \n",
       "4                     0.0                     0.0  117310.979016       0  \n",
       "\n",
       "[5 rows x 371 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cefb05b1-b66e-4bf6-b82e-e142ea2a286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "dd163d26-6abe-4af2-915e-4edc6e7e231e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_components',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_components&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('whiten',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">whiten&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('svd_solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">svd_solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('iterated_power',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">iterated_power&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_oversamples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_oversamples&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('power_iteration_normalizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">power_iteration_normalizer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "cumulative_variance_ratio\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6c23809e-11a3-404a-8d5a-b32ded3a7862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Principal Component</th>\n",
       "      <th>Explained Variance Ratio</th>\n",
       "      <th>Cumulative Explained Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC1</td>\n",
       "      <td>0.619070</td>\n",
       "      <td>0.619070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC2</td>\n",
       "      <td>0.152909</td>\n",
       "      <td>0.771979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PC3</td>\n",
       "      <td>0.072563</td>\n",
       "      <td>0.844542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PC4</td>\n",
       "      <td>0.063316</td>\n",
       "      <td>0.907858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PC5</td>\n",
       "      <td>0.035373</td>\n",
       "      <td>0.943231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>PC366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>PC367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>PC368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>PC369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>PC370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Principal Component  Explained Variance Ratio  \\\n",
       "0                   PC1                  0.619070   \n",
       "1                   PC2                  0.152909   \n",
       "2                   PC3                  0.072563   \n",
       "3                   PC4                  0.063316   \n",
       "4                   PC5                  0.035373   \n",
       "..                  ...                       ...   \n",
       "365               PC366                  0.000000   \n",
       "366               PC367                  0.000000   \n",
       "367               PC368                  0.000000   \n",
       "368               PC369                  0.000000   \n",
       "369               PC370                  0.000000   \n",
       "\n",
       "     Cumulative Explained Variance  \n",
       "0                         0.619070  \n",
       "1                         0.771979  \n",
       "2                         0.844542  \n",
       "3                         0.907858  \n",
       "4                         0.943231  \n",
       "..                             ...  \n",
       "365                       1.000000  \n",
       "366                       1.000000  \n",
       "367                       1.000000  \n",
       "368                       1.000000  \n",
       "369                       1.000000  \n",
       "\n",
       "[370 rows x 3 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 주성분의 분산 기여율\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# 누적 분산 기여율 계산\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "pca_df = pd.DataFrame({\n",
    "    'Principal Component': [f'PC{i+1}' for i in range(len(explained_variance_ratio))],\n",
    "    'Explained Variance Ratio': explained_variance_ratio,\n",
    "    'Cumulative Explained Variance': cumulative_variance_ratio\n",
    "})\n",
    "\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "122c1d63-a239-4e33-ad31-4f5318e904be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0MAAAH5CAYAAABDDuXVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAR/1JREFUeJzt3Xt4VOW99//PJEwmHJIgpyRIDBFRwCCFIJAg2moJYEVtNzWtWzwUqkiLAv25tymyMWpL6fMrBw9k1y3seKiFpx5q3U9E4tPKQUAKAgp4gIKGwsSUUxKISSaT9fwBMyVkEjIxa+4F835dVy6YNWtWvuvLars+ve+5l8uyLEsAAAAAEGViTBcAAAAAACYQhgAAAABEJcIQAAAAgKhEGAIAAAAQlQhDAAAAAKISYQgAAABAVCIMAQAAAIhKHUwX0F4aGhp06NAhJSQkyOVymS4HAAAAgCGWZamqqkq9e/dWTEzz4z8XTBg6dOiQ0tLSTJcBAAAAwCEOHDigPn36NPv+BROGEhISJJ064cTERCM1+Hw+rV69Wrm5uXK73UZqiGb03xx6bw69N4v+m0PvzaL/5tD71qmsrFRaWlowIzTngglDgalxiYmJRsNQp06dlJiYyMVpAP03h96bQ+/Nov/m0Huz6L859D485/r6DAsoAAAAAIhKhCEAAAAAUYkwBAAAACAqEYYAAAAARCXCEAAAAICoRBgCAAAAEJUIQwAAAACiEmEIAAAAQFQiDAEAAACISoQhAAAAAFGJMAQAAAAgKhGGAAAAAEQlwhAAAACAqNTBdAEIn7/B0ub9R1VW8ZWOnqxT105xOnqyVse/8smypIs6xalb5zgdrz713tf9045j23HMf1RVa+sXLn1c8pm6d+no2DovxGMeOfGVvih36csNn6t7l46OrfNCPOaREzX62xcx8q7/XD0Tm++96Tov1GOe69p3Sp0X4jETPbE60Ir/3jFd54V6zOaufafVeSEes7X/m2uiTpdcyu7XXaMu7a7YGJfpW+ZWcVmWZYXzgbVr1+p//a//pa1bt8rr9er111/Xrbfe2uJn1qxZo9mzZ2vXrl3q3bu3/u3f/k3Tpk1rtM+rr76quXPn6m9/+5v69eunX/ziF/rud7/b6roqKyuVlJSkiooKJSYmhnNK7cbn86m4uFg33nij3G63Lb9j1U6vCt7cLW9FjS3HBwAAAL6Orp3c+tX3Bmt8ZqqxGlqbDcKeJnfy5EkNGTJETz/9dKv2379/v2688UaNGTNG27Zt089//nM98MADevXVV4P7bNy4UXl5eZo8ebJ27NihyZMn67bbbtP7778fbnkXtOIPvZr20gcEIQAAADjW8Wqfpr30gVbt9Jou5ZzCHhlq9GGX65wjQ//+7/+uP/3pT/r444+D26ZNm6YdO3Zo48aNkqS8vDxVVlbqrbfeCu4zfvx4XXTRRfr973/fqlou9JGh4g8P6ae/36aGNv9rAQAAAJGTmhSv9f9+vZEpc63NBrZ/Z2jjxo3Kzc1ttG3cuHFatmyZfD6f3G63Nm7cqFmzZjXZZ/Hixc0et7a2VrW1tcHXlZWVkk4FEp/P134nEIbA723v3//WzjI9sPLDdj0mAAAAYCdvRY027i3XyIxuEf/drb0ftz0MlZWVKTk5udG25ORk1dfX6/Dhw0pNTW12n7KysmaPO3/+fBUUFDTZvnr1anXq1Kl9im+jkpKSdjlOgyW9fcCltw/GSDo/voQGAAAABKxe976OfBz5qU3V1dWt2i8iq8m5XI1v5AMz887cHmqfs7edKT8/X7Nnzw6+rqysVFpamnJzc41OkyspKdHYsWO/9jS5t3d9qXlv7NLxr+rbqToAAAAgsnLHjDQyMhSYNXYutoehlJSUJiM85eXl6tChg7p3797iPmePFp3J4/HI4/E02e52u21bya21vm4NxR969dMVO9qxIgAAACCyUpPilX1ZLyPfGWrtvbjtD13Nzs5uMm1s9erVGj58eLDI5vbJycmxuzzHObVQwgemywAAAAC+lnkTBzn+eUNhjwydOHFCe/fuDb7ev3+/tm/frm7duumSSy5Rfn6+Dh48qBdeeEHSqZXjnn76ac2ePVs//vGPtXHjRi1btqzRKnEPPvigrr32Wi1YsEC33HKL3njjDb3zzjtav359O5zi+aP4Q6+mv7zNdBkAAABAm13Uya35hp8z1Fphh6EtW7boW9/6VvB14Hs7d911l4qKiuT1elVaWhp8PyMjQ8XFxZo1a5aeeeYZ9e7dW08++aT+5V/+JbhPTk6OVqxYoUceeURz585Vv379tHLlSo0cOfLrnNt5JbB0dlvclX2J+lzUqd2fJny+PaX5H1XV2vrhJ+p3WT9179LRsXVeiMc8cuIrffHZx0q/fGCLT8M2XeeFeMwjJ2r0t737lDV4gHomhv8k8vP53J1wzHNd+06p80I8ZqInVgf2nvu/d0zXeaEes7lr32l1XojHbO3/5pqo0yWXsvt116hLuzt+RCgg7DD0zW9+Uy09mqioqKjJtuuuu04ffNDy1K9JkyZp0qRJ4ZZzQVi1s20jQjEu6ekfDtONVzk/dUeCz+dTasXHunHs5ca/NxZtfD6fio/v1o05fel9hPl8PhX79urGa+i9CVz75vh8PhVX0ntTuPbNoffty/bvDKFl/gZLBW/ubtNnn/7hUIIQAAAA0EYRWVobzdu8/6i8FTVhfeZ8mocJAAAAOBVhyLDyqtYHIZekB2/orxk39D9v5mECAAAATkUYMqxXQnyr933m9qG68areNlYDAAAARA++M2TYsZO1OtcgT4xLWnr7MIIQAAAA0I4YGTJo1U6vfvLyNjW/Nt8pLJQAAAAAtD9GhgwJrCLXUhBiRAgAAACwD2HIkNasItdgSRd1jotQRQAAAEB0IQwZ0tpV5MJZbQ4AAABA6xGGDGntKnLhrDYHAAAAoPUIQ4acaxU5l6TUpHiNyOgWsZoAAACAaMJqcga0dhW5eRMH8XBVAAAAwCaMDEVYa1eRe+b2YRqfyXLaAAAAgF0IQxHGKnIAAACAMxCGIoxV5AAAAABnIAxFGKvIAQAAAM5AGIqwERndlJoUr+aWRWAVOQAAACAyCEMRFhvj0ryJgySpSSAKvGYVOQAAAMB+hCEDxmemqvCOYUpJajwVLiUpXoV3sIocAAAAEAk8Z8gAf4OlpI5xuqxnZ/VKiFPulakadslFGpHRjREhAAAAIEIIQxG2aqdXBW/ubrS89t+P1ajfdzsThAAAAIAIYppcBK3a6dX9L33Q5DlDR0/W6f6XPtCqnV5DlQEAAADRhzAUIf4GSwVv7pYV4r3AtoI3d8vfEGoPAAAAAO2NMBQhm/cfbTIidCZLkreiRpv3H41cUQAAAEAUIwxFSHlV80GoLfsBAAAA+HoIQxHSKyH+3DuFsR8AAACAr4cwFCEjMropNSm+yYNWA1ySUpPiNSKjWyTLAgAAAKIWYShCYmNcmjdxkCQ1CUSB1/MmDmJ5bQAAACBCCEMRND4zVYV3DFNKUuOpcClJ8Sq8Y5jGZ6YaqgwAAACIPjx0NcLGZ6Zq7KAUbd5/VOVVNeqVcGpqHCNCAAAAQGQxMmRAbIxLz63bp7c+KlP/5C4EIQAAAMAAwpAB/gZL//eTcq3aVdbsggoAAAAA7EUYMuBETX3w7wnxboOVAAAAANGLMGRAZY1PkuTpEKO4DvwTAAAAACZwJ25AIAwldmRUCAAAADCFMGRA1elpcgnxLOYHAAAAmEIYMuCfYYiRIQAAAMAUwpABX/n8inFJiYwMAQAAAMZwN27AzUN6a+JVqaqtbzBdCgAAABC1GBkyxOVyKd4da7oMAAAAIGoRhgAAAABEJcKQAcvW79f9L23V//34S9OlAAAAAFGLMGTAB18c01s7y3TgaLXpUgAAAICoRRgyIPDQVZbWBgAAAMwhDBnAQ1cBAAAA89oUhpYuXaqMjAzFx8crKytL69ata3H/Z555RgMHDlTHjh11xRVX6IUXXmj0flFRkVwuV5OfmpqatpTneFWnR4YSOzIyBAAAAJgS9tDEypUrNXPmTC1dulSjR4/Wb3/7W02YMEG7d+/WJZdc0mT/wsJC5efn67/+67909dVXa/Pmzfrxj3+siy66SBMnTgzul5iYqE8//bTRZ+Pj49twSs7HyBAAAABgXth34wsXLtSUKVM0depUSdLixYv19ttvq7CwUPPnz2+y/4svvqj77rtPeXl5kqRLL71UmzZt0oIFCxqFIZfLpZSUlFbXUVtbq9ra2uDryspKSZLP55PP5wv3tNpF4Pee6/cHvjPUscO590Xrtbb/aH/03hx6bxb9N4fem0X/zaH3rdPa/oQVhurq6rR161Y9/PDDjbbn5uZqw4YNIT9TW1vbZISnY8eO2rx5s3w+n9zuU1PFTpw4ofT0dPn9fn3jG9/Q448/rqFDhzZby/z581VQUNBk++rVq9WpU6dwTqvdlZSUNPuev0Gq9cVKcmnT2nf1ETPl2l1L/Ye96L059N4s+m8OvTeL/ptD71tWXd26VZvDCkOHDx+W3+9XcnJyo+3JyckqKysL+Zlx48bpueee06233qphw4Zp69atWr58uXw+nw4fPqzU1FQNGDBARUVFGjx4sCorK7VkyRKNHj1aO3bsUP/+/UMeNz8/X7Nnzw6+rqysVFpamnJzc5WYmBjOabUbn8+nkpISjR07NhjyQrnpO5ZO1vnVOS5WLpcrghVe2Frbf7Q/em8OvTeL/ptD782i/+bQ+9YJzBo7lzZ9aeXsG3jLspq9qZ87d67Kyso0atQoWZal5ORk3X333fr1r3+t2NhYSdKoUaM0atSo4GdGjx6tYcOG6amnntKTTz4Z8rgej0cej6fJdrfbbfzCaE0NcXERKiYKOeEaiFb03hx6bxb9N4fem0X/zaH3LWttb8JaTa5Hjx6KjY1tMgpUXl7eZLQooGPHjlq+fLmqq6v1+eefq7S0VH379lVCQoJ69OgRuqiYGF199dXas2dPOOWdF/wNljb+7Yje2H5QG/92RP4Gy3RJAAAAQFQKa2QoLi5OWVlZKikp0Xe/+93g9pKSEt1yyy0tftbtdqtPnz6SpBUrVuimm25STEzoLGZZlrZv367BgweHU57jrdrp1SN/3KnDJ+qC21KT4jVv4iCNz0w1WBkAAAAQfcKeJjd79mxNnjxZw4cPV3Z2tp599lmVlpZq2rRpkk59l+fgwYPBZwl99tln2rx5s0aOHKljx45p4cKF2rlzp55//vngMQsKCjRq1Cj1799flZWVevLJJ7V9+3Y988wz7XSa5q3a6dX9L32gs8eByipqdP9LH6jwjmEEIgAAACCCwg5DeXl5OnLkiB577DF5vV5lZmaquLhY6enpkiSv16vS0tLg/n6/X7/5zW/06aefyu1261vf+pY2bNigvn37Bvc5fvy47r33XpWVlSkpKUlDhw7V2rVrNWLEiK9/hg7gb7BU8ObuJkFIkixJLkkFb+7W2EEpio1hQQUAAAAgEtq0gML06dM1ffr0kO8VFRU1ej1w4EBt27atxeMtWrRIixYtaksp54XN+4/KW1HT7PuWJG9FjTbvP6rsft0jVxgAAAAQxcJaQAFtU17VfBBqy34AAAAAvj7CUAT0Sog/905h7AcAAADg6yMMRcCIjG5KTYpXc98GcunUqnIjMrpFsiwAAAAgqhGGIiA2xqV5EweFfC8QkOZNHMTiCQAAAEAEEYYiZHxmqgrvGKaUxMZT4VKS4llWGwAAADCgTavJoW3GZ6Zq7KAUbd5/VOVVNeqVcGpqHCNCAAAAQOQRhiIsNsbF8tkAAACAAxCGIuyJ/9mtyhqf7v/mZcro0dl0OQAAAEDU4jtDEVb8kVf/e8vfVfmVz3QpAAAAQFQjDEXYyTq/JKmzJ9ZwJQAAAEB0IwxFkGVZOllbL0nq7GGGIgAAAGASYSiC6vwNqm+wJBGGAAAAANMIQxF0stYf/HsnN9PkAAAAAJMIQxEUmCIX745Rh1haDwAAAJjEHXkEnaw7/X2hOKbIAQAAAKZxVx5Bl/dK0EeP5uorn//cOwMAAACwFWEogmJiXEqIdysh3m26FAAAACDqMU0OAAAAQFQiDEXQ+/uO6N9f+VAvv19quhQAAAAg6hGGIujTL6u0cssBrd/7D9OlAAAAAFGPMBRBJ2pZTQ4AAABwCsJQBFWffuhqZw9hCAAAADCNMBRBwZEhT6zhSgAAAAAQhiLo5Okw1IlpcgAAAIBxhKEIqq47NU2uC9PkAAAAAOMIQxF0IjgyxDQ5AAAAwDSGKCLomX8dpqoanxLi3aZLAQAAAKIeYSiCung6MEUOAAAAcAimyQEAAACISgxTRNAT/7NbknTfdf3UM8FjuBoAAAAguhGGIuil979Qja9Bd+X0NV0KAAAAEPWYJhch/gZLNb4GSawmBwAAADgBYShCTtbVB//emUUUAAAAAOMIQxFSXXvqgauxMS55OtB2AAAAwDTuyiOk4iufJCku1qVN+47K32AZrggAAACIboShCFi106vbn9skSfrK16Af/tcmXbPgz1q102u4MgAAACB6EYZstmqnV/e/9IGOnKhrtL2sokb3v/QBgQgAAAAwhDBkI3+DpYI3dyvUhLjAtoI3dzNlDgAAADCAMGSjzfuPyltR0+z7liRvRY027z8auaIAAAAASCIM2aq8qvkg1Jb9AAAAALQfwpCNeiXEt+t+AAAAANoPYchGIzK6KTUpXq5m3ndJSk2K14iMbpEsCwAAAIAIQ7aKjXFp3sRBId8LBKR5EwcpNqa5uAQAAADALoQhm43PTFXhHcPUxdOh0faUpHgV3jFM4zNTDVUGAAAARLc2haGlS5cqIyND8fHxysrK0rp161rc/5lnntHAgQPVsWNHXXHFFXrhhRea7PPqq69q0KBB8ng8GjRokF5//fW2lOZI4zNTNTn7EknStf176Pc/HqX1/349QQgAAAAwKOwwtHLlSs2cOVNz5szRtm3bNGbMGE2YMEGlpaUh9y8sLFR+fr4effRR7dq1SwUFBfrJT36iN998M7jPxo0blZeXp8mTJ2vHjh2aPHmybrvtNr3//vttPzOHqfefepbQwNREZffrztQ4AAAAwLCww9DChQs1ZcoUTZ06VQMHDtTixYuVlpamwsLCkPu/+OKLuu+++5SXl6dLL71UP/jBDzRlyhQtWLAguM/ixYs1duxY5efna8CAAcrPz9cNN9ygxYsXt/nEnKa2vkGSFNeBmYkAAACAE3Q49y7/VFdXp61bt+rhhx9utD03N1cbNmwI+Zna2lrFxzdeOrpjx47avHmzfD6f3G63Nm7cqFmzZjXaZ9y4cS2GodraWtXW1gZfV1ZWSpJ8Pp98Pl84p9VuAr831O+vqauXJMW6Qr+Pr6+l/sNe9N4cem8W/TeH3ptF/82h963T2v6EFYYOHz4sv9+v5OTkRtuTk5NVVlYW8jPjxo3Tc889p1tvvVXDhg3T1q1btXz5cvl8Ph0+fFipqakqKysL65iSNH/+fBUUFDTZvnr1anXq1Cmc02p3JSUlTbYNlnTpEKnz8U9UXPxJ5IuKIqH6j8ig9+bQe7Povzn03iz6bw69b1l1dXWr9gsrDAW4XI2/72JZVpNtAXPnzlVZWZlGjRoly7KUnJysu+++W7/+9a8VGxvbpmNKUn5+vmbPnh18XVlZqbS0NOXm5ioxMbEtp/W1+Xw+lZSUaOzYsXK73UZqiGb03xx6bw69N4v+m0PvzaL/5tD71gnMGjuXsMJQjx49FBsb22TEpry8vMnITkDHjh21fPly/fa3v9WXX36p1NRUPfvss0pISFCPHj0kSSkpKWEdU5I8Ho88Hk+T7W632/iF4YQaohn9N4fem0PvzaL/5tB7s+i/OfS+Za3tTVjf5o+Li1NWVlaTYbmSkhLl5OScs6A+ffooNjZWK1as0E033aSYmFO/Pjs7u8kxV69efc5jnk/+sOWAFpV8pk/KWpdSAQAAANgr7Glys2fP1uTJkzV8+HBlZ2fr2WefVWlpqaZNmybp1PS1gwcPBp8l9Nlnn2nz5s0aOXKkjh07poULF2rnzp16/vnng8d88MEHde2112rBggW65ZZb9MYbb+idd97R+vXr2+k0zXvtg4PauO+ILu3ZWQNSzEzjAwAAAPBPYYehvLw8HTlyRI899pi8Xq8yMzNVXFys9PR0SZLX6230zCG/36/f/OY3+vTTT+V2u/Wtb31LGzZsUN++fYP75OTkaMWKFXrkkUc0d+5c9evXTytXrtTIkSO//hk6RJ3/1NLaHpbWBgAAAByhTQsoTJ8+XdOnTw/5XlFRUaPXAwcO1LZt2855zEmTJmnSpEltKee8UMdzhgAAAABH4c48QoJh6IwV9AAAAACYQxiKkMA0OUaGAAAAAGfgzjxCmCYHAAAAOAt35hFSG5wmR8sBAAAAJ2jTAgoI30tTR+irOr8yenQ2XQoAAAAAEYYihmcLAQAAAM7CnC0AAAAAUYmRoQjwN1gqfHev4jrE6K6cvvJ0YHltAAAAwDTCUATU1vv1/6/+TJJ0x6h0w9UAAAAAkJgmFxGBZbUlVpMDAAAAnII78wgIhKEYl9SBMAQAAAA4AnfmEVDLA1cBAAAAx+HuPALq/DxwFQAAAHAa7s4joC44MsQqcgAAAIBTEIYiIBCGPEyTAwAAAByDpbUjoF+vLvrDtGzFuFymSwEAAABwGmEoArp4Oujqvt1MlwEAAADgDMzbAgAAABCVGBmKgP2HT+ovn5Srd9eOGp+ZYrocAAAAAGJkKCI+Olihx/5nt4o27DddCgAAAIDTCEMRwNLaAAAAgPMQhiIgGIZ46CoAAADgGNydR0BdvV8SzxkCAAAAnIS78wio8wemydFuAAAAwCm4O48ApskBAAAAzsPdeQT8cwEF2g0AAAA4Bc8ZioB/yeqjrL7dlJIYb7oUAAAAAKcRhiIgvXtnpXfvbLoMAAAAAGdg3hYAAACAqMTIUARs2HtYpUerNfSSi3RFSoLpcgAAAACIkaGI+N9bDujh1z7Suj3/MF0KAAAAgNMIQxHAc4YAAAAA5+HuPAJ4zhAAAADgPNydR0AtzxkCAAAAHIe78wjgoasAAACA83B3HgHB7wwxTQ4AAABwDO7OI4CRIQAAAMB5eM5QBMy9aZCOnazToN6JpksBAAAAcBphKAJGXdrddAkAAAAAzsK8LQAAAABRiZGhCHhzxyFZkr51RU8lxLtNlwMAAABAjAxFRP5rH+mB32/TkRN1pksBAAAAcBphKAJYTQ4AAABwHu7ObWZZVvA5Q26eMwQAAAA4RpvuzpcuXaqMjAzFx8crKytL69ata3H/3/3udxoyZIg6deqk1NRU3XPPPTpy5Ejw/aKiIrlcriY/NTU1bSnPUQJBSGJkCAAAAHCSsO/OV65cqZkzZ2rOnDnatm2bxowZowkTJqi0tDTk/uvXr9edd96pKVOmaNeuXfrDH/6gv/71r5o6dWqj/RITE+X1ehv9xMfHt+2sHCQwRU6SPIQhAAAAwDHCvjtfuHChpkyZoqlTp2rgwIFavHix0tLSVFhYGHL/TZs2qW/fvnrggQeUkZGha665Rvfdd5+2bNnSaD+Xy6WUlJRGPxeCM8NQHNPkAAAAAMcIa2nturo6bd26VQ8//HCj7bm5udqwYUPIz+Tk5GjOnDkqLi7WhAkTVF5erldeeUXf+c53Gu134sQJpaeny+/36xvf+IYef/xxDR06tNlaamtrVVtbG3xdWVkpSfL5fPL5fOGcVrsJ/N4zf//JmlMryHWIccnvr5ffb6S0qBCq/4gMem8OvTeL/ptD782i/+bQ+9ZpbX9clmVZrT3ooUOHdPHFF+u9995TTk5OcPsvf/lLPf/88/r0009Dfu6VV17RPffco5qaGtXX1+vmm2/WK6+8Irf71DN3Nm3apL1792rw4MGqrKzUkiVLVFxcrB07dqh///4hj/noo4+qoKCgyfaXX35ZnTp1au0p2a7WL+065lKDJQ3v2epWAwAAAGij6upq3X777aqoqFBiYmKz+7UpDG3YsEHZ2dnB7b/4xS/04osv6pNPPmnymd27d+vb3/62Zs2apXHjxsnr9eqhhx7S1VdfrWXLloX8PQ0NDRo2bJiuvfZaPfnkkyH3CTUylJaWpsOHD7d4wnby+XwqKSnR2LFjg0HP32BpyxfHVF5Vq14JHg1Pv0ixMS4j9V3oQvUfkUHvzaH3ZtF/c+i9WfTfHHrfOpWVlerRo8c5w1BY0+R69Oih2NhYlZWVNdpeXl6u5OTkkJ+ZP3++Ro8erYceekiSdNVVV6lz584aM2aMnnjiCaWmpjb5TExMjK6++mrt2bOn2Vo8Ho88Hk+T7W632/iFEahh1U6vCt7cLW/FP1fFS02K17yJgzQ+s+l5o3044RqIVvTeHHpvFv03h96bRf/Nofcta21vwvpGf1xcnLKyslRSUtJoe0lJSaNpc2eqrq5WTEzjXxMbGyvp1DN4QrEsS9u3bw8ZlM4Xq3Z6df9LHzQKQpJUVlGj+1/6QKt2eg1VBgAAAEBqw2pys2fP1nPPPafly5fr448/1qxZs1RaWqpp06ZJkvLz83XnnXcG9584caJee+01FRYWat++fXrvvff0wAMPaMSIEerdu7ckqaCgQG+//bb27dun7du3a8qUKdq+fXvwmOcbf4Olgjd3K1TUC2wreHO3/A18hwgAAAAwJaxpcpKUl5enI0eO6LHHHpPX61VmZqaKi4uVnp4uSfJ6vY2eOXT33XerqqpKTz/9tH72s5+pa9euuv7667VgwYLgPsePH9e9996rsrIyJSUlaejQoVq7dq1GjBjRDqcYeVu+ONZkROhMliRvRY027z+q7H7dI1cYAAAAgKCww5AkTZ8+XdOnTw/5XlFRUZNtM2bM0IwZM5o93qJFi7Ro0aK2lOJI5VW1595JUnlV84EJAAAAgL14CqgNeiU0Xdgh9H7xNlcCAAAAoDmEIRsMT79IqUnxam4BbZdOrSo3IqNbJMsCAAAAcAbCkA1iY1yaN3FQyPcCAWnexEE8bwgAAAAwiDBkk/GZqSq8Y5iSOjZe4zwlKV6FdwzjOUMAAACAYW1aQAGtMz4zVZf27KJXth5QjCtG113eUyMyujEiBAAAADgAYchmlycn6Oc3hp4yBwAAAMAcpskBAAAAiEqMDNls3z9O6MCxr9Tnoo7q17OL6XIAAAAAnMbIkM3+uO2g7lq+WS9s+Nx0KQAAAADOQBiyWa2/QZLkjqXVAAAAgJNwh24zX70lSXJ3oNUAAACAk3CHbjMfI0MAAACAI3GHbrNAGIqL5dlCAAAAgJMQhmxWFwhDTJMDAAAAHIU7dJv5/Ke/M8Q0OQAAAMBReM6QzSZl9dHQtK4akdHNdCkAAAAAzkAYstl1l/fUdZf3NF0GAAAAgLMwdwsAAABAVGJkyGY7D1boK59fl/Xsoos6x5kuBwAAAMBpjAzZ7D/e2Knv/+dGbf78qOlSAAAAAJyBMGSzwGpycawmBwAAADgKd+g2Czx0laW1AQAAAGfhDt1mdcEw5DJcCQAAAIAzEYZsVld/KgzFdaDVAAAAgJNwh24zpskBAAAAzsQdus2CCygwMgQAAAA4Cs8ZstkD11+mE7X16tHFY7oUAAAAAGcgDNns7tEZpksAAAAAEAJztwAAAABEJUaGbNTQYOnDgxVyx7o0ICVRsTEsrw0AAAA4BSNDNqrzN+jWZ97Td55crxqf33Q5AAAAAM5AGLJR4IGrEktrAwAAAE7DHbqNfPVnhiGmyAEAAABOQhiyUeAZQ+5Yl1wuwhAAAADgJIQhG/lOT5NjihwAAADgPNyl26iOMAQAAAA4FnfpNqqrJwwBAAAATsVzhmzUvXOcHryhvzxuwhAAAADgNIQhG/VKjNessZebLgMAAABACAxZAAAAAIhKjAzZqKrGJ29FjTp7Oujirh1NlwMAAADgDIwM2ej9fUeVu2itpr+01XQpAAAAAM5CGLIRzxkCAAAAnIu7dBsFnjMU14E2AwAAAE7Tprv0pUuXKiMjQ/Hx8crKytK6deta3P93v/udhgwZok6dOik1NVX33HOPjhw50mifV199VYMGDZLH49GgQYP0+uuvt6U0R/H5LUmMDAEAAABOFPZd+sqVKzVz5kzNmTNH27Zt05gxYzRhwgSVlpaG3H/9+vW68847NWXKFO3atUt/+MMf9Ne//lVTp04N7rNx40bl5eVp8uTJ2rFjhyZPnqzbbrtN77//ftvPzAGYJgcAAAA4V9h36QsXLtSUKVM0depUDRw4UIsXL1ZaWpoKCwtD7r9p0yb17dtXDzzwgDIyMnTNNdfovvvu05YtW4L7LF68WGPHjlV+fr4GDBig/Px83XDDDVq8eHGbT8wJfMFpci7DlQAAAAA4W1hLa9fV1Wnr1q16+OGHG23Pzc3Vhg0bQn4mJydHc+bMUXFxsSZMmKDy8nK98sor+s53vhPcZ+PGjZo1a1ajz40bN67FMFRbW6va2trg68rKSkmSz+eTz+cL57TaTeD3Bv6sqauXJMW6ZKymaHJ2/xE59N4cem8W/TeH3ptF/82h963T2v6EFYYOHz4sv9+v5OTkRtuTk5NVVlYW8jM5OTn63e9+p7y8PNXU1Ki+vl4333yznnrqqeA+ZWVlYR1TkubPn6+CgoIm21evXq1OnTqFc1rtrqSkRJJUVSldnxqjrtUHVVz8d6M1RZNA/xF59N4cem8W/TeH3ptF/82h9y2rrq5u1X5teuiqy9V42pdlWU22BezevVsPPPCA/uM//kPjxo2T1+vVQw89pGnTpmnZsmVtOqYk5efna/bs2cHXlZWVSktLU25urhITE9tyWl+bz+dTSUmJxo4dK7fbbaSGaEb/zaH35tB7s+i/OfTeLPpvDr1vncCssXMJKwz16NFDsbGxTUZsysvLm4zsBMyfP1+jR4/WQw89JEm66qqr1LlzZ40ZM0ZPPPGEUlNTlZKSEtYxJcnj8cjj8TTZ7na7jV8YTqghmtF/c+i9OfTeLPpvDr03i/6bQ+9b1trehLWAQlxcnLKyspoMy5WUlCgnJyfkZ6qrqxUT0/jXxMbGSjo1+iNJ2dnZTY65evXqZo95vjh6sk5/P1atqhrmdAIAAABOE/ZqcrNnz9Zzzz2n5cuX6+OPP9asWbNUWlqqadOmSTo1fe3OO+8M7j9x4kS99tprKiws1L59+/Tee+/pgQce0IgRI9S7d29J0oMPPqjVq1drwYIF+uSTT7RgwQK98847mjlzZvucpSFP/3mvrlnwFxW++zfTpQAAAAA4S9jfGcrLy9ORI0f02GOPyev1KjMzU8XFxUpPT5ckeb3eRs8cuvvuu1VVVaWnn35aP/vZz9S1a1ddf/31WrBgQXCfnJwcrVixQo888ojmzp2rfv36aeXKlRo5cmQ7nKI5dX6/JJ4zBAAAADhRmxZQmD59uqZPnx7yvaKioibbZsyYoRkzZrR4zEmTJmnSpEltKcexfPWnpgHGdSAMAQAAAE7DXbqNAg9ddcfy0FUAAADAaQhDNqoLhiHaDAAAADgNd+k2CowMMU0OAAAAcB7u0m3k85/6zhAjQwAAAIDztGkBBbTOt67oqdSkeF3Wq4vpUgAAAACchTBko8nZfU2XAAAAAKAZzN8CAAAAEJUYGbLRkRO1crlcSojvwPeGAAAAAIfhDt1G//rc+xr2eIk27z9quhQAAAAAZyEM2YjnDAEAAADOxV26jXzBMOQyXAkAAACAsxGGbFRXz8gQAAAA4FTcpdso8NDVuA60GQAAAHAa7tJt5GNkCAAAAHAs7tJtVMd3hgAAAADH4jlDNvresItV62tQgsdtuhQAAAAAZyEM2Wj+964yXQIAAACAZjBNDgAAAEBUIgzZpKHBUlWNTzU+vyzLMl0OAAAAgLMQhmzyjxO1Gvzoag2Yu0qb9h2Rv4FABAAAADgJYcgGb+/6UhOfWh98/cP/el/XLPizVu30GqwKAAAAwJkIQ+1sxxGXZqzYofKq2kbbyypqdP9LHxCIAAAAAIcgDLUjf4Ol1z6PUagJcYFtBW/uZsocAAAA4ACEoXa05YtjOl7X/ANWLUneihpt3n80ckUBAAAACIkw1I7OnhrX/H41NlcCAAAA4FwIQ+2oV4KnlfvF21wJAAAAgHMhDLWj4ekXqWucpeYmyrkkpSbFa0RGt0iWBQAAACAEwlA7io1x6Xt9GySpSSAKvJ43cZBiY5r/XhEAAACAyCAMtbMh3S099YMhSklqPBUuJSlehXcM0/jMVEOVAQAAADhTB9MFXIjGXZmscZm9tfnzozpcVateiaemxjEiBAAAADgHI0M22fz5Uf3rc++rcM3flN2vO0EIAAAAcBjCkE0CD1Z1uQhBAAAAgBMRhmzit06FoVg6DAAAADgSt+o2aTg9MhTLyBAAAADgSIQhmwSmycXwXSEAAADAkQhDNmmwGBkCAAAAnIwwZBP/qWevMjIEAAAAOBTPGbJJr0SPbhjQS/2TE0yXAgAAACAEwpBNru7bTVff3c10GQAAAACawTQ5AAAAAFGJMAQAAAAgKhGGbPKHLQd0xSNvafrvtpouBQAAAEAIhCGb+PyWausb5PNbpksBAAAAEAJhyCZ+njMEAAAAOFqbwtDSpUuVkZGh+Ph4ZWVlad26dc3ue/fdd8vlcjX5ufLKK4P7FBUVhdynpqamLeU5QkPD6TDEc4YAAAAARwo7DK1cuVIzZ87UnDlztG3bNo0ZM0YTJkxQaWlpyP2XLFkir9cb/Dlw4IC6deum73//+432S0xMbLSf1+tVfHx8287KAfynwxAPXQUAAACcKewwtHDhQk2ZMkVTp07VwIEDtXjxYqWlpamwsDDk/klJSUpJSQn+bNmyRceOHdM999zTaD+Xy9Vov5SUlLadkUM0BKfJGS4EAAAAQEhhPXS1rq5OW7du1cMPP9xoe25urjZs2NCqYyxbtkzf/va3lZ6e3mj7iRMnlJ6eLr/fr2984xt6/PHHNXTo0GaPU1tbq9ra2uDryspKSZLP55PP52vtKbWrwO/1+Xzy1ftPbbQsY/VEmzP7j8ii9+bQe7Povzn03iz6bw69b53W9sdlWVarlzs7dOiQLr74Yr333nvKyckJbv/lL3+p559/Xp9++mmLn/d6vUpLS9PLL7+s2267Lbh906ZN2rt3rwYPHqzKykotWbJExcXF2rFjh/r37x/yWI8++qgKCgqabH/55ZfVqVOn1p6SbT447NJ7X7o0oKulsRezohwAAAAQKdXV1br99ttVUVGhxMTEZvcLa2QowHXWCmmWZTXZFkpRUZG6du2qW2+9tdH2UaNGadSoUcHXo0eP1rBhw/TUU0/pySefDHms/Px8zZ49O/i6srJSaWlpys3NbfGE7eTz+VRSUqKxY8fqRrfbSA3R7Mz+u+l/RNF7c+i9WfTfHHpvFv03h963TmDW2LmEFYZ69Oih2NhYlZWVNdpeXl6u5OTkFj9rWZaWL1+uyZMnKy4ursV9Y2JidPXVV2vPnj3N7uPxeOTxeJpsd7vdxi8MJ9QQzei/OfTeHHpvFv03h96bRf/Nofcta21vwlpAIS4uTllZWSopKWm0vaSkpNG0uVDWrFmjvXv3asqUKef8PZZlafv27UpNTQ2nPAAAAABotbCnyc2ePVuTJ0/W8OHDlZ2drWeffValpaWaNm2apFPT1w4ePKgXXnih0eeWLVumkSNHKjMzs8kxCwoKNGrUKPXv31+VlZV68skntX37dj3zzDNtPC3znvnLXv3Xun26fcQl+rfxA0yXAwAAAOAsYYehvLw8HTlyRI899pi8Xq8yMzNVXFwcXB3O6/U2eeZQRUWFXn31VS1ZsiTkMY8fP657771XZWVlSkpK0tChQ7V27VqNGDGiDafkDCdr63W82qevfH7TpQAAAAAIoU0LKEyfPl3Tp08P+V5RUVGTbUlJSaqurm72eIsWLdKiRYvaUopj+YPPGeJBQwAAAIAThf3QVbROQ8PpMBRDGAIAAACciDBkE3/DqT9jCEMAAACAIxGGbNLANDkAAADA0QhDNgmEIQaGAAAAAGciDNnk4q4dNSStq1K7djRdCgAAAIAQ2rSaHM7tvuv66b7r+pkuAwAAAEAzGBkCAAAAEJUIQwAAAACiEmHIJo/+aZdy5v9frdhcaroUAAAAACEQhmxy9GSdDlXU6GSd33QpAAAAAEIgDNnEH3zOkOFCAAAAAIREGLJJQ8PpMMSDhgAAAABHIgzZJPjQVcIQAAAA4EiEIZv4G079GeMiDAEAAABORBiySUPwO0OEIQAAAMCJCEM26d01Xpcnd1FSJ7fpUgAAAACE0MF0AReqJ24dbLoEAAAAAC1gZAgAAABAVCIMAQAAAIhKhCGbPLhim274zbtat+cfpksBAAAAEAJhyCYHjlbrb/84qeo6v+lSAAAAAIRAGLKJ/9TK2iytDQAAADgUYcgmVuA5QzGEIQAAAMCJCEM28TecCkMMDAEAAADORBiySSAMMTIEAAAAOBNhyCYNgWlyDA0BAAAAjtTBdAEXqpSkjqqu8ys+LtZ0KQAAAABCIAzZ5IUfjTBdAgAAAIAWME0OAAAAQFQiDAEAAACISoQhm9y1fLMmPrVee8tPmC4FAAAAQAh8Z8gmH3srVV5Vq9p6v+lSAAAAAITAyJBNgktr85whAAAAwJEIQzY5/cxVxfCcIQAAAMCRCEM28Z9OQ4QhAAAAwJkIQzZpaGCaHAAAAOBkhCGb+APfGWJkCAAAAHAkVpOzSfcucepY61eHWMIQAAAA4ESEIZus+7frTZcAAAAAoAVMkwMAAAAQlQhDAAAAAKISYcgGDQ2WJhVu0G3/uVFVNT7T5QAAAAAIge8M2aC+wdKWL45J+ufDVwEAAAA4CyNDNrCsfyYgHjMEAAAAOFObwtDSpUuVkZGh+Ph4ZWVlad26dc3ue/fdd8vlcjX5ufLKKxvt9+qrr2rQoEHyeDwaNGiQXn/99baU5gj+M8IQD10FAAAAnCnsMLRy5UrNnDlTc+bM0bZt2zRmzBhNmDBBpaWlIfdfsmSJvF5v8OfAgQPq1q2bvv/97wf32bhxo/Ly8jR58mTt2LFDkydP1m233ab333+/7WdmkL/hn3+P4aGrAAAAgCOFHYYWLlyoKVOmaOrUqRo4cKAWL16stLQ0FRYWhtw/KSlJKSkpwZ8tW7bo2LFjuueee4L7LF68WGPHjlV+fr4GDBig/Px83XDDDVq8eHGbT8ykBkaGAAAAAMcLawGFuro6bd26VQ8//HCj7bm5udqwYUOrjrFs2TJ9+9vfVnp6enDbxo0bNWvWrEb7jRs3rsUwVFtbq9ra2uDryspKSZLP55PPZ2YFt8Dvra2rC25rqK+Xr4FAFAmB/pv6949m9N4cem8W/TeH3ptF/82h963T2v6EFYYOHz4sv9+v5OTkRtuTk5NVVlZ2zs97vV699dZbevnllxttLysrC/uY8+fPV0FBQZPtq1evVqdOnc5Zi53efXeNPLGxsixp1aq3jNYSjUpKSkyXELXovTn03iz6bw69N4v+m0PvW1ZdXd2q/dq0tLbrrO/BWJbVZFsoRUVF6tq1q2699davfcz8/HzNnj07+LqyslJpaWnKzc1VYmLiOWuxg8/nU0lJib5741jddovbSA3RLND/sWPHyu2m/5FE782h92bRf3PovVn03xx63zqBWWPnElYY6tGjh2JjY5uM2JSXlzcZ2TmbZVlavny5Jk+erLi4uEbvpaSkhH1Mj8cjj8fTZLvb7TZ+YTihhmhG/82h9+bQe7Povzn03iz6bw69b1lrexPWAgpxcXHKyspqMixXUlKinJycFj+7Zs0a7d27V1OmTGnyXnZ2dpNjrl69+pzHBAAAAIC2Cnua3OzZszV58mQNHz5c2dnZevbZZ1VaWqpp06ZJOjV97eDBg3rhhRcafW7ZsmUaOXKkMjMzmxzzwQcf1LXXXqsFCxbolltu0RtvvKF33nlH69evb+NpmfVlZY3y//iBOsd10H9OzjJdDgAAAIAQwg5DeXl5OnLkiB577DF5vV5lZmaquLg4uDqc1+tt8syhiooKvfrqq1qyZEnIY+bk5GjFihV65JFHNHfuXPXr108rV67UyJEj23BK5lXX+bVuz2ElxLfpK1kAAAAAIqBNd+vTp0/X9OnTQ75XVFTUZFtSUtI5V3SYNGmSJk2a1JZyHMffcOo5QzxwFQAAAHCusB+6inMLPHSVB64CAAAAzkUYsoG/4dSfjAwBAAAAzkUYssE/R4YMFwIAAACgWdyu2yDwnaFYRoYAAAAAxyIM2cCSFOOSYvjOEAAAAOBYrP1sgyF9krRv/ndknZ4uBwAAAMB5GBmykYtpcgAAAIBjEYYAAAAARCXCkA0+KavSvS9s0eP/s9t0KQAAAACawXeGbPCPE7VavftLDUhJMF0KAAAAgGYwMmSDhsDS2qwmBwAAADgWYcgG/tOLyBGGAAAAAOciDNnAOj0yFMNqcgAAAIBjEYZs4LeYJgcAAAA4HWHIBv7Ad4YYGQIAAAAcizBkg9NZSDF0FwAAAHAslta2wYQrkzXhifE6PVsOAAAAgAMRhmwQE+OSu0Os6TIAAAAAtICJXAAAAACiEiNDNnh//1G98sEhZV6cpKljLjVdDgAAAIAQGBmywedHqvXH7Ye0ad9R06UAAAAAaAZhyAbBpbXpLgAAAOBY3K7boIGHrgIAAACORxiyQWBkKIaHrgIAAACORRiyQeChq4wMAQAAAM5FGLJB8DtDjAwBAAAAjkUYskEgDLkIQwAAAIBj8ZwhG9ydfYn+dVRfuTuQNQEAAACnIgzZwOOOVRe323QZAAAAAFrA0AUAAACAqMTIkA3e+bhca/ceVU6/7po4pLfpcgAAAACEwMiQDT78e4V+v7lUW784ZroUAAAAAM0gDNnAb51eWpvnDAEAAACORRiyQfA5Q4QhAAAAwLEIQzY4nYUUw3OGAAAAAMciDNngnyNDhgsBAAAA0Cxu123QcPo7Q4wMAQAAAM5FGLJBYGSIMAQAAAA4F88ZssH/N7a/ZtxwuTp7aC8AAADgVNyt2yCxo1tut9t0GQAAAABawDQ5AAAAAFGJkSEbvLH9kHaXnVTulckadWl30+UAAAAACIGRIRus2XNYy9/br50HK0yXAgAAAKAZhCEbNDSc+jM2htXkAAAAAKdqUxhaunSpMjIyFB8fr6ysLK1bt67F/WtrazVnzhylp6fL4/GoX79+Wr58efD9oqIiuVyuJj81NTVtKc84vxV46CphCAAAAHCqsL8ztHLlSs2cOVNLly7V6NGj9dvf/lYTJkzQ7t27dckll4T8zG233aYvv/xSy5Yt02WXXaby8nLV19c32icxMVGffvppo23x8fHhlucIPGcIAAAAcL6ww9DChQs1ZcoUTZ06VZK0ePFivf322yosLNT8+fOb7L9q1SqtWbNG+/btU7du3SRJffv2bbKfy+VSSkpKuOU4UoNFGAIAAACcLqwwVFdXp61bt+rhhx9utD03N1cbNmwI+Zk//elPGj58uH7961/rxRdfVOfOnXXzzTfr8ccfV8eOHYP7nThxQunp6fL7/frGN76hxx9/XEOHDm22ltraWtXW1gZfV1ZWSpJ8Pp98Pl84p9VuAr+33n/6S0OW31gt0SjQa3oeefTeHHpvFv03h96bRf/Nofet09r+hBWGDh8+LL/fr+Tk5Ebbk5OTVVZWFvIz+/bt0/r16xUfH6/XX39dhw8f1vTp03X06NHg94YGDBigoqIiDR48WJWVlVqyZIlGjx6tHTt2qH///iGPO3/+fBUUFDTZvnr1anXq1Cmc02p35f/4h6QY7fzoI3X+8kOjtUSjkpIS0yVELXpvDr03i/6bQ+/Nov/m0PuWVVdXt2o/l2WdntPVCocOHdLFF1+sDRs2KDs7O7j9F7/4hV588UV98sknTT6Tm5urdevWqaysTElJSZKk1157TZMmTdLJkycbjQ4FNDQ0aNiwYbr22mv15JNPhqwl1MhQWlqaDh8+rMTExNaeUrvy+XwqKSnR4JFjVNcQo55d4pTY0W2klmgU6P/YsWPldtP3SKL35tB7s+i/OfTeLPpvDr1vncrKSvXo0UMVFRUtZoOwRoZ69Oih2NjYJqNA5eXlTUaLAlJTU3XxxRcHg5AkDRw4UJZl6e9//3vIkZ+YmBhdffXV2rNnT7O1eDweeTyeJtvdbrfxCyOte4LxGqKZE66BaEXvzaH3ZtF/c+i9WfTfHHrfstb2JqyltePi4pSVldVkWK6kpEQ5OTkhPzN69GgdOnRIJ06cCG777LPPFBMToz59+oT8jGVZ2r59u1JTU8MpDwAAAABaLeznDM2ePVvPPfecli9fro8//lizZs1SaWmppk2bJknKz8/XnXfeGdz/9ttvV/fu3XXPPfdo9+7dWrt2rR566CH96Ec/Ck6RKygo0Ntvv619+/Zp+/btmjJlirZv3x485vlm5Za/6zerP9WeL6tMlwIAAACgGWEvrZ2Xl6cjR47osccek9frVWZmpoqLi5Weni5J8nq9Ki0tDe7fpUsXlZSUaMaMGRo+fLi6d++u2267TU888URwn+PHj+vee+8Nfq9o6NChWrt2rUaMGNEOpxh5r207pA9Kj+vK3knqn5xguhwAAAAAIYQdhiRp+vTpmj59esj3ioqKmmwbMGBAiyteLFq0SIsWLWpLKY4UeOhqbAzPGQIAAACcKuxpcji3wENXY+kuAAAA4FjcrtsgMDLkcjEyBAAAADgVYcgGDYFpcoQhAAAAwLEIQzbwW3xnCAAAAHA6wpAN/A2n/oxhZAgAAABwrDatJoeWPfPDIaq3YpTRs7PpUgAAAAA0gzBkg8t6dZHb7TZdBgAAAIAWME0OAAAAQFRiZMgGL2wqVU29pe8P76NeCfGmywEAAAAQAmHIBs+u3a8vq2p13eU9CUMAAACAQzFNzgYsrQ0AAAA4H2HIBv4GwhAAAADgdIQhGzScHhkiCwEAAADORRiyAQ9dBQAAAJyPMGSDBr4zBAAAADgeYcgGge8MMTIEAAAAOBdLa9vghXuGS64Y9UzwmC4FAAAAQDMIQzYYdklXud1u02UAAAAAaAHT5AAAAABEJUaG2pllSf+94Qu5O8TqhyMuUbw71nRJAAAAAEIgDLWzBkv65VufSpK+N7QPYQgAAABwKKbJtbOGM/4eQ3cBAAAAx+J2vZ3Vn5GGtnx+LLjMNgAAAABnIQy1o7d3fan52/85Le6eor/qmgV/1qqdXoNVAQAAAAiFMNROVu30asaKHarwNd5eVlGj+1/6gEAEAAAAOAxhqB34GywVvLlbpybEuRq9F5gkV/DmbqbMAQAAAA5CGGoHm/cflbeiptn3LUneihpt3n80ckUBAAAAaBFhqB2UVzUfhNqyHwAAAAD7EYbaQa+E+HbdDwAAAID9CEPtYERGN6UmxZ/1baF/cklKTYrXiIxukSwLAAAAQAsIQ+0gNsaleRMHnX7VeJGEQECaN3GQYmOai0sAAAAAIo0w1E7GZ6bqqR8MUde4xttTkuJVeMcwjc9MNVMYAAAAgJA6mC7gQjLuymT5Pver56BROlJdr14Jp6bGMSIEAAAAOA9hqJ3FuKSRGd3kdrtNlwIAAACgBUyTAwAAABCVCEMAAAAAohJhCAAAAEBUIgwBAAAAiEqEIQAAAABRiTAEAAAAICoRhgAAAABEJcIQAAAAgKhEGAIAAAAQlQhDAAAAAKISYQgAAABAVCIMAQAAAIhKhCEAAAAAUamD6QLai2VZkqTKykpjNfh8PlVXV6uyslJut9tYHdGK/ptD782h92bRf3PovVn03xx63zqBTBDICM25YMJQVVWVJCktLc1wJQAAAACcoKqqSklJSc2+77LOFZfOEw0NDTp06JASEhLkcrmM1FBZWam0tDQdOHBAiYmJRmqIZvTfHHpvDr03i/6bQ+/Nov/m0PvWsSxLVVVV6t27t2Jimv9m0AUzMhQTE6M+ffqYLkOSlJiYyMVpEP03h96bQ+/Nov/m0Huz6L859P7cWhoRCmABBQAAAABRiTAEAAAAICoRhtqRx+PRvHnz5PF4TJcSlei/OfTeHHpvFv03h96bRf/Nofft64JZQAEAAAAAwsHIEAAAAICoRBgCAAAAEJUIQwAAAACiEmEIAAAAQFQiDAEAAACISoShdrJ06VJlZGQoPj5eWVlZWrdunemSLkiPPvqoXC5Xo5+UlJTg+5Zl6dFHH1Xv3r3VsWNHffOb39SuXbsMVnz+Wrt2rSZOnKjevXvL5XLpj3/8Y6P3W9Pr2tpazZgxQz169FDnzp1188036+9//3sEz+L8da7+33333U3+szBq1KhG+9D/tpk/f76uvvpqJSQkqFevXrr11lv16aefNtqH698erek91759CgsLddVVVykxMVGJiYnKzs7WW2+9FXyf694+5+o91719CEPtYOXKlZo5c6bmzJmjbdu2acyYMZowYYJKS0tNl3ZBuvLKK+X1eoM/H330UfC9X//611q4cKGefvpp/fWvf1VKSorGjh2rqqoqgxWfn06ePKkhQ4bo6aefDvl+a3o9c+ZMvf7661qxYoXWr1+vEydO6KabbpLf74/UaZy3ztV/SRo/fnyj/ywUFxc3ep/+t82aNWv0k5/8RJs2bVJJSYnq6+uVm5urkydPBvfh+rdHa3ovce3bpU+fPvrVr36lLVu2aMuWLbr++ut1yy23BAMP1719ztV7ieveNha+thEjRljTpk1rtG3AgAHWww8/bKiiC9e8efOsIUOGhHyvoaHBSklJsX71q18Ft9XU1FhJSUnWf/7nf0aowguTJOv1118Pvm5Nr48fP2653W5rxYoVwX0OHjxoxcTEWKtWrYpY7ReCs/tvWZZ11113Wbfcckuzn6H/7ae8vNySZK1Zs8ayLK7/SDq795bFtR9pF110kfXcc89x3RsQ6L1lcd3biZGhr6murk5bt25Vbm5uo+25ubnasGGDoaoubHv27FHv3r2VkZGhH/zgB9q3b58kaf/+/SorK2v0b+HxeHTdddfxb9HOWtPrrVu3yufzNdqnd+/eyszM5N+jnbz77rvq1auXLr/8cv34xz9WeXl58D36334qKiokSd26dZPE9R9JZ/c+gGvffn6/XytWrNDJkyeVnZ3NdR9BZ/c+gOveHh1MF3C+O3z4sPx+v5KTkxttT05OVllZmaGqLlwjR47UCy+8oMsvv1xffvmlnnjiCeXk5GjXrl3Bfof6t/jiiy9MlHvBak2vy8rKFBcXp4suuqjJPvxn4+ubMGGCvv/97ys9PV379+/X3Llzdf3112vr1q3yeDz0v51YlqXZs2frmmuuUWZmpiSu/0gJ1XuJa99uH330kbKzs1VTU6MuXbro9ddf16BBg4I31Fz39mmu9xLXvZ0IQ+3E5XI1em1ZVpNt+PomTJgQ/PvgwYOVnZ2tfv366fnnnw9+kZB/i8hpS6/592gfeXl5wb9nZmZq+PDhSk9P1//5P/9H3/ve95r9HP0Pz09/+lN9+OGHWr9+fZP3uP7t1VzvufbtdcUVV2j79u06fvy4Xn31Vd11111as2ZN8H2ue/s01/tBgwZx3duIaXJfU48ePRQbG9skdZeXlzf5f0/Q/jp37qzBgwdrz549wVXl+LewX2t6nZKSorq6Oh07dqzZfdB+UlNTlZ6erj179kii/+1hxowZ+tOf/qS//OUv6tOnT3A717/9mut9KFz77SsuLk6XXXaZhg8frvnz52vIkCFasmQJ130ENNf7ULju2w9h6GuKi4tTVlaWSkpKGm0vKSlRTk6OoaqiR21trT7++GOlpqYqIyNDKSkpjf4t6urqtGbNGv4t2llrep2VlSW3291oH6/Xq507d/LvYYMjR47owIEDSk1NlUT/vw7LsvTTn/5Ur732mv785z8rIyOj0ftc//Y5V+9D4dq3l2VZqq2t5bo3IND7ULju21HEl2y4AK1YscJyu93WsmXLrN27d1szZ860OnfubH3++eemS7vg/OxnP7Peffdda9++fdamTZusm266yUpISAj2+le/+pWVlJRkvfbaa9ZHH31k/fCHP7RSU1OtyspKw5Wff6qqqqxt27ZZ27ZtsyRZCxcutLZt22Z98cUXlmW1rtfTpk2z+vTpY73zzjvWBx98YF1//fXWkCFDrPr6elOndd5oqf9VVVXWz372M2vDhg3W/v37rb/85S9Wdna2dfHFF9P/dnD//fdbSUlJ1rvvvmt5vd7gT3V1dXAfrn97nKv3XPv2ys/Pt9auXWvt37/f+vDDD62f//znVkxMjLV69WrLsrju7dRS77nu7UUYaifPPPOMlZ6ebsXFxVnDhg1rtAwo2k9eXp6Vmppqud1uq3fv3tb3vvc9a9euXcH3GxoarHnz5lkpKSmWx+Oxrr32Wuujjz4yWPH56y9/+YslqcnPXXfdZVlW63r91VdfWT/96U+tbt26WR07drRuuukmq7S01MDZnH9a6n91dbWVm5tr9ezZ03K73dYll1xi3XXXXU16S//bJlTfJVn//d//HdyH698e5+o91769fvSjHwXvZXr27GndcMMNwSBkWVz3dmqp91z39nJZlmVFbhwKAAAAAJyB7wwBAAAAiEqEIQAAAABRiTAEAAAAICoRhgAAAABEJcIQAAAAgKhEGAIAAAAQlQhDAAAAAKISYQgAAABAVCIMAQAAAIhKhCEAAAAAUYkwBAAAACAq/T+mX0XqjowCFQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, marker='o', linestyle='--')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7f04ec60-0f47-42a9-9252-b412d52a00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "fa03ebbc-e1a6-44e1-ba0c-03d8942e4a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_df = pd.DataFrame(data=X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ff3faddd-39a6-43a6-bfdb-9e1cd9125a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_df = pd.DataFrame(data=X_pca, \n",
    "                        columns=[f'PC{i+1}' for i in range(X_scaled_pca.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c370badf-747f-451b-ad6b-20b3bca5776d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76020, 370), (76020, 5))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_df.shape, X_pca_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b00ef963-9ce5-4afe-bccc-f4f09bd3f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, random_state=42)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "318eddaa-d06d-48ff-aca4-c44d2ce55691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1691, number of negative: 40880\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13636\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 249\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039722 -> initscore=-3.185321\n",
      "[LightGBM] [Info] Start training from score -3.185321\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's auc: 0.907745\ttraining's binary_logloss: 0.115095\tvalid_1's auc: 0.828938\tvalid_1's binary_logloss: 0.134587\n",
      "ROC AUC: 0.8389\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=500, early_stopping_round=100)\n",
    "\n",
    "eval_set = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_metric='auc', eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\n",
    "print(f'ROC AUC: {lgbm_roc_score:.4f}')\n",
    "\n",
    "model = 'lgbm_scaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4cbf1fc9-3ac1-48d9-98f6-51f345f72450",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': model, 'auc_score': f'{lgbm_roc_score:.4f}'}\n",
    "scores_df.loc[len(scores_df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9abb0786-23fa-4955-8c5d-bc46f8885527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_ft</td>\n",
       "      <td>0.8393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.8386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.8377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgbm_ft</td>\n",
       "      <td>0.8414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbm_scaled</td>\n",
       "      <td>0.8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgbm_scaled_ft</td>\n",
       "      <td>0.8396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model auc_score\n",
       "0      xgboost_ft    0.8393\n",
       "1         xgboost    0.8386\n",
       "2            lgbm    0.8377\n",
       "3         lgbm_ft    0.8414\n",
       "4     lgbm_scaled    0.8389\n",
       "5  lgbm_scaled_ft    0.8396"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9318db98-3807-4fb6-bda6-7fb06f940290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008165 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13058                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[92]\ttraining's auc: 0.88666\ttraining's binary_logloss: 0.123147\tvalid_1's auc: 0.822392\tvalid_1's binary_logloss: 0.135306\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008054 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[96]\ttraining's auc: 0.885133\ttraining's binary_logloss: 0.12298\tvalid_1's auc: 0.839687\tvalid_1's binary_logloss: 0.136201\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007162 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13086                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\ttraining's auc: 0.865913\ttraining's binary_logloss: 0.133313\tvalid_1's auc: 0.836646\tvalid_1's binary_logloss: 0.140059\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006393 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's auc: 0.920617\ttraining's binary_logloss: 0.110306\tvalid_1's auc: 0.820169\tvalid_1's binary_logloss: 0.136392\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007719 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.881032\ttraining's binary_logloss: 0.125684\tvalid_1's auc: 0.835197\tvalid_1's binary_logloss: 0.139162\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005172 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13138                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 198                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\ttraining's auc: 0.913881\ttraining's binary_logloss: 0.112783\tvalid_1's auc: 0.835229\tvalid_1's binary_logloss: 0.135981\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006532 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.883929\ttraining's binary_logloss: 0.126483\tvalid_1's auc: 0.821465\tvalid_1's binary_logloss: 0.136709\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007789 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\ttraining's auc: 0.90263\ttraining's binary_logloss: 0.117622\tvalid_1's auc: 0.837398\tvalid_1's binary_logloss: 0.136503\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006381 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[51]\ttraining's auc: 0.912658\ttraining's binary_logloss: 0.113685\tvalid_1's auc: 0.83666\tvalid_1's binary_logloss: 0.135293\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006479 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's auc: 0.891504\ttraining's binary_logloss: 0.123582\tvalid_1's auc: 0.819752\tvalid_1's binary_logloss: 0.137159\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006767 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13128                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's auc: 0.899472\ttraining's binary_logloss: 0.120037\tvalid_1's auc: 0.834542\tvalid_1's binary_logloss: 0.138166\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005161 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13147                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[30]\ttraining's auc: 0.921094\ttraining's binary_logloss: 0.11035\tvalid_1's auc: 0.832123\tvalid_1's binary_logloss: 0.136238\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006796 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\ttraining's auc: 0.887364\ttraining's binary_logloss: 0.125982\tvalid_1's auc: 0.821388\tvalid_1's binary_logloss: 0.136623\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006409 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[44]\ttraining's auc: 0.904062\ttraining's binary_logloss: 0.117084\tvalid_1's auc: 0.838435\tvalid_1's binary_logloss: 0.136267\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006539 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[63]\ttraining's auc: 0.9215\ttraining's binary_logloss: 0.110419\tvalid_1's auc: 0.835418\tvalid_1's binary_logloss: 0.135572\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007078 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13058                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.878676\ttraining's binary_logloss: 0.128286\tvalid_1's auc: 0.821162\tvalid_1's binary_logloss: 0.136757\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006417 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.874547\ttraining's binary_logloss: 0.128295\tvalid_1's auc: 0.839218\tvalid_1's binary_logloss: 0.138489\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007556 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[81]\ttraining's auc: 0.870827\ttraining's binary_logloss: 0.131096\tvalid_1's auc: 0.835762\tvalid_1's binary_logloss: 0.139029\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007536 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.877586\ttraining's binary_logloss: 0.127596\tvalid_1's auc: 0.820791\tvalid_1's binary_logloss: 0.136663\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006804 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8]\ttraining's auc: 0.867734\ttraining's binary_logloss: 0.130224\tvalid_1's auc: 0.837248\tvalid_1's binary_logloss: 0.139602\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007397 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\ttraining's auc: 0.904145\ttraining's binary_logloss: 0.115736\tvalid_1's auc: 0.834753\tvalid_1's binary_logloss: 0.135678\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007802 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13058                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's auc: 0.912985\ttraining's binary_logloss: 0.113662\tvalid_1's auc: 0.815759\tvalid_1's binary_logloss: 0.136801\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005614 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.888229\ttraining's binary_logloss: 0.123405\tvalid_1's auc: 0.831934\tvalid_1's binary_logloss: 0.13936\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006688 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13138                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 198                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\ttraining's auc: 0.917726\ttraining's binary_logloss: 0.11099\tvalid_1's auc: 0.831079\tvalid_1's binary_logloss: 0.136773\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005740 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\ttraining's auc: 0.876098\ttraining's binary_logloss: 0.127336\tvalid_1's auc: 0.819401\tvalid_1's binary_logloss: 0.136441\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007512 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\ttraining's auc: 0.874151\ttraining's binary_logloss: 0.12641\tvalid_1's auc: 0.838397\tvalid_1's binary_logloss: 0.13757\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006632 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\ttraining's auc: 0.893262\ttraining's binary_logloss: 0.119666\tvalid_1's auc: 0.835038\tvalid_1's binary_logloss: 0.135791\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006610 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\ttraining's auc: 0.890435\ttraining's binary_logloss: 0.123624\tvalid_1's auc: 0.821645\tvalid_1's binary_logloss: 0.136139\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008676 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.88583\ttraining's binary_logloss: 0.124752\tvalid_1's auc: 0.836291\tvalid_1's binary_logloss: 0.138488\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006325 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[51]\ttraining's auc: 0.918779\ttraining's binary_logloss: 0.111447\tvalid_1's auc: 0.836055\tvalid_1's binary_logloss: 0.135177\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008132 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13161                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.899209\ttraining's binary_logloss: 0.119099\tvalid_1's auc: 0.815463\tvalid_1's binary_logloss: 0.137826\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006830 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13132                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 201                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.900427\ttraining's binary_logloss: 0.11761\tvalid_1's auc: 0.829674\tvalid_1's binary_logloss: 0.139466\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007937 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13178                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 204                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's auc: 0.912541\ttraining's binary_logloss: 0.113033\tvalid_1's auc: 0.830761\tvalid_1's binary_logloss: 0.137866\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008251 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.894851\ttraining's binary_logloss: 0.123363\tvalid_1's auc: 0.819976\tvalid_1's binary_logloss: 0.136701\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007478 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's auc: 0.910907\ttraining's binary_logloss: 0.115187\tvalid_1's auc: 0.838688\tvalid_1's binary_logloss: 0.136346\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007767 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[47]\ttraining's auc: 0.917159\ttraining's binary_logloss: 0.11273\tvalid_1's auc: 0.833879\tvalid_1's binary_logloss: 0.135796\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007200 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13108                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 198                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.885013\ttraining's binary_logloss: 0.123998\tvalid_1's auc: 0.817249\tvalid_1's binary_logloss: 0.136935\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007633 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13128                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's auc: 0.901802\ttraining's binary_logloss: 0.115979\tvalid_1's auc: 0.833918\tvalid_1's binary_logloss: 0.137236\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006667 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13174                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.907597\ttraining's binary_logloss: 0.113777\tvalid_1's auc: 0.833343\tvalid_1's binary_logloss: 0.136752\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007506 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[48]\ttraining's auc: 0.901375\ttraining's binary_logloss: 0.118381\tvalid_1's auc: 0.820744\tvalid_1's binary_logloss: 0.135509\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007901 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13128                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[35]\ttraining's auc: 0.889103\ttraining's binary_logloss: 0.12315\tvalid_1's auc: 0.838167\tvalid_1's binary_logloss: 0.13786\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007732 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13147                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[86]\ttraining's auc: 0.92617\ttraining's binary_logloss: 0.108141\tvalid_1's auc: 0.83579\tvalid_1's binary_logloss: 0.135156\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007655 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13058                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's auc: 0.882945\ttraining's binary_logloss: 0.123988\tvalid_1's auc: 0.81926\tvalid_1's binary_logloss: 0.135999\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006516 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\ttraining's auc: 0.88493\ttraining's binary_logloss: 0.122765\tvalid_1's auc: 0.836665\tvalid_1's binary_logloss: 0.136984\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006044 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13138                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 198                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[37]\ttraining's auc: 0.910551\ttraining's binary_logloss: 0.113206\tvalid_1's auc: 0.837504\tvalid_1's binary_logloss: 0.135061\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006464 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.895969\ttraining's binary_logloss: 0.123629\tvalid_1's auc: 0.820578\tvalid_1's binary_logloss: 0.136656\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005823 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[29]\ttraining's auc: 0.895684\ttraining's binary_logloss: 0.12196\tvalid_1's auc: 0.837558\tvalid_1's binary_logloss: 0.138107\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006698 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[49]\ttraining's auc: 0.918247\ttraining's binary_logloss: 0.112589\tvalid_1's auc: 0.835225\tvalid_1's binary_logloss: 0.135506\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006927 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13058                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[59]\ttraining's auc: 0.880274\ttraining's binary_logloss: 0.127271\tvalid_1's auc: 0.82078\tvalid_1's binary_logloss: 0.136685\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006601 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[83]\ttraining's auc: 0.886607\ttraining's binary_logloss: 0.123076\tvalid_1's auc: 0.839357\tvalid_1's binary_logloss: 0.13665\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007789 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13086                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[46]\ttraining's auc: 0.872188\ttraining's binary_logloss: 0.130662\tvalid_1's auc: 0.836108\tvalid_1's binary_logloss: 0.138941\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007575 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13058                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.909506\ttraining's binary_logloss: 0.11515\tvalid_1's auc: 0.81665\tvalid_1's binary_logloss: 0.136357\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006603 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.889319\ttraining's binary_logloss: 0.123316\tvalid_1's auc: 0.83638\tvalid_1's binary_logloss: 0.138462\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007951 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[29]\ttraining's auc: 0.915599\ttraining's binary_logloss: 0.112605\tvalid_1's auc: 0.834277\tvalid_1's binary_logloss: 0.135951\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006502 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13058                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6]\ttraining's auc: 0.87669\ttraining's binary_logloss: 0.129814\tvalid_1's auc: 0.818713\tvalid_1's binary_logloss: 0.138598\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005539 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's auc: 0.897675\ttraining's binary_logloss: 0.118615\tvalid_1's auc: 0.835066\tvalid_1's binary_logloss: 0.137509\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007854 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13138                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 198                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.924252\ttraining's binary_logloss: 0.107716\tvalid_1's auc: 0.831988\tvalid_1's binary_logloss: 0.136941\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006326 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13058                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[92]\ttraining's auc: 0.892903\ttraining's binary_logloss: 0.121077\tvalid_1's auc: 0.820894\tvalid_1's binary_logloss: 0.135505\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007134 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[74]\ttraining's auc: 0.884643\ttraining's binary_logloss: 0.124213\tvalid_1's auc: 0.839638\tvalid_1's binary_logloss: 0.137048\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006787 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13086                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[99]\ttraining's auc: 0.895537\ttraining's binary_logloss: 0.11998\tvalid_1's auc: 0.836965\tvalid_1's binary_logloss: 0.135396\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007446 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[47]\ttraining's auc: 0.883942\ttraining's binary_logloss: 0.126153\tvalid_1's auc: 0.822927\tvalid_1's binary_logloss: 0.136208\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007542 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[76]\ttraining's auc: 0.895989\ttraining's binary_logloss: 0.119938\tvalid_1's auc: 0.8395\tvalid_1's binary_logloss: 0.136092\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007838 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[96]\ttraining's auc: 0.907285\ttraining's binary_logloss: 0.115949\tvalid_1's auc: 0.83757\tvalid_1's binary_logloss: 0.134883\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006588 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.883246\ttraining's binary_logloss: 0.126774\tvalid_1's auc: 0.821966\tvalid_1's binary_logloss: 0.136477\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007523 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[32]\ttraining's auc: 0.897929\ttraining's binary_logloss: 0.118948\tvalid_1's auc: 0.838023\tvalid_1's binary_logloss: 0.136205\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007500 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's auc: 0.909315\ttraining's binary_logloss: 0.114769\tvalid_1's auc: 0.836746\tvalid_1's binary_logloss: 0.135194\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007399 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\ttraining's auc: 0.883365\ttraining's binary_logloss: 0.126734\tvalid_1's auc: 0.82346\tvalid_1's binary_logloss: 0.136175\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006494 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[70]\ttraining's auc: 0.897111\ttraining's binary_logloss: 0.119585\tvalid_1's auc: 0.840027\tvalid_1's binary_logloss: 0.136001\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007933 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[98]\ttraining's auc: 0.912652\ttraining's binary_logloss: 0.113858\tvalid_1's auc: 0.836812\tvalid_1's binary_logloss: 0.135081\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007612 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[43]\ttraining's auc: 0.885985\ttraining's binary_logloss: 0.125084\tvalid_1's auc: 0.822075\tvalid_1's binary_logloss: 0.136091\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005779 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[66]\ttraining's auc: 0.897296\ttraining's binary_logloss: 0.119432\tvalid_1's auc: 0.839689\tvalid_1's binary_logloss: 0.136024\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006548 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[90]\ttraining's auc: 0.911359\ttraining's binary_logloss: 0.114203\tvalid_1's auc: 0.837349\tvalid_1's binary_logloss: 0.134949\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006593 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\ttraining's auc: 0.884448\ttraining's binary_logloss: 0.125334\tvalid_1's auc: 0.820134\tvalid_1's binary_logloss: 0.13642\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006421 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[34]\ttraining's auc: 0.902761\ttraining's binary_logloss: 0.117207\tvalid_1's auc: 0.838248\tvalid_1's binary_logloss: 0.135998\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007389 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\ttraining's auc: 0.910939\ttraining's binary_logloss: 0.113986\tvalid_1's auc: 0.836222\tvalid_1's binary_logloss: 0.135326\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007518 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's auc: 0.883832\ttraining's binary_logloss: 0.125995\tvalid_1's auc: 0.822648\tvalid_1's binary_logloss: 0.13614\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006416 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[74]\ttraining's auc: 0.900304\ttraining's binary_logloss: 0.118276\tvalid_1's auc: 0.838709\tvalid_1's binary_logloss: 0.136077\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006844 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[87]\ttraining's auc: 0.908218\ttraining's binary_logloss: 0.115183\tvalid_1's auc: 0.837083\tvalid_1's binary_logloss: 0.135151\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007469 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.880383\ttraining's binary_logloss: 0.129692\tvalid_1's auc: 0.822012\tvalid_1's binary_logloss: 0.137427\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007859 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.87551\ttraining's binary_logloss: 0.129561\tvalid_1's auc: 0.838177\tvalid_1's binary_logloss: 0.139688\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007203 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[77]\ttraining's auc: 0.871866\ttraining's binary_logloss: 0.13339\tvalid_1's auc: 0.834822\tvalid_1's binary_logloss: 0.140935\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006535 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16]\ttraining's auc: 0.888143\ttraining's binary_logloss: 0.126152\tvalid_1's auc: 0.820032\tvalid_1's binary_logloss: 0.136971\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008379 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[28]\ttraining's auc: 0.903332\ttraining's binary_logloss: 0.117516\tvalid_1's auc: 0.83864\tvalid_1's binary_logloss: 0.136661\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006250 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\ttraining's auc: 0.919207\ttraining's binary_logloss: 0.111051\tvalid_1's auc: 0.836074\tvalid_1's binary_logloss: 0.135347\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006308 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.866756\ttraining's binary_logloss: 0.133321\tvalid_1's auc: 0.820459\tvalid_1's binary_logloss: 0.138226\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007508 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[99]\ttraining's auc: 0.862714\ttraining's binary_logloss: 0.133265\tvalid_1's auc: 0.838231\tvalid_1's binary_logloss: 0.14064\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007548 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[89]\ttraining's auc: 0.861214\ttraining's binary_logloss: 0.134791\tvalid_1's auc: 0.835595\tvalid_1's binary_logloss: 0.140533\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007473 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\ttraining's auc: 0.881396\ttraining's binary_logloss: 0.127221\tvalid_1's auc: 0.821683\tvalid_1's binary_logloss: 0.136447\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007451 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[65]\ttraining's auc: 0.892259\ttraining's binary_logloss: 0.12108\tvalid_1's auc: 0.83939\tvalid_1's binary_logloss: 0.136175\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006322 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[84]\ttraining's auc: 0.903565\ttraining's binary_logloss: 0.117008\tvalid_1's auc: 0.838271\tvalid_1's binary_logloss: 0.134863\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006476 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's auc: 0.875008\ttraining's binary_logloss: 0.129552\tvalid_1's auc: 0.821163\tvalid_1's binary_logloss: 0.137313\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006418 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[37]\ttraining's auc: 0.894384\ttraining's binary_logloss: 0.119952\tvalid_1's auc: 0.839564\tvalid_1's binary_logloss: 0.136013\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005663 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\ttraining's auc: 0.899157\ttraining's binary_logloss: 0.118112\tvalid_1's auc: 0.837515\tvalid_1's binary_logloss: 0.135182\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006319 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's auc: 0.875678\ttraining's binary_logloss: 0.128943\tvalid_1's auc: 0.820222\tvalid_1's binary_logloss: 0.136917\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007421 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.887663\ttraining's binary_logloss: 0.121882\tvalid_1's auc: 0.837775\tvalid_1's binary_logloss: 0.136558\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007616 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\ttraining's auc: 0.895687\ttraining's binary_logloss: 0.118908\tvalid_1's auc: 0.836676\tvalid_1's binary_logloss: 0.135211\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006126 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\ttraining's auc: 0.903246\ttraining's binary_logloss: 0.117613\tvalid_1's auc: 0.82108\tvalid_1's binary_logloss: 0.135618\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006520 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\ttraining's auc: 0.900103\ttraining's binary_logloss: 0.117815\tvalid_1's auc: 0.83786\tvalid_1's binary_logloss: 0.136427\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006429 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.89961\ttraining's binary_logloss: 0.118822\tvalid_1's auc: 0.834954\tvalid_1's binary_logloss: 0.135859\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007495 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[56]\ttraining's auc: 0.882245\ttraining's binary_logloss: 0.127025\tvalid_1's auc: 0.823045\tvalid_1's binary_logloss: 0.136274\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007653 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[93]\ttraining's auc: 0.894885\ttraining's binary_logloss: 0.120427\tvalid_1's auc: 0.840448\tvalid_1's binary_logloss: 0.136016\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007621 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[100]\ttraining's auc: 0.899693\ttraining's binary_logloss: 0.118907\tvalid_1's auc: 0.837733\tvalid_1's binary_logloss: 0.135141\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006666 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[28]\ttraining's auc: 0.888229\ttraining's binary_logloss: 0.126205\tvalid_1's auc: 0.820266\tvalid_1's binary_logloss: 0.137042\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006606 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\ttraining's auc: 0.895547\ttraining's binary_logloss: 0.121191\tvalid_1's auc: 0.8394\tvalid_1's binary_logloss: 0.136911\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007795 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[66]\ttraining's auc: 0.916644\ttraining's binary_logloss: 0.112645\tvalid_1's auc: 0.836106\tvalid_1's binary_logloss: 0.135172\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007490 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[83]\ttraining's auc: 0.889941\ttraining's binary_logloss: 0.124303\tvalid_1's auc: 0.821779\tvalid_1's binary_logloss: 0.136181\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008023 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[98]\ttraining's auc: 0.892831\ttraining's binary_logloss: 0.122059\tvalid_1's auc: 0.838597\tvalid_1's binary_logloss: 0.137062\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009676 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[52]\ttraining's auc: 0.874881\ttraining's binary_logloss: 0.131179\tvalid_1's auc: 0.835214\tvalid_1's binary_logloss: 0.139884\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006820 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\ttraining's auc: 0.895483\ttraining's binary_logloss: 0.11982\tvalid_1's auc: 0.821034\tvalid_1's binary_logloss: 0.135435\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006939 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's auc: 0.894016\ttraining's binary_logloss: 0.119935\tvalid_1's auc: 0.84004\tvalid_1's binary_logloss: 0.135552\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007871 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[50]\ttraining's auc: 0.902992\ttraining's binary_logloss: 0.116977\tvalid_1's auc: 0.83935\tvalid_1's binary_logloss: 0.134587\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007293 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[44]\ttraining's auc: 0.898267\ttraining's binary_logloss: 0.119075\tvalid_1's auc: 0.822643\tvalid_1's binary_logloss: 0.135083\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006531 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.873395\ttraining's binary_logloss: 0.12772\tvalid_1's auc: 0.839162\tvalid_1's binary_logloss: 0.137756\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007318 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[48]\ttraining's auc: 0.900393\ttraining's binary_logloss: 0.117447\tvalid_1's auc: 0.838163\tvalid_1's binary_logloss: 0.134815\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007755 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\ttraining's auc: 0.897959\ttraining's binary_logloss: 0.118743\tvalid_1's auc: 0.820571\tvalid_1's binary_logloss: 0.135642\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007447 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's auc: 0.892679\ttraining's binary_logloss: 0.120287\tvalid_1's auc: 0.838684\tvalid_1's binary_logloss: 0.136007\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008144 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\ttraining's auc: 0.908839\ttraining's binary_logloss: 0.114084\tvalid_1's auc: 0.836723\tvalid_1's binary_logloss: 0.135449\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005585 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[36]\ttraining's auc: 0.887237\ttraining's binary_logloss: 0.122959\tvalid_1's auc: 0.822486\tvalid_1's binary_logloss: 0.13525\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007273 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[44]\ttraining's auc: 0.891278\ttraining's binary_logloss: 0.120828\tvalid_1's auc: 0.840238\tvalid_1's binary_logloss: 0.135605\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005626 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[75]\ttraining's auc: 0.914174\ttraining's binary_logloss: 0.11237\tvalid_1's auc: 0.838374\tvalid_1's binary_logloss: 0.134826\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008243 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33]\ttraining's auc: 0.88525\ttraining's binary_logloss: 0.124928\tvalid_1's auc: 0.822168\tvalid_1's binary_logloss: 0.135938\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007371 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[50]\ttraining's auc: 0.89545\ttraining's binary_logloss: 0.119683\tvalid_1's auc: 0.838658\tvalid_1's binary_logloss: 0.136242\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007365 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[80]\ttraining's auc: 0.916856\ttraining's binary_logloss: 0.111533\tvalid_1's auc: 0.838735\tvalid_1's binary_logloss: 0.134718\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007414 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.8878\ttraining's binary_logloss: 0.122321\tvalid_1's auc: 0.821514\tvalid_1's binary_logloss: 0.135527\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006299 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[29]\ttraining's auc: 0.888422\ttraining's binary_logloss: 0.121514\tvalid_1's auc: 0.839784\tvalid_1's binary_logloss: 0.135682\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007384 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[32]\ttraining's auc: 0.895107\ttraining's binary_logloss: 0.119536\tvalid_1's auc: 0.838092\tvalid_1's binary_logloss: 0.13504\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006423 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\ttraining's auc: 0.879525\ttraining's binary_logloss: 0.127219\tvalid_1's auc: 0.821513\tvalid_1's binary_logloss: 0.136548\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004791 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's auc: 0.893385\ttraining's binary_logloss: 0.120163\tvalid_1's auc: 0.840387\tvalid_1's binary_logloss: 0.135704\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006518 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[53]\ttraining's auc: 0.903568\ttraining's binary_logloss: 0.116514\tvalid_1's auc: 0.836402\tvalid_1's binary_logloss: 0.135156\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007059 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's auc: 0.907141\ttraining's binary_logloss: 0.11559\tvalid_1's auc: 0.819215\tvalid_1's binary_logloss: 0.135854\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006964 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.890732\ttraining's binary_logloss: 0.120702\tvalid_1's auc: 0.838095\tvalid_1's binary_logloss: 0.136544\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005756 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\ttraining's auc: 0.909998\ttraining's binary_logloss: 0.113893\tvalid_1's auc: 0.8348\tvalid_1's binary_logloss: 0.135805\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008050 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13192                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 206                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's auc: 0.901348\ttraining's binary_logloss: 0.117438\tvalid_1's auc: 0.817778\tvalid_1's binary_logloss: 0.136286\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006966 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13132                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 201                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's auc: 0.876606\ttraining's binary_logloss: 0.126037\tvalid_1's auc: 0.838116\tvalid_1's binary_logloss: 0.137916\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007800 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13222                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 206                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\ttraining's auc: 0.906532\ttraining's binary_logloss: 0.114828\tvalid_1's auc: 0.836518\tvalid_1's binary_logloss: 0.135241\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008468 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.88604\ttraining's binary_logloss: 0.124966\tvalid_1's auc: 0.81818\tvalid_1's binary_logloss: 0.137513\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006429 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.90428\ttraining's binary_logloss: 0.116564\tvalid_1's auc: 0.836364\tvalid_1's binary_logloss: 0.136979\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006518 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\ttraining's auc: 0.909554\ttraining's binary_logloss: 0.114372\tvalid_1's auc: 0.834602\tvalid_1's binary_logloss: 0.136119\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007586 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13058                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[71]\ttraining's auc: 0.904224\ttraining's binary_logloss: 0.116919\tvalid_1's auc: 0.821801\tvalid_1's binary_logloss: 0.13513\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006583 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[55]\ttraining's auc: 0.891791\ttraining's binary_logloss: 0.120973\tvalid_1's auc: 0.83928\tvalid_1's binary_logloss: 0.136176\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007489 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[89]\ttraining's auc: 0.912368\ttraining's binary_logloss: 0.113281\tvalid_1's auc: 0.838651\tvalid_1's binary_logloss: 0.134743\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006311 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.887905\ttraining's binary_logloss: 0.125163\tvalid_1's auc: 0.820858\tvalid_1's binary_logloss: 0.136608\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007726 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's auc: 0.902269\ttraining's binary_logloss: 0.117929\tvalid_1's auc: 0.838662\tvalid_1's binary_logloss: 0.136066\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006887 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[56]\ttraining's auc: 0.915501\ttraining's binary_logloss: 0.112709\tvalid_1's auc: 0.836285\tvalid_1's binary_logloss: 0.135076\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006722 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 196                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.895682\ttraining's binary_logloss: 0.120045\tvalid_1's auc: 0.818762\tvalid_1's binary_logloss: 0.136615\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006480 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13128                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8]\ttraining's auc: 0.88825\ttraining's binary_logloss: 0.12296\tvalid_1's auc: 0.829321\tvalid_1's binary_logloss: 0.140053\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007853 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13147                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 200                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.89708\ttraining's binary_logloss: 0.119657\tvalid_1's auc: 0.832675\tvalid_1's binary_logloss: 0.137626\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007366 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13048                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[97]\ttraining's auc: 0.883154\ttraining's binary_logloss: 0.124714\tvalid_1's auc: 0.822082\tvalid_1's binary_logloss: 0.135518\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008778 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13062                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[58]\ttraining's auc: 0.866016\ttraining's binary_logloss: 0.13097\tvalid_1's auc: 0.838971\tvalid_1's binary_logloss: 0.139205\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007830 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13078                                                                                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 193                          \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[58]\ttraining's auc: 0.868035\ttraining's binary_logloss: 0.130963\tvalid_1's auc: 0.83599\tvalid_1's binary_logloss: 0.13831\n",
      "100%|███████████████████████████████████████████████| 50/50 [01:10<00:00,  1.42s/trial, best loss: -0.8337420409018205]\n",
      "best: {'learning_rate': np.float64(0.025846083637068917), 'max_depth': np.float64(144.0), 'min_child_samples': np.float64(97.0), 'num_leaves': np.float64(42.0), 'subsample': np.float64(0.9126493184291335)}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn=objective_func, \n",
    "            space=lgbm_search_space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=50, \n",
    "            trials=trials, \n",
    "            rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print(f'best: {best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1a4224f0-94f4-4b84-bf9d-89e91a412534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] Number of positive: 1691, number of negative: 40880\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13208\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 193\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039722 -> initscore=-3.185321\n",
      "[LightGBM] [Info] Start training from score -3.185321\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.896602\ttraining's binary_logloss: 0.120582\tvalid_1's auc: 0.834378\tvalid_1's binary_logloss: 0.133806\n",
      "ROC AUC: 0.8396\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=100,\n",
    "                          early_stopping_rounds=100,\n",
    "                          num_leaves = int(best['num_leaves']),\n",
    "                          max_depth=int(best['max_depth']), \n",
    "                          min_child_samples=int(best['min_child_samples']), \n",
    "                          subsample=round(best['subsample'], 5),\n",
    "                          learning_rate=round(best['learning_rate'], 5))\n",
    "\n",
    "eval_set = eval_set=[(X_tr, y_tr), (X_val, y_val)]\n",
    "\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_metric='auc', eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\n",
    "print(f'ROC AUC: {lgbm_roc_score:.4f}')\n",
    "\n",
    "model = 'lgbm_scaled_ft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67c9e5-f6e3-4f8b-9741-a26cc8dd0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': model, 'auc_score': f'{lgbm_roc_score:.4f}'}\n",
    "scores_df.loc[len(scores_df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e1f197b5-1373-455a-9393-0d8e6cbc2668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_ft</td>\n",
       "      <td>0.8393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.8386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.8377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgbm_ft</td>\n",
       "      <td>0.8414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbm_scaled</td>\n",
       "      <td>0.8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgbm_scaled_ft</td>\n",
       "      <td>0.8396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model auc_score\n",
       "0      xgboost_ft    0.8393\n",
       "1         xgboost    0.8386\n",
       "2            lgbm    0.8377\n",
       "3         lgbm_ft    0.8414\n",
       "4     lgbm_scaled    0.8389\n",
       "5  lgbm_scaled_ft    0.8396"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "01c77279-aa0d-475e-9500-4df7bb9549ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_df, y, test_size=0.2, random_state=42)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "050ca80b-beea-4e94-bbb5-9cd6bfa51a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1691, number of negative: 40880\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039722 -> initscore=-3.185321\n",
      "[LightGBM] [Info] Start training from score -3.185321\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's auc: 0.698258\ttraining's binary_logloss: 0.155431\tvalid_1's auc: 0.616868\tvalid_1's binary_logloss: 0.15981\n",
      "ROC AUC: 0.6260\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=500, early_stopping_round=100)\n",
    "\n",
    "eval_set = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_metric='auc', eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\n",
    "print(f'ROC AUC: {lgbm_roc_score:.4f}')\n",
    "\n",
    "model = 'lgbm_pca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "cdbaf46e-06b2-446c-8ad3-4084bf378ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': model, 'auc_score': f'{lgbm_roc_score:.4f}'}\n",
    "scores_df.loc[len(scores_df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c452aa92-c49e-4093-94d4-6c2d7032ac0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001977 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\ttraining's auc: 0.66304\ttraining's binary_logloss: 0.164353\tvalid_1's auc: 0.612616\tvalid_1's binary_logloss: 0.161882\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.684203\ttraining's binary_logloss: 0.160393\tvalid_1's auc: 0.648969\tvalid_1's binary_logloss: 0.163546\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000138 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.663459\ttraining's binary_logloss: 0.160419\tvalid_1's auc: 0.623843\tvalid_1's binary_logloss: 0.164306\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\ttraining's auc: 0.693287\ttraining's binary_logloss: 0.157266\tvalid_1's auc: 0.613971\tvalid_1's binary_logloss: 0.159767\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000139 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.715885\ttraining's binary_logloss: 0.153338\tvalid_1's auc: 0.640135\tvalid_1's binary_logloss: 0.161728\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.697637\ttraining's binary_logloss: 0.153928\tvalid_1's auc: 0.627296\tvalid_1's binary_logloss: 0.162612\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.69345\ttraining's binary_logloss: 0.157301\tvalid_1's auc: 0.613719\tvalid_1's binary_logloss: 0.159603\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\ttraining's auc: 0.693252\ttraining's binary_logloss: 0.158769\tvalid_1's auc: 0.644898\tvalid_1's binary_logloss: 0.162904\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000256 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\ttraining's auc: 0.701898\ttraining's binary_logloss: 0.153135\tvalid_1's auc: 0.623631\tvalid_1's binary_logloss: 0.162525\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000138 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16]\ttraining's auc: 0.700912\ttraining's binary_logloss: 0.15594\tvalid_1's auc: 0.610057\tvalid_1's binary_logloss: 0.15985\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8]\ttraining's auc: 0.701472\ttraining's binary_logloss: 0.157342\tvalid_1's auc: 0.642641\tvalid_1's binary_logloss: 0.162717\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\ttraining's auc: 0.680825\ttraining's binary_logloss: 0.158593\tvalid_1's auc: 0.622297\tvalid_1's binary_logloss: 0.163965\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000134 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's auc: 0.694553\ttraining's binary_logloss: 0.157137\tvalid_1's auc: 0.613046\tvalid_1's binary_logloss: 0.159657\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[35]\ttraining's auc: 0.714472\ttraining's binary_logloss: 0.153609\tvalid_1's auc: 0.639394\tvalid_1's binary_logloss: 0.161882\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's auc: 0.681128\ttraining's binary_logloss: 0.157757\tvalid_1's auc: 0.624834\tvalid_1's binary_logloss: 0.163356\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\ttraining's auc: 0.666273\ttraining's binary_logloss: 0.163128\tvalid_1's auc: 0.613688\tvalid_1's binary_logloss: 0.161267\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[45]\ttraining's auc: 0.687162\ttraining's binary_logloss: 0.159669\tvalid_1's auc: 0.647002\tvalid_1's binary_logloss: 0.163174\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[48]\ttraining's auc: 0.669273\ttraining's binary_logloss: 0.159915\tvalid_1's auc: 0.62294\tvalid_1's binary_logloss: 0.164103\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\ttraining's auc: 0.681797\ttraining's binary_logloss: 0.15784\tvalid_1's auc: 0.614619\tvalid_1's binary_logloss: 0.159631\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000371 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5]\ttraining's auc: 0.686301\ttraining's binary_logloss: 0.159005\tvalid_1's auc: 0.646729\tvalid_1's binary_logloss: 0.162681\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\ttraining's auc: 0.697554\ttraining's binary_logloss: 0.153786\tvalid_1's auc: 0.624936\tvalid_1's binary_logloss: 0.16255\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.697581\ttraining's binary_logloss: 0.156685\tvalid_1's auc: 0.609203\tvalid_1's binary_logloss: 0.160015\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4]\ttraining's auc: 0.69815\ttraining's binary_logloss: 0.158445\tvalid_1's auc: 0.638952\tvalid_1's binary_logloss: 0.163185\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\ttraining's auc: 0.700966\ttraining's binary_logloss: 0.153975\tvalid_1's auc: 0.622366\tvalid_1's binary_logloss: 0.162795\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's auc: 0.683473\ttraining's binary_logloss: 0.15758\tvalid_1's auc: 0.615273\tvalid_1's binary_logloss: 0.159676\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4]\ttraining's auc: 0.680552\ttraining's binary_logloss: 0.160004\tvalid_1's auc: 0.647094\tvalid_1's binary_logloss: 0.16322\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\ttraining's auc: 0.691211\ttraining's binary_logloss: 0.154336\tvalid_1's auc: 0.623982\tvalid_1's binary_logloss: 0.162417\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's auc: 0.691335\ttraining's binary_logloss: 0.15762\tvalid_1's auc: 0.613553\tvalid_1's binary_logloss: 0.159622\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16]\ttraining's auc: 0.701534\ttraining's binary_logloss: 0.156624\tvalid_1's auc: 0.642597\tvalid_1's binary_logloss: 0.162126\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000229 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.692978\ttraining's binary_logloss: 0.155129\tvalid_1's auc: 0.623307\tvalid_1's binary_logloss: 0.162754\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000130 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8]\ttraining's auc: 0.70299\ttraining's binary_logloss: 0.155816\tvalid_1's auc: 0.605852\tvalid_1's binary_logloss: 0.160181\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.720686\ttraining's binary_logloss: 0.152869\tvalid_1's auc: 0.639361\tvalid_1's binary_logloss: 0.161925\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6]\ttraining's auc: 0.693858\ttraining's binary_logloss: 0.155714\tvalid_1's auc: 0.622743\tvalid_1's binary_logloss: 0.163203\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[28]\ttraining's auc: 0.701473\ttraining's binary_logloss: 0.156217\tvalid_1's auc: 0.609858\tvalid_1's binary_logloss: 0.15978\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000138 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's auc: 0.704907\ttraining's binary_logloss: 0.157461\tvalid_1's auc: 0.639925\tvalid_1's binary_logloss: 0.162721\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[32]\ttraining's auc: 0.702161\ttraining's binary_logloss: 0.15387\tvalid_1's auc: 0.622473\tvalid_1's binary_logloss: 0.162743\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\ttraining's auc: 0.688473\ttraining's binary_logloss: 0.158029\tvalid_1's auc: 0.611588\tvalid_1's binary_logloss: 0.16001\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\ttraining's auc: 0.711055\ttraining's binary_logloss: 0.153704\tvalid_1's auc: 0.649848\tvalid_1's binary_logloss: 0.161139\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5]\ttraining's auc: 0.675859\ttraining's binary_logloss: 0.157965\tvalid_1's auc: 0.624403\tvalid_1's binary_logloss: 0.163504\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000133 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.689534\ttraining's binary_logloss: 0.15827\tvalid_1's auc: 0.613807\tvalid_1's binary_logloss: 0.159826\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000449 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.69299\ttraining's binary_logloss: 0.16059\tvalid_1's auc: 0.642898\tvalid_1's binary_logloss: 0.164068\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[30]\ttraining's auc: 0.690469\ttraining's binary_logloss: 0.155866\tvalid_1's auc: 0.623148\tvalid_1's binary_logloss: 0.163041\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000134 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.68534\ttraining's binary_logloss: 0.157594\tvalid_1's auc: 0.613517\tvalid_1's binary_logloss: 0.159642\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[3]\ttraining's auc: 0.675381\ttraining's binary_logloss: 0.1616\tvalid_1's auc: 0.646742\tvalid_1's binary_logloss: 0.164223\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.670637\ttraining's binary_logloss: 0.158088\tvalid_1's auc: 0.626644\tvalid_1's binary_logloss: 0.163223\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's auc: 0.701514\ttraining's binary_logloss: 0.15667\tvalid_1's auc: 0.608956\tvalid_1's binary_logloss: 0.159798\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.707613\ttraining's binary_logloss: 0.156567\tvalid_1's auc: 0.640202\tvalid_1's binary_logloss: 0.162428\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\ttraining's auc: 0.706368\ttraining's binary_logloss: 0.152732\tvalid_1's auc: 0.621742\tvalid_1's binary_logloss: 0.162733\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[36]\ttraining's auc: 0.675686\ttraining's binary_logloss: 0.16033\tvalid_1's auc: 0.613562\tvalid_1's binary_logloss: 0.160139\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000139 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's auc: 0.682594\ttraining's binary_logloss: 0.161888\tvalid_1's auc: 0.647997\tvalid_1's binary_logloss: 0.164656\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[30]\ttraining's auc: 0.67052\ttraining's binary_logloss: 0.159438\tvalid_1's auc: 0.623523\tvalid_1's binary_logloss: 0.163924\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16]\ttraining's auc: 0.697936\ttraining's binary_logloss: 0.156536\tvalid_1's auc: 0.608783\tvalid_1's binary_logloss: 0.159747\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.706808\ttraining's binary_logloss: 0.156542\tvalid_1's auc: 0.642284\tvalid_1's binary_logloss: 0.162255\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's auc: 0.709614\ttraining's binary_logloss: 0.15174\tvalid_1's auc: 0.621608\tvalid_1's binary_logloss: 0.16268\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8]\ttraining's auc: 0.692647\ttraining's binary_logloss: 0.157656\tvalid_1's auc: 0.610986\tvalid_1's binary_logloss: 0.159895\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\ttraining's auc: 0.700217\ttraining's binary_logloss: 0.156172\tvalid_1's auc: 0.642785\tvalid_1's binary_logloss: 0.162008\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.690341\ttraining's binary_logloss: 0.155131\tvalid_1's auc: 0.623346\tvalid_1's binary_logloss: 0.162944\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000257 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[68]\ttraining's auc: 0.687761\ttraining's binary_logloss: 0.157489\tvalid_1's auc: 0.614688\tvalid_1's binary_logloss: 0.159564\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\ttraining's auc: 0.689047\ttraining's binary_logloss: 0.159908\tvalid_1's auc: 0.648313\tvalid_1's binary_logloss: 0.163366\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[37]\ttraining's auc: 0.675117\ttraining's binary_logloss: 0.15852\tvalid_1's auc: 0.625245\tvalid_1's binary_logloss: 0.163533\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000139 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16]\ttraining's auc: 0.688227\ttraining's binary_logloss: 0.158062\tvalid_1's auc: 0.615092\tvalid_1's binary_logloss: 0.159851\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\ttraining's auc: 0.692598\ttraining's binary_logloss: 0.159539\tvalid_1's auc: 0.642358\tvalid_1's binary_logloss: 0.163353\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000137 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's auc: 0.68871\ttraining's binary_logloss: 0.15517\tvalid_1's auc: 0.623898\tvalid_1's binary_logloss: 0.16313\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000138 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's auc: 0.688423\ttraining's binary_logloss: 0.157227\tvalid_1's auc: 0.611478\tvalid_1's binary_logloss: 0.159674\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000364 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5]\ttraining's auc: 0.687284\ttraining's binary_logloss: 0.159464\tvalid_1's auc: 0.645045\tvalid_1's binary_logloss: 0.163156\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000798 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6]\ttraining's auc: 0.669746\ttraining's binary_logloss: 0.159286\tvalid_1's auc: 0.623485\tvalid_1's binary_logloss: 0.164028\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.677722\ttraining's binary_logloss: 0.158411\tvalid_1's auc: 0.611113\tvalid_1's binary_logloss: 0.159591\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[32]\ttraining's auc: 0.7099\ttraining's binary_logloss: 0.153795\tvalid_1's auc: 0.643983\tvalid_1's binary_logloss: 0.161425\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's auc: 0.674608\ttraining's binary_logloss: 0.15708\tvalid_1's auc: 0.625018\tvalid_1's binary_logloss: 0.162808\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.684909\ttraining's binary_logloss: 0.157701\tvalid_1's auc: 0.612336\tvalid_1's binary_logloss: 0.159738\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000550 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4]\ttraining's auc: 0.682005\ttraining's binary_logloss: 0.160747\tvalid_1's auc: 0.645131\tvalid_1's binary_logloss: 0.163794\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16]\ttraining's auc: 0.680897\ttraining's binary_logloss: 0.156016\tvalid_1's auc: 0.626537\tvalid_1's binary_logloss: 0.162604\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.683626\ttraining's binary_logloss: 0.157652\tvalid_1's auc: 0.612264\tvalid_1's binary_logloss: 0.159854\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6]\ttraining's auc: 0.695719\ttraining's binary_logloss: 0.157128\tvalid_1's auc: 0.646049\tvalid_1's binary_logloss: 0.161877\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's auc: 0.693055\ttraining's binary_logloss: 0.154329\tvalid_1's auc: 0.622261\tvalid_1's binary_logloss: 0.16277\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[45]\ttraining's auc: 0.679338\ttraining's binary_logloss: 0.158067\tvalid_1's auc: 0.615496\tvalid_1's binary_logloss: 0.159489\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000133 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\ttraining's auc: 0.683655\ttraining's binary_logloss: 0.159367\tvalid_1's auc: 0.646989\tvalid_1's binary_logloss: 0.162806\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.6672\ttraining's binary_logloss: 0.159311\tvalid_1's auc: 0.623459\tvalid_1's binary_logloss: 0.163811\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\ttraining's auc: 0.689301\ttraining's binary_logloss: 0.157362\tvalid_1's auc: 0.614397\tvalid_1's binary_logloss: 0.159733\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\ttraining's auc: 0.704348\ttraining's binary_logloss: 0.154858\tvalid_1's auc: 0.644585\tvalid_1's binary_logloss: 0.161566\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\ttraining's auc: 0.689581\ttraining's binary_logloss: 0.155205\tvalid_1's auc: 0.624315\tvalid_1's binary_logloss: 0.162812\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000134 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.68033\ttraining's binary_logloss: 0.15848\tvalid_1's auc: 0.615859\tvalid_1's binary_logloss: 0.159909\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.688172\ttraining's binary_logloss: 0.159119\tvalid_1's auc: 0.646218\tvalid_1's binary_logloss: 0.162765\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8]\ttraining's auc: 0.665014\ttraining's binary_logloss: 0.160088\tvalid_1's auc: 0.6272\tvalid_1's binary_logloss: 0.164149\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[99]\ttraining's auc: 0.679306\ttraining's binary_logloss: 0.15913\tvalid_1's auc: 0.615973\tvalid_1's binary_logloss: 0.159737\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000247 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[34]\ttraining's auc: 0.683961\ttraining's binary_logloss: 0.16112\tvalid_1's auc: 0.647496\tvalid_1's binary_logloss: 0.164114\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[48]\ttraining's auc: 0.668465\ttraining's binary_logloss: 0.160353\tvalid_1's auc: 0.625906\tvalid_1's binary_logloss: 0.164347\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.683397\ttraining's binary_logloss: 0.157912\tvalid_1's auc: 0.617902\tvalid_1's binary_logloss: 0.159684\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8]\ttraining's auc: 0.682676\ttraining's binary_logloss: 0.159776\tvalid_1's auc: 0.648123\tvalid_1's binary_logloss: 0.163099\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[34]\ttraining's auc: 0.689219\ttraining's binary_logloss: 0.154257\tvalid_1's auc: 0.625234\tvalid_1's binary_logloss: 0.162539\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[36]\ttraining's auc: 0.679764\ttraining's binary_logloss: 0.158365\tvalid_1's auc: 0.615517\tvalid_1's binary_logloss: 0.159691\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000133 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5]\ttraining's auc: 0.675358\ttraining's binary_logloss: 0.16303\tvalid_1's auc: 0.649471\tvalid_1's binary_logloss: 0.165367\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\ttraining's auc: 0.660307\ttraining's binary_logloss: 0.162411\tvalid_1's auc: 0.624601\tvalid_1's binary_logloss: 0.165539\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[34]\ttraining's auc: 0.682325\ttraining's binary_logloss: 0.158802\tvalid_1's auc: 0.614306\tvalid_1's binary_logloss: 0.159805\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's auc: 0.6873\ttraining's binary_logloss: 0.160214\tvalid_1's auc: 0.647937\tvalid_1's binary_logloss: 0.163476\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\ttraining's auc: 0.66985\ttraining's binary_logloss: 0.159394\tvalid_1's auc: 0.624976\tvalid_1's binary_logloss: 0.163846\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000133 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.688331\ttraining's binary_logloss: 0.157627\tvalid_1's auc: 0.612914\tvalid_1's binary_logloss: 0.159813\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000138 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\ttraining's auc: 0.696904\ttraining's binary_logloss: 0.157596\tvalid_1's auc: 0.645936\tvalid_1's binary_logloss: 0.162374\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's auc: 0.68045\ttraining's binary_logloss: 0.157465\tvalid_1's auc: 0.623688\tvalid_1's binary_logloss: 0.163435\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000179 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.680367\ttraining's binary_logloss: 0.158204\tvalid_1's auc: 0.615918\tvalid_1's binary_logloss: 0.159715\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000137 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.682977\ttraining's binary_logloss: 0.159656\tvalid_1's auc: 0.648405\tvalid_1's binary_logloss: 0.16304\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[36]\ttraining's auc: 0.689032\ttraining's binary_logloss: 0.15444\tvalid_1's auc: 0.624829\tvalid_1's binary_logloss: 0.162448\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000151 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\ttraining's auc: 0.695775\ttraining's binary_logloss: 0.15698\tvalid_1's auc: 0.613225\tvalid_1's binary_logloss: 0.159557\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[29]\ttraining's auc: 0.700387\ttraining's binary_logloss: 0.15653\tvalid_1's auc: 0.644861\tvalid_1's binary_logloss: 0.161949\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\ttraining's auc: 0.67388\ttraining's binary_logloss: 0.159253\tvalid_1's auc: 0.625299\tvalid_1's binary_logloss: 0.163913\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001540 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's auc: 0.68294\ttraining's binary_logloss: 0.158642\tvalid_1's auc: 0.614281\tvalid_1's binary_logloss: 0.159779\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6]\ttraining's auc: 0.686628\ttraining's binary_logloss: 0.159887\tvalid_1's auc: 0.646712\tvalid_1's binary_logloss: 0.163257\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\ttraining's auc: 0.668796\ttraining's binary_logloss: 0.159854\tvalid_1's auc: 0.624549\tvalid_1's binary_logloss: 0.164092\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[87]\ttraining's auc: 0.681444\ttraining's binary_logloss: 0.160052\tvalid_1's auc: 0.613826\tvalid_1's binary_logloss: 0.160132\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000138 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.683395\ttraining's binary_logloss: 0.162725\tvalid_1's auc: 0.64513\tvalid_1's binary_logloss: 0.165285\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[83]\ttraining's auc: 0.675528\ttraining's binary_logloss: 0.158609\tvalid_1's auc: 0.625226\tvalid_1's binary_logloss: 0.163673\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000245 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[50]\ttraining's auc: 0.698463\ttraining's binary_logloss: 0.156815\tvalid_1's auc: 0.612967\tvalid_1's binary_logloss: 0.159703\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000133 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\ttraining's auc: 0.696569\ttraining's binary_logloss: 0.160472\tvalid_1's auc: 0.641365\tvalid_1's binary_logloss: 0.164116\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\ttraining's auc: 0.682482\ttraining's binary_logloss: 0.158807\tvalid_1's auc: 0.622542\tvalid_1's binary_logloss: 0.163985\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\ttraining's auc: 0.68456\ttraining's binary_logloss: 0.157809\tvalid_1's auc: 0.612339\tvalid_1's binary_logloss: 0.159619\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000138 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[3]\ttraining's auc: 0.679698\ttraining's binary_logloss: 0.161053\tvalid_1's auc: 0.645228\tvalid_1's binary_logloss: 0.164002\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\ttraining's auc: 0.692969\ttraining's binary_logloss: 0.153662\tvalid_1's auc: 0.62708\tvalid_1's binary_logloss: 0.162411\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27]\ttraining's auc: 0.690403\ttraining's binary_logloss: 0.157792\tvalid_1's auc: 0.615092\tvalid_1's binary_logloss: 0.15975\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000138 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8]\ttraining's auc: 0.691595\ttraining's binary_logloss: 0.160797\tvalid_1's auc: 0.644707\tvalid_1's binary_logloss: 0.164078\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000149 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.681482\ttraining's binary_logloss: 0.157075\tvalid_1's auc: 0.625604\tvalid_1's binary_logloss: 0.163355\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.68232\ttraining's binary_logloss: 0.158026\tvalid_1's auc: 0.613162\tvalid_1's binary_logloss: 0.159637\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000504 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\ttraining's auc: 0.681444\ttraining's binary_logloss: 0.160872\tvalid_1's auc: 0.645942\tvalid_1's binary_logloss: 0.163878\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.664401\ttraining's binary_logloss: 0.160486\tvalid_1's auc: 0.625005\tvalid_1's binary_logloss: 0.164323\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.686959\ttraining's binary_logloss: 0.1577\tvalid_1's auc: 0.614449\tvalid_1's binary_logloss: 0.15978\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001661 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\ttraining's auc: 0.689894\ttraining's binary_logloss: 0.159324\tvalid_1's auc: 0.646844\tvalid_1's binary_logloss: 0.162939\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\ttraining's auc: 0.686287\ttraining's binary_logloss: 0.155545\tvalid_1's auc: 0.625751\tvalid_1's binary_logloss: 0.162736\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000133 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's auc: 0.683891\ttraining's binary_logloss: 0.157557\tvalid_1's auc: 0.612\tvalid_1's binary_logloss: 0.159863\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4]\ttraining's auc: 0.680408\ttraining's binary_logloss: 0.161055\tvalid_1's auc: 0.649152\tvalid_1's binary_logloss: 0.163934\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8]\ttraining's auc: 0.670152\ttraining's binary_logloss: 0.158919\tvalid_1's auc: 0.626894\tvalid_1's binary_logloss: 0.163646\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000137 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15]\ttraining's auc: 0.687612\ttraining's binary_logloss: 0.15805\tvalid_1's auc: 0.614158\tvalid_1's binary_logloss: 0.159702\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13]\ttraining's auc: 0.697667\ttraining's binary_logloss: 0.156489\tvalid_1's auc: 0.644969\tvalid_1's binary_logloss: 0.16188\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000146 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.692685\ttraining's binary_logloss: 0.154824\tvalid_1's auc: 0.623845\tvalid_1's binary_logloss: 0.162619\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\ttraining's auc: 0.70215\ttraining's binary_logloss: 0.15673\tvalid_1's auc: 0.609872\tvalid_1's binary_logloss: 0.159701\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22]\ttraining's auc: 0.714717\ttraining's binary_logloss: 0.155057\tvalid_1's auc: 0.63888\tvalid_1's binary_logloss: 0.162078\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[32]\ttraining's auc: 0.704358\ttraining's binary_logloss: 0.15354\tvalid_1's auc: 0.622016\tvalid_1's binary_logloss: 0.162808\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000138 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[34]\ttraining's auc: 0.692783\ttraining's binary_logloss: 0.157117\tvalid_1's auc: 0.611758\tvalid_1's binary_logloss: 0.159663\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.70592\ttraining's binary_logloss: 0.156171\tvalid_1's auc: 0.642221\tvalid_1's binary_logloss: 0.162112\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000854 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\ttraining's auc: 0.685866\ttraining's binary_logloss: 0.156835\tvalid_1's auc: 0.622458\tvalid_1's binary_logloss: 0.163202\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\ttraining's auc: 0.687129\ttraining's binary_logloss: 0.157849\tvalid_1's auc: 0.61262\tvalid_1's binary_logloss: 0.159878\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5]\ttraining's auc: 0.68945\ttraining's binary_logloss: 0.159283\tvalid_1's auc: 0.645691\tvalid_1's binary_logloss: 0.162977\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\ttraining's auc: 0.681336\ttraining's binary_logloss: 0.156127\tvalid_1's auc: 0.621599\tvalid_1's binary_logloss: 0.163021\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[66]\ttraining's auc: 0.693736\ttraining's binary_logloss: 0.157838\tvalid_1's auc: 0.612277\tvalid_1's binary_logloss: 0.159872\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000138 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[30]\ttraining's auc: 0.698386\ttraining's binary_logloss: 0.159279\tvalid_1's auc: 0.642342\tvalid_1's binary_logloss: 0.163441\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Did not meet early stopping. Best iteration is:                                                                        \n",
      "[75]\ttraining's auc: 0.69352\ttraining's binary_logloss: 0.155592\tvalid_1's auc: 0.622015\tvalid_1's binary_logloss: 0.163066\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000334 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[39]\ttraining's auc: 0.6972\ttraining's binary_logloss: 0.157613\tvalid_1's auc: 0.613668\tvalid_1's binary_logloss: 0.159787\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000820 seconds.                \n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17]\ttraining's auc: 0.702029\ttraining's binary_logloss: 0.159361\tvalid_1's auc: 0.640895\tvalid_1's binary_logloss: 0.163617\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[62]\ttraining's auc: 0.704681\ttraining's binary_logloss: 0.153369\tvalid_1's auc: 0.621301\tvalid_1's binary_logloss: 0.162851\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1617, number of negative: 38927                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039883 -> initscore=-3.181116                                        \n",
      "[LightGBM] [Info] Start training from score -3.181116                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33]\ttraining's auc: 0.682406\ttraining's binary_logloss: 0.157809\tvalid_1's auc: 0.614032\tvalid_1's binary_logloss: 0.159618\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1593, number of negative: 38951                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039291 -> initscore=-3.196685                                        \n",
      "[LightGBM] [Info] Start training from score -3.196685                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\ttraining's auc: 0.678926\ttraining's binary_logloss: 0.161516\tvalid_1's auc: 0.647714\tvalid_1's binary_logloss: 0.164236\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] Number of positive: 1592, number of negative: 38952                                                  \n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000144 seconds.                \n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275                                                                                      \n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 5                            \n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039266 -> initscore=-3.197339                                        \n",
      "[LightGBM] [Info] Start training from score -3.197339                                                                  \n",
      "Training until validation scores don't improve for 30 rounds                                                           \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\ttraining's auc: 0.684745\ttraining's binary_logloss: 0.155358\tvalid_1's auc: 0.62458\tvalid_1's binary_logloss: 0.162507\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:19<00:00,  2.51trial/s, best loss: -0.6304197906466585]\n",
      "best: {'learning_rate': np.float64(0.07586823592074275), 'max_depth': np.float64(138.0), 'min_child_samples': np.float64(61.0), 'num_leaves': np.float64(32.0), 'subsample': np.float64(0.8549719636086978)}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(fn=objective_func, \n",
    "            space=lgbm_search_space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=50, \n",
    "            trials=trials, \n",
    "            rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print(f'best: {best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "37a047d7-7877-4301-9479-9bf68ca90a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] Number of positive: 1691, number of negative: 40880\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 5\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039722 -> initscore=-3.185321\n",
      "[LightGBM] [Info] Start training from score -3.185321\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[48]\ttraining's auc: 0.703319\ttraining's binary_logloss: 0.154396\tvalid_1's auc: 0.616077\tvalid_1's binary_logloss: 0.160117\n",
      "ROC AUC: 0.6215\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=100,\n",
    "                          early_stopping_rounds=100,\n",
    "                          num_leaves = int(best['num_leaves']),\n",
    "                          max_depth=int(best['max_depth']), \n",
    "                          min_child_samples=int(best['min_child_samples']), \n",
    "                          subsample=round(best['subsample'], 5),\n",
    "                          learning_rate=round(best['learning_rate'], 5))\n",
    "\n",
    "eval_set = eval_set=[(X_tr, y_tr), (X_val, y_val)]\n",
    "\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_metric='auc', eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\n",
    "print(f'ROC AUC: {lgbm_roc_score:.4f}')\n",
    "\n",
    "model = 'lgbm_pca_ft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "14681e8c-dd31-443a-9502-2060a2c90662",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'model': model, 'auc_score': f'{lgbm_roc_score:.4f}'}\n",
    "scores_df.loc[len(scores_df)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1268a881-389f-47f2-a0fe-f81f73ae5049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost_ft</td>\n",
       "      <td>0.8393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.8386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgbm</td>\n",
       "      <td>0.8377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgbm_ft</td>\n",
       "      <td>0.8414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgbm_scaled</td>\n",
       "      <td>0.8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgbm_scaled_ft</td>\n",
       "      <td>0.8396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgbm_pca</td>\n",
       "      <td>0.6260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lgbm_pca_ft</td>\n",
       "      <td>0.6215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model auc_score\n",
       "0      xgboost_ft    0.8393\n",
       "1         xgboost    0.8386\n",
       "2            lgbm    0.8377\n",
       "3         lgbm_ft    0.8414\n",
       "4     lgbm_scaled    0.8389\n",
       "5  lgbm_scaled_ft    0.8396\n",
       "6        lgbm_pca    0.6260\n",
       "7     lgbm_pca_ft    0.6215"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
